{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzsbbe12_bPz"
      },
      "source": [
        "# Finetuned GPT-4o-mini"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x885odBj5Ilc"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "OxbHh80-_XaE",
        "outputId": "176af8cf-bd32-4c64-9eb8-ba6a3d09e178"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
            "Collecting openai\n",
            "  Downloading openai-1.55.3-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.9.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
            "Downloading openai-1.55.3-py3-none-any.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.54.4\n",
            "    Uninstalling openai-1.54.4:\n",
            "      Successfully uninstalled openai-1.54.4\n",
            "Successfully installed openai-1.55.3\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxKJgwWE_eWh"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import json\n",
        "import os\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, f1_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6yMhZPAx56a",
        "outputId": "5928b6e2-d23d-4dbd-d3d1-70e41d0c6251"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting github-clone\n",
            "  Downloading github_clone-1.2.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from github-clone) (2.32.3)\n",
            "Collecting docopt>=0.6.2 (from github-clone)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->github-clone) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->github-clone) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->github-clone) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20.0->github-clone) (2024.8.30)\n",
            "Downloading github_clone-1.2.0-py3-none-any.whl (9.1 kB)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=8a33219692b8e18eca28dbc6f76484569b2afe6edc7c15d6685118f607d9e87a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built docopt\n",
            "Installing collected packages: docopt, github-clone\n",
            "Successfully installed docopt-0.6.2 github-clone-1.2.0\n",
            "Cloning into 'data'...\n",
            "done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(\"data\"):\n",
        "  !pip install github-clone\n",
        "  !ghclone https://github.com/yiw008/nondet-project/tree/main/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZjHL_5oDdOD"
      },
      "outputs": [],
      "source": [
        "def str_to_bool(string):\n",
        "  if string == \"True\":\n",
        "    return True\n",
        "  elif string == \"False\":\n",
        "    return False\n",
        "  return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmQl17p7_l6F"
      },
      "outputs": [],
      "source": [
        "api_key = \"\" # TODO\n",
        "os.environ['OPENAI_API_KEY'] = api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S88BK4IN_mPB"
      },
      "outputs": [],
      "source": [
        "client = OpenAI()\n",
        "our_model = \"gpt-4o-mini-2024-07-18\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndlH4nrsyev9"
      },
      "outputs": [],
      "source": [
        "def test_project(project_name):\n",
        "  print(f\"Test project: {project_name}\")\n",
        "  test_set = []\n",
        "  y_test = []\n",
        "  with open(f\"data/{project_name}/test_set.jsonl\", \"r\") as file:\n",
        "    for line in file:\n",
        "      data = json.loads(line)\n",
        "      test_set.append(data['messages'])\n",
        "      y_test.append(str_to_bool(data['messages'][2]['content']))\n",
        "\n",
        "  training_response = client.files.create(\n",
        "    file=open(f\"data/{project_name}/training_set.jsonl\", \"rb\"),\n",
        "    purpose=\"fine-tune\"\n",
        "  )\n",
        "  training_file_id = training_response.id\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  fine_tuning_job_response = client.fine_tuning.jobs.create(\n",
        "    training_file=training_file_id,\n",
        "    model=our_model\n",
        "  )\n",
        "\n",
        "  fine_tuning_job_id = fine_tuning_job_response.id\n",
        "  print(f\"Fine tuning job ID: {fine_tuning_job_id}\")\n",
        "\n",
        "  status = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
        "  while status.status not in [\"succeeded\", \"failed\"]:\n",
        "    time.sleep(1)\n",
        "    status = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
        "\n",
        "  end = time.time()\n",
        "  print(f\"Finetuning time (Not accurate): {end - start:.4f} seconds\")\n",
        "\n",
        "  status = client.fine_tuning.jobs.retrieve(fine_tuning_job_id)\n",
        "  print(f\"Status: {status}\")\n",
        "  print(f\"Created at: {status.created_at}\")\n",
        "  print(f\"Finished at: {status.finished_at}\")\n",
        "  print(f\"Duration: {status.finished_at - status.created_at}\")\n",
        "  print(f\"Hyperparams: {status.hyperparameters}\")\n",
        "\n",
        "  fine_tuned_model = status.fine_tuned_model\n",
        "\n",
        "  y_pred = []\n",
        "  start = time.time()\n",
        "\n",
        "  for i in range(len(test_set)):\n",
        "    completion = client.chat.completions.create(\n",
        "      model=fine_tuned_model,\n",
        "      messages=test_set[i]\n",
        "    )\n",
        "    y_pred.append(str_to_bool(completion.choices[0].message.content))\n",
        "\n",
        "  end = time.time()\n",
        "  print(f\"Testing time: {end - start:.4f} seconds\")\n",
        "\n",
        "  print(\"Y_test:\")\n",
        "  print(y_test)\n",
        "  print(\"Y_pred:\")\n",
        "  print(y_pred)\n",
        "\n",
        "  confusion_matrix_res = confusion_matrix(y_test, y_pred, labels=[False, True])\n",
        "  print(\"Confusion Matrix:\")\n",
        "  print(confusion_matrix_res)\n",
        "\n",
        "  accuracy = accuracy_score(y_test, y_pred)\n",
        "  print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "  precision = precision_score(y_test, y_pred)\n",
        "  print(f\"Precision: {precision}\")\n",
        "\n",
        "  f1 = f1_score(y_test, y_pred)\n",
        "  print(f\"F1 Score: {f1}\")\n",
        "\n",
        "  recall = recall_score(y_test, y_pred)\n",
        "  print(f\"Recall: {recall}\")\n",
        "\n",
        "  return accuracy, precision, f1, recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bvbWdun4CHc"
      },
      "source": [
        "## Let's Go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jWPZboR4dHAA"
      },
      "outputs": [],
      "source": [
        "accuracy_values = [0] * 10\n",
        "precision_values = [0] * 10\n",
        "f1_values = [0] * 10\n",
        "recall_values = [0] * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2k2gEam2hHt",
        "outputId": "574d4b77-ccbb-4f37-ec06-73f4e1d6a7a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: Butter.MAS.PythonAPI\n",
            "Fine tuning job ID: ftjob-4Dg1JGruBlQ4p3KxatexyZeB\n",
            "Finetuning time (Not accurate): 1850.7017 seconds\n",
            "Status: FineTuningJob(id='ftjob-4Dg1JGruBlQ4p3KxatexyZeB', created_at=1733078102, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZjYG09H', finished_at=1733079942, hyperparameters=Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-RzexZcTTiUsisxki2oT3X9'], seed=34039770, status='succeeded', trained_tokens=955854, training_file='file-2dKWa7AhcZWTV5DbskQFkt', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733078102\n",
            "Finished at: 1733079942\n",
            "Duration: 1840\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8)\n",
            "Testing time: 42.2603 seconds\n",
            "Y_test:\n",
            "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, False, True, False, False, False, True, True, False, True, True, True, False, False, True, False]\n",
            "Y_pred:\n",
            "[True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, False, False, True, True, True, False, True, False, True, False, False, True, True]\n",
            "Confusion Matrix:\n",
            "[[ 7  4]\n",
            " [ 4 49]]\n",
            "Accuracy: 0.875\n",
            "Precision: 0.9245283018867925\n",
            "F1 Score: 0.9245283018867925\n",
            "Recall: 0.9245283018867925\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[0], precision_values[0], f1_values[0], recall_values[0] = test_project(\"Butter.MAS.PythonAPI\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZwsonFFdK0L",
        "outputId": "c82ef43c-b785-40a8-9a49-a7ba4f212ea9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: flask-multi-redis\n",
            "Fine tuning job ID: ftjob-u6vyXFAuZCSuSLgqouKe17GM\n",
            "Finetuning time (Not accurate): 1829.4719 seconds\n",
            "Status: FineTuningJob(id='ftjob-u6vyXFAuZCSuSLgqouKe17GM', created_at=1733079995, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZk2TydM', finished_at=1733081815, hyperparameters=Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-Dc2HyvQX9Fm3hZYb6nwJ7m'], seed=830087391, status='succeeded', trained_tokens=931974, training_file='file-5eMPgzutVXxPS7ftqdEN7M', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733079995\n",
            "Finished at: 1733081815\n",
            "Duration: 1820\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8)\n",
            "Testing time: 17.4228 seconds\n",
            "Y_test:\n",
            "[True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True, False, False, False, True, True, True, True, False, True, True, True, True, False, True, True, True, True]\n",
            "Y_pred:\n",
            "[True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
            "Confusion Matrix:\n",
            "[[ 4  3]\n",
            " [ 0 26]]\n",
            "Accuracy: 0.9090909090909091\n",
            "Precision: 0.896551724137931\n",
            "F1 Score: 0.9454545454545454\n",
            "Recall: 1.0\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[1], precision_values[1], f1_values[1], recall_values[1] = test_project(\"flask-multi-redis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "onZormhr2lVw",
        "outputId": "fed55cdd-18e1-4476-cfbd-4c07836f53be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: centreon-sdk-python\n",
            "Fine tuning job ID: ftjob-ew8Lh0ZSfKqP5LJewfYNxYzB\n",
            "Finetuning time (Not accurate): 2165.0766 seconds\n",
            "Status: FineTuningJob(id='ftjob-ew8Lh0ZSfKqP5LJewfYNxYzB', created_at=1733082667, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZkoyEAY', finished_at=1733084822, hyperparameters=Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-2GZKX635cHfUzbxF3VUkgH'], seed=747279891, status='succeeded', trained_tokens=924984, training_file='file-XYPPMb7DSRGPa2n1beAhHD', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733082667\n",
            "Finished at: 1733084822\n",
            "Duration: 2155\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8)\n",
            "Testing time: 32.8394 seconds\n",
            "Y_test:\n",
            "[True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
            "Y_pred:\n",
            "[True, True, True, True, True, False, False, True, True, True, True, False, True, False, True, False, True, True, True, False, True, True, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, False, True, True, True, True]\n",
            "Confusion Matrix:\n",
            "[[ 1  0]\n",
            " [ 8 33]]\n",
            "Accuracy: 0.8095238095238095\n",
            "Precision: 1.0\n",
            "F1 Score: 0.8918918918918919\n",
            "Recall: 0.8048780487804879\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[2], precision_values[2], f1_values[2], recall_values[2] = test_project(\"centreon-sdk-python\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJxoyNrf2yHC",
        "outputId": "3c24efa1-bcf0-4ecd-d371-dec3f71c4e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: cloudnetpy\n",
            "Fine tuning job ID: ftjob-vw5DnAiZ5NeG6RpHp28CKlpI\n",
            "Finetuning time (Not accurate): 2224.4830 seconds\n",
            "Status: FineTuningJob(id='ftjob-vw5DnAiZ5NeG6RpHp28CKlpI', created_at=1733084876, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZlPZh7b', finished_at=1733087091, hyperparameters=Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-MJDJjTbzs2ubomg1h6B2cN'], seed=1951613179, status='succeeded', trained_tokens=731553, training_file='file-EmNLGfxNf3NSTG4d5M9gMr', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733084876\n",
            "Finished at: 1733087091\n",
            "Duration: 2215\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=1.8)\n",
            "Testing time: 166.4945 seconds\n",
            "Y_test:\n",
            "[False, True, True, True, True, True, False, True, True, False, False, False, False, False, True, False, False, False, True, True, False, False, True, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False, False, True, True, False, False, False, False, True, True, False, True, False, False, False, False, False, True, False, False, False, False, True, True, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, True, False, False, False, False, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, True, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False]\n",
            "Y_pred:\n",
            "[False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
            "Confusion Matrix:\n",
            "[[231  15]\n",
            " [ 51   0]]\n",
            "Accuracy: 0.7777777777777778\n",
            "Precision: 0.0\n",
            "F1 Score: 0.0\n",
            "Recall: 0.0\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[3], precision_values[3], f1_values[3], recall_values[3] = test_project(\"cloudnetpy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2s4iQym20jO",
        "outputId": "66db03d4-577a-41ff-a463-f3bb4a9ab821"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: crom\n",
            "Fine tuning job ID: ftjob-J40zkeN7RF41v4DMaFp7xxr7\n",
            "Finetuning time (Not accurate): 1770.5959 seconds\n",
            "Status: FineTuningJob(id='ftjob-J40zkeN7RF41v4DMaFp7xxr7', created_at=1733087268, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZlupLkK', finished_at=1733089030, hyperparameters=Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-4LjU7WC6mqEJaXxsX7Revn'], seed=1290515692, status='succeeded', trained_tokens=883272, training_file='file-Gpbyuowr1DEy3v1GYX8Zaq', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733087268\n",
            "Finished at: 1733089030\n",
            "Duration: 1762\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8)\n",
            "Testing time: 63.8474 seconds\n",
            "Y_test:\n",
            "[True, False, False, False, True, False, True, False, True, False, True, False, False, False, True, False, False, True, True, False, True, False, False, False, True, True, False, False, True, True, False, False, False, True, True, False, True, True, True, False, True, False, True, False, True, True, False, False, True, True, False, False, False, True, True, False, False, True, True, False, False, False, True, False, False, True, False, False, False, False, False, False, False, True, True, True, False, True, True, True, False, True, False, True]\n",
            "Y_pred:\n",
            "[False, False, False, False, False, False, True, False, True, True, False, False, False, False, False, False, True, True, False, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, True, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, True, True, True, False, True, False, False, False, False, True]\n",
            "Confusion Matrix:\n",
            "[[40  6]\n",
            " [26 12]]\n",
            "Accuracy: 0.6190476190476191\n",
            "Precision: 0.6666666666666666\n",
            "F1 Score: 0.42857142857142855\n",
            "Recall: 0.3157894736842105\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[4], precision_values[4], f1_values[4], recall_values[4] = test_project(\"crom\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "x4qlFACs22V8",
        "outputId": "654a8981-5c07-48f2-c3fc-3d2869b0365c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: easypy\n",
            "Fine tuning job ID: ftjob-WnfNYDlmzVlscUGNQSAWTaAX\n",
            "Finetuning time (Not accurate): 2103.1076 seconds\n",
            "Status: FineTuningJob(id='ftjob-WnfNYDlmzVlscUGNQSAWTaAX', created_at=1733089103, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZmTmWcd', finished_at=1733091197, hyperparameters=Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-JDQsokcAR8Qdo4K1CxQsuF'], seed=703816759, status='succeeded', trained_tokens=865029, training_file='file-GytEmcBM3GayZGmQkQmzg8', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733089103\n",
            "Finished at: 1733091197\n",
            "Duration: 2094\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=1.8)\n",
            "Testing time: 104.6540 seconds\n",
            "Y_test:\n",
            "[False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, True, True, True, False, False, True, False, True, False, False, True, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, True, False, False, False, True, True, False, True, True, False, False, True, True, False, False, False, True, True, False, False, False, True, False, False, False, True, False, False, False, True, True, False, False, False, True, False, False, False, False, False, False, True, False, False, False, True, False, False, True, False, True, False, False, False, False, True, False, False, False, False, False, False, True, False, True, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, True, True, False, True, False, False, False, True, True, False, True, True, False, True, False, False, False, False, False, False, False, False, False]\n",
            "Y_pred:\n",
            "[False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, True, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, False, True, False, False, False, False, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, True, False, False, False, False, False, False, False, False, False, False, True]\n",
            "Confusion Matrix:\n",
            "[[123   7]\n",
            " [ 32  12]]\n",
            "Accuracy: 0.7758620689655172\n",
            "Precision: 0.631578947368421\n",
            "F1 Score: 0.38095238095238093\n",
            "Recall: 0.2727272727272727\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[5], precision_values[5], f1_values[5], recall_values[5] = test_project(\"easypy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kBB_nmRz24BR",
        "outputId": "9e2c7582-dcd3-4bde-db4c-f172af377628"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: eppy\n",
            "Fine tuning job ID: ftjob-YiVwOhwYEMbdsglZDXHr94YF\n",
            "Finetuning time (Not accurate): 2517.8165 seconds\n",
            "Status: FineTuningJob(id='ftjob-YiVwOhwYEMbdsglZDXHr94YF', created_at=1733091312, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZnA6FH4', finished_at=1733093820, hyperparameters=Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-7PdiaqxsYvRuWR79xoVwXk'], seed=157843580, status='succeeded', trained_tokens=730995, training_file='file-4dmXovt7pYuCF5ywKCNXui', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733091312\n",
            "Finished at: 1733093820\n",
            "Duration: 2508\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=3, learning_rate_multiplier=1.8)\n",
            "Testing time: 131.5819 seconds\n",
            "Y_test:\n",
            "[True, True, False, True, False, True, False, True, False, False, False, True, False, False, True, False, False, True, False, True, True, False, False, False, False, False, True, False, False, False, True, False, False, True, True, True, True, True, False, False, False, True, True, True, False, False, False, True, False, False, True, True, False, False, True, True, False, True, True, False, True, True, False, False, False, False, False, False, True, True, True, False, True, False, True, False, False, False, True, True, False, False, True, False, True, False, False, True, False, True, False, True, False, False, False, True, True, False, True, False, True, True, True, False, False, False, False, False, True, False, True, True, False, True, True, False, False, False, True, True, True, False, True, False, False, True, True, False, False, False, False, False, False, False, False, True, False, False, False, False, True, True, True, True, False, True, True, False, True, False, True, False, False, False, True, True, False, True, False, False, False, False, False, False, False, True, True, True, False, False, False, False, True, True, True, True, False, True, True, False, False, False, False, True, True, False, False, False, False, False, False, True, True, True]\n",
            "Y_pred:\n",
            "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
            "Confusion Matrix:\n",
            "[[107   3]\n",
            " [ 84   0]]\n",
            "Accuracy: 0.5515463917525774\n",
            "Precision: 0.0\n",
            "F1 Score: 0.0\n",
            "Recall: 0.0\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[6], precision_values[6], f1_values[6], recall_values[6] = test_project(\"eppy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OtX5wqqXdTju",
        "outputId": "4ad07410-ada0-4bdb-937a-adfb97aca622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: pykicad\n",
            "Fine tuning job ID: ftjob-qiKJ3caQLZP0aeKTV81Qg9Ag\n",
            "Finetuning time (Not accurate): 2092.6796 seconds\n",
            "Status: FineTuningJob(id='ftjob-qiKJ3caQLZP0aeKTV81Qg9Ag', created_at=1733093962, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZnk0XJA', finished_at=1733096046, hyperparameters=Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-YBYFzgwFpS1DZWqJ4TZDrZ'], seed=699512230, status='succeeded', trained_tokens=931356, training_file='file-RXbHo7vrtxuWg9MeRN9ZC9', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733093962\n",
            "Finished at: 1733096046\n",
            "Duration: 2084\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8)\n",
            "Testing time: 45.3176 seconds\n",
            "Y_test:\n",
            "[False, False, False, True, False, True, True, True, False, True, True, False, True, True, False, False, False, False, True, True, True, True, True, True, False, True, False, True, False, False, True, True, True, False, False, False, True, True, True, False, True, True, True, True, True, True, False, False]\n",
            "Y_pred:\n",
            "[False, False, True, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, True, True, False, False, False, False, True, False, False, False, True, False, False, True, False, False, True]\n",
            "Confusion Matrix:\n",
            "[[18  2]\n",
            " [19  9]]\n",
            "Accuracy: 0.5625\n",
            "Precision: 0.8181818181818182\n",
            "F1 Score: 0.46153846153846156\n",
            "Recall: 0.32142857142857145\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[7], precision_values[7], f1_values[7], recall_values[7] = test_project(\"pykicad\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yGR4iPBS25sS",
        "outputId": "079915c1-b73b-47f6-c470-adb747438d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: reframe\n",
            "Fine tuning job ID: ftjob-PjdkNOHxi6qWo3zbFZTwecjR\n",
            "Finetuning time (Not accurate): 2401.8701 seconds\n",
            "Status: FineTuningJob(id='ftjob-PjdkNOHxi6qWo3zbFZTwecjR', created_at=1733096102, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZoNUgRR', finished_at=1733098495, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-BCoSCnu7yinWHpYWPurqQR'], seed=1159480762, status='succeeded', trained_tokens=565647, training_file='file-WbdJvTLwPz3HawXW9JKxPt', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733096102\n",
            "Finished at: 1733098495\n",
            "Duration: 2393\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8)\n",
            "Testing time: 325.7708 seconds\n",
            "Y_test:\n",
            "[False, True, False, False, False, False, True, False, True, False, False, False, False, False, False, False, True, True, False, True, False, False, False, False, False, False, False, False, True, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, True, False, True, False, False, False, False, False, False, False, True, False, True, True, False, False, False, False, False, True, True, True, True, True, False, False, False, False, False, False, False, False, False, True, False, True, False, True, False, True, False, True, True, True, False, False, False, False, False, False, False, False, False, False, False, True, True, False, True, False, False, False, False, False, True, False, True, False, False, False, True, False, True, True, False, False, False, False, True, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, False, False, True, False, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, True, True, False, True, True, False, True, False, False, False, True, True, False, False, True, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, True, False, True, False, False, True, False, False, False, False, True, True, False, False, False, True, True, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, True, True, False, False, False, True, True, True, False, True, True, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, True, False, False, False, False, False, True, True, False, True, False, True, False, True, True, False, False, False, True, False, False, False, True, False, False, True, False, False, True, False, False, True, False, False, True, True, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, True, False, False, False, False, True, True, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, True, False, False, False, False, True, False, False, True, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, True, False, False, False, False, False, False, False, True, False, True, False, False, False, False, True, False, False, True, False, False, True, False, False, False, False, True, False, False, False, True, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, True, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False]\n",
            "Y_pred:\n",
            "[False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, False, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
            "Confusion Matrix:\n",
            "[[456   9]\n",
            " [124  12]]\n",
            "Accuracy: 0.778702163061564\n",
            "Precision: 0.5714285714285714\n",
            "F1 Score: 0.15286624203821655\n",
            "Recall: 0.08823529411764706\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[8], precision_values[8], f1_values[8], recall_values[8] = test_project(\"reframe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PWNGsC6d29KH",
        "outputId": "e07eb294-c7d5-4058-81d1-c0057461f6b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test project: webssh\n",
            "Fine tuning job ID: ftjob-fSiFSdGrQOp8APi7udxENgmY\n",
            "Finetuning time (Not accurate): 2034.3964 seconds\n",
            "Status: FineTuningJob(id='ftjob-fSiFSdGrQOp8APi7udxENgmY', created_at=1733098830, error=Error(code=None, message=None, param=None), fine_tuned_model='ft:gpt-4o-mini-2024-07-18:personal::AZozaUZf', finished_at=1733100856, hyperparameters=Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-tI0WpKootnbW2KXQbHxLn75u', result_files=['file-Ao2ASjucmsz8chy3BSkgMb'], seed=1044403182, status='succeeded', trained_tokens=877932, training_file='file-6ZRsU7iL5jZqAmoiUpcYZz', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
            "Created at: 1733098830\n",
            "Finished at: 1733100856\n",
            "Duration: 2026\n",
            "Hyperparams: Hyperparameters(n_epochs=3, batch_size=4, learning_rate_multiplier=1.8)\n",
            "Testing time: 64.2903 seconds\n",
            "Y_test:\n",
            "[True, False, False, True, False, False, False, False, True, True, False, False, True, True, False, True, False, False, True, False, False, False, False, False, True, False, True, True, False, True, False, False, False, True, False, False, False, False, False, True, False, True, False, False, False, False, False, False, False, True, False, False, True, False, True, True, False, False, False, False, False, False, True, False, False, True, False, False, False, True, True, False, True, False, False, False, False, False, False, True, False, False, False, True, True, False, True, False, True]\n",
            "Y_pred:\n",
            "[True, False, False, True, False, False, False, False, False, True, False, False, False, True, False, True, False, False, True, False, False, False, False, True, True, False, True, False, False, True, True, False, False, False, True, False, False, False, True, False, False, False, False, False, True, False, False, False, False, False, False, False, True, True, False, True, False, False, True, False, False, False, True, False, False, False, False, False, False, False, True, False, True, False, True, False, False, True, False, True, False, True, False, True, False, False, False, False, True]\n",
            "Confusion Matrix:\n",
            "[[50 10]\n",
            " [12 17]]\n",
            "Accuracy: 0.7528089887640449\n",
            "Precision: 0.6296296296296297\n",
            "F1 Score: 0.6071428571428571\n",
            "Recall: 0.5862068965517241\n"
          ]
        }
      ],
      "source": [
        "accuracy_values[9], precision_values[9], f1_values[9], recall_values[9] = test_project(\"webssh\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NtpJ9eb8dXzA",
        "outputId": "83114d60-f9ec-4ead-d9e2-c82df078445e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Accuracy: 0.7411859727983818\n",
            "Average Precision: 0.6138565659299831\n",
            "Average F1 Score: 0.4792946109476574\n",
            "Average Recall: 0.4313793859176706\n"
          ]
        }
      ],
      "source": [
        "avg_accuracy = sum(accuracy_values) / len(accuracy_values)\n",
        "avg_precision = sum(precision_values) / len(precision_values)\n",
        "avg_f1 = sum(f1_values) / len(f1_values)\n",
        "avg_recall = sum(recall_values) / len(recall_values)\n",
        "\n",
        "print(f\"Average Accuracy: {avg_accuracy}\")\n",
        "print(f\"Average Precision: {avg_precision}\")\n",
        "print(f\"Average F1 Score: {avg_f1}\")\n",
        "print(f\"Average Recall: {avg_recall}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlDDXOTAJe8HHKAk5HLpvl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}