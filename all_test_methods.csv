Row,URL,Class,Test,Content,Detected
2,https://github.com/nordwind80/BT-Tracker/blob/558c15b399871c1ca11d0c4ae1eb598e3060931e/Tracker/tests/test_event.py,TestEvent,test_object,"def test_object(self):
        assert id(status.state) == id(status.state)

    ",True
3,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_command_context.py,,test_manual_context_noccr,"def test_manual_context_noccr():
    Breathe.add_commands(
        CommandContext(""test"") | AppContext(""italy""),
        {""spaghetti"": DoNothing()},
        ccr=False
    )
    # Loaded rule should be referencing the original
    # ""test"" context loaded above, which should already be
    # active
    engine.mimic([""spaghetti""])
    engine.mimic([""disable"", ""test""])
    with pytest.raises(MimicFailure):
        engine.mimic([""spaghetti""])
        engine.mimic([""pizza"", ""curry""])
    engine.mimic([""spaghetti""], executable=""italy"")

",True
4,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_loading.py,,test_loading,"def test_loading_failure():
    with open(file_path, ""w"") as f:
        f.write(""""""
from breathe import Breathe
from ..testutils import DoNothing

Breathe.add_commands(,,,
    None,
    {
        ""apple"": DoNothing(),
    }
)
""""""
        )
    modules = {
        ""tests"": {
            ""my_grammar"": [""fruit""],
        }
    }
    Breathe.load_modules(modules)
    assert len(Breathe.modules) == 1
    assert len(Breathe.core_commands) == 0

",True
5,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_loading.py,,test_loading_failure,"def test_loading_failure():
    with open(file_path, ""w"") as f:
        f.write(""""""
from breathe import Breathe
from ..testutils import DoNothing

Breathe.add_commands(,,,
    None,
    {
        ""apple"": DoNothing(),
    }
)
""""""
        )
    modules = {
        ""tests"": {
            ""my_grammar"": [""fruit""],
        }
    }
    Breathe.load_modules(modules)
    assert len(Breathe.modules) == 1
    assert len(Breathe.core_commands) == 0

",True
6,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_loading.py,,test_reloading,"def test_reloading():
    with open(file_path, ""w"") as f:
        f.write(""""""
from breathe import Breathe
from ..testutils import DoNothing

Breathe.add_commands(
    None,
    {
        ""parsnip"": DoNothing(),
    }
)
""""""
        )
    # I have no idea why this is necessary, it's a total hack
    if PY2:
        os.remove(file_path + ""c"")
    engine.mimic(""rebuild everything test"")
    with pytest.raises(MimicFailure):
        engine.mimic(""apple"")
    engine.mimic(""parsnip"")
    assert len(Breathe.modules) == 1


",True
7,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_merger.py,,test_context_commands,"def test_context_commands():
    Breathe.add_commands(
        AppContext(""notepad""),
        {""test [<num>]"": lambda num: DoNothing().execute()},
        [Choice(""num"", {""four"": ""4"", ""five"": ""5"", ""six"": ""6""})],
        {""num"": """"},
    )
    with pytest.raises(MimicFailure):
        engine.mimic([""test"", ""three"", ""test"", ""four""])
    engine.mimic([""test"", ""three"", ""test"", ""four""], executable=""notepad"")


",True
8,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_merger.py,,test_core_commands,"def test_core_commands():
    Breathe.add_commands(
        None,
        {
            ""test one"": DoNothing(),
            ""test two"": DoNothing(),
            ""test three"": DoNothing(),
            ""banana [<n>]"": DoNothing() * Repeat(""n""),
        },
        [IntegerRef(""n"", 1, 10, 1)],
    )
    engine.mimic([""test"", ""three"", ""test"", ""two"", ""banana"", ""five""])


",True
9,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_merger.py,,test_grammar_numbers,"def test_grammar_numbers():
    engine.mimic([""test"", ""three""])
    # Ensure that we are not adding more grammars than necessary
    assert len(engine.grammars) == 4


",True
10,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_merger.py,,test_invalid,"def test_invalid():
    Breathe.add_commands(
        AppContext(""code.exe""),
        {
            ""test that <nonexistent_extra>"": DoNothing(),
            1: DoNothing(),
        },
    )
    assert len(Breathe.contexts) == 1
    assert len(Breathe.context_commands) == 1


",True
11,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_merger.py,,test_noccr_commands,"def test_noccr_commands():
    Breathe.add_commands(
        AppContext(""firefox""),
        {""dictation <text>"": DoNothing(), ""testing static"": DoNothing()},
        ccr=False,
    )
    engine.mimic([""testing"", ""static""], executable=""firefox"")
    with pytest.raises(MimicFailure):
        engine.mimic([""dictation"", ""TESTING""])
        engine.mimic([""testing"", ""static"", ""testing"", ""static""], executable=""firefox"")
    engine.mimic([""dictation"", ""TESTING""], executable=""firefox"")


",True
12,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_top_level.py,,test_recognition,"def test_recognition():
    engine.mimic(""lemon"", executable=""notepad"")
    engine.mimic(""fruit from lemon banana orange and five"", executable=""notepad"")

    engine.mimic(
        ""fruit from pear banana orange and grapefruit"",
        executable=""notepad"",
        title=""chrome"",
    )
    with pytest.raises(MimicFailure):
        engine.mimic(
            ""fruit from pear banana orange and grapefruit"", executable=""notepad""
        )

    engine.mimic(""orange grapefruit are preferable to grapefruit"")
    engine.mimic(""orange grapefruit are preferable to lemon banana"", executable=""notepad"")
    assert len(Breathe.top_level_commands) == 2

",True
13,https://github.com/mrob95/Breathe/blob/4600818e24f4156cd7bb8cc0f43886b27323968e/tests/test_top_level.py,,test_top_level_command_failure,"def test_top_level_command_failure():
    Breathe.add_commands(
        AppContext(""china""),
        {
            ""not marked top level <sequence1> and <sequence2> [<n>]"": DoNothing()
            + Exec(""sequence1"")
            + DoNothing()
            + Exec(""sequence2"")* Repeat(""n"")
        },
        extras=[CommandsRef(""sequence1""), CommandsRef(""sequence2"", 2), IntegerRef(""n"", 1, 10, 1)],
        top_level=False,
    )
    assert len(Breathe.top_level_commands) == 2

",True
14,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testGetAvailableAnimations,"def testGetAvailableAnimations(self):
        self.assertIsNotNone(self.client.getAvailableAnimations())

    ",True
15,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testGetAvailableHandlers,"def testGetAvailableHandlers(self):
        self.assertIsNotNone(self.client.getAvailableHandlers())

    ",True
16,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testGetAvailableMotorRegisters,"def testGetAvailableMotorRegisters(self):
        self.assertIsNotNone(self.client.getAvailableMotorRegisters('base'))

    ",True
17,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testGetAvailableSounds,"def testGetAvailableSounds(self):
        self.assertIsNotNone(self.client.getAvailableSounds())

    ",True
18,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testGetMotorRegister,"def testGetMotorRegister(self):
        self.assertIsNotNone(self.client.getMotorRegister('base', 'goal_position'))

    ",True
19,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testGetMotorRegisterRange,"def testGetMotorRegisterRange(self):
        self.assertIsNotNone(self.client.getMotorRegisterRange('base', 'goal_position'))

    ",True
20,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testMoveMotorInDirection,"def testMoveMotorInDirection(self):
        self.assertIsNotNone(self.client.moveMotorToPosition('base', 'left', '2'))

    # ",True
21,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testMoveMotorInTime,"def testMoveMotorInTime(self):
        self.assertIsNotNone(self.client.moveMotorInTime('base', '2048', '12'))

    ",True
22,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testMoveMotorToPosition,"def testMoveMotorToPosition(self):
        self.assertIsNotNone(self.client.moveMotorToPosition('base', '2048', '2'))

    ",True
23,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testPauseAnimation,"def testPauseAnimation(self):
        self.assertIsNotNone(self.client.pauseAnimation())

    ",True
24,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testPauseAudio,"def testPauseAudio(self):
        self.assertIsNotNone(self.client.pauseAudio())

    ",True
25,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testPlayAnimation,"def testPlayAnimation(self):
        self.assertIsNotNone(self.client.playAnimation('welcome'))

    ",True
26,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testPlayAudio,"def testPlayAudio(self):
        self.assertIsNotNone(self.client.playAudio('hello'))

    ",True
27,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testResumeAnimation,"def testResumeAnimation(self):
        self.assertIsNotNone(self.client.resumeAnimation())

    ",True
28,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testResumeAudio,"def testResumeAudio(self):
        self.assertIsNotNone(self.client.resumeAudio())

    ",True
29,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testSetMotorRegister,"def testSetMotorRegister(self):
        self.assertIsNotNone(self.client.setMotorRegister('base', 'goal_position', '2048'))

    ",True
30,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testStopAnimation,"def testStopAnimation(self):
        self.assertIsNotNone(self.client.stopAnimation())

    ",True
31,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_http_test.py,TestHttpClientApiMethods,testStopAudio,"def testStopAudio(self):
        self.assertIsNotNone(self.client.stopAudio())
",True
32,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testGetAvailableAnimations,"def testGetAvailableAnimations(self):
        self.assertIsNotNone(self.client.getAvailableAnimations())

    ",True
33,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testGetAvailableHandlers,"def testGetAvailableHandlers(self):
        self.assertIsNotNone(self.client.getAvailableHandlers())

    ",True
34,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testGetAvailableMotorRegisters,"def testGetAvailableMotorRegisters(self):
        self.assertIsNotNone(self.client.getAvailableMotorRegisters('base'))

    ",True
35,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testGetAvailableSounds,"def testGetAvailableSounds(self):
        self.assertIsNotNone(self.client.getAvailableSounds())

    ",True
36,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testGetMotorRegister,"def testGetMotorRegister(self):
        self.assertIsNotNone(self.client.getMotorRegister('base', 'goal_position'))

    ",True
37,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testGetMotorRegisterRange,"def testGetMotorRegisterRange(self):
        self.assertIsNotNone(self.client.getMotorRegisterRange('base', 'goal_position'))

    ",True
38,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testMoveMotorInDirection,"def testMoveMotorInDirection(self):
        self.assertIsNotNone(self.client.moveMotorToPosition('base', 'left', '2'))

    # ",True
39,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testMoveMotorInTime,"def testMoveMotorInTime(self):
        self.assertIsNotNone(self.client.moveMotorInTime('base', '2048', '12'))

    ",True
40,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testMoveMotorToPosition,"def testMoveMotorToPosition(self):
        self.assertIsNotNone(self.client.moveMotorToPosition('base', '2048', '2'))

    ",True
41,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testPauseAnimation,"def testPauseAnimation(self):
        self.assertIsNotNone(self.client.pauseAnimation())

    ",True
42,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testPauseAudio,"def testPauseAudio(self):
        self.assertIsNotNone(self.client.pauseAudio())

    ",True
43,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testPlayAnimation,"def testPlayAnimation(self):
        self.assertIsNotNone(self.client.playAnimation('welcome'))

    ",True
44,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testPlayAudio,"def testPlayAudio(self):
        self.assertIsNotNone(self.client.playAudio('hello'))

    ",True
45,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testResumeAnimation,"def testResumeAnimation(self):
        self.assertIsNotNone(self.client.resumeAnimation())

    ",True
46,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testResumeAudio,"def testResumeAudio(self):
        self.assertIsNotNone(self.client.resumeAudio())

    ",True
47,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testSetMotorRegister,"def testSetMotorRegister(self):
        self.assertIsNotNone(self.client.setMotorRegister('base', 'goal_position', '2048'))

    ",True
48,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testStopAnimation,"def testStopAnimation(self):
        self.assertIsNotNone(self.client.stopAnimation())

    ",True
49,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_tcp_test.py,TestTcpClientApiMethods,testStopAudio,"def testStopAudio(self):
        self.assertIsNotNone(self.client.stopAudio())
",True
50,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testGetAvailableAnimations,"def testGetAvailableAnimations(self):
        self.assertIsNotNone(self.client.getAvailableAnimations())

    ",True
51,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testGetAvailableHandlers,"def testGetAvailableHandlers(self):
        self.assertIsNotNone(self.client.getAvailableHandlers())

    ",True
52,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testGetAvailableMotorRegisters,"def testGetAvailableMotorRegisters(self):
        self.assertIsNotNone(self.client.getAvailableMotorRegisters('base'))

    ",True
53,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testGetAvailableSounds,"def testGetAvailableSounds(self):
        self.assertIsNotNone(self.client.getAvailableSounds())

    ",True
54,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testGetMotorRegister,"def testGetMotorRegister(self):
        self.assertIsNotNone(self.client.getMotorRegister('base', 'goal_position'))

    ",True
55,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testMoveMotorInDirection,"def testMoveMotorInDirection(self):
        self.assertIsNotNone(self.client.moveMotorToPosition('base', 'left', '2'))

    # ",True
56,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testMoveMotorInTime,"def testMoveMotorInTime(self):
        self.assertIsNotNone(self.client.moveMotorInTime('base', '2048', '12'))

    ",True
57,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testMoveMotorToPosition,"def testMoveMotorToPosition(self):
        self.assertIsNotNone(self.client.moveMotorToPosition('base', '2048', '2'))

    ",True
58,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testPauseAnimation,"def testPauseAnimation(self):
        self.assertIsNotNone(self.client.pauseAnimation())

    ",True
59,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testPauseAudio,"def testPauseAudio(self):
        self.assertIsNotNone(self.client.pauseAudio())

    ",True
60,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testPlayAnimation,"def testPlayAnimation(self):
        self.assertIsNotNone(self.client.playAnimation('welcome'))

    ",True
61,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testPlayAudio,"def testPlayAudio(self):
        self.assertIsNotNone(self.client.playAudio('hello'))

    ",True
62,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testResumeAnimation,"def testResumeAnimation(self):
        self.assertIsNotNone(self.client.resumeAnimation())

    ",True
63,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testResumeAudio,"def testResumeAudio(self):
        self.assertIsNotNone(self.client.resumeAudio())

    ",True
64,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testSetMotorRegister,"def testSetMotorRegister(self):
        self.assertIsNotNone(self.client.setMotorRegister('base', 'goal_position', '2048'))

    ",True
65,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testStopAnimation,"def testStopAnimation(self):
        self.assertIsNotNone(self.client.stopAnimation())

    ",True
66,https://github.com/bennymeg/Butter.MAS.PythonAPI/blob/f86ebe75df3826f62a268645cdbe4400b43fab07/butter/mas/tests/clients/client_udp_test.py,TestUdpClientApiMethods,testStopAudio,"def testStopAudio(self):
        self.assertIsNotNone(self.client.stopAudio())
",True
67,https://github.com/PyDataBlog/Coinsta/blob/7cdce24669e5ab40852f0b88329c68e5bb568f5b/tests/test_coinsta.py,TestCoinsta,test_get_current,"def test_get_current(self):
        cur = Current(TestCoinsta.k)
        cur_btc = cur.get_current('btc')
        size = len(cur_btc.keys())
        self.assertEqual(size, 13)

    ",False
68,https://github.com/Erik-White/ColonyScanalyser/blob/38034b7d62a7c4f72a9f6981d0218c23f22cc7c8/tests/unit/test_base.py,TestUnique,test_init,"def test_init(self, unique):
        assert unique.id == 1

    ",True
69,https://github.com/Erik-White/ColonyScanalyser/blob/38034b7d62a7c4f72a9f6981d0218c23f22cc7c8/tests/unit/test_base.py,TestUnique,test_unique,"def test_unique(self, unique):
        assert unique.id == 1
        unique = None
        assert Unique().id != 1

    ",True
70,https://github.com/Gsllchb/DotDot/blob/89a6f7a86866de9c348f7e91da57c359c94568db/tests/test_dot.py,,test_dot,"def test_dot():
    import dot
    import dotdot
    import dotdotdot
    import dotdotdotdot
    assert sys.path[0] == DOT
",True
71,https://github.com/Gsllchb/DotDot/blob/89a6f7a86866de9c348f7e91da57c359c94568db/tests/test_dotdot.py,,test_dotdot,"def test_dotdot():
    import dotdot
    import dot
    import dotdotdot
    import dotdotdotdot
    assert sys.path[0] == DOTDOT
",True
72,https://github.com/Gsllchb/DotDot/blob/89a6f7a86866de9c348f7e91da57c359c94568db/tests/test_dotdotdot.py,,test_dotdotdot,"def test_dotdotdot():
    import dotdotdot
    import dotdot
    import dot
    import dotdotdot
    import dotdotdotdot
    assert sys.path[0] == DOTDOTDOT
",True
73,https://github.com/Gsllchb/DotDot/blob/89a6f7a86866de9c348f7e91da57c359c94568db/tests/test_dotdotdotdot.py,,test_dotdotdotdot,"def test_dotdotdotdot():
    import dotdotdotdot
    import dotdotdot
    import dotdot
    import dot
    import dotdotdot
    assert sys.path[0] == DOTDOTDOTDOT
",True
74,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_api_named_routes,"def test_api_named_routes(self, test_client):
        rv = test_client.get(""/api/v1/test"")
        assert ""200"" in str(rv.status)

    ",True
75,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_before_middleware,"def test_before_middleware(self, monkeypatch, TestMockEntity, mock_token):
        app = Flask(__name__)
        @app.route(""/test"", methods=[""GET""])
        ",True
76,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_dynamic_params,"def test_dynamic_params(self, test_client):
        rv = test_client.put(""/api/v1/apples/sub/1"")
        assert ""200"" in str(rv.status)

        rv = test_client.get(""/api/v1/apples/sub/"")
        assert ""404"" in str(rv.status)

        rv = test_client.get(""/api/v1/apples/sub/hello"")
        assert ""404"" in str(rv.status)

    ",True
77,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_handle_pre_flight_request,"def test_handle_pre_flight_request(self, test_client):
        rv = test_client.options(""/"")
        assert ""200"" in str(rv.status)
",True
78,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_ignored_route_path,"def test_ignored_route_path(self, test_client):
        rv = test_client.get(""/"")
        assert ""200"" in str(rv.status)

    ",True
79,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_ignored_routes,"def test_ignored_routes(self, test_client):
        rv = test_client.get(""/ignore"")
        assert ""200"" in str(rv.status)

    ",True
80,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_jwt_route,"def test_jwt_route(self, jwt_router_client, entity_model, expected):
        rv = jwt_router_client.get(""/test"")
        assert expected in str(rv.status)

    ",True
81,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_jwt_route,"def test_jwt_route(self, jwt_router_client, entity_model, expected):
        rv = jwt_router_client.get(""/test"")
        assert expected in str(rv.status)

    ",True
82,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_jwt_route,"def test_jwt_route(self, jwt_router_client, entity_model, expected):
        rv = jwt_router_client.get(""/test"")
        assert expected in str(rv.status)

    ",True
83,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_jwt_route,"def test_jwt_route(self, jwt_router_client, entity_model, expected):
        rv = jwt_router_client.get(""/test"")
        assert expected in str(rv.status)

    ",True
84,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_static_client,"def test_static_client(self, test_client_static):
        rv = test_client_static.get(""/static_copy/images/Group.jpg"")
        assert ""200"" in str(rv.status)

    ",True
85,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_static_routes,"def test_static_routes(self, test_client):
        """"""
        Tests if the static path is handled both by default and
        if the path is past to the static_folder kwarg
        """"""
        rv = test_client.get(""/static/images/Group.jpg"")
        assert ""200"" in str(rv.status)

        rv = test_client.get(""/"")
        assert ""200"" in str(rv.status)

    ",True
86,https://github.com/joegasewicz/Flask-JWT-Router/blob/0fb1e256c81409be6f08d8be12f07e5f58b4f914/tests/test_routing.py,TestRouting,test_sub_paths,"def test_sub_paths(self, test_client):
        rv = test_client.get(""/api/v1/bananas/sub"")
        assert ""200"" in str(rv.status)
        assert rv.get_json()[""data""] == ""sub""

        rv = test_client.get(""/api/v1/test/sub_two"")
        assert ""401"" in str(rv.status)

    ",True
87,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregated_delitem_method,"def test_aggregated_delitem_method(mocked_aggregated):
    """"""Test FlaskMultiRedis aggregated __delitem__ method.""""""

    del(mocked_aggregated['name'])
    for node in mocked_aggregated._aggregator._redis_nodes:
        assert not hasattr(node, 'name')
    mocked_aggregated._aggregator._redis_nodes = []
    del(mocked_aggregated['name'])
",True
88,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregated_getitem_method,"def test_aggregated_getitem_method(mocked_aggregated):
    """"""Test FlaskMultiRedis aggregated __getitem__ method.""""""

    assert mocked_aggregated['pattern'] == 'node2'
    mocked_aggregated._aggregator._redis_nodes = []
    assert mocked_aggregated['pattern'] is None


",True
89,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregated_setitem_method,"def test_aggregated_setitem_method(mocked_aggregated):
    """"""Test FlaskMultiRedis aggregated __setitem__ method.""""""

    mocked_aggregated['name'] = 'node0'
    nodes = mocked_aggregated._aggregator._redis_nodes
    assert [x.name for x in nodes] == ['node0', 'node0', 'node0']
    mocked_aggregated._aggregator._redis_nodes = []
    mocked_aggregated['name'] = 'node0'


",True
90,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregator_delete_method,"def test_aggregator_delete_method(mocked_aggregated):
    """"""Test aggregator delete method.""""""

    res = mocked_aggregated.delete('pattern')
    assert type(res) is int
    for node in mocked_aggregated._aggregator._redis_nodes:
        assert not hasattr(node, 'name')


",True
91,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregator_get_method,"def test_aggregator_get_method(mocked_aggregated):
    """"""Test aggregator get method.""""""

    assert mocked_aggregated.get('pattern') == 'node2'


",True
92,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregator_keys_method,"def test_aggregator_keys_method(mocked_aggregated):
    """"""Test aggregator keys method.""""""

    assert mocked_aggregated.keys('pattern') == ['node3', 'pattern']


",True
93,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregator_keys_method_with_empty_nodes,"def test_aggregator_keys_method_with_empty_nodes(mocked_aggregated):
    """"""Test aggregator keys method with empty nodes.""""""

    assert mocked_aggregated.keys('empty') == []


",True
94,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregator_scan_iter_method,"def test_aggregator_scan_iter_method(mocked_aggregated):
    """"""Test aggregator scan_iter method.""""""

    for node in mocked_aggregated._aggregator._redis_nodes:
        node.set('value', 'pattern')
    results = [x for x in mocked_aggregated.scan_iter('value')]
    assert results == ['pattern', 'pattern', 'pattern']


",True
95,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregator_set_method,"def test_aggregator_set_method(mocked_aggregated):
    """"""Test aggregator set method.""""""

    res = mocked_aggregated.set('value', 'pattern')
    assert res is True
    for node in mocked_aggregated._aggregator._redis_nodes:
        assert node.value == 'pattern'


",True
96,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_aggregator_strategy,"def test_aggregator_strategy(aggregated):
    """"""Test that a constructor with aggregate strategy will initialize
    the connection.""""""
    assert aggregated._redis_client is not None
    assert hasattr(aggregated._redis_client, 'connection_pool')
    assert hasattr(aggregated._app, 'extensions')
    assert 'redis' in aggregated._app.extensions
    assert aggregated._app.extensions['redis'] == aggregated


",True
97,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_attributes_transmission_from_aggregated_node,"def test_attributes_transmission_from_aggregated_node(aggregated):
    """"""Test that attributes from aggregated nodes are
    available directly from FlaskMultiRedis object.""""""

    node = aggregated._aggregator._redis_nodes[0]
    assert aggregated.connection_pool is node.connection_pool


",True
98,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_attributes_transmission_from_loadbalanced_node,"def test_attributes_transmission_from_loadbalanced_node(loadbalanced):
    """"""Test that attributes from loadbalanced nodes are
    available directly from FlaskMultiRedis object.""""""

    node = loadbalanced._redis_nodes[0]
    assert loadbalanced.connection_pool is node.connection_pool


",True
99,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_attributes_transmission_if_aggregated_has_no_host,"def test_attributes_transmission_if_aggregated_has_no_host(aggregated):
    """"""Test that attributes transmission return None if Aggregator
    has an empty node list.""""""
    aggregated._aggregator._redis_nodes = []
    assert aggregated._redis_client is None


",True
100,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_constructor,"def test_constructor(loadbalanced):
    """"""Test that a constructor with app instance will initialize the
    connection.""""""
    assert loadbalanced._redis_client is not None
    assert hasattr(loadbalanced._redis_client, 'connection_pool')
    assert hasattr(loadbalanced._app, 'extensions')
    assert 'redis' in loadbalanced._app.extensions
    assert loadbalanced._app.extensions['redis'] is loadbalanced


",True
101,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_custom_default_config,"def test_custom_default_config(app_custom_default):
    """"""Test that we can pass a custom default configuration.""""""

    redis = FlaskMultiRedis(app_custom_default)
    assert redis.connection_pool.connection_kwargs['port'] == 16379
    assert redis.connection_pool.connection_kwargs['db'] == 9
    assert redis.connection_pool.connection_kwargs['password'] == 'password'
    assert redis.connection_pool.connection_kwargs['socket_timeout'] == 2


",True
102,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_custom_default_ssl,"def test_custom_default_ssl(app_custom_default_ssl):
    """"""Test that we can pass a custom default ssl configuration.""""""

    redis = FlaskMultiRedis(app_custom_default_ssl)
    kwargs = redis.connection_pool.connection_kwargs
    assert kwargs['ssl_keyfile'] == 'ssl/rediskey.pem'
    assert kwargs['ssl_certfile'] == 'ssl/rediscert.pem'
    assert kwargs['ssl_ca_certs'] == 'ssl/rediscert.pem'
    assert kwargs['ssl_cert_reqs'] == 'required'


",True
103,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_custom_node,"def test_custom_node(app_custom_node):
    """"""Test that we can pass a custom node configuration.""""""

    redis = FlaskMultiRedis(app_custom_node)
    kwargs = redis.connection_pool.connection_kwargs
    assert kwargs['port'] == 16379
    assert kwargs['db'] == 9
    assert kwargs['password'] == 'password'
    assert kwargs['socket_timeout'] == 2
    assert kwargs['ssl_keyfile'] == 'ssl/rediskey.pem'
    assert kwargs['ssl_certfile'] == 'ssl/rediscert.pem'
    assert kwargs['ssl_ca_certs'] == 'ssl/rediscert.pem'
    assert kwargs['ssl_cert_reqs'] == 'required'


",True
104,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_custom_prefix,"def test_custom_prefix(app):
    """"""Test that config prefixes enable distinct connections.""""""
    app.config['DBA_NODES'] = [{'host': 'localhost', 'db': 1}]
    app.config['DBB_NODES'] = [{'host': 'localhost', 'db': 2}]
    redis_a = FlaskMultiRedis(app, config_prefix='DBA')
    redis_b = FlaskMultiRedis(app, config_prefix='DBB')
    assert redis_a.connection_pool.connection_kwargs['db'] == 1
    assert redis_b.connection_pool.connection_kwargs['db'] == 2


",True
105,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_extension_registration_if_app_has_no_extensions,"def test_extension_registration_if_app_has_no_extensions(app):
    """"""Test that the constructor is able to register FlaskMultiRedis
    as an extension even if app has no extensions attribute.""""""
    delattr(app, 'extensions')
    redis = FlaskMultiRedis(app)
    assert hasattr(app, 'extensions')
    assert 'redis' in app.extensions
    assert app.extensions['redis'] == redis


",True
106,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_init_app,"def test_init_app(app):
    """"""Test that a constructor without app instance will not initialize the
    connection.

    After FlaskMultiRedis.init_app(app) is called, the connection will be
    initialized.""""""
    redis = FlaskMultiRedis()
    assert redis._app is None
    assert len(redis._redis_nodes) == 0
    redis.init_app(app)
    assert redis._app is app
    assert len(redis._redis_nodes) == 1
    assert hasattr(redis._redis_client, 'connection_pool')


",True
107,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_loadbalanced_delitem_method,"def test_loadbalanced_delitem_method(mocked_loadbalanced):
    """"""Test FlaskMultiRedis loadbalanced __delitem__ method.""""""

    del(mocked_loadbalanced['name'])
    for node in mocked_loadbalanced._redis_nodes:
        assert not hasattr(node, 'name')
    mocked_loadbalanced._redis_nodes = []
    del(mocked_loadbalanced['name'])


",True
108,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_loadbalanced_getitem_method,"def test_loadbalanced_getitem_method(mocked_loadbalanced):
    """"""Test FlaskMultiRedis loadbalanced __getitem__ method.""""""

    assert mocked_loadbalanced['pattern'] in ['node1', 'node2', 'node3']
    mocked_loadbalanced._redis_nodes = []
    assert mocked_loadbalanced['pattern'] is None


",True
109,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_loadbalanced_setitem_method,"def test_loadbalanced_setitem_method(mocked_loadbalanced):
    """"""Test FlaskMultiRedis loadbalanced __setitem__ method.""""""

    mocked_loadbalanced['name'] = 'node0'
    assert 'node0' in [x.name for x in mocked_loadbalanced._redis_nodes]
    mocked_loadbalanced._redis_nodes = []
    mocked_loadbalanced['name'] = 'node0'


",True
110,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_methods_transmission_from_aggregator,"def test_methods_transmission_from_aggregator(aggregated):
    """"""Test that methods from aggregator are available
    directly from FlaskMultiRedis object (aggregate).""""""

    assert isinstance(aggregated.keys.__self__, Aggregator)


",True
111,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_methods_transmission_from_redis,"def test_methods_transmission_from_redis(loadbalanced):
    """"""Test that methods from redis are available
    direcly from FlaskMultiRedis object (loadbalancing).""""""

    assert isinstance(loadbalanced.keys.__self__, StrictRedis)


",True
112,https://github.com/max-k/flask-multi-redis/blob/fa781d3598448a6429309a686de9a8adb53f9f34/test/integration/test_flask_multi_redis.py,,test_task_runner,"def test_task_runner(mocked_aggregated):
    """"""Test task runner in nominal operations.""""""

    ",True
113,https://github.com/brettvanderwerff/Flaskerizer/blob/5a9724804f4e479fc3289e8644dc788adfeff06d/flaskerizer/flaskerizer_src/tests/test_structure_directory.py,TestStructureDirectory,test_migrate_files,"def test_migrate_files(self):
        '''tests that migrate_files migrates the correct number of files from the Example bootstrap template directory
         to the Test_application directory. This is done by walking through the Test_application directory with os.walk
         and counting the number of files with a particular set of extensions (see extensions list) and comparing this
         number to the number of files gotten from walking through a ""gold_standard"" respective Test_application_test_folder.
        '''
        migrate_dict = self.test.detect_static_files()
        self.test.migrate_files(migrate_dict)
        extensions = ['.js', '.css', '.jpg', '.png', 'gif', '.ico', '.otf',
                      '.eot', '.svg', '.ttf', '.woff', '.woff2']
        test_dir = self.flaskerized_app_dir
        test_file_list = []
        gold_standard_file_list = []
        for dir in [test_dir, self.gold_standard_dir]:
            for path, subdir, files in os.walk(dir):
                for name in files:
                    for extension in extensions:
                        if name.endswith(extension):
                            if dir == test_dir:
                                test_file_list.append(name)
                            if dir == self.gold_standard_dir:
                                gold_standard_file_list.append(name)
        self.assertEqual(len(test_file_list), len(gold_standard_file_list))



",False
114,https://github.com/leopepe/GOApy/blob/a8e0dfe5f0f593107884ad54f89a27f67ee28129/tests/Sensor_test.py,SensorsTest,test_remove_sensor_success,"def test_remove_sensor_success(self):
        assert self.sensors.remove(name='SenseTmpDirContent') is True

    ",True
115,https://github.com/Tedyst/HikLoad/blob/b3eb7be65bd34040992e1b7b15f23ff4ce2e8dc4/tests/test_config.py,,test_envvar,"def test_envvar():
    import os
    os.environ[""server""] = ""1""
    assert config.CONFIG[""server""] == ""1""

# Can't add a lot of tests since Hikvision's API is pretty unreliable
",True
116,https://github.com/omersaraf/IOCynergy/blob/1821423680f741d8ca06bcc6a02c8b21156f9ba0/cynergy/tests/test_register_multiple.py,,test_register_multiple,"def test_register_multiple():
    container.register_many(Example, [Example1, Example2])
    instance = container.get(List[Example])

    assert type(instance) is list
    assert len(instance) == 2
    assert type(instance[0]) is Example1
    assert type(instance[1]) is Example2


",True
117,https://github.com/TheodoreKrypton/JavPy/blob/61df53aafbfbd05ed1efa8c51a08d6e9252cb533/JavPy/tests/test_clients/test_telegram.py,,test_interactive,"def test_interactive():
    ",False
118,https://github.com/TheodoreKrypton/JavPy/blob/61df53aafbfbd05ed1efa8c51a08d6e9252cb533/JavPy/tests/test_clients/test_telegram.py,,test_new,"def test_new(params):
    mock_message = MockMessage(mock_user, mock_chat.id, ""/new"")
    mock_update = MockUpdate(mock_message)
    get_new(mock_bot, mock_update, params)
    received = mock_user.look_received()
    for res in received:
        if requests.get(res[""photo""], proxies=proxy).status_code == 200:
            return
    assert False


@pytest.mark.parametrize(""params"", [""-a 1 -b 20"".split(), ""-m 1 -u 10a"".split()])
",False
119,https://github.com/TheodoreKrypton/JavPy/blob/61df53aafbfbd05ed1efa8c51a08d6e9252cb533/JavPy/tests/test_clients/test_webserver.py,,test_newly_released,"def test_newly_released(data):
    data[""userpass""] = get_userpass()
    rv = client.post(""/new"", data=json.dumps(data))
    rsp = json.loads(rv.data.decode(""utf-8""))
    assert len(rsp) > 0


if __name__ == ""__main__"":
    # test_static_files()
    # test_search_by_code()
    test_search_by_actress()
    # test_search_magnet_by_code()
    # test_newly_released()
",False
120,https://github.com/TheodoreKrypton/JavPy/blob/61df53aafbfbd05ed1efa8c51a08d6e9252cb533/JavPy/tests/test_clients/test_webserver.py,,test_newly_released,"def test_newly_released(data):
    data[""userpass""] = get_userpass()
    rv = client.post(""/new"", data=json.dumps(data))
    rsp = json.loads(rv.data.decode(""utf-8""))
    assert len(rsp) > 0


if __name__ == ""__main__"":
    # test_static_files()
    # test_search_by_code()
    test_search_by_actress()
    # test_search_magnet_by_code()
    # test_newly_released()
",False
121,https://github.com/TheodoreKrypton/JavPy/blob/61df53aafbfbd05ed1efa8c51a08d6e9252cb533/JavPy/tests/test_clients/test_webserver.py,,test_search_magnet_by_code,"def test_search_magnet_by_code(code):
    rv = client.post(""/search_magnet_by_code"", data=json.dumps({""code"": code, ""userpass"": get_userpass()}))
    rsp = json.loads(rv.data.decode(""utf-8""))
    assert len(rsp) > 0


@pytest.mark.parametrize(""data"", [{""up_to"": 30}, {""page"": 1}])
",False
122,https://github.com/TheodoreKrypton/JavPy/blob/61df53aafbfbd05ed1efa8c51a08d6e9252cb533/JavPy/tests/test_clients/test_webserver.py,,test_search_magnet_by_code,"def test_search_magnet_by_code(code):
    rv = client.post(""/search_magnet_by_code"", data=json.dumps({""code"": code, ""userpass"": get_userpass()}))
    rsp = json.loads(rv.data.decode(""utf-8""))
    assert len(rsp) > 0


@pytest.mark.parametrize(""data"", [{""up_to"": 30}, {""page"": 1}])
",False
123,https://github.com/TheodoreKrypton/JavPy/blob/61df53aafbfbd05ed1efa8c51a08d6e9252cb533/JavPy/tests/test_sources.py,,test_avsox_net,"def test_avsox_net():
    avsox_net.AVSoxNet.test()


",False
124,https://github.com/gjvnq/LabIFSC/blob/cb56b75f51eb54680d0b81f4c87aa0234538a2a8/tests/medida_test.py,,test_medida_si_2,"def test_medida_si_2():
    m = Medida(""1+-0.1"", ""ft²"").SI()

    assert m.nominal - 0.092903 < 1E-4
    assert m.incerteza - 0.0092903 < 1E-4
    assert unidades_em_texto(m.unidades_originais) == ""m²""

",True
125,https://github.com/gjvnq/LabIFSC/blob/cb56b75f51eb54680d0b81f4c87aa0234538a2a8/tests/medida_test.py,,test_medida_si_3,"def test_medida_si_3():
    m = Medida(""1+-0.1"", ""ft² deg lb h °F A mol^-1"").SI()

    assert unidades_em_texto(m.unidades_originais) == ""m² rad kg s K A mol⁻¹""

",True
126,https://github.com/kushao1267/MusicAPI/blob/c6340d5dd6df869a90a44a311d3cd7a383bd4cf4/tests/music_test.py,,test_xiami_music_id,"def test_xiami_music_id():
    result = XiaMi(music_id=""1459299"", use_id=True).__repr__()
    assert ""Jo Dee Messina"" in result
    assert ""I Know a Heartache When I See One"" in result
    assert 'http://m128.xiami.net' in result  # domain


",False
127,https://github.com/kushao1267/MusicAPI/blob/c6340d5dd6df869a90a44a311d3cd7a383bd4cf4/tests/music_test.py,,test_xiami_music_link,"def test_xiami_music_link():
    result = XiaMi(url=""https://www.xiami.com/song/1459299"", use_id=False).__repr__()
    assert ""Jo Dee Messina"" in result
    assert ""I Know a Heartache When I See One"" in result
    assert 'http://m128.xiami.net' in result  # domain
",False
128,https://github.com/cahoy/NestedDictionary/blob/881f0ea8af36a60fcd1b9d7a84b1aec4cd7072b2/easy_dict/tests/test_01_default.py,,test_del,"def test_del(x):
    del x[123]

    # assert x == {'foo': 'bar', 'baz': 'qux', 'def': 456}
    with raises(KeyError):
        assert x[123]


",True
129,https://github.com/Neuraxio/Neuraxle/blob/20c6e5713198345b43bf6899355f1b5cf65eb02c/testing/hyperparams/test_distributions.py,,test_gaussian_distribution_mixture_log,"def test_gaussian_distribution_mixture_log():
    distribution_amplitudes = [1, 1, 1]
    means = [-2, 0, 2]
    stds = [1, 1, 1]
    distribution_mins = [None for _ in range(len(means))]
    distribution_max = [None for _ in range(len(means))]

    hd = DistributionMixture.build_gaussian_mixture(distribution_amplitudes, means, stds, distribution_mins,
                                                    distribution_max, use_logs=True)

    samples = get_many_samples_for(hd)

    samples_median = np.median(samples)
    assert 0.5 < samples_median < 1.5
    samples_std = np.std(samples)
    assert 1 < samples_std < 4
    assert abs(hd.pdf(-2.) - 0.) < 1e-6
    assert abs(hd.pdf(1.) - 0.24377901627294607) < 1e-6
    assert abs(hd.pdf(5.) - 0.03902571107126729) < 1e-6
    assert abs(hd.cdf(-2.) - 0.) < 1e-6
    assert abs(hd.cdf(1.) - 0.5) < 1e-6
    assert abs(hd.cdf(5.) - 0.8720400927468334) < 1e-6

    assert hd.min() == 0
    assert hd.max() == np.inf
    assert abs(hd.mean() - 2.225189976999746) < 1e-6
    assert abs(hd.var() - 9.916017516376925) < 1e-6
    assert abs(hd.std() - 3.1489708662318434) < 1e-6
    # Verify that hd mean and variance also correspond to mean and variance of sampling.
    assert abs(hd.mean() - np.mean(samples)) < 1e-1
    assert abs(hd.var() - np.var(samples)) < 5e-1


",True
130,https://github.com/Neuraxio/Neuraxle/blob/20c6e5713198345b43bf6899355f1b5cf65eb02c/testing/test_streaming.py,,test_parallel_queued_parallelize_correctly,"def test_parallel_queued_parallelize_correctly():
    sleep_time = 0.001
    p = SequentialQueuedPipeline([
        ('1', 4, 10, Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)])),
        ('2', 4, 10, Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)])),
        ('3', 4, 10, Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)])),
        ('4', 4, 10, Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)]))
    ], batch_size=10)

    a = time.time()
    outputs_streaming = p.transform(list(range(100)))
    b = time.time()
    time_queued_pipeline = b - a

    p = Pipeline([
        Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)]),
        Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)]),
        Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)]),
        Pipeline([ForEachDataInput(Sleep(sleep_time=sleep_time)), MultiplyByN(2)])
    ])

    a = time.time()
    outputs_vanilla = p.transform(list(range(100)))
    b = time.time()
    time_vanilla_pipeline = b - a

    assert time_queued_pipeline < time_vanilla_pipeline
    assert np.array_equal(outputs_streaming, outputs_vanilla)


",False
131,https://github.com/neuropsychology/NeuroKit.py/blob/fc77dc94e421d5b166a5516b7186bae483d753bd/tests/test_ecg.py,TestEcg,test_ecg_process,"def test_ecg_process(self):
        ecg_processed = nk.ecg_process(self.ecg, rsp=None, sampling_rate=1000, quality_model=None)
        self.assertAlmostEqual(ecg_processed[""df""][""Heart_Rate""].mean(), 60.0, places=1)

    ",False
132,https://github.com/mortele/OccamTools/blob/26c47709f6b870c89403f03ade0950de9f301639/test/test_occam_data.py,,test_occam_data_not_save_to_npy,"def test_occam_data_not_save_to_npy():
    assert not os.path.exists(class_dir)
    _ = OccamData(file_name_fort_1, save_to_npy=False, silent=True)
    assert not os.path.exists(class_dir)
",True
133,https://github.com/mortele/OccamTools/blob/26c47709f6b870c89403f03ade0950de9f301639/test/test_occam_data.py,,test_occam_data_progress_bars,"def test_occam_data_progress_bars():
    fort1, fort7, fort8 = _load_default_forts()
    occam_data_silent = OccamData(fort1, fort7, fort8)
    fort1, fort7, fort8 = _load_default_forts(silent=False)
    occam_data_verbose = OccamData(fort1, fort7, fort8)
    for key in occam_data_silent.__dict__:
        assert _check_equal(occam_data_silent.__dict__[key],
                            occam_data_verbose.__dict__[key])
    occam_data_verbose.save()
    occam_data_verbose_npy = OccamData(file_name_fort_1, load_from_npy=False,
                                       silent=True)
    occam_data_verbose_npy = OccamData(file_name_fort_1, load_from_npy=True,
                                       silent=False)
    for key in occam_data_silent.__dict__:
        assert _check_equal(occam_data_silent.__dict__[key],
                            occam_data_verbose_npy.__dict__[key])
    shutil.rmtree(class_dir)


",True
134,https://github.com/goodmami/penman/blob/e83cf6d006724d72a3e19a955aad94412da912b7/tests/test_layout.py,,test_rearrange,"def test_rearrange():
    t = codec.parse('''
        (a / alpha
           :ARG0 (b / beta
                    :ARG0 (g / gamma)
                    :ARG1 (d / delta))
           :ARG0-of d
           :ARG1 (e / epsilon))''')

    rearrange(t, model.original_order)
    assert codec.format(t) == (
        '(a / alpha\n'
        '   :ARG0 (b / beta\n'
        '            :ARG0 (g / gamma)\n'
        '            :ARG1 (d / delta))\n'
        '   :ARG0-of d\n'
        '   :ARG1 (e / epsilon))')

    rearrange(t, model.random_order)
    assert codec.format(t) == (
        '(a / alpha\n'
        '   :ARG0-of d\n'
        '   :ARG1 (e / epsilon)\n'
        '   :ARG0 (b / beta\n'
        '            :ARG0 (g / gamma)\n'
        '            :ARG1 (d / delta)))')

    rearrange(t, model.canonical_order)
    assert codec.format(t) == (
        '(a / alpha\n'
        '   :ARG0 (b / beta\n'
        '            :ARG0 (g / gamma)\n'
        '            :ARG1 (d / delta))\n'
        '   :ARG1 (e / epsilon)\n'
        '   :ARG0-of d)')


",True
136,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_delete_vertex,"def test_delete_vertex(self):
        vertex_delete = self.graph.delete_vertex(""a"")
        assert self.graph.num_vertex() == 1
        assert str(vertex_delete) == ""Vértice a""

    ",True
137,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_duplicated_edge,"def test_duplicated_edge(self):
        with pytest.raises(EdgeDuplicatedException):
            assert self.graph.add_edge(""b"", ""c"")
",True
138,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_edge_exists,"def test_edge_exists(self):
        assert self.graph.edge_exists(""a"", ""b"")

    ",True
139,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_false_cycle_graph,"def test_false_cycle_graph(self):
        self.graph.delete_edge(""c"", ""a"")
        self.graph.add_vertex(""d"")
        self.graph.add_edge(""c"", ""d"", 3)
        assert self.graph.has_cycle() is False
        assert self.graph.has_loop() is False

    ",True
140,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_false_regular_graph,"def test_false_regular_graph(self):
        self.graph.add_edge(""b"", ""c"", 3)
        assert self.graph.check_regular_graph() is False

    ",True
141,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_is_terminal,"def test_is_terminal(self):
        self.graph.add_vertex(""a"")
        edge = self.graph.add_edge(""a"", ""b"", ""ab"")
        assert self.graph.is_terminal(edge, 'a') and \
            self.graph.is_terminal(edge, 'b')

    ",True
142,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_list_graph_edges,"def test_list_graph_edges(self):
        edges = []
        for edge in self.graph.edges:
            edges.append(edge.name)
        assert str(self.graph.list_graph_edges()) == \
            ""['ab', 'x', 'x', 'x', 'x']""

    ",True
143,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_list_graph_vertices,"def test_list_graph_vertices(self):
        vertices = []
        for vertex in self.graph.vertices:
            vertices.append(vertex)
        assert str(self.graph.list_graph_vertices()) == \
            ""['b', 'a', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9']""

    ",True
144,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_num_edges,"def test_num_edges(self):
        assert self.graph.num_edges() == 1

    ",True
145,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_num_vertex,"def test_num_vertex(self):
        self.graph.add_vertex(""a"")
        assert self.graph.num_vertex() == 1

    ",True
146,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_show_edge,"def test_show_edge(self):
        assert str(self.graph.show_edge('a', 'b')) == \
            str('ab: Vértice a -> Vértice b')

    ",True
147,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_true_cycle_graph,"def test_true_cycle_graph(self):
        self.graph.add_vertex(""c"")
        self.graph.add_edge(""b"", ""c"", 2)
        self.graph.add_edge(""c"", ""a"", 3)
        assert self.graph.has_cycle() is True
        assert self.graph.has_loop() is False

    ",True
148,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_vertex_degree,"def test_vertex_degree(self):
        assert len(self.graph.vertex_neighbors(""b"")) == 1

    ",True
149,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_vertex_exists,"def test_vertex_exists(self):
        assert self.graph.vertex_exists(""a"")

    ",True
150,https://github.com/Rickecr/PyGraph/blob/e81c3a0f543f5bfcda1a603c6dcecde13d582c57/__tests__/test_simple_graph.py,TestSimpleGraph,test_vertices_adjacency,"def test_vertices_adjacency(self):
        neighbors_vertices = self.graph.vertex_neighbors(""a"")
        vertex_b = self.graph.vertices.get(""b"")
        assert vertex_b in neighbors_vertices

    ",True
151,https://github.com/maboualidev/PyJsonFriendly/blob/8b1ee498bc7a27024851b5101bf09913031e2477/tests/test_pyJsonFriendly.py,TestPyJsonFriendly,test_01,"def test_01(self):
        o = NotJsonFriendly(1, 2)
        with self.assertRaises(TypeError):
            json.dumps(o)

    ",True
152,https://github.com/washad/PyRedisEasyIO/blob/30d566760aa622ae6e8fcc1fa4abdc79b6bda614/tests/test_operator_overloads.py,TestOperatorOverloads,test_plus_equals,"def test_plus_equals(self):
        group = self.group
        group.Int1 += 5
        assert_that(group.Int1).is_equal_to(5)",True
153,https://github.com/DusanMadar/PySyncDroid/blob/9a217a54f4286af8e7505c184eb2a6775f52d815/tests/test_sync.py,TestSync,test_do_sync,"def test_do_sync(self, mock_copy_file):
        """"""
        Test 'do_sync' copies source files to their destination and updates
        destination files list.
        """"""
        sync = Sync(FAKE_MTP_DETAILS, ""/tmp"", ""Card/Music"")
        sync.set_source_abs()
        sync.set_destination_abs()
        sync.do_sync(FAKE_SYNC_DATA)

        self.assertEqual(
            FAKE_SYNC_DATA[""dst_dir_fls""],
            [
                ""/run/user/<user>/gvfs/mtp:host=%5Busb%3A002%2C003%5D/Card/Music/testdir/oldsong.mp3""
            ],  # noqa
        )

        mock_copy_file.assert_called_once_with(
            ""/tmp/testdir/song.mp3"",
            ""/run/user/<user>/gvfs/mtp:host=%5Busb%3A002%2C003%5D/Card/Music/testdir/song.mp3"",  # noqa
        )

    @patch.object(pysyncdroid.sync.Sync, ""copy_file"")
    ",True
154,https://github.com/Tencent/QTAF/blob/c9141e8fbdfd89f5f13dd59dfab17f9e8193dcf8/tests/test_testbase/test_assert.py,AssertionTest,test_assert_failure,"def test_assert_failure(self):
        case = AssertionFailureTest()
        old_run_test_code = case.run_test.__func__.__code__
        case.debug_run()
        self.assertEqual(case.test_result.passed, False, ""断言失败，用例没有失败"")
        self.assertEqual(len(case.test_result._step_results), 2, ""设置了断言失败继续执行，但是用例没有继续执行"")
        self.assertEqual(self.is_func_rewritten(case.run_test, old_run_test_code), True, ""重写assert失败，code对象没有改变"")

    ",True
155,https://github.com/klieret/RandomFileTree/blob/aaaa975ae61afa6f0f5b481ebafcfa0f0216e471/randomfiletree/test/test_core.py,TestTreeCreation,test_create_random_dirs,"def test_create_random_dirs(self):
        iterative_gaussian_tree(self.basedir.name, -10, 2, 3, None)
        dirs, files = self.get_content()
        self.assertEqual(len(files), 0)
        self.assertGreater(len(dirs), 1)

    ",True
156,https://github.com/ivoire/ReactOBus/blob/841d5c0442ffe92fcaec278e07053afe5b93d925/tests/test_db.py,,test_run,"def test_run(monkeypatch, tmpdir):
    zmq_instance = mock.ZMQContextInstance()
    monkeypatch.setattr(zmq.Context, ""instance"", zmq_instance)
    monkeypatch.setattr(zmq, ""Poller"", mock.ZMQPoller)

    from reactobus.db import DB, Message

    dbname = tmpdir.join(""testing.sqlite3"")
    db_url = ""sqlite:///%s"" % dbname
    db = DB({""url"": db_url}, ""inproc://test_run"")
    with pytest.raises(IndexError):
        db.run()
    sub = zmq_instance.socks[zmq.SUB]
    assert len(sub.recv) == 0
    assert sub.connected is True
    assert sub.opts == {zmq.SUBSCRIBE: b""""}

    # Test that wrong message will not make the process crash
    sub.recv = [[]]
    with pytest.raises(IndexError):
        db.run()
    assert len(sub.recv) == 0

    # Check that the db is empty
    session = db.sessions()
    assert session.query(Message).count() == 0

    # Test that wrong message will not make the process crash
    sub.recv = [
        [
            ""org.reactobus.1"",
            str(uuid.uuid1()),
            datetime.datetime.utcnow().isoformat(),
            ""lavaserver"",
            json.dumps({}),
        ],
        [
            ""org.reactobus.2"",
            str(uuid.uuid1()),
            datetime.datetime.utcnow().isoformat(),
            ""lavaserver"",
            json.dumps({}),
        ],
        [
            ""org.reactobus.3"",
            str(uuid.uuid1()),
            datetime.datetime.utcnow().isoformat(),
            ""lavaserver"",
            json.dumps({}),
        ],
        [
            ""org.reactobus.4"",
            str(uuid.uuid1()),
            ""2016/01/01"",
            ""lavaserver"",
            json.dumps({}),
        ],
        [
            ""org.reactobus.5"",
            str(uuid.uuid1()),
            datetime.datetime.utcnow().isoformat(),
            ""lavaserver"",
            json.dumps({}),
        ],
    ]
    with pytest.raises(IndexError):
        db.run()
    # Force the databse flush
    db.save_to_db()
    assert len(sub.recv) == 0

    # Check that the db is empty
    session = db.sessions()
    assert session.query(Message).count() == 4
    assert session.query(Message).get(1).topic == ""org.reactobus.1""
    assert session.query(Message).get(2).topic == ""org.reactobus.2""
    assert session.query(Message).get(3).topic == ""org.reactobus.3""
    assert session.query(Message).get(4).topic == ""org.reactobus.5""


class SessionMock(object):
    ",True
157,https://github.com/holzkohlengrill/SCout/blob/8fd1eca0607b27d6e0c537b2ea1211d23356edff/tests/test_header.py,TestHeaderLogger,testSingleArg,"def testSingleArg(self):
        singleHeader = sc().header(TEXTSINGLE, symbol=""/"", disableColour=True)
        self.assertMultiLineEqual(HEADEROUTPUT_EXPECTED, singleHeader)


",True
158,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_bad_table_id_err,"def test_bad_table_id_err(self):
        """"""Test an InvalidObjId exception is raised for a made up Id""""""

        self.assertRaises(InvalidTableId, self.test_class.load_table, 'fake_id')

    ",False
159,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_cache_not_mutated,"def test_cache_not_mutated(self):
        """"""Test mutating returned tables does not mutate them in the cache""""""

        table_names = self.test_class.get_available_tables()
        if len(table_names) == 0:
            self.fail('No available Tables')

        table_id = table_names[0]
        original_table = self.test_class.load_table(table_id)
        original_table_len = len(original_table)
        original_table.remove_row(0)
        new_table = self.test_class.load_table(table_id)

        self.assertEqual(
            original_table_len, len(new_table),
            'Table length was mutated in memory')

    ",False
160,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_jd_time_format,"def test_jd_time_format(self):
        """"""Test time values are specified as julian dates when formatting
        for sncosmo.
        """"""

        col_name = self.date_col_name
        test_id = self.test_class.get_available_ids()[0]
        test_data = self.test_class.get_data_for_id(test_id, format_table=True)
        is_greater = np.greater(test_data[col_name], 275300.5).all()
        self.assertTrue(is_greater)

    ",False
161,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_minimal_metadata_keys,"def test_minimal_metadata_keys(self):
        """"""Test data table metadata has the expected minimum data
        ('obj_id', 'ra', 'dec', 'z', 'z_err')
        """"""

        test_id = self.test_class.get_available_ids()[0]
        test_data = self.test_class.get_data_for_id(test_id)
        for key in ['obj_id', 'ra', 'dec', 'z', 'z_err']:
            self.assertIn(key, test_data.meta)

    ",False
162,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_no_duplicate_aliases,"def test_no_duplicate_aliases(self):
        """"""Test column names do not have duplicate sncosmo aliases""""""

        test_id = self.test_class.get_available_ids()[0]
        test_data = self.test_class.get_data_for_id(test_id, format_table=True)

        sncosmo.utils.alias_map(
            test_data.colnames,
            sncosmo.photdata.PHOTDATA_ALIASES,
            required=sncosmo.photdata.PHOTDATA_REQUIRED_ALIASES)

    ",False
163,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_no_empty_data_tables,"def test_no_empty_data_tables(self, lim: int = 25):
        """"""Test for empty tables in ``iter_data``

        Args:
            lim: Maximum number of tables to check (default: 25)
        """"""

        i = -1
        for i, input_table in enumerate(self.test_class.iter_data()):
            if i >= lim:
                return

            obj_id = input_table.meta['obj_id']
            self.assertTrue(
                input_table,
                msg=f'Empty table for obj_id {obj_id}.')

        if i < 0:
            self.fail('No data yielded')

    ",False
164,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_paper_tables_are_parsed,"def test_paper_tables_are_parsed(self):
        """"""Test no errors are raised by ``load_table`` when parsing any of the
        table numbers returned by ``get_available_tables``
        """"""

        table_names = self.test_class.get_available_tables()
        if len(table_names) == 0:
            self.fail('No available Tables')

        err_msg = 'Empty table number {}'
        for table in table_names:
            try:
                table = self.test_class.load_table(table)

            except:
                self.fail(f'Cannot parse table {table}')

            self.assertTrue(table, err_msg.format(table))

    ",False
165,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_sncosmo_registered_band_names,"def test_sncosmo_registered_band_names(self):
        """"""Test registered bands do have the correct name""""""

        self.test_class.register_filters(force=True)
        for band_name in self.test_class.band_names:
            sncosmo_band = sncosmo.get_bandpass(band_name)
            self.assertEqual(band_name, sncosmo_band.name)
",False
166,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_standard_column_names,"def test_standard_column_names(self):
        """"""Test columns required by sncosmo are included in formatted tables

        Columns checked to exist include:
            'time', 'band', 'flux', 'fluxerr', 'zp', 'zpsys'
        """"""

        test_id = self.test_class.get_available_ids()[0]
        test_data = self.test_class.get_data_for_id(test_id, format_table=True)

        expected_cols = ('time', 'band', 'flux', 'fluxerr', 'zp', 'zpsys')
        for column in expected_cols:
            self.assertIn(column, test_data.colnames)

    ",False
167,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sdss.py,Sako18Parsing,test_unique_ids,"def test_unique_ids(self):
        """"""Test all object Ids are unique""""""

        obj_ids = self.test_class.get_available_ids()
        unique_elements, count = np.unique(obj_ids, return_counts=True, axis=0)
        duplicates = unique_elements[count > 1]
        self.assertTrue(len(duplicates) == 0, f'Duplicate Ids: {duplicates}')

    ",False
168,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sweetspot.py,DR1Parsing,test_bad_table_id_err,"def test_bad_table_id_err(self):
        """"""Test an InvalidObjId exception is raised for a made up Id""""""

        self.assertRaises(InvalidTableId, self.test_class.load_table, 'fake_id')

    ",False
169,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sweetspot.py,DR1Parsing,test_get_zp,"def test_get_zp(self):
        """"""Test that ``sndata.get_zp`` returns the correct zero point""""""

        returned_zp = [get_zp(b) for b in self.test_class.band_names]
        actual_zp = self.test_class.zero_point
        self.assertSequenceEqual(actual_zp, returned_zp)

    # Overwrites parent class method
    ",False
170,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sweetspot.py,DR1Parsing,test_minimal_metadata_keys,"def test_minimal_metadata_keys(self):
        """"""Test data table metadata has the expected minimum data
        ('obj_id', 'ra', 'dec', 'z', 'z_err')
        """"""

        test_id = self.test_class.get_available_ids()[0]
        test_data = self.test_class.get_data_for_id(test_id)
        for key in ['obj_id', 'ra', 'dec', 'z', 'z_err']:
            self.assertIn(key, test_data.meta)

    ",False
171,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sweetspot.py,DR1Parsing,test_no_empty_data_tables,"def test_no_empty_data_tables(self, lim: int = 25):
        """"""Test for empty tables in ``iter_data``

        Args:
            lim: Maximum number of tables to check (default: 25)
        """"""

        i = -1
        for i, input_table in enumerate(self.test_class.iter_data()):
            if i >= lim:
                return

            obj_id = input_table.meta['obj_id']
            self.assertTrue(
                input_table,
                msg=f'Empty table for obj_id {obj_id}.')

        if i < 0:
            self.fail('No data yielded')

    ",False
172,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sweetspot.py,DR1Parsing,test_no_empty_ids,"def test_no_empty_ids(self):
        """"""Test no object Ids are empty strings""""""

        self.assertNotIn('', self.test_class.get_available_ids())

    ",False
173,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_sweetspot.py,DR1Parsing,test_sncosmo_registered_band_names,"def test_sncosmo_registered_band_names(self):
        """"""Test registered bands do have the correct name""""""

        self.test_class.register_filters(force=True)
        for band_name in self.test_class.band_names:
            sncosmo_band = sncosmo.get_bandpass(band_name)
            self.assertEqual(band_name, sncosmo_band.name)
",False
174,https://github.com/djperrefort/SNData/blob/e4854f0dc357484b437b15f9dac15f7c589eff58/tests/test_combined_datasets.py,CombinedDataStringIDs,test_duplicate_obj_id_strings,"def test_duplicate_obj_id_strings(self):
        """"""Test an error is raised for non unique string Ids""""""

        dummy_release = csp.DR3()
        dummy_release.release = '234'
        combined_data = CombinedDataset(csp.DR3(), dummy_release)
        with self.assertRaises(RuntimeError):
            combined_data.get_data_for_id('2010ae')


class MapReduction(TestCase):
    """"""Tests for the _reduce_id_mapping function""""""

    ",False
175,https://github.com/irmen/Tale/blob/a2a26443465ab6978b32d9253e833471500e7b68/tests/test_mudobjects.py,TestLiving,test_move_notify,"def test_move_notify(self):
        class LocationNotify(Location):
            ",False
176,https://github.com/irmen/Tale/blob/a2a26443465ab6978b32d9253e833471500e7b68/tests/test_pubsub.py,TestPubsub,test_idletime,"def test_idletime(self):
        sync()
        s = topic(""testA"")
        self.assertLess(s.idle_time, 0.1)
        time.sleep(0.2)
        self.assertGreater(s.idle_time, 0.1)
        s.send(""event"")
        self.assertLess(s.idle_time, 0.1)


",True
177,https://github.com/irmen/Tale/blob/a2a26443465ab6978b32d9253e833471500e7b68/tests/test_pubsub.py,TestPubsub,test_unsubscribe_all,"def test_unsubscribe_all(self):
        s1 = topic(""testA"")
        s2 = topic(""testB"")
        s3 = topic(""testC"")
        subber = Subber(""sub1"")
        s1.subscribe(subber)
        s2.subscribe(subber)
        s3.subscribe(subber)
        s1.send(""one"")
        s2.send(""two"")
        s3.send(""three"")
        sync()
        self.assertEqual({('testA', 'one'), ('testB', 'two'), ('testC', 'three')}, set(subber.messages))
        subber.clear()
        unsubscribe_all(subber)
        unsubscribe_all(subber)
        s1.send(""one"")
        s2.send(""two"")
        s3.send(""three"")
        sync()
        self.assertEqual([], subber.messages)

    ",True
178,https://github.com/vilkasgroup/Verifone/blob/5509c08767a9b482cfe5a9572854cf4c73ad6c02/tests/test_verifone.py,TestVerifone,test_001_create_object_with_defaults,"def test_001_create_object_with_defaults(self):
        """""" Test creating a new object with default values """"""
        self.assertTrue(self._verifone_client._currency == ""EUR"")
        self.assertTrue(self._verifone_client._test_mode == 0)

    ",True
179,https://github.com/openworm/YAROM/blob/cd4fb6cb8fac72a198858225ce89ad8b9c9175fd/tests/test_mapper.py,MapperTest,test_children_are_added,"def test_children_are_added(self):
        """""" Ensure that, on registration, children are added """"""
        cls = MappedClass(""TestDOM"", (self.DataObject,), dict())
        self.mapper.add_class(cls)
        self.assertIn(
            cls,
            self.DataObject.children,
            msg=""The test class is a child"")

    ",True
180,https://github.com/openworm/YAROM/blob/cd4fb6cb8fac72a198858225ce89ad8b9c9175fd/tests/test_mapper.py,MapperTest,test_children_are_deregistered,"def test_children_are_deregistered(self):
        """""" Ensure that, on deregistration, DataObject types are cleared from
            the module namespace
        """"""
        self.mapper.deregister_all()
        self.assertEqual(len(self.mapper.MappedClasses), 0,
                         msg=""No mapped classes"")
",True
181,https://github.com/openworm/YAROM/blob/cd4fb6cb8fac72a198858225ce89ad8b9c9175fd/tests/test_mapper.py,MapperTest,test_object_from_id_class,"def test_object_from_id_class(self):
        """""" Ensure we get an object from just the class name """"""
        dc = MappedClass(""TestDOM"", (self.DataObject,), dict())
        self.mapper.add_class(dc)
        self.mapper.remap()
        g = self.mapper.oid(dc.rdf_type)
        self.assertIsInstance(g, dc)

    ",True
182,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_no_implementation_deleter,"def test_implements_no_implementation_deleter():
    """"""
    Case: do not implement interface member that is deleter.
    Expect: class does not implement interface member error message.
    """"""
    class HumanNameInterface:

        @property
        ",True
183,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_no_implementation_getter,"def test_implements_no_implementation_getter():
    """"""
    Case: do not implement interface member that is getter.
    Expect: class does not implement interface member error message.
    """"""
    class HumanNameInterface:

        @property
        ",True
184,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_no_implementation_instance_method,"def test_implements_no_implementation_instance_method():
    """"""
    Case: do not implement interface member that is method.
    Expect: class does not implement interface member error message.
    """"""
    class HumanBasicsInterface:

        ",True
185,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_no_implementation_setter,"def test_implements_no_implementation_setter():
    """"""
    Case: do not implement interface member that is setter.
    Expect: class does not implement interface member error message.
    """"""
    class HumanNameInterface:

        @property
        ",True
186,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_no_implementation_static_method,"def test_implements_no_implementation_static_method():
    """"""
    Case: do not implement interface member that is static method.
    Expect: class does not implement interface member error message.
    """"""
    class HumanBasicsInterface:

        @staticmethod
        ",True
187,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_not_cls_convention,"def test_implements_not_cls_convention():
    """"""
    Case: do not implement interface member, which do not follow naming convention, that is class method.
    Expect: class does not implement interface member error message.
    """"""
    class HumanBasicsInterface:

        @classmethod
        ",True
188,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_not_self_convention,"def test_implements_not_self_convention():
    """"""
    Case: do not implement interface member, which do not follow naming convention.
    Expect: class does not implement interface member error message.
    """"""
    class HumanBasicsInterface:

        ",True
189,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_not_self_convention_in_deleter,"def test_implements_not_self_convention_in_deleter():
    """"""
    Case: do not implement interface member, which do not follow naming convention, that is deleter.
    Expect: class does not implement interface member error message.
    """"""
    class HumanNameInterface:

        @property
        ",True
190,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_not_self_convention_in_getter,"def test_implements_not_self_convention_in_getter():
    """"""
    Case: do not implement interface member, which do not follow naming convention, that is getter.
    Expect: class does not implement interface member error message.
    """"""
    class HumanNameInterface:

        @property
        ",True
191,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_implements_not_self_convention_in_setter,"def test_implements_not_self_convention_in_setter():
    """"""
    Case: do not implement interface member, which do not follow naming convention, that is setter.
    Expect: class does not implement interface member error message.
    """"""
    class HumanNameInterface:

        @property
        ",True
192,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_not_implements_private_access,"def test_not_implements_private_access():
    """"""
    Case: do not implement interface member with mismatched private access.
    Expect: class mismatches interface member access modifier error message.
    """"""
    class HumanSoulInterface:

        @private
        @staticmethod
        @custom_decorator
        ",True
193,https://github.com/dmytrostriletskyi/accessify/blob/6b7cf8657ffe18cd6a43c6cfb73b071084f0331e/tests/interfaces/test_implements.py,,test_not_implements_protected_access,"def test_not_implements_protected_access():
    """"""
    Case: do not implement interface member with mismatched protected access.
    Expect: class mismatches interface member access modifier error message.
    """"""
    class HumanSoulInterface:

        @protected
        @classmethod
        @custom_decorator
        ",True
194,https://github.com/mswart/acme-mgmtserver/blob/c3a0d90f80ced8724515e7bbec3764b16581e5b6/tests/test_config.py,,test_error_on_option_without_section,"def test_error_on_option_without_section():
    with pytest.warns(config.UnusedOptionWarning) as w:
        parse('''
            acme-server = https://acme.example.org/directory
            [account]
            [mgmt]
            ''')
    assert 'acme-server' in str(w[-1].message)
    assert 'https://acme.example.org/directory' in str(w[-1].message)


",False
195,https://github.com/netedgeplus/aiobfd/blob/090122474d5bf6266393f0908c13be5812fdb1c3/tests/test_session.py,,test_sess_rx_interval_get,"def test_sess_rx_interval_get(session):
    """"""Attempt to get the Required Min Rx Interval""""""
    assert session.required_min_rx_interval == 1000000


",False
196,https://github.com/dmarkey/aiopylimit/blob/b4075a8ac30dbbef59a2243f618a35a2f54b590c/aiopylimit/tests/test_aiopylimit.py,TestPyLimit,test_exception,"def test_exception(self):
        limit = AIOPyRateLimit(10, 10)
        await self.assertAsyncRaises(AIOPyRateLimitException,
                                     limit.attempt('test_namespace'))

    async ",True
197,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/memory/test_delay.py,,test_memory_delay_add_task_non_coroutine_as_input,"def test_memory_delay_add_task_non_coroutine_as_input(event_loop):
    import logging

    logger = logging.getLogger(""aiotasks"")

    class CustomLogger(logging.StreamHandler):
        ",True
198,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/memory/test_delay.py,,test_memory_delay_task_decorator_invalid_function,"def test_memory_delay_task_decorator_invalid_function(event_loop):

    import logging

    logger = logging.getLogger(""aiotasks"")

    class CustomLogger(logging.StreamHandler):

        ",True
199,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/memory/test_delay.py,,test_memory_delay_task_decorator_invalid_task_id_format,"def test_memory_delay_task_decorator_invalid_task_id_format(event_loop):

    import random
    import logging

    logger = logging.getLogger(""aiotasks"")

    class CustomLogger(logging.StreamHandler):

        ",True
200,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/memory/test_subscribers.py,,test_memory_subscribers_empty_topics,"def test_memory_subscribers_empty_topics(event_loop):
    import logging

    logger = logging.getLogger(""aiotasks"")

    class CustomLogger(logging.StreamHandler):
        ",True
201,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/redis/test_delay.py,,test_redis_delay_add_task_non_coroutine_as_input,"def test_redis_delay_add_task_non_coroutine_as_input(event_loop, redis_instance):
    import logging

    logger = logging.getLogger(""aiotasks"")

    class CustomLogger(logging.StreamHandler):
        ",False
202,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/redis/test_delay.py,,test_redis_delay_task_decorator_invalid_function,"def test_redis_delay_task_decorator_invalid_function(event_loop, redis_instance):

    import logging

    logger = logging.getLogger(""aiotasks"")

    class CustomLogger(logging.StreamHandler):

        ",False
203,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/redis/test_delay.py,,test_redis_delay_task_decorator_invalid_task_id_format,"def test_redis_delay_task_decorator_invalid_task_id_format(event_loop, redis_instance):

    import random
    import logging

    logger = logging.getLogger(""aiotasks"")

    class CustomLogger(logging.StreamHandler):

        ",False
204,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/redis/test_delay.py,,test_redis_delay_task_decorator_no_port_gotten,"def test_redis_delay_task_decorator_no_port_gotten(event_loop, redis_instance):

    _redis_instance, _ = redis_instance.rsplit("":"", maxsplit=1)

    manager = build_manager(dsn=_redis_instance, loop=event_loop)

    globals()[""test_redis_delay_task_decorator_no_port_gotten_finished""] = False

    @manager.task()
    async ",False
205,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/redis/test_subscribers.py,,test_redis_subscribers_empty_topics,"def test_redis_subscribers_empty_topics(event_loop, redis_instance):
    import logging

    logger = logging.getLogger(""aiotasks"")

    class CustomLogger(logging.StreamHandler):
        ",False
206,https://github.com/cr0hn/aiotasks/blob/ec485c84db55227c9283319a9c58401e294a06ff/tests/unittesting/tasks/test_base_async.py,,test_build_manager_invalid_prefix,"def test_build_manager_invalid_prefix(event_loop):
    import logging
    
    logger = logging.getLogger(""aiotasks"")
    
    class CustomLogger(logging.StreamHandler):
        ",True
207,https://github.com/ylaizet/alphanum_code/blob/fb5cd313dc41f046aac01ff01d6e1561d17894a6/tests/test_alphanum_code.py,,test_init_code,"def test_init_code(coder):
    code = coder.next_code(""init code test"")
    assert code == INIT_CODE


",True
208,https://github.com/ylaizet/alphanum_code/blob/fb5cd313dc41f046aac01ff01d6e1561d17894a6/tests/test_alphanum_code.py,,test_next_code,"def test_next_code(coder):
    coder.next_code()
    code = coder.next_code(""next code test"")
    assert code == ""52ZA1""
",True
209,https://github.com/sjoerdk/anonapi/blob/5e70dfd9fcb7dcc4e2345a6a153d9530f4886e73/tests/test_cli_create.py,,test_job_parameter_set,"def test_job_parameter_set(all_parameters):
    """"""Map Parameter objects to their parameter names in job-creation functions""""""
    mapped = JobParameterSet(all_parameters).as_kwargs()
    assert mapped[""anon_name""] == ""patientName0""

    # sending an unknown parameter will raise an exception
    class UnknownIdentifier(SourceIdentifier):
        pass

    with pytest.raises(ParameterMappingException):
        JobParameterSet(
            all_parameters + [SourceIdentifierParameter(str(UnknownIdentifier(None)))]
        ).as_kwargs()

    class UnknownParameter(Parameter):
        pass

    with pytest.raises(ParameterMappingException):
        JobParameterSet(all_parameters + [UnknownParameter()]).as_kwargs()


",True
210,https://github.com/datacommonsorg/api-python/blob/6d09ca1557da0af893f008f7302801f12afc2d46/datacommons/test/set_api_key_test.py,TestApiKey,test_query_no_api_key,"def test_query_no_api_key(self, urlopen):
    del os.environ[utils._ENV_VAR_API_KEY]
    # Issue a dummy SPARQL query that tells the mock to not expect a key
    self.assertEqual(dc.query(_SPARQL_NO_KEY), [])

  @mock.patch('six.moves.urllib.request.urlopen', side_effect=request_mock)
  ",True
211,https://github.com/datacommonsorg/api-python/blob/6d09ca1557da0af893f008f7302801f12afc2d46/datacommons/test/set_api_key_test.py,TestApiKey,test_send_request_no_api_key,"def test_send_request_no_api_key(self, urlopen):
    del os.environ[utils._ENV_VAR_API_KEY]
    # Issue a dummy url that tells the mock to not expect a key
    self.assertEqual(utils._send_request(_SEND_REQ_NO_KEY, {'foo': ['bar']}), {})

  @mock.patch('six.moves.urllib.request.urlopen', side_effect=request_mock)
  ",True
212,https://github.com/hyperledger/aries-staticagent-python/blob/62f0e4e435e4e324f76a8fb724d0f733192bc0c3/tests/test_pack_unpack.py,,test_pack_unpack_anon,"def test_pack_unpack_anon(alice, bob):
    """""" Test the pack-unpack loop with anoncrypt. """"""
    msg = {'@type': 'doc;protocol/1.0/name'}
    packed_msg = alice.pack(msg, anoncrypt=True)
    assert isinstance(packed_msg, bytes)

    unpacked_msg = bob.unpack(packed_msg)
    assert isinstance(unpacked_msg, Message)
    assert hasattr(unpacked_msg, 'mtc')
    assert unpacked_msg.mtc.is_anoncrypted()
    assert unpacked_msg.mtc.sender is None
    assert unpacked_msg.mtc.recipient == bob.verkey_b58


",True
213,https://github.com/hyperledger/aries-staticagent-python/blob/62f0e4e435e4e324f76a8fb724d0f733192bc0c3/tests/test_pack_unpack.py,,test_pack_unpack_auth,"def test_pack_unpack_auth(alice, bob):
    """""" Test the pack-unpack loop with authcrypt. """"""
    msg = Message({'@type': 'doc;protocol/1.0/name'})
    packed_msg = alice.pack(msg)
    assert isinstance(packed_msg, bytes)

    unpacked_msg = bob.unpack(packed_msg)
    assert isinstance(unpacked_msg, Message)
    assert hasattr(unpacked_msg, 'mtc')
    assert unpacked_msg.mtc.is_authcrypted()
    assert unpacked_msg.mtc.sender == alice.verkey_b58
    assert unpacked_msg.mtc.recipient == bob.verkey_b58


",True
214,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_benchmarks.py,,test_invalid_benchmark_tree,"def test_invalid_benchmark_tree(tmpdir):
    tmpdir = six.text_type(tmpdir)
    os.chdir(tmpdir)

    d = {}
    d.update(ASV_CONF_JSON)
    d['benchmark_dir'] = INVALID_BENCHMARK_DIR
    d['env_dir'] = ""env""
    d['repo'] = tools.generate_test_repo(tmpdir, [0]).path
    conf = config.Config.from_json(d)

    repo = get_repo(conf)
    envs = list(environment.get_environments(conf, None))
    commit_hash = repo.get_hash_from_name(repo.get_branch_name())

    with pytest.raises(util.UserError):
        b = benchmarks.Benchmarks.discover(conf, repo, envs, [commit_hash])


",False
215,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_check.py,,test_check,"def test_check(capsys, basic_conf):
    tmpdir, local, conf = basic_conf

    # Test check runs (with full benchmark suite)
    with pytest.raises(util.UserError, match=""Benchmark suite check failed""):
        tools.run_asv_with_conf(conf, 'check', ""--python=same"")

    text, err = capsys.readouterr()

    assert re.search(r""params_examples\.track_wrong_number_of_args: call: ""
                     r""wrong number of arguments.*: expected 1, has 2"", text)
    assert text.count(""wrong number of arguments"") == 1
",False
216,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_compare.py,,test_compare,"def test_compare(capsys, tmpdir, example_results):
    tmpdir = six.text_type(tmpdir)
    os.chdir(tmpdir)

    conf = config.Config.from_json(
        {'results_dir': example_results,
         'repo': tools.generate_test_repo(tmpdir).path,
         'project': 'asv',
         'environment_type': ""shouldn't matter what""})

    tools.run_asv_with_conf(conf, 'compare', '22b920c6', 'fcf8c079', '--machine=cheetah',
                            '--factor=2', '--environment=py2.7-numpy1.8')

    text, err = capsys.readouterr()
    assert text.strip() == REFERENCE.strip()

    tools.run_asv_with_conf(conf, 'compare', '22b920c6', 'fcf8c079', '--machine=cheetah',
                            '--factor=2', '--split', '--environment=py2.7-numpy1.8')
    text, err = capsys.readouterr()
    assert text.strip() == REFERENCE_SPLIT.strip()

    # Check print_table output as called from Continuous
    status = Compare.print_table(conf, '22b920c6', 'fcf8c079', factor=2, machine='cheetah',
                                 split=False, only_changed=True, sort='ratio',
                                 env_names=[""py2.7-numpy1.8""],
                                 commit_names={'22b920c6': 'name1', 'fcf8c079': 'name2'})
    worsened, improved = status
    assert worsened
    assert improved
    text, err = capsys.readouterr()
    assert text.strip() == REFERENCE_ONLY_CHANGED.strip()

    # Check table with multiple environments
    status = Compare.print_table(conf, '22b920c6', 'fcf8c079', factor=2, machine='cheetah',
                                 split=False, only_changed=True, sort='ratio')
    text, err = capsys.readouterr()
    assert text.strip() == REFERENCE_ONLY_CHANGED_MULTIENV.strip()

    # Check results with no stats
    tools.run_asv_with_conf(conf, 'compare', '22b920c6', 'fcf8c079', '--machine=cheetah',
                            '--factor=2', '--sort=ratio', '--environment=py2.7-numpy1.8',
                            '--no-stats', '--only-changed')
    text, err = capsys.readouterr()
    assert text.strip() == REFERENCE_ONLY_CHANGED_NOSTATS.strip()
    assert ""time_ci_big"" in text.strip()


@pytest.mark.parametrize(""dvcs_type"", [
    ""git"",
    pytest.param(""hg"", marks=pytest.mark.skipif(hglib is None, reason=""needs hglib""))
])
",False
217,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_compare.py,,test_compare_name_lookup,"def test_compare_name_lookup(dvcs_type, capsys, tmpdir, example_results):
    tmpdir = six.text_type(tmpdir)
    os.chdir(tmpdir)

    repo = tools.generate_test_repo(tmpdir, dvcs_type=dvcs_type)
    branch_name = 'master' if dvcs_type == 'git' else 'default'
    commit_hash = repo.get_branch_hashes(branch_name)[0]

    result_dir = os.path.join(tmpdir, 'results')

    src = os.path.join(example_results, 'cheetah')
    dst = os.path.join(result_dir, 'cheetah')
    os.makedirs(dst)

    for fn in ['feea15ca-py2.7-Cython-numpy1.8.json', 'machine.json']:
        shutil.copyfile(os.path.join(src, fn), os.path.join(dst, fn))

    shutil.copyfile(os.path.join(example_results, 'benchmarks.json'),
                    os.path.join(result_dir, 'benchmarks.json'))

    # Copy to different commit
    fn_1 = os.path.join(dst, 'feea15ca-py2.7-Cython-numpy1.8.json')
    fn_2 = os.path.join(dst, commit_hash[:8] + '-py2.7-Cython-numpy1.8.json')
    data = util.load_json(fn_1)
    data['commit_hash'] = commit_hash
    util.write_json(fn_2, data)

    conf = config.Config.from_json(
        {'results_dir': result_dir,
         'repo': repo.path,
         'project': 'asv',
         'environment_type': ""shouldn't matter what""})

    # Lookup with symbolic name
    tools.run_asv_with_conf(conf, 'compare', branch_name, 'feea15ca', '--machine=cheetah',
                            '--factor=2', '--environment=py2.7-Cython-numpy1.8',
                            '--only-changed')

    # Nothing should be printed since no results were changed
    text, err = capsys.readouterr()
    assert text.strip() == ''
",False
218,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_compare.py,,test_compare_name_lookup,"def test_compare_name_lookup(dvcs_type, capsys, tmpdir, example_results):
    tmpdir = six.text_type(tmpdir)
    os.chdir(tmpdir)

    repo = tools.generate_test_repo(tmpdir, dvcs_type=dvcs_type)
    branch_name = 'master' if dvcs_type == 'git' else 'default'
    commit_hash = repo.get_branch_hashes(branch_name)[0]

    result_dir = os.path.join(tmpdir, 'results')

    src = os.path.join(example_results, 'cheetah')
    dst = os.path.join(result_dir, 'cheetah')
    os.makedirs(dst)

    for fn in ['feea15ca-py2.7-Cython-numpy1.8.json', 'machine.json']:
        shutil.copyfile(os.path.join(src, fn), os.path.join(dst, fn))

    shutil.copyfile(os.path.join(example_results, 'benchmarks.json'),
                    os.path.join(result_dir, 'benchmarks.json'))

    # Copy to different commit
    fn_1 = os.path.join(dst, 'feea15ca-py2.7-Cython-numpy1.8.json')
    fn_2 = os.path.join(dst, commit_hash[:8] + '-py2.7-Cython-numpy1.8.json')
    data = util.load_json(fn_1)
    data['commit_hash'] = commit_hash
    util.write_json(fn_2, data)

    conf = config.Config.from_json(
        {'results_dir': result_dir,
         'repo': repo.path,
         'project': 'asv',
         'environment_type': ""shouldn't matter what""})

    # Lookup with symbolic name
    tools.run_asv_with_conf(conf, 'compare', branch_name, 'feea15ca', '--machine=cheetah',
                            '--factor=2', '--environment=py2.7-Cython-numpy1.8',
                            '--only-changed')

    # Nothing should be printed since no results were changed
    text, err = capsys.readouterr()
    assert text.strip() == ''
",False
219,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_conf.py,,test_load_plugin,"def test_load_plugin():
    os.chdir(dirname(__file__))

    parser, subparsers = commands.make_argparser()
    args = parser.parse_args(['custom'])

    assert hasattr(args, 'func')

    args.func(args)

    for env in util.iter_subclasses(environment.Environment):
        print(env.__name__)
        if env.__name__ == 'MyEnvironment':
            break
    else:
        assert False, ""Custom plugin not loaded""
",False
220,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_console.py,,test_color_print_nofail,"def test_color_print_nofail(capfd):
    # Try out color print

    color_print(""hello"", ""red"")
    color_print(""indeed難"", ""blue"")
    with pytest.raises(ValueError):
        color_print(b""really\xfe"", ""green"", ""not really"")

    out, err = capfd.readouterr()
    assert 'hello' in out
    assert 'indeed' in out


",False
221,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_console.py,,test_write_with_fallback,"def test_write_with_fallback(tmpdir, capfd):
    tmpdir = six.text_type(tmpdir)

    ",False
222,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_dev.py,,test_dev,"def test_dev(capsys, basic_conf):
    tmpdir, local, conf = basic_conf

    # Test Dev runs (with full benchmark suite)
    ret = tools.run_asv_with_conf(conf, 'dev', '--quick', '-e',
                                  _machine_file=join(tmpdir, 'asv-machine.json'))
    assert ret is None
    text, err = capsys.readouterr()

    # time_with_warnings failure case
    assert re.search(""File.*time_exception.*RuntimeError"", text, re.S)
    assert re.search(r""time_secondary.track_value\s+42.0"", text)

    # Check that it did not clone or install
    assert ""Cloning"" not in text
    assert ""Installing"" not in text


",False
223,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_dev.py,,test_dev_strict,"def test_dev_strict(basic_conf):
    tmpdir, local, conf = basic_conf
    ret = tools.run_asv_with_conf(conf, 'dev', '--strict', '--quick',
                                  '--bench=TimeSecondary',
                                  _machine_file=join(tmpdir, 'asv-machine.json'))
    assert ret == 2


",False
224,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_dev.py,,test_dev_with_repo_subdir,"def test_dev_with_repo_subdir(capsys, basic_conf_with_subdir):
    """"""
    Same as test_dev, but with the Python project inside a subdirectory.
    """"""
    tmpdir, local, conf = basic_conf_with_subdir

    # Test Dev runs
    tools.run_asv_with_conf(conf, 'dev', '--quick',
                            '--bench=time_secondary.track_value',
                            _machine_file=join(tmpdir, 'asv-machine.json'))
    text, err = capsys.readouterr()

    # Benchmarks were found and run
    assert re.search(r""time_secondary.track_value\s+42.0"", text)

    # Check that it did not clone or install
    assert ""Cloning"" not in text
    assert ""Installing"" not in text


",False
225,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_dev.py,,test_profile_python_same,"def test_profile_python_same(capsys, basic_conf):
    tmpdir, local, conf = basic_conf

    # Test Profile can run with python=same
    tools.run_asv_with_conf(conf, 'profile', '--python=same', ""time_secondary.track_value"",
                            _machine_file=join(tmpdir, 'asv-machine.json'))
    text, err = capsys.readouterr()

    # time_with_warnings failure case
    assert re.search(r""^\s+1\s+.*time_secondary.*\(track_value\)"", text, re.M)

    # Check that it did not clone or install
    assert ""Cloning"" not in text
    assert ""Installing"" not in text


",False
226,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_dev.py,,test_run_python_same,"def test_run_python_same(capsys, basic_conf):
    tmpdir, local, conf = basic_conf

    # Test Run runs with python=same
    tools.run_asv_with_conf(conf, 'run', '--python=same',
                            '--bench=time_secondary.TimeSecondary.time_exception',
                            '--bench=time_secondary.track_value',
                            _machine_file=join(tmpdir, 'asv-machine.json'))
    text, err = capsys.readouterr()

    assert re.search(""time_exception.*failed"", text, re.S)
    assert re.search(r""time_secondary.track_value\s+42.0"", text)

    # Check that it did not clone or install
    assert ""Cloning"" not in text
    assert ""Installing"" not in text


",False
227,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_environment.py,,test_environment_env_matrix,"def test_environment_env_matrix():
    # (build_vars, non_build_vars, environ_count, build_count)
    configs = [
        ({}, {}, 1, 1),
        ({""var1"": [""val1""]}, {}, 1, 1),
        ({""var1"": [""val1"", ""val2"", ""val3""]}, {}, 3, 3),
        ({""var1"": [""val1"", ""val2""], ""var2"": ['val3', 'val4']}, {}, 4, 4),
        ({""var1"": [""val1"", ""val2""], ""var2"": ['val3', None]}, {}, 4, 4),
        ({""var1"": [""val1"", ""val2""]}, {""var2"": ['val3', None]}, 4, 2),
        ({""var1"": [""val1"", ""val2""], ""var2"": ['val3', 'val4']},
         {""var3"": ['val5', None]}, 8, 4),
    ]

    for build_vars, non_build_vars, environ_count, build_count in configs:
        conf = config.Config()

        conf.matrix = {
            ""env"": build_vars,
            ""env_nobuild"": non_build_vars,
        }
        environments = list(environment.get_environments(conf, None))

        assert len(environments) == environ_count
        assert len(set(e.dir_name for e in environments)) == build_count


",False
228,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_environment.py,,test_environment_select,"def test_environment_select():
    conf = config.Config()
    conf.environment_type = ""conda""
    conf.pythons = [""2.7"", ""3.5""]
    conf.matrix = {
        ""six"": [""1.10""],
    }
    conf.include = [
        {'environment_type': 'conda', 'python': '1.9'}
    ]

    # Check default environment config
    environments = list(environment.get_environments(conf, None))
    items = sorted([(env.tool_name, env.python) for env in environments])
    assert items == [('conda', '1.9'), ('conda', '2.7'), ('conda', '3.5')]

    if HAS_VIRTUALENV:
        # Virtualenv plugin fails on initialization if not available,
        # so these tests pass only if virtualenv is present

        conf.pythons = [PYTHON_VER1]

        # Check default python specifiers
        environments = list(environment.get_environments(conf, [""conda"", ""virtualenv""]))
        items = sorted((env.tool_name, env.python) for env in environments)
        assert items == [('conda', '1.9'), ('conda', PYTHON_VER1), ('virtualenv', PYTHON_VER1)]

        # Check specific python specifiers
        environments = list(environment.get_environments(conf, [""conda:3.5"", ""virtualenv:""+PYTHON_VER1]))
        items = sorted((env.tool_name, env.python) for env in environments)
        assert items == [('conda', '3.5'), ('virtualenv', PYTHON_VER1)]

    # Check same specifier
    environments = list(environment.get_environments(conf, [""existing:same"", "":same"", ""existing""]))
    items = [env.tool_name for env in environments]
    assert items == ['existing', 'existing', 'existing']

    # Check autodetect existing
    executable = os.path.relpath(os.path.abspath(sys.executable))
    environments = list(environment.get_environments(conf, [""existing"",
                                                            "":same"",
                                                            "":"" + executable]))
    assert len(environments) == 3
    for env in environments:
        assert env.tool_name == ""existing""
        assert env.python == ""{0[0]}.{0[1]}"".format(sys.version_info)
        assert os.path.normcase(os.path.abspath(env._executable)) == os.path.normcase(os.path.abspath(sys.executable))

    # Select by environment name
    conf.pythons = [""2.7""]
    environments = list(environment.get_environments(conf, [""conda-py2.7-six1.10""]))
    assert len(environments) == 1
    assert environments[0].python == ""2.7""
    assert environments[0].tool_name == ""conda""
    assert environments[0].requirements == {'six': '1.10'}

    # Check interaction with exclude
    conf.exclude = [{'environment_type': ""conda""}]
    environments = list(environment.get_environments(conf, [""conda-py2.7-six1.10""]))
    assert len(environments) == 0

    conf.exclude = [{'environment_type': 'matches nothing'}]
    environments = list(environment.get_environments(conf, [""conda-py2.7-six1.10""]))
    assert len(environments) == 1


",False
229,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_environment.py,,test_matrix_empty,"def test_matrix_empty():
    conf = config.Config()
    conf.environment_type = """"
    conf.pythons = [PYTHON_VER1]
    conf.matrix = {}

    # Check default environment config
    environments = list(environment.get_environments(conf, None))
    items = [env.python for env in environments]
    assert items == [PYTHON_VER1]


",False
230,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_gh_pages.py,,test_gh_pages,"def test_gh_pages(rewrite, tmpdir, generate_result_dir, monkeypatch):
    tmpdir = os.path.abspath(six.text_type(tmpdir))

    monkeypatch.setenv(str('EMAIL'), str('test@asv'))
    monkeypatch.setenv(str('GIT_COMMITTER_NAME'), str('asv test'))
    monkeypatch.setenv(str('GIT_AUTHOR_NAME'), str('asv test'))

    conf, repo, commits = generate_result_dir([1, 2, 3, 4])

    dvcs_dir = os.path.join(tmpdir, 'repo1')
    dvcs_dir2 = os.path.join(tmpdir, 'repo2')

    os.makedirs(dvcs_dir)

    os.chdir(dvcs_dir)

    dvcs = tools.Git(dvcs_dir)
    dvcs.init()

    open(os.path.join(dvcs_dir, 'dummy'), 'wb').close()

    dvcs.add('dummy')
    dvcs.commit('Initial commit')

    if rewrite:
        rewrite_args = (""--rewrite"",)
    else:
        rewrite_args = ()

    # Check with no existing gh-pages branch, no push
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
    assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == 1
    dvcs.checkout('master')
    assert not os.path.isfile(os.path.join(dvcs_dir, 'index.html'))

    # Check with existing (and checked out) gh-pages branch, with no changes
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
    if rewrite:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == 1
    else:
        # Timestamp may have changed
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) <= 2
    dvcs.checkout('master')

    # Check with existing (not checked out) gh-pages branch, with some changes
    benchmarks_json = os.path.join(conf.results_dir, 'benchmarks.json')
    data = asv.util.load_json(benchmarks_json)
    data['time_func']['pretty_name'] = 'something changed'
    asv.util.write_json(benchmarks_json, data)

    prev_len = len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines())
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    if not rewrite:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == prev_len + 1
    else:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == prev_len

    # Check that the push option works
    dvcs.run_git(['branch', '-D', 'gh-pages'])
    dvcs.run_git(['clone', dvcs_dir, dvcs_dir2])

    os.chdir(dvcs_dir2)
    tools.run_asv_with_conf(conf, ""gh-pages"", *rewrite_args)

    os.chdir(dvcs_dir)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
",False
231,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_gh_pages.py,,test_gh_pages,"def test_gh_pages(rewrite, tmpdir, generate_result_dir, monkeypatch):
    tmpdir = os.path.abspath(six.text_type(tmpdir))

    monkeypatch.setenv(str('EMAIL'), str('test@asv'))
    monkeypatch.setenv(str('GIT_COMMITTER_NAME'), str('asv test'))
    monkeypatch.setenv(str('GIT_AUTHOR_NAME'), str('asv test'))

    conf, repo, commits = generate_result_dir([1, 2, 3, 4])

    dvcs_dir = os.path.join(tmpdir, 'repo1')
    dvcs_dir2 = os.path.join(tmpdir, 'repo2')

    os.makedirs(dvcs_dir)

    os.chdir(dvcs_dir)

    dvcs = tools.Git(dvcs_dir)
    dvcs.init()

    open(os.path.join(dvcs_dir, 'dummy'), 'wb').close()

    dvcs.add('dummy')
    dvcs.commit('Initial commit')

    if rewrite:
        rewrite_args = (""--rewrite"",)
    else:
        rewrite_args = ()

    # Check with no existing gh-pages branch, no push
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
    assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == 1
    dvcs.checkout('master')
    assert not os.path.isfile(os.path.join(dvcs_dir, 'index.html'))

    # Check with existing (and checked out) gh-pages branch, with no changes
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
    if rewrite:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == 1
    else:
        # Timestamp may have changed
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) <= 2
    dvcs.checkout('master')

    # Check with existing (not checked out) gh-pages branch, with some changes
    benchmarks_json = os.path.join(conf.results_dir, 'benchmarks.json')
    data = asv.util.load_json(benchmarks_json)
    data['time_func']['pretty_name'] = 'something changed'
    asv.util.write_json(benchmarks_json, data)

    prev_len = len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines())
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    if not rewrite:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == prev_len + 1
    else:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == prev_len

    # Check that the push option works
    dvcs.run_git(['branch', '-D', 'gh-pages'])
    dvcs.run_git(['clone', dvcs_dir, dvcs_dir2])

    os.chdir(dvcs_dir2)
    tools.run_asv_with_conf(conf, ""gh-pages"", *rewrite_args)

    os.chdir(dvcs_dir)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
",False
232,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_gh_pages.py,,test_gh_pages,"def test_gh_pages(rewrite, tmpdir, generate_result_dir, monkeypatch):
    tmpdir = os.path.abspath(six.text_type(tmpdir))

    monkeypatch.setenv(str('EMAIL'), str('test@asv'))
    monkeypatch.setenv(str('GIT_COMMITTER_NAME'), str('asv test'))
    monkeypatch.setenv(str('GIT_AUTHOR_NAME'), str('asv test'))

    conf, repo, commits = generate_result_dir([1, 2, 3, 4])

    dvcs_dir = os.path.join(tmpdir, 'repo1')
    dvcs_dir2 = os.path.join(tmpdir, 'repo2')

    os.makedirs(dvcs_dir)

    os.chdir(dvcs_dir)

    dvcs = tools.Git(dvcs_dir)
    dvcs.init()

    open(os.path.join(dvcs_dir, 'dummy'), 'wb').close()

    dvcs.add('dummy')
    dvcs.commit('Initial commit')

    if rewrite:
        rewrite_args = (""--rewrite"",)
    else:
        rewrite_args = ()

    # Check with no existing gh-pages branch, no push
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
    assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == 1
    dvcs.checkout('master')
    assert not os.path.isfile(os.path.join(dvcs_dir, 'index.html'))

    # Check with existing (and checked out) gh-pages branch, with no changes
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
    if rewrite:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == 1
    else:
        # Timestamp may have changed
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) <= 2
    dvcs.checkout('master')

    # Check with existing (not checked out) gh-pages branch, with some changes
    benchmarks_json = os.path.join(conf.results_dir, 'benchmarks.json')
    data = asv.util.load_json(benchmarks_json)
    data['time_func']['pretty_name'] = 'something changed'
    asv.util.write_json(benchmarks_json, data)

    prev_len = len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines())
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    if not rewrite:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == prev_len + 1
    else:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == prev_len

    # Check that the push option works
    dvcs.run_git(['branch', '-D', 'gh-pages'])
    dvcs.run_git(['clone', dvcs_dir, dvcs_dir2])

    os.chdir(dvcs_dir2)
    tools.run_asv_with_conf(conf, ""gh-pages"", *rewrite_args)

    os.chdir(dvcs_dir)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
",False
233,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_gh_pages.py,,test_gh_pages,"def test_gh_pages(rewrite, tmpdir, generate_result_dir, monkeypatch):
    tmpdir = os.path.abspath(six.text_type(tmpdir))

    monkeypatch.setenv(str('EMAIL'), str('test@asv'))
    monkeypatch.setenv(str('GIT_COMMITTER_NAME'), str('asv test'))
    monkeypatch.setenv(str('GIT_AUTHOR_NAME'), str('asv test'))

    conf, repo, commits = generate_result_dir([1, 2, 3, 4])

    dvcs_dir = os.path.join(tmpdir, 'repo1')
    dvcs_dir2 = os.path.join(tmpdir, 'repo2')

    os.makedirs(dvcs_dir)

    os.chdir(dvcs_dir)

    dvcs = tools.Git(dvcs_dir)
    dvcs.init()

    open(os.path.join(dvcs_dir, 'dummy'), 'wb').close()

    dvcs.add('dummy')
    dvcs.commit('Initial commit')

    if rewrite:
        rewrite_args = (""--rewrite"",)
    else:
        rewrite_args = ()

    # Check with no existing gh-pages branch, no push
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
    assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == 1
    dvcs.checkout('master')
    assert not os.path.isfile(os.path.join(dvcs_dir, 'index.html'))

    # Check with existing (and checked out) gh-pages branch, with no changes
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
    if rewrite:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == 1
    else:
        # Timestamp may have changed
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) <= 2
    dvcs.checkout('master')

    # Check with existing (not checked out) gh-pages branch, with some changes
    benchmarks_json = os.path.join(conf.results_dir, 'benchmarks.json')
    data = asv.util.load_json(benchmarks_json)
    data['time_func']['pretty_name'] = 'something changed'
    asv.util.write_json(benchmarks_json, data)

    prev_len = len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines())
    tools.run_asv_with_conf(conf, ""gh-pages"", ""--no-push"", *rewrite_args)
    if not rewrite:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == prev_len + 1
    else:
        assert len(dvcs.run_git(['rev-list', 'gh-pages']).splitlines()) == prev_len

    # Check that the push option works
    dvcs.run_git(['branch', '-D', 'gh-pages'])
    dvcs.run_git(['clone', dvcs_dir, dvcs_dir2])

    os.chdir(dvcs_dir2)
    tools.run_asv_with_conf(conf, ""gh-pages"", *rewrite_args)

    os.chdir(dvcs_dir)
    dvcs.checkout('gh-pages')
    assert os.path.isfile(os.path.join(dvcs_dir, 'index.html'))
",False
234,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_machine.py,,test_machine,"def test_machine(tmpdir):
    tmpdir = six.text_type(tmpdir)

    m = machine.Machine.load(
        interactive=False,
        machine=""orangutan"",
        os=""BeOS"",
        arch=""MIPS"",
        cpu=""10 MHz"",
        ram=""640k"",
        _path=join(tmpdir, 'asv-machine.json'))

    m = machine.Machine.load(
        _path=join(tmpdir, 'asv-machine.json'), interactive=False)

    assert m.machine == 'orangutan'
    assert m.os == 'BeOS'
    assert m.arch == 'MIPS'
    assert m.cpu == '10 MHz'
    assert m.ram == '640k'


",False
235,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_machine.py,,test_machine_defaults,"def test_machine_defaults(tmpdir):
    tmpdir = six.text_type(tmpdir)

    m = machine.Machine.load(
        interactive=True,
        use_defaults=True,
        _path=join(tmpdir, 'asv-machine.json'))

    assert m.__dict__ == m.get_defaults()
",False
236,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_publish.py,,test_publish,"def test_publish(tmpdir, example_results):
    tmpdir = six.text_type(tmpdir)
    os.chdir(tmpdir)

    result_dir = join(tmpdir, 'sample_results')
    os.makedirs(result_dir)
    os.makedirs(join(result_dir, 'cheetah'))

    # Synthesize history with two branches that both have commits
    result_files = [fn for fn in os.listdir(join(example_results, 'cheetah'))
                    if fn.endswith('.json') and fn != 'machine.json']
    result_files.sort()
    master_values = list(range(len(result_files)*2//3))
    branch_values = list(range(len(master_values), len(result_files)))
    dvcs = tools.generate_test_repo(tmpdir, master_values, 'git',
                                    [('master~6', 'some-branch', branch_values)])

    # Copy and modify result files, fixing commit hashes and setting result
    # dates to distinguish the two branches
    master_commits = dvcs.get_branch_hashes('master')
    only_branch = [x for x in dvcs.get_branch_hashes('some-branch')
                   if x not in master_commits]
    commits = master_commits + only_branch
    for k, item in enumerate(zip(result_files, commits)):
        fn, commit = item
        src = join(example_results, 'cheetah', fn)
        dst = join(result_dir, 'cheetah', commit[:8] + fn[8:])
        try:
            data = util.load_json(src)
        except util.UserError:
            # intentionally malformed file, ship it as is
            shutil.copyfile(src, dst)
            continue
        data['commit_hash'] = commit
        util.write_json(dst, data)

    shutil.copyfile(join(example_results, 'benchmarks.json'),
                    join(result_dir, 'benchmarks.json'))
    shutil.copyfile(join(example_results, 'cheetah', 'machine.json'),
                    join(result_dir, 'cheetah', 'machine.json'))

    # Publish the synthesized data
    conf = config.Config.from_json(
        {'benchmark_dir': BENCHMARK_DIR,
         'results_dir': result_dir,
         'html_dir': join(tmpdir, 'html'),
         'repo': dvcs.path,
         'project': 'asv'})

    tools.run_asv_with_conf(conf, 'publish')

    # Check output
    assert isfile(join(tmpdir, 'html', 'index.html'))
    assert isfile(join(tmpdir, 'html', 'index.json'))
    assert isfile(join(tmpdir, 'html', 'asv.js'))
    assert isfile(join(tmpdir, 'html', 'asv.css'))
    assert not isdir(join(tmpdir, 'html', 'graphs', 'Cython', 'arch-x86_64',
                          'branch-some-branch'))
    assert not isdir(join(tmpdir, 'html', 'graphs', 'Cython-null', 'arch-x86_64',
                          'branch-some-branch'))
    index = util.load_json(join(tmpdir, 'html', 'index.json'))
    assert index['params']['branch'] == ['master']

    repo = get_repo(conf)
    revision_to_hash = dict((r, h) for h, r in six.iteritems(repo.get_revisions(commits)))

    ",False
237,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_publish.py,,test_publish_range_spec,"def test_publish_range_spec(generate_result_dir):
    conf, repo, commits = generate_result_dir(5 * [1])
    for range_spec, expected in (
        ([commits[0], commits[-1]], set([commits[0], commits[-1]])),
        ('HEAD~2..HEAD' if repo.dvcs == 'git' else '.~1:',
            set(commits[-2:])),
    ):
        tools.run_asv_with_conf(conf, ""publish"", range_spec)
        data = util.load_json(join(conf.html_dir, 'index.json'))
        assert set(data['revision_to_hash'].values()) == expected


",False
238,https://github.com/airspeed-velocity/asv/blob/a131ca742daf53c4521fbfefeb53507b5c140c84/test/test_util.py,,test_parallelfailure,"def test_parallelfailure():
    # Check the workaround for https://bugs.python.org/issue9400 works

    if WIN and os.path.basename(sys.argv[0]).lower().startswith('py.test'):
        # Multiprocessing in spawn mode can result to problems with py.test
        pytest.skip(""Multiprocessing spawn mode on Windows not safe to run ""
                    ""from py.test runner."")

    # The exception class must be pickleable
    exc = util.ParallelFailure(""test"", Exception, ""something"")
    exc2 = pickle.loads(pickle.dumps(exc))
    assert exc.message == exc2.message
    assert exc.exc_cls == exc2.exc_cls
    assert exc.traceback_str == exc2.traceback_str
    assert str(exc) == ""Exception: test\n    something""

    # Check multiprocessing does not hang (it would hang on Python
    # 2.7.8 if the 'raise utill.ParallelFailure ...' above is changed
    # to just 'raise')
    pool = multiprocessing.Pool(4)
    try:
        pool.map(_multiprocessing_raise_processerror, range(10))
    except util.ParallelFailure as exc:
        pass
    finally:
        pool.close()

    # Check reraising UserError
    pool = multiprocessing.Pool(4)
    try:
        try:
            pool.map(_multiprocessing_raise_usererror, range(10))
        except util.ParallelFailure as exc:
            exc.reraise()
        finally:
            pool.close()
        assert False
    except util.UserError as exc:
        # OK
        pass


",False
239,https://github.com/dgkim5360/asyncloop/blob/e4f50156a74ee6430a8ade66f201ba61066396e4/asyncloop/tests/test_thread.py,,test_init_and_destroy,"def test_init_and_destroy():
    aloop = AsyncLoop()
    assert isinstance(aloop._event_loop, asyncio.AbstractEventLoop)
    assert not aloop.is_alive()

    aloop.start()
    assert aloop.is_alive()
    assert aloop._event_loop.is_running()

    aloop.stop()
    time.sleep(.01)
    assert not aloop._event_loop.is_running()
    assert not aloop.is_alive()


",False
240,https://github.com/jpoullet2000/atlasclient/blob/02b3e7d9a6596d1123fc22b6bfed08d60105d19e/tests/test_models.py,TestDiscoveryREST,test_search_attribute_get,"def test_search_attribute_get(self, mocker, atlas_client, search_attribute_response):
        mocker.patch.object(atlas_client.search_attribute.client, 'get')
        atlas_client.search_attribute.client.get.return_value =  search_attribute_response 
        params = {'attrName': 'attrName', 'attrValue': 'attrVal', 'offset': '1'}
        search_results = atlas_client.search_attribute(**params) 
        for s in search_results:
            assert s.queryType == 'GREMLIN'
            atlas_client.search_attribute.client.get.assert_called_with(s.url, params=params)
        for s in search_results:
            for e in s.entities:
                assert e.attributes['property1'] == {}

    ",True
241,https://github.com/zdhoward/aud/blob/2dfc81dad3da78537e1b1c6f5cc5630ba5b837f9/aud/test_aud.py,,test_afx_2,"def test_afx_2():
    global dir
    a = aud.Dir(dir)
    a.config_set_extensions([""wav""])

    assert a.afx_normalize(passes=2)
    assert a.afx_invert_stereo_phase(""both"")
    assert a.afx_hpf(80)
    assert a.afx_lpf(12000)


",True
242,https://github.com/zdhoward/aud/blob/2dfc81dad3da78537e1b1c6f5cc5630ba5b837f9/aud/test_aud.py,,test_afx_3,"def test_afx_3():
    global dir
    a = aud.Dir(dir)
    a.config_set_extensions([""wav""])

    assert a.afx_strip_silence()
    assert a.afx_join(""mock/joined.wav"", ""wav"")
    assert a.afx_gain(3)
    assert a.afx_gain(-3)


",True
243,https://github.com/zdhoward/aud/blob/2dfc81dad3da78537e1b1c6f5cc5630ba5b837f9/aud/test_aud.py,,test_config,"def test_config():
    global dir
    a = aud.Dir(dir)

    print(""SETTING EXTENSIONS"")
    assert a.config_set_extensions([""txt""])
    assert a.config_get_extensions() == ["".txt""]

    print(""SETTING denylist"")
    assert a.config_set_denylist([""test.txt""])
    assert a.config_get_denylist() == [""test.txt""]
    assert sorted(a.get_all()) == [""abc.txt""]
    assert a.config_set_allowlist(regex=""test.txt"")
    assert sorted(a.get_all()) == [""abc.txt"", ""test.txt""]
    assert a.config_set_allowlist([])
    assert a.config_set_denylist(regex=""test.txt"")
    assert sorted(a.get_all()) == [""abc.txt""]

    print(""SETTING allowlist"")
    assert a.config_set_allowlist([""test.txt""])
    assert a.config_get_allowlist() == [""test.txt""]
    assert sorted(a.get_all()) == [""abc.txt"", ""test.txt""]


",True
244,https://github.com/zdhoward/aud/blob/2dfc81dad3da78537e1b1c6f5cc5630ba5b837f9/aud/test_aud.py,,test_dir,"def test_dir():
    global dir
    a = aud.Dir(dir)
    a.config_set_extensions([""wav""])

    a.config_set_log_file(""mock/test.log"")
    assert a.log(""TESTING LOG"")

    assert sorted(a.get_all()) == [""bloop.wav"", ""song.wav""]

    assert a.get_single(0) == ""bloop.wav""  # doesn't work because its not sorted

    assert a.backup(join(dir, ""backup""))
    assert sorted(a.get_all()) == [""bloop.wav"", ""song.wav""]
    assert sorted(listdir(join(dir, ""backup""))) == [""bloop.wav"", ""song.wav""]

    assert a.copy(join(dir, ""copy""))
    assert sorted(a.get_all()) == [""bloop.wav"", ""song.wav""]
    assert sorted(listdir(join(dir, ""copy""))) == [""bloop.wav"", ""song.wav""]

    assert a.move(join(dir, ""move""))
    assert sorted(a.get_all()) == [""bloop.wav"", ""song.wav""]
    assert sorted(listdir(join(dir, ""move""))) == [""bloop.wav"", ""song.wav""]

    assert a.move(dir)
    assert sorted(a.get_all()) == [""bloop.wav"", ""song.wav""]
    assert sorted(listdir(dir)) == [
        ""abc.txt"",
        ""backup"",
        ""bloop.wav"",
        ""copy"",
        ""move"",
        ""song.wav"",
        ""test.log"",
        ""test.txt"",
    ]

    assert a.zip(""mock/test.zip"")
    assert isfile(""mock/test.zip"")
    with zipfile.ZipFile(""mock/test.zip"") as file:
        assert sorted(file.namelist()) == [""bloop.wav"", ""song.wav""]


",True
245,https://github.com/zdhoward/aud/blob/2dfc81dad3da78537e1b1c6f5cc5630ba5b837f9/aud/test_aud.py,,test_export,"def test_export():
    global dir
    a = aud.Dir(dir)

    a.config_set_extensions([""wav""])

    assert a.export_for(""amuse"", ""mock/amuse"")
    assert sorted(listdir(join(dir, ""amuse""))) == [
        ""bloop.wav"",
        ""joined.wav"",
        ""song.wav"",
    ]
",True
246,https://github.com/zdhoward/aud/blob/2dfc81dad3da78537e1b1c6f5cc5630ba5b837f9/aud/test_aud.py,,test_name,"def test_name():
    global dir
    a = aud.Dir(dir)

    a.config_set_extensions([""txt""])
    assert a.config_get_extensions() == ["".txt""]
    assert sorted(a.get_all()) == [""abc.txt"", ""test.txt""]

    assert a.name_upper()
    assert sorted(a.get_all()) == [""ABC.txt"", ""TEST.txt""]

    assert a.name_lower()
    assert sorted(a.get_all()) == [""abc.txt"", ""test.txt""]

    assert a.name_prepend(""abc_"")
    assert sorted(a.get_all()) == [""abc_abc.txt"", ""abc_test.txt""]

    assert a.name_append(""_test"")
    assert sorted(a.get_all()) == [""abc_abc_test.txt"", ""abc_test_test.txt""]

    assert a.name_replace(""_"", ""-"")
    assert sorted(a.get_all()) == [""abc-abc-test.txt"", ""abc-test-test.txt""]

    # doesn't work because its not sorted
    assert a.name_iterate(4, ""  "")
    assert sorted(a.get_all()) == [""0001  abc-abc-test.txt"", ""0002  abc-test-test.txt""]

    assert a.name_replace_spaces(""_"")
    assert sorted(a.get_all()) == [""0001__abc-abc-test.txt"", ""0002__abc-test-test.txt""]


",True
247,https://github.com/waqasbhatti/authnzerver/blob/bc735a1c9e1c084c40854a539a000d69a50ed486/authnzerver/tests/test_auth_creation.py,,test_create_user,"def test_create_user():
    '''
    This runs through various iterations of creating a user.

    '''
    try:
        os.remove('test-creation.authdb.sqlite')
    except Exception:
        pass
    try:
        os.remove('test-creation.authdb.sqlite-shm')
    except Exception:
        pass
    try:
        os.remove('test-creation.authdb.sqlite-wal')
    except Exception:
        pass

    get_test_authdb()

    # 1. dumb password
    payload = {'full_name':'Test User',
               'email':'testuser@test.org',
               'password':'password',
               'reqid':1,
               'pii_salt':'super-random-salt'}
    user_created = actions.create_new_user(
        payload,
        override_authdb_path='sqlite:///test-creation.authdb.sqlite'
    )
    assert user_created['success'] is False
    assert user_created['user_email'] == 'testuser@test.org'
    assert user_created['user_id'] is None
    assert user_created['send_verification'] is False
    assert ('Your password is too short. It must have at least 12 characters.'
            in user_created['messages'])
    assert ('Your password is too similar to either '
            'the domain name of this server or your '
            'own name or email address.' in user_created['messages'])
    assert ('Your password is not complex enough. '
            'One or more characters appear appear too frequently.'
            in user_created['messages'])
    assert ('Your password is on the list of the most common '
            'passwords and is vulnerable to guessing.'
            in user_created['messages'])

    # 2. all numeric password
    payload = {'full_name':'Test User',
               'email':'testuser@test.org',
               'password':'239420349823904802398402375025',
               'reqid':1,
               'pii_salt':'super-random-salt'}
    user_created = actions.create_new_user(
        payload,
        override_authdb_path='sqlite:///test-creation.authdb.sqlite'
    )
    assert user_created['success'] is False
    assert user_created['user_email'] == 'testuser@test.org'
    assert user_created['user_id'] is None
    assert user_created['send_verification'] is False
    assert ('Your password cannot be all numbers.' in user_created['messages'])

    # 3a. password ~= email address
    payload = {'full_name': 'Test User',
               'email':'testuser@test.org',
               'password':'testuser',
               'reqid':1,
               'pii_salt':'super-random-salt'}
    user_created = actions.create_new_user(
        payload,
        override_authdb_path='sqlite:///test-creation.authdb.sqlite'
    )
    assert user_created['success'] is False
    assert user_created['user_email'] == 'testuser@test.org'
    assert user_created['user_id'] is None
    assert user_created['send_verification'] is False
    assert ('Your password is not complex enough. '
            'One or more characters appear appear too frequently.'
            in user_created['messages'])
    assert ('Your password is too similar to either '
            'the domain name of this server or your '
            'own name or email address.' in user_created['messages'])

    # 3b. password ~= full name
    payload = {'full_name': 'Test User',
               'email':'testuser@test.org',
               'password':'TestUser123',
               'reqid':1,
               'pii_salt':'super-random-salt'}
    user_created = actions.create_new_user(
        payload,
        override_authdb_path='sqlite:///test-creation.authdb.sqlite'
    )
    assert user_created['success'] is False
    assert user_created['user_email'] == 'testuser@test.org'
    assert user_created['user_id'] is None
    assert user_created['send_verification'] is False
    assert ('Your password is too similar to either '
            'the domain name of this server or your '
            'own name or email address.' in user_created['messages'])

    # 4. password is OK
    payload = {'full_name': 'Test User',
               'email':'testuser@test.org',
               'password':'aROwQin9L8nNtPTEMLXd',
               'reqid':1,
               'pii_salt':'super-random-salt'}
    user_created = actions.create_new_user(
        payload,
        override_authdb_path='sqlite:///test-creation.authdb.sqlite'
    )
    assert user_created['success'] is True
    assert user_created['user_email'] == 'testuser@test.org'
    assert user_created['user_id'] == 4
    assert user_created['send_verification'] is True
    assert ('User account created. Please verify your email address to log in.'
            in user_created['messages'])

    # 5. try to create a new user with an existing email address
    payload = {'full_name': 'Test User',
               'email':'testuser@test.org',
               'password':'aROwQin9L8nNtPTEMLXd',
               'reqid':1,
               'pii_salt':'super-random-salt'}
    user_created = actions.create_new_user(
        payload,
        override_authdb_path='sqlite:///test-creation.authdb.sqlite'
    )
    assert user_created['success'] is False
    assert user_created['user_email'] == 'testuser@test.org'
    assert user_created['user_id'] == 4

    # we should not send a verification email because the user already has an
    # account or if the account is not active yet, the last verification email
    # was sent less than 24 hours ago
    assert user_created['send_verification'] is False
    assert ('User account created. Please verify your email address to log in.'
            in user_created['messages'])

    try:
        os.remove('test-creation.authdb.sqlite')
    except Exception:
        pass
    try:
        os.remove('test-creation.authdb.sqlite-shm')
    except Exception:
        pass
    try:
        os.remove('test-creation.authdb.sqlite-wal')
    except Exception:
        pass


",True
248,https://github.com/waqasbhatti/authnzerver/blob/bc735a1c9e1c084c40854a539a000d69a50ed486/authnzerver/tests/test_auth_permissions.py,,test_role_permissions,"def test_role_permissions():
    '''
    This tests if we can check the permissions for a logged-in user.

    '''

    try:
        os.remove('test-permcheck.authdb.sqlite')
    except Exception:
        pass
    try:
        os.remove('test-permcheck.authdb.sqlite-shm')
    except Exception:
        pass
    try:
        os.remove('test-permcheck.authdb.sqlite-wal')
    except Exception:
        pass

    get_test_authdb()

    # create the user
    user_payload = {'full_name': 'Test User',
                    'email':'testuser-permcheck@test.org',
                    'password':'aROwQin9L8nNtPTEMLXd',
                    'pii_salt':'super-secret-salt',
                    'reqid':1}
    user_created = actions.create_new_user(
        user_payload,
        override_authdb_path='sqlite:///test-permcheck.authdb.sqlite'
    )
    assert user_created['success'] is True
    assert user_created['user_email'] == 'testuser-permcheck@test.org'
    assert ('User account created. Please verify your email address to log in.'
            in user_created['messages'])

    # verify our email
    emailverify = (
        actions.set_user_emailaddr_verified(
            {'email':user_payload['email'],
             'user_id': user_created['user_id'],
             'pii_salt':'super-secret-salt',
             'reqid':1},
            override_authdb_path='sqlite:///test-permcheck.authdb.sqlite'
        )
    )

    # make a non-verified user
    user_payload2 = {'full_name': 'Test User',
                     'email':'testuser-permcheck2@test.org',
                     'password':'aROwQin9L8nNtPTEMLXd',
                     'pii_salt':'super-secret-salt',
                     'reqid':1}
    user_created2 = actions.create_new_user(
        user_payload2,
        override_authdb_path='sqlite:///test-permcheck.authdb.sqlite'
    )
    assert user_created2['success'] is True
    assert user_created2['user_email'] == 'testuser-permcheck2@test.org'
    assert ('User account created. Please verify your email address to log in.'
            in user_created2['messages'])

    #
    # now run the permissions checks
    #

    # get the permissions JSON
    thisdir = os.path.dirname(__file__)
    permissions_json = os.path.abspath(
        os.path.join(thisdir, '..', 'default-permissions-model.json')
    )

    # 1. view a non-owned public object
    access_check = actions.check_user_access(
        {'user_id':emailverify['user_id'],
         'user_role':'authenticated',
         'action':'view',
         'target_name':'object',
         'target_owner':1,
         'target_visibility':'public',
         'target_sharedwith':'',
         'reqid':1,
         'pii_salt':'dummy-pii-salt'},
        override_authdb_path='sqlite:///test-permcheck.authdb.sqlite',
        override_permissions_json=permissions_json,
        raiseonfail=True,
    )
    assert access_check['success'] is True
    assert (
        ""Access request check successful. Access granted: True."" in
        access_check['messages']
    )

    # 2. delete a non-owned public object
    access_check = actions.check_user_access(
        {'user_id':emailverify['user_id'],
         'user_role':'authenticated',
         'action':'delete',
         'target_name':'object',
         'target_owner':1,
         'target_visibility':'public',
         'target_sharedwith':'',
         'reqid':1,
         'pii_salt':'dummy-pii-salt'},
        override_authdb_path='sqlite:///test-permcheck.authdb.sqlite',
        override_permissions_json=permissions_json,
        raiseonfail=True,
    )
    assert access_check['success'] is False
    assert (
        ""Access request check successful. Access granted: False."" in
        access_check['messages']
    )

    # 3. edit a self owned dataset
    access_check = actions.check_user_access(
        {'user_id':emailverify['user_id'],
         'user_role':'authenticated',
         'action':'edit',
         'target_name':'dataset',
         'target_owner':emailverify['user_id'],
         'target_visibility':'private',
         'target_sharedwith':'',
         'reqid':1,
         'pii_salt':'dummy-pii-salt'},
        override_authdb_path='sqlite:///test-permcheck.authdb.sqlite',
        override_permissions_json=permissions_json,
        raiseonfail=True,
    )
    assert access_check['success'] is True
    assert (
        ""Access request check successful. Access granted: True."" in
        access_check['messages']
    )

    # 3. as superuser, delete someone else's private dataset
    access_check = actions.check_user_access(
        {'user_id':1,
         'user_role':'superuser',
         'action':'delete',
         'target_name':'dataset',
         'target_owner':4,
         'target_visibility':'private',
         'target_sharedwith':'',
         'reqid':1,
         'pii_salt':'dummy-pii-salt'},
        override_authdb_path='sqlite:///test-permcheck.authdb.sqlite',
        override_permissions_json=permissions_json,
        raiseonfail=True,
    )
    assert access_check['success'] is True
    assert (
        ""Access request check successful. Access granted: True."" in
        access_check['messages']
    )

    # 4. as locked user, try to view a public collection
    access_check = actions.check_user_access(
        {'user_id': 3,
         'user_role':'locked',
         'action':'view',
         'target_name':'collection',
         'target_owner':1,
         'target_visibility':'public',
         'target_sharedwith':'',
         'reqid':1,
         'pii_salt':'dummy-pii-salt'},
        override_authdb_path='sqlite:///test-permcheck.authdb.sqlite',
        override_permissions_json=permissions_json,
        raiseonfail=True,
    )
    assert access_check['success'] is False
    assert (
        ""Access request check successful. Access granted: False."" in
        access_check['messages']
    )

    # 5. as an unknown user with superuser privileges, try to edit a private
    # dataset
    access_check = actions.check_user_access(
        {'user_id':10,
         'user_role':'superuser',
         'action':'edit',
         'target_name':'dataset',
         'target_owner':1,
         'target_visibility':'private',
         'target_sharedwith':'',
         'reqid':1,
         'pii_salt':'dummy-pii-salt'},
        override_authdb_path='sqlite:///test-permcheck.authdb.sqlite',
        override_permissions_json=permissions_json,
        raiseonfail=True,
    )
    assert access_check['success'] is False
    assert (
        ""Access request check successful. Access granted: False."" in
        access_check['messages']
    )

    # 6. as a known user but non-activated account, try to view a collection
    access_check = actions.check_user_access(
        {'user_id':5,
         'user_role':'authenticated',
         'action':'view',
         'target_name':'collection',
         'target_owner':1,
         'target_visibility':'public',
         'target_sharedwith':'',
         'reqid':1,
         'pii_salt':'dummy-pii-salt'},
        override_authdb_path='sqlite:///test-permcheck.authdb.sqlite',
        override_permissions_json=permissions_json,
        raiseonfail=True,
    )
    assert access_check['success'] is False
    assert (
        ""Access request check successful. Access granted: False."" in
        access_check['messages']
    )

    #
    # teardown
    #

    currproc = mp.current_process()
    if getattr(currproc, 'authdb_meta', None):
        del currproc.authdb_meta

    if getattr(currproc, 'connection', None):
        currproc.authdb_conn.close()
        del currproc.authdb_conn

    if getattr(currproc, 'authdb_engine', None):
        currproc.authdb_engine.dispose()
        del currproc.authdb_engine

    try:
        os.remove('test-permcheck.authdb.sqlite')
    except Exception:
        pass
    try:
        os.remove('test-permcheck.authdb.sqlite-shm')
    except Exception:
        pass
    try:
        os.remove('test-permcheck.authdb.sqlite-wal')
    except Exception:
        pass


",True
249,https://github.com/waqasbhatti/authnzerver/blob/bc735a1c9e1c084c40854a539a000d69a50ed486/authnzerver/tests/test_email.py,,test_create_user_with_email,"def test_create_user_with_email(tmpdir):
    '''
    This creates a user and tries to send a verification code to their email.

    '''

    test_authdb_url = get_test_authdb(tmpdir)

    # 0. start the email server
    email_server, maildir = generate_email_server(tmpdir)
    email_server.start()
    time.sleep(3.0)

    # 1a. create a new session
    session_payload = {
        'user_id':2,
        'user_agent':'Mozzarella Killerwhale',
        'expires':datetime.utcnow()+timedelta(hours=1),
        'ip_address': '1.1.1.1',
        'extra_info_json':{'pref_datasets_always_private':True},
        'pii_salt':'super-secret-salt',
        'reqid':1
    }
    session_token_info = actions.auth_session_new(
        session_payload,
        raiseonfail=True,
        override_authdb_path=test_authdb_url
    )

    # 1b. create a new user
    payload = {'full_name': 'Test User',
               'email':'testuser@test.org',
               'password':'aROwQin9L8nNtPTEMLXd',
               'reqid':1,
               'pii_salt':'super-secret-salt'}
    user_created = actions.create_new_user(
        payload,
        raiseonfail=True,
        override_authdb_path=test_authdb_url
    )
    assert user_created['success'] is True
    assert user_created['user_email'] == 'testuser@test.org'
    assert user_created['user_id'] == 4
    assert user_created['send_verification'] is True
    assert ('User account created. Please verify your email address to log in.'
            in user_created['messages'])

    token_key = Fernet.generate_key()

    # 2. generate a verification token and send them an email
    verify_token = tokens.generate_email_token(
        session_payload['ip_address'],
        session_payload['user_agent'],
        'testuser@test.org',
        session_token_info['session_token'],
        token_key
    )

    # this uses the payload method of sending SMTP settings to the backend
    # function
    verification_email_info = actions.send_signup_verification_email(
        {'email_address':'testuser@test.org',
         'session_token':session_token_info['session_token'],
         'created_info':user_created,
         'server_name':'Authnzerver',
         'server_baseurl':'https://localhost/auth',
         'account_verify_url':'/users/verify',
         'verification_token':verify_token,
         'verification_expiry':900,
         'emailuser':None,
         'emailpass':None,
         'emailserver':'localhost',
         'emailport':2587,
         'emailsender':'Authnzerver <authnzerver@test.org>',
         'reqid':1337,
         'pii_salt':'super-secret-salt'},
        raiseonfail=True,
        override_authdb_path=test_authdb_url
    )
    assert verification_email_info['success'] is True
    assert verification_email_info['email_address'] == 'testuser@test.org'

    # 3. check the mailbox to see if the email was received
    mailbox = Maildir(maildir)

    email_found = False

    for _, message in mailbox.items():

        if 'Please verify your account sign up request' in message['Subject']:

            email_found = True
            assert message['From'] == 'Authnzerver <authnzerver@test.org>'
            assert message['To'] == 'testuser@test.org'
            assert (
                '\n'.join(textwrap.wrap(verify_token.decode()))
                in message.as_string()
            )
            break

    assert email_found is True

    # now verify that the token from the email contains the same info we
    # provided
    received_token_base64 = re.findall(
        r'enter this code:([\S\n]+)into the account verification',
        message.as_string(),
    )
    received_token_base64 = received_token_base64[0]
    received_token_base64 = received_token_base64.replace('\n','')
    received_token_valid = tokens.verify_email_token(
        received_token_base64,
        session_payload['ip_address'],
        session_payload['user_agent'],
        session_token_info['session_token'],
        'testuser@test.org',
        token_key,
        match_returned_items=('ipa','usa','stk','ema'),
    )
    assert received_token_valid is True

    # 4. set the user's email address as verified
    email_verified_info = actions.set_user_emailaddr_verified(
        {'email':'testuser@test.org',
         'reqid':123,
         'pii_salt':'super-secret-salt'},
        raiseonfail=True,
        override_authdb_path=test_authdb_url
    )

    assert email_verified_info['success'] is True
    assert email_verified_info['user_id'] == 4
    assert email_verified_info['is_active'] is True
    assert email_verified_info['user_role'] == 'authenticated'

    # 5. send a password forgot email to the user

    # 5a. create a new session for the user first
    session_payload = {
        'user_id':4,
        'user_agent':'Mozzarella Killerwhale',
        'expires':datetime.utcnow()+timedelta(hours=1),
        'ip_address': '1.1.1.1',
        'extra_info_json':{'pref_datasets_always_private':True},
        'pii_salt':'super-secret-salt',
        'reqid':1
    }
    session_token_info = actions.auth_session_new(
        session_payload,
        raiseonfail=True,
        override_authdb_path=test_authdb_url
    )

    # 5b. now send a forgot-password email
    forgotpass_token = tokens.generate_email_token(
        session_payload['ip_address'],
        session_payload['user_agent'],
        'testuser@test.org',
        session_token_info['session_token'],
        token_key
    )

    # this uses the config object method of sending SMTP settings to the backend
    # function
    config_obj = SimpleNamespace()
    config_obj.emailuser = None
    config_obj.emailpass = None
    config_obj.emailserver = 'localhost'
    config_obj.emailport = 2587
    config_obj.emailsender = 'Authnzerver <authnzerver@test.org>'

    forgotpass_email_info = actions.send_forgotpass_verification_email(
        {'email_address':'testuser@test.org',
         'session_token':session_token_info['session_token'],
         'server_name':'Authnzerver',
         'server_baseurl':'https://localhost/auth',
         'password_forgot_url':'/password/reset-step1',
         'verification_token':forgotpass_token,
         'verification_expiry':900,
         'reqid':1337,
         'pii_salt':'super-secret-salt'},
        raiseonfail=True,
        override_authdb_path=test_authdb_url,
        config=config_obj
    )
    assert forgotpass_email_info['success'] is True
    assert forgotpass_email_info['email_address'] == 'testuser@test.org'

    # 6. check the mailbox to see if the forgot password email was received
    mailbox = Maildir(maildir)

    email_found = False

    for _, message in mailbox.items():

        if 'Please verify your password reset request' in message['Subject']:

            email_found = True
            assert message['From'] == 'Authnzerver <authnzerver@test.org>'
            assert message['To'] == 'testuser@test.org'
            assert (
                '\n'.join(textwrap.wrap(forgotpass_token.decode()))
                in message.as_string()
            )
            break

    assert email_found is True

    # now verify that the token from the email contains the same info we
    # provided
    received_token_base64 = re.findall(
        r'enter this code:([\S\n]+)into the password reset',
        message.as_string(),
    )
    received_token_base64 = received_token_base64[0]
    received_token_base64 = received_token_base64.replace('\n','')
    received_token_valid = tokens.verify_email_token(
        received_token_base64,
        session_payload['ip_address'],
        session_payload['user_agent'],
        session_token_info['session_token'],
        'testuser@test.org',
        token_key,
        match_returned_items=('ipa','usa','stk','ema'),
    )
    assert received_token_valid is True

    #
    # clean up
    #

    email_server.stop()
",False
250,https://github.com/waqasbhatti/authnzerver/blob/bc735a1c9e1c084c40854a539a000d69a50ed486/authnzerver/tests/test_email.py,,test_email_works,"def test_email_works(tmpdir):
    '''
    This is a basic test of the email server working OK.

    '''

    email_server, maildir = generate_email_server(tmpdir)
    email_server.start()
    time.sleep(3.0)

    # send a test email
    email_sent = actions.send_email(
        'test@test.org',
        'Hello',
        'this is a test',
        ['test@test.org'],
        '127.0.0.1',
        None,
        None,
        'salt',
        port=2587
    )

    assert email_sent is True

    # check if it was received
    mailbox = Maildir(maildir)

    for _, message in mailbox.items():

        if message['Subject'] == 'Hello':
            assert message['From'] == 'test@test.org'
            assert message['To'] == 'test@test.org'
            assert 'this is a test' in message.as_string()

    email_server.stop()


",False
251,https://github.com/pierrepo/autoclasswrapper/blob/af43dd833e5586386098d1793a59332e968069da/tests/test_output.py,TestOutputClass,test_aggregate_input_data,"def test_aggregate_input_data(self, caplog, tmp_dir):
        res = wrapper.Output(target_root_name)
        res.extract_results()
        res.aggregate_input_data()
        assert ""Aggregating input data"" in caplog.text
        assert os.path.isfile(res.root_out_name+"".tsv"")
        ref_file = target_root_path + ""_out.tsv""
        assert filecmp.cmp(ref_file, res.root_out_name + "".tsv"", shallow=False)

    ",False
252,https://github.com/pierrepo/autoclasswrapper/blob/af43dd833e5586386098d1793a59332e968069da/tests/test_output.py,TestOutputClass,test_extract_results,"def test_extract_results(self, caplog, tmp_dir):
        res = wrapper.Output(target_root_name)
        res.extract_results()
        assert ""Found 600 cases classified in 3 classes"" in caplog.text
        assert res.stats[""main-class""].nunique() == 3
        assert res.stats.shape == (600, 5)

    ",False
253,https://github.com/pierrepo/autoclasswrapper/blob/af43dd833e5586386098d1793a59332e968069da/tests/test_output.py,TestOutputClass,test_write_cdt,"def test_write_cdt(self, caplog, tmp_dir):
        res = wrapper.Output(target_root_name)
        res.extract_results()
        res.aggregate_input_data()
        res.write_cdt()
        assert os.path.isfile(res.root_out_name+"".cdt"")
        ref_file = target_root_path + ""_out.cdt""
        assert filecmp.cmp(ref_file, res.root_out_name + "".cdt"", shallow=False)

    ",False
254,https://github.com/pierrepo/autoclasswrapper/blob/af43dd833e5586386098d1793a59332e968069da/tests/test_output.py,TestOutputClass,test_write_cdt_with_proba,"def test_write_cdt_with_proba(self, caplog, tmp_dir):
        res = wrapper.Output(target_root_name)
        res.extract_results()
        res.aggregate_input_data()
        res.write_cdt(with_proba=True)
        assert os.path.isfile(res.root_out_name + ""_withproba.cdt"")
        ref_file = target_root_path + ""_out_withproba.cdt""
        assert filecmp.cmp(ref_file,
                           res.root_out_name + ""_withproba.cdt"",
                           shallow=False)

    ",False
255,https://github.com/pierrepo/autoclasswrapper/blob/af43dd833e5586386098d1793a59332e968069da/tests/test_output.py,TestOutputClass,test_write_cluster_stats,"def test_write_cluster_stats(self, caplog, tmp_dir):
        res = wrapper.Output(target_root_name)
        res.extract_results()
        res.aggregate_input_data()
        res.write_class_stats()
        assert os.path.isfile(res.root_out_name + ""_stats.tsv"")
        ref_file = target_root_path + ""_out_stats.tsv""
        assert filecmp.cmp(ref_file,
                           res.root_out_name + ""_stats.tsv"",
                           shallow=False)

    ",False
256,https://github.com/pierrepo/autoclasswrapper/blob/af43dd833e5586386098d1793a59332e968069da/tests/test_output.py,TestOutputClass,test_write_dendrogram,"def test_write_dendrogram_no_stats(self, caplog, tmp_dir):
        res = wrapper.Output(target_root_name)
        res.extract_results()
        res.aggregate_input_data()
        res.write_dendrogram()
        statfile = res.root_out_name + ""_stats.tsv""
        assert ""Cannot find {}"".format(statfile) in caplog.text

    ",True
257,https://github.com/pierrepo/autoclasswrapper/blob/af43dd833e5586386098d1793a59332e968069da/tests/test_output.py,TestOutputClass,test_write_dendrogram_no_stats,"def test_write_dendrogram_no_stats(self, caplog, tmp_dir):
        res = wrapper.Output(target_root_name)
        res.extract_results()
        res.aggregate_input_data()
        res.write_dendrogram()
        statfile = res.root_out_name + ""_stats.tsv""
        assert ""Cannot find {}"".format(statfile) in caplog.text

    ",True
258,https://github.com/nicolaszein/autodiscover/blob/3009f81c51b7a4cb077427e429d740db98eb173b/tests/test_autodiscover.py,TestAutoDiscover,test_autodiscover_with_pattern,"def test_autodiscover_with_pattern(self):
        path = pathlib.Path(PATH)
        autodiscover = AutoDiscover(path=path, pattern='pattern.py')
        module = 'tests.module_to_import.pattern'
        sys.modules.pop(module)

        autodiscover()

        self.assertIn(module, sys.modules)
",True
259,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_gen_each_case.py,TestUnittest,test_foo_bar,"def test_foo_bar(self):
        """""" POST /foo/bar """"""
        res = self.client.post_json('/foo/bar', params={
            'id': 1,
            'message': 'foo'
        })
        self.assertEqual(res.status_code, 200)

        return res
",True
260,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_gen_each_case.py,TestUnittest,test_get,"def test_get(self):
        """""" GET / """"""
        res = self.client.get('/')
        self.assertEqual(res.status_code, 200)

        return res

    @autodoc.generate('var/test_post.rst')
    @autodoc.describe('POST /')
    ",True
261,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_gen_each_case.py,TestUnittest,test_post,"def test_post(self):
        """""" POST / """"""
        res = self.client.post_json('/', params={'id': 1, 'message': 'foo'})
        self.assertEqual(res.status_code, 200)

        return res

    @autodoc.generate('var/test_foo_bar.rst')
    @autodoc.describe('POST /foo/bar')
    ",True
262,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_pytest.py,,test_index,"def test_index():
    app = TestApp(create_app)
    res = app.get('/')
    assert res.status_code == 200

    return res


@autodoc.describe('POST /')
",True
263,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_pytest.py,,test_post,"def test_post(setup):
    res = setup.post_json('/', params={'id': 1, 'message': 'foo'})
    assert res.status_code == 200

    return res
",True
264,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_requests.py,TestUnittest,test_foo_bar,"def test_foo_bar(self):
        """""" POST /foo/bar """"""
        params = {'id': 1, 'message': 'foo'}
        req = self.create_request('http://localhost:5000/foo/bar', 'POST',
                                  params)
        res = self.send(req, params, '../tests/data/post.json')
        self.assertEqual(res.status_code, 200)

        return res
",True
265,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_requests.py,TestUnittest,test_get,"def test_get(self):
        """""" GET / """"""
        req = self.create_request('http://localhost:5000/', 'GET')
        res = self.send(req, '', '../tests/data/get.json')
        self.assertEqual(res.status_code, 200)

        return res

    @autodoc.describe('POST /')
    ",True
266,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_requests.py,TestUnittest,test_post,"def test_post(self):
        """""" POST / """"""
        params = {'id': 1, 'message': 'foo'}
        req = self.create_request('http://localhost:5000/', 'POST', params)
        res = self.send(req, params, '../tests/data/post.json')

        self.assertEqual(res.status_code, 200)

        return res

    @autodoc.describe('POST /foo/bar')
    ",True
267,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_unittest.py,TestUnittest,test_foo_bar,"def test_foo_bar(self):
        """""" POST /foo/bar """"""
        res = self.client.post_json('/foo/bar', params={
            'id': 1,
            'message': 'foo'
        })
        self.assertEqual(res.status_code, 200)

        return res
",True
268,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_unittest.py,TestUnittest,test_get,"def test_get(self):
        """""" GET / """"""
        res = self.client.get('/')
        self.assertEqual(res.status_code, 200)

        return res

    @autodoc.describe('POST /')
    ",True
269,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/examples/test_unittest.py,TestUnittest,test_post,"def test_post(self):
        """""" POST / """"""
        res = self.client.post_json('/', params={'id': 1, 'message': 'foo'})
        self.assertEqual(res.status_code, 200)

        return res

    @autodoc.describe('POST /foo/bar')
    ",True
270,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/tests/test_autodoc.py,TestAutodoc,test_create_document,"def test_create_document(self):
        """""" Should create reST document. """"""
        res = self.client.get('/')
        autodoc.parse('GET /', res)
        autodoc.create_document(os.path.join(self.root_path,
                                             'var/test_autodoc.rst'))
        self.assertTrue(os.path.exists(os.path.join(self.root_path,
                                                    'var/test_autodoc.rst')))
        autodoc.clear()

    ",True
271,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/tests/test_autodoc.py,TestAutodoc,test_parse_response,"def test_parse_response(self):
        """""" Should parse WebTest response. """"""
        res = self.client.post_json('/', params={'message': 'foo'})
        autodoc.parse('POST /', res)

        var = {
            'describe': 'POST /',
            'describe_separators': '======',
            'target_url': 'http://localhost:80',
            'status_code': 200,
            'request': 'POST /',
            'response_body': '{\n  ""response"": ""create""\n}',
            'response_content_type': 'application/json',
            'params': '{\n  ""message"": ""foo""\n}'
        }
        for k, v in iteritems(autodoc.vars[0]):
            self.assertEqual(v, var[k])

        autodoc.clear()

    ",True
272,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/tests/test_autodoc.py,TestAutodoc,test_parse_responses,"def test_parse_responses(self):
        """""" Should stack responses. """"""
        res = self.client.get('/')
        autodoc.parse('GET /', res)
        autodoc.parse('GET /', res)
        var = {
            'response_content_type': 'application/json',
            'response_body': '{\n  ""response"": ""index""\n}',
            'describe': 'GET /',
            'request': 'GET /',
            'params': '',
            'status_code': 200,
            'target_url': 'http://localhost:80',
            'describe_separators': '====='
        }
        vars = [var, var]
        self.assertEqual(autodoc.vars, vars)
        autodoc.clear()

    ",True
273,https://github.com/heavenshell/py-autodoc/blob/001d5ff03d41a5d714075eb08e666c413d50f0ac/tests/test_autodoc.py,TestAutodoc,test_should_change_separators,"def test_should_change_separators(self):
        """""" Should change separators. """"""
        res = self.client.get('/')
        autodoc.separators = '*'
        autodoc.parse('GET /', res)
        var = {
            'response_content_type': 'application/json',
            'response_body': '{\n  ""response"": ""index""\n}',
            'describe': 'GET /',
            'request': 'GET /',
            'params': '',
            'status_code': 200,
            'target_url': 'http://localhost:80',
            'describe_separators': '*****'
        }
        for k, v in iteritems(autodoc.vars[0]):
            self.assertEqual(v, var[k])

        autodoc.clear()


class TestWebTestResponse(TestCase):
    ",True
274,https://github.com/martyni/autoyaml/blob/be3f450667bcca477683e63bcc49c67c5d170855/tests/autoyaml_test.py,TestAutoyamlMethods,test_b_decrypt_config,"def test_b_decrypt_config(self):
        loaded_config = load_config(self.enc_app, password_function=self.password_function) 
        self.assertEqual(loaded_config, self.enc_config)
        loaded_config[""extra_field""] = random_string()
        write_config(loaded_config, self.enc_app, encrypted=True, password_function=self.password_function)
        loaded_config2 = load_config(self.enc_app, password_function=self.password_function) 
        self.assertEqual(loaded_config, loaded_config2)
        os.remove(self.writer(self.enc_app, encrypted=True))

    ",True
275,https://github.com/martyni/autoyaml/blob/be3f450667bcca477683e63bcc49c67c5d170855/tests/autoyaml_test.py,TestEncryptorMethods,test_b_decrypt,"def test_b_decrypt(self):
       decrypt_file(self.file_name, self.password, self.salt)
       with open(self.file_name) as test_file:
          self.assertEqual(self.contents, test_file.read())

",True
276,https://github.com/gridsmartercities/aws-lambda-decorators/blob/bbd25a7002b99e57fe7da225b6aad06cb1e43b9c/tests/test_decoders.py,DecodersTests,test_extract_multiple_parameters_from_jwt_hits_cache,"def test_extract_multiple_parameters_from_jwt_hits_cache(self):
        dictionary = {
            ""a"": TEST_JWT
        }

        initial_cache_info = decode_jwt.cache_info()

        @extract([
            Parameter(""a[jwt]/sub"", ""event"", var_name=""sub""),
            Parameter(""a[jwt]/aud"", ""event"", var_name=""aud"")
        ])
        ",False
277,https://github.com/mattdavis90/base10/blob/93577e85215e4cd7f02a504ff6a23501d56a1748/base10/test/test_helpers.py,TestMetricHelper,test_metric_helper_fields_exception,"def test_metric_helper_fields_exception(self):
        class MyMetric(MetricHelper):
            _name = self.metric_name
            _metadata = self.metric_metadata

        with pytest.raises(Base10Error) as exc:
            metric = MyMetric(**self.metric_values)

        assert '_fields is required' == str(exc.value)

    ",True
278,https://github.com/mattdavis90/base10/blob/93577e85215e4cd7f02a504ff6a23501d56a1748/base10/test/test_helpers.py,TestMetricHelper,test_metric_helper_handles_time_field,"def test_metric_helper_handles_time_field(self):
        class MyMetric(MetricHelper):
            _name = self.metric_name
            _fields = self.metric_fields + ['time']
            _metadata = self.metric_metadata

        metric = MyMetric(**self.metric_values)

        assert metric.fields == self.metric_fields

    ",True
279,https://github.com/mattdavis90/base10/blob/93577e85215e4cd7f02a504ff6a23501d56a1748/base10/test/test_helpers.py,TestMetricHelper,test_metric_helper_metadata_exception,"def test_metric_helper_metadata_exception(self):
        class MyMetric(MetricHelper):
            _name = self.metric_name
            _fields = self.metric_fields

        with pytest.raises(Base10Error) as exc:
            metric = MyMetric(**self.metric_values)

        assert '_metadata is required' == str(exc.value)

    ",True
280,https://github.com/mattdavis90/base10/blob/93577e85215e4cd7f02a504ff6a23501d56a1748/base10/test/test_helpers.py,TestMetricHelper,test_metric_helper_name_exception,"def test_metric_helper_name_exception(self):
        class MyMetric(MetricHelper):
            _fields = self.metric_fields
            _metadata = self.metric_metadata

        with pytest.raises(Base10Error) as exc:
            metric = MyMetric(**self.metric_values)

        assert '_name is required' == str(exc.value)

    ",True
281,https://github.com/rorymurdock/basic_auth/blob/622f2133c13988cec549f4ea55bed14e50f90876/tests/test_basic.py,,test_check_config_dir,"def test_check_config_dir():
    """"""Test directory related operations""""""
    # Check no folder exists already
    assert AUTH.check_config_dir() is False

    # Create directory
    assert AUTH.create_config_directory() is True

    # Verify directory exists
    assert AUTH.check_config_dir() is True

    # Create read only directory
    Auth(config_dir=""config/readonly"").create_config_directory()
    os.chmod(""config/readonly"", 444)

    # Test writing to read only
    assert Auth(
        config_dir=""config/readonly/test"").create_config_directory() is False


",False
282,https://github.com/rorymurdock/basic_auth/blob/622f2133c13988cec549f4ea55bed14e50f90876/tests/test_basic.py,,test_read_config,"def test_read_config():
    """"""Test opening files""""""
    # Try to open a non existant config
    assert AUTH.read_config('nofile.json') is False

    # Try a directory
    assert AUTH.read_config('readonly') is False

    # Try a good file
    assert isinstance(AUTH.read_config(""test.json""), dict) is True

    # Try a bad file
    with open(""config/bad_file.json"", 'w') as outfile:
        outfile.write(""Thisisbaddata"")
    assert AUTH.read_config(""bad_file.json"") is False


",True
283,https://github.com/rorymurdock/basic_auth/blob/622f2133c13988cec549f4ea55bed14e50f90876/tests/test_basic.py,,test_verify_config,"def test_verify_config():
    """"""Verify written config""""""
    # Verify config written earlier
    assert AUTH.verify_config(""test.json"", KEY, VALUE) is True

    # Verify config mismatch
    assert AUTH.verify_config(""test.json"", KEY, ""Not value"") is False

    # Verify non json data
    assert AUTH.verify_config(""bad_file.json"", KEY, VALUE) is False
",True
284,https://github.com/rorymurdock/basic_auth/blob/622f2133c13988cec549f4ea55bed14e50f90876/tests/test_basic.py,,test_write_config,"def test_write_config():
    """"""Test writing config to files""""""
    # Create some dummy data
    data = {}
    data[KEY] = VALUE

    # Overwrite file from previous test with random data
    assert AUTH.write_config(data, ""test.json"") is True

    # Try to write in a readonly folder
    assert Auth(""config/readonly"").write_config(data, ""test.json"") is False

    # Try to create a new folder
    assert Auth(""config/newfolder"").write_config(data, ""test.json"") is True

    # Create new folder in read only will sys.exit
    with pytest.raises(SystemExit) as pytest_wrapped_e:
        Auth(""config/readonly/newfolder"").write_config(data, ""test.json"")
    assert pytest_wrapped_e.type == SystemExit


",False
285,https://github.com/rorymurdock/basic_auth/blob/622f2133c13988cec549f4ea55bed14e50f90876/tests/test_general.py,,test_file_data_arguments,"def test_file_data_arguments():
    """"""Verify the data written via mock arguments""""""
    filename = 'general_args.json'
    assert AUTH.check_file_exists(filename) is True

    assert AUTH.verify_config(filename, 'authorization',
                              AUTH.encode(RANDOM_USERNAME,
                                          RANDOM_PASSWORD)) is True
    assert AUTH.verify_config(filename, 'url', RANDOM_URL) is True


",True
286,https://github.com/rorymurdock/basic_auth/blob/622f2133c13988cec549f4ea55bed14e50f90876/tests/test_general.py,,test_file_data_interactive,"def test_file_data_interactive():
    """"""Verify the data written via mock std in""""""
    filename = 'general_interactive.json'
    assert AUTH.check_file_exists(filename) is True

    assert AUTH.verify_config(filename, 'authorization',
                              AUTH.encode(RANDOM_USERNAME,
                                          RANDOM_PASSWORD)) is True
    assert AUTH.verify_config(filename, 'url', RANDOM_URL) is True


",True
287,https://github.com/rorymurdock/basic_auth/blob/622f2133c13988cec549f4ea55bed14e50f90876/tests/test_wso.py,,test_file_data_arguments,"def test_file_data_arguments():
    """"""Verify the data written via mock arguments""""""
    filename = 'wso_args.json'
    assert AUTH.check_file_exists(filename) is True

    assert AUTH.verify_config(filename, 'authorization',
                              AUTH.encode(RANDOM_USERNAME,
                                          RANDOM_PASSWORD)) is True
    assert AUTH.verify_config(filename, 'url', RANDOM_URL) is True
    assert AUTH.verify_config(filename, 'aw-tenant-code',
                              RANDOM_TENANTCODE) is True


",True
288,https://github.com/rorymurdock/basic_auth/blob/622f2133c13988cec549f4ea55bed14e50f90876/tests/test_wso.py,,test_file_data_interactive,"def test_file_data_interactive():
    """"""Verify the data written via mock std in""""""
    filename = 'wso_interactive.json'
    assert AUTH.check_file_exists(filename) is True

    assert AUTH.verify_config(filename, 'authorization',
                              AUTH.encode(RANDOM_USERNAME,
                                          RANDOM_PASSWORD)) is True
    assert AUTH.verify_config(filename, 'url', RANDOM_URL) is True
    assert AUTH.verify_config(filename, 'aw-tenant-code',
                              RANDOM_TENANTCODE) is True


",True
289,https://github.com/rorymurdock/basic_auth/blob/622f2133c13988cec549f4ea55bed14e50f90876/tests/test_wso.py,,test_main_results,"def test_main_results():
    """"""Test the results of the real arguments""""""
    # Due to complexities testing with arguments to get full coverage
    # run the script externally with full arguments
    os.popen('python3 -m pip install -e .')
    os.popen(
        'python3 Examples/WSO.py -url cn1234.awtest.com -username citests -password hunter2 -tenantcode shibboleet'
    ).read()

    filename = ""uem.json""

    assert AUTH.check_file_exists(filename) is True
    assert AUTH.verify_config(filename, 'authorization',
                              AUTH.encode(""citests"", ""hunter2"")) is True
    assert AUTH.verify_config(filename, 'url', ""cn1234.awtest.com"") is True
    assert AUTH.verify_config(filename, 'aw-tenant-code', ""shibboleet"") is True
",False
290,https://github.com/Poogles/bloomtime/blob/94343456192c0a4837ddad2c421d59c7a3fd02fa/tests/test_bloomtime.py,,test_set,"def test_set(bloomtime_fixture, caplog):
    caplog.set_level(logging.DEBUG)

    bloomtime_fixture.set('foo')
    # We know 9 hashes should be set.
    total = 0
    for i in bloomtime_fixture._container:
        if i > 0:
            total += 1
    assert total == 9


",False
291,https://github.com/matheuswhite/bluebees/blob/ca18ee6dae60393480bac3893038790957727748/tests/test_application_data.py,,test_cleanup,"def test_cleanup():
    pathlib.Path(base_dir + app_dir + 'test_app.yml').unlink()
",True
292,https://github.com/matheuswhite/bluebees/blob/ca18ee6dae60393480bac3893038790957727748/tests/test_file_helper.py,,test_cleanup,"def test_cleanup():
    ",True
293,https://github.com/matheuswhite/bluebees/blob/ca18ee6dae60393480bac3893038790957727748/tests/test_network_data.py,,test_cleanup,"def test_cleanup():
    pathlib.Path(base_dir + net_dir + 'test_net.yml').unlink()
",True
294,https://github.com/matheuswhite/bluebees/blob/ca18ee6dae60393480bac3893038790957727748/tests/test_node_data.py,,test_cleanup,"def test_cleanup():
    pathlib.Path(base_dir + node_dir + 'test_node.yml').unlink()
",True
295,https://github.com/aguinane/bomweather/blob/cfe945a64900a9207a44c42551ec2c365916b7d2/tests/test_stations.py,,test_closest_obs_station_uncached,"def test_closest_obs_station_uncached():
    """""" Test some example locations and check against expected names """"""

    st = closest_obs_station(-27.470125, 153.021072, rescrape=True)
    assert ""BRISBANE"" in st.site_name


",False
296,https://github.com/jedie/bootstrap_env/blob/ab68025d8f6b9a17d8feeed83e8aae26e3f28769/bootstrap_env/tests/test_boot.py,BootstrapEnvTestCase,test_setup,"def test_setup(self):
        self.assertTrue(self.base_path.is_dir())

    ",True
297,https://github.com/jedie/bootstrap_env/blob/ab68025d8f6b9a17d8feeed83e8aae26e3f28769/bootstrap_env/tests/test_test_utils.py,BootstrapEnvTestCase,test_setup,"def test_setup(self):
        self.assertTrue(self.base_path.is_dir())

    ",True
298,https://github.com/agile4you/bottle-neck/blob/ebc670a4b178255473d68e9b4122ba04e38f4810/test/test_handlers.py,,test_handler_register_class_pass,"def test_handler_register_class_pass(mock_app, mock_handler):
    """"""Test `bottle_neck.handlers.BaseHandler.register_app` method.
    """"""

    mock_handler.register_app(mock_app)

    assert all(['/mock' in i.rule for i in mock_app.routes])
",True
299,https://github.com/agile4you/bottle-neck/blob/ebc670a4b178255473d68e9b4122ba04e38f4810/test/test_routing.py,,test_router_mount_pass,"def test_router_mount_pass(mock_router, mock_app):
    """"""Test `bottle_neck.routing.Router.mount` method.
    """"""
    init_mounts = len(mock_app.routes)
    mock_router.mount(mock_app)

    assert len(mock_app.routes) > init_mounts
",True
300,https://github.com/agile4you/bottle-neck/blob/ebc670a4b178255473d68e9b4122ba04e38f4810/test/test_routing.py,,test_router_register_handler_cbv_pass,"def test_router_register_handler_cbv_pass(mock_router, mock_handler):
    """"""Test `bottle_neck.routing.Router.register_handler` for class-based
    handler pass.
    """"""

    mock_router.register_handler(mock_handler, entrypoint='/api')

    assert len(mock_router) == 2


",True
301,https://github.com/agile4you/bottle-neck/blob/ebc670a4b178255473d68e9b4122ba04e38f4810/test/test_routing.py,,test_router_register_handler_fn_pass,"def test_router_register_handler_fn_pass(mock_router):
    """"""Test `bottle_neck.routing.Router.register_handler` for function-based
    handler pass.
    """"""

    ",True
302,https://github.com/brian-team/brian2modelfitting/blob/7f01463bf5be47cc82e26f033819c8a82cefac2b/brian2modelfitting/tests/test_modelfitting_tracefitter.py,,test_fitter_generate_traces_standalone,"def test_fitter_generate_traces_standalone(setup_standalone):
    dt, tf = setup_standalone
    results, errors = tf.fit(n_rounds=2,
                             optimizer=n_opt,
                             metric=metric,
                             g=[1*nS, 30*nS],
                             restart=False,)

    traces = tf.generate_traces()
    assert isinstance(traces, np.ndarray)
    assert_equal(np.shape(traces), np.shape(output_traces))


",False
303,https://github.com/brian-team/brian2modelfitting/blob/7f01463bf5be47cc82e26f033819c8a82cefac2b/brian2modelfitting/tests/test_modelfitting_tracefitter.py,,test_fitter_refine_standalone,"def test_fitter_refine_standalone(setup_standalone):
    dt, tf = setup_standalone
    results, errors = tf.fit(n_rounds=2,
                             optimizer=n_opt,
                             metric=metric,
                             g=[1*nS, 30*nS],
                             callback=None)
    # Run refine after running fit
    params, result = tf.refine()
    assert result.method == 'leastsq'
    assert isinstance(params, dict)
    assert isinstance(result, lmfit.minimizer.MinimizerResult)

    # Pass options to lmfit.minimize
    params, result = tf.refine(method='least_squares')
    assert result.method == 'least_squares'


@pytest.mark.skipif(lmfit is None, reason=""needs lmfit package"")
",False
304,https://github.com/SebastianoF/bruker2nifti/blob/4fbac970e9125f3e53dd5e31d63b971ad739a6d2/test/test_convert_banana.py,,test_warning_banana_bad_n,"def test_warning_banana_bad_n():

    for n in [""1"", ""2"", ""3""]:

        pfo_study_in = os.path.join(root_dir, ""test_data"", ""bru_banana_bad_"" + n)
        pfo_study_out = os.path.join(root_dir, ""test_data"", ""nifti_banana"")

        bru = Bruker2Nifti(pfo_study_in, pfo_study_out, study_name=""banana"")
        bru.correct_slope = True
        bru.verbose = 2
        if sys.version_info.major == 2:
            with pytest.raises(OSError):
                bru.convert()
        else:
            with pytest.raises(FileExistsError):
                bru.convert()
",False
305,https://github.com/kivy/buildozer/blob/4a18fb321e8410c44c9a62bd65671f33df3a470b/tests/test_buildozer.py,TestBuildozer,test_p4a_recommended_android_ndk_found,"def test_p4a_recommended_android_ndk_found(
            self, mock_open, mock_exists, mock_isfile
    ):
        self.set_specfile_log_level(self.specfile.name, 1)
        buildozer = Buildozer(self.specfile.name, 'android')
        expected_ndk = '19b'
        recommended_line = 'RECOMMENDED_NDK_VERSION = {expected_ndk}\n'.format(
            expected_ndk=expected_ndk)
        mock_open.return_value = StringIO(recommended_line)
        ndk_version = buildozer.target.p4a_recommended_android_ndk
        p4a_dir = os.path.join(
            buildozer.platform_dir, buildozer.target.p4a_directory_name)
        mock_open.assert_called_once_with(
            os.path.join(p4a_dir, ""pythonforandroid"", ""recommendations.py""), 'r'
        )
        assert ndk_version == expected_ndk

        # now test that we only read one time p4a file, so we call again to
        # `p4a_recommended_android_ndk` and we should still have one call to `open`
        # file, the performed above
        ndk_version = buildozer.target.p4a_recommended_android_ndk
        mock_open.assert_called_once()
",False
306,https://github.com/michaelpb/bupper/blob/d3751472b90132e781dfb32310b5b567658b7f31/test/test_bupper.py,TestFullBehavior,test_backup_unmocked_commands,"def test_backup_unmocked_commands(self):
        bupper.main(bupper.parse_args([
            '-s', self.source_dir,
            '-l', self.local_dir,
            '-r', self.remote_dir,
        ]))
        local_dir_contents = os.listdir(self.local_dir)
        remote_dir_contents = os.listdir(self.remote_dir)
        assert len(local_dir_contents) == 4
        assert len(remote_dir_contents) == 2
        local_fns = [fn for fn in local_dir_contents if fn.startswith('2017')]
        assert set(local_fns) == set(remote_dir_contents)
        path_1 = join(self.source_dir, 'example/path/to')
        path_2 = join(self.source_dir, 'other/backup')
        assert set(local_fns) == set([
            utils.get_backup_archive_filename('ISO', path_1),
            utils.get_backup_archive_filename('ISO', path_2),
        ])

    ",False
307,https://github.com/michaelpb/bupper/blob/d3751472b90132e781dfb32310b5b567658b7f31/test/test_bupper.py,TestPaths,test_get_targets,"def test_get_targets(self):
        # Test that it shows up when searching
        d = tempfile.mkdtemp(prefix='tmp_bupper_test_')
        os.makedirs(join(d, 'some/other'))

        # ensure it picks up on nothing
        assert list(bupper.get_targets(join(d))) == []

        # now check that it gets it correctly
        open(join(d, 'some/other/_BACKUP_THIS'), 'w+').write(' ')
        assert list(bupper.get_targets(join(d))) == [join(d, 'some/other')]

        # clean up test
        os.remove(join(d, 'some/other/_BACKUP_THIS'))
        os.removedirs(join(d, 'some/other'))


class TestPathGenerators:
    FILES = [
        '_vimrc',
        '_config/openbox/openbox.xml',
    ]

    @classmethod
    ",False
308,https://github.com/michaelpb/bupper/blob/d3751472b90132e781dfb32310b5b567658b7f31/test/test_bupper.py,TestUtils,test_makedirs_to,"def test_makedirs_to(self):
        # Make a directory tree
        d = tempfile.mkdtemp(prefix='tmp_bupper_test_')
        utils.makedirs_to(join(d, 'some/other/thing'))
        assert exists(join(d, 'some/other'))
        assert not exists(join(d, 'some/other/thing'))
        os.removedirs(join(d, 'some/other'))

    ",False
309,https://github.com/Tetrite/cBinder/blob/940e8c78eb9cf2eda1bc69427a6279b8b832bfe1/tests/simplecases/externaldeps/test_StaticDependences.py,StaticDependencesOnLinux64,test_generate_bindings_to_gsl_sf_bessel_J,"def test_generate_bindings_to_gsl_sf_bessel_J(self):
        self.current_working_directory_path = pathlib.Path(os.path.dirname(os.path.realpath(__file__)))
        self.deps_path = self.current_working_directory_path / 'dependencies'
        os.makedirs(self.deps_path, exist_ok=True)
        os.chdir(self.deps_path)
        # get gsl - dependency of source
        os.system(r'curl ""http://cz.archive.ubuntu.com/ubuntu/pool/universe/g/gsl/libgsl-dev_2.5+dfsg-6_amd64.deb"" --output libgsl-dev.deb')
        os.system(r'dpkg -x libgsl-dev.deb .')
        self.sources_path = self.current_working_directory_path.joinpath('sources/gsl_dependent')
        self.include_path = self.current_working_directory_path.joinpath('dependencies/usr/include')
        self.libs_main_dir = self.current_working_directory_path.joinpath('dependencies/usr/lib')
        # there is one thing in ""libs_main_dir"" directory containing libs
        # name of this dir can vary, hence below line
        self.libs_path = self.libs_main_dir.joinpath(os.listdir(self.libs_main_dir)[0])
        self.destination_path = self.current_working_directory_path.joinpath('generated')
        if not os.path.exists(str(self.destination_path)):
            os.makedirs(str(self.destination_path))
        clear_folder_contents(self.destination_path)
        os.chdir(""../../../.."")
        os.system(r'python cBinder sources -f ' + str(self.sources_path)
                  + ' -d ' + str(self.destination_path) + ' compile '
                  + ' -i ' + str(self.include_path)
                  + ' -b ' + str(self.libs_path) + ' -l gsl -l gslcblas -l m ')
        os.chdir(self.destination_path)
        os.environ['PATH'] = os.getcwd() + os.pathsep + os.environ['PATH']

        from tests.simplecases.externaldeps.generated.sources import example
        # c function return 0 if call was succesful
        self.assertEqual(example.print_gsl_sf_bessel_J0(1.7), 0)


class StaticDependencesOnWin64(unittest.TestCase):

    @unittest.skipUnless(sys.platform in (""win32"", ""cygwin"") and platform.architecture()[0] == ""64bit"", ""Test windows x64 specific"")
    ",False
310,https://github.com/bofm/python-caching/blob/16de50c119f8896e923e3f10488ecf6ffe535f45/tests/test_storage_sqlite.py,,test_ttl_gt0,"def test_ttl_gt0(tmpdir):
    storage = SQLiteStorage(
        filepath=f'{tmpdir}/cache',
        ttl=0.001,
        maxsize=100,
    )
    storage[b'1'] = b'one'
    time.sleep(0.0011)
    assert storage.get(b'1') is None

    storage = SQLiteStorage(
        filepath=f'{tmpdir}/cache',
        ttl=99,
        maxsize=100,
    )
    storage[b'x'] = b'x'
    assert storage[b'x'] == b'x'


@pytest.mark.parametrize('ttl', (0, -1, -100, -0.5, -1.5))
",False
311,https://github.com/eillarra/carbonize/blob/efc89b8a9e44f9d64110406ce70929a9671517c7/tests/test_api.py,TestFootprint,test_flight,"def test_flight(self):
        self.fp.add_flight(a=""BRU"", b=""BCN"")
        self.assertEqual(len(self.fp.steps), 1)
        self.assertAlmostEqual(self.fp.emissions, 116, delta=5)

    ",True
312,https://github.com/eillarra/carbonize/blob/efc89b8a9e44f9d64110406ce70929a9671517c7/tests/test_api.py,TestFootprint,test_flight_two_way,"def test_flight_two_way(self):
        self.fp.add_flight(a=""BRU"", b=""BCN"", two_way=True)
        self.assertEqual(len(self.fp.steps), 3)
        self.assertAlmostEqual(self.fp.emissions, 116 * 3, delta=10)
",True
313,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_command.py,TestCommands,test_command_add,"def test_command_add(self, centreon_con):
        values = [
            'command_test',
            'check',
            '/my/plugins my command'
        ]
        data = {}
        data['action'] = 'add'
        data['object'] = 'CMD'
        data['values'] = values

        with patch('requests.post') as patched_post:
            centreon_con.commands.add(""command_test"",
                                          ""check"",
                                          ""/my/plugins my command"",
                                          post_refresh=False
                                          )
            patched_post.assert_called_with(self.clapi_url, headers=self.headers, data=json.dumps(data), verify=True)

    ",True
314,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_command.py,TestCommands,test_command_delete,"def test_command_delete(self, centreon_con):
        data = {}
        data['action'] = 'del'
        data['object'] = 'CMD'
        data['values'] = 'command_test'

        with patch('requests.post') as patched_post:
            centreon_con.commands.delete('command_test', post_refresh=False)
            patched_post.assert_called_with(self.clapi_url, headers=self.headers, data=json.dumps(data), verify=True)

    @responses.activate
    ",True
315,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_command.py,TestCommands,test_command_list,"def test_command_list(self, centreon_con):
        with open(resource_dir / 'test_commands_list.json') as data:
            wsresponses = json.load(data)
        responses.add(responses.POST,
                      'http://api.domain.tld/centreon/api/index.php?action=action&object=centreon_clapi',
                      json=wsresponses, status=200, content_type='application/json')

        _, res = centreon_con.commands.get('OS-Linux-SNMP-Memory')
        assert res.id == ""111""

    @responses.activate
    ",True
316,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_command.py,TestCommands,test_command_not_exist,"def test_command_not_exist(self, centreon_con):
        with open(resource_dir / 'test_commands_list.json') as data:
            wsresponses = json.load(data)
        responses.add(responses.POST,
                      'http://api.domain.tld/centreon/api/index.php?action=action&object=centreon_clapi',
                      json=wsresponses, status=200, content_type='application/json')
        state, cmd = centreon_con.commands.get(""empty"")
        assert state == False

    ",True
317,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_command.py,TestCommands,test_command_setparam,"def test_command_setparam(self):
        with open(resource_dir / 'test_commands_1.json') as data:
            cmd = Command(json.load(data))
        values = [
            cmd.name,
            'type',
            'notif',
        ]
        data = {}
        data['action'] = 'setparam'
        data['object'] = 'CMD'
        data['values'] = values

        with patch('requests.post') as patched_post:
            cmd.setparam('type', 'notif')
            patched_post.assert_called_with(self.clapi_url, headers=self.headers, data=json.dumps(data), verify=True)



",True
318,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_addcontact,"def test_host_addcontactgroupt(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_contactgroup.json') as cg:
            cgs = ContactGroup(json.load(cg))

        data = dict()
        data['action'] = 'addcontactgroup'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""astreinte""]

        with patch('requests.post') as patched_post:
            host.addcontactgroup(cgs)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
319,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_addcontactgroupt,"def test_host_addcontactgroupt(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_contactgroup.json') as cg:
            cgs = ContactGroup(json.load(cg))

        data = dict()
        data['action'] = 'addcontactgroup'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""astreinte""]

        with patch('requests.post') as patched_post:
            host.addcontactgroup(cgs)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
320,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_addparent,"def test_host_addparent(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_parent.json') as parent:
            parents = Host(json.load(parent))

        data = dict()
        data['action'] = 'addparent'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""mail-neptune-frontend""]

        with patch('requests.post') as patched_post:
            host.addparent(parents)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
321,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_addtemplate,"def test_host_addtemplate(self, host_load_data):
        host = host_load_data
        templates = list()
        with open(resource_dir / 'test_host_template.json') as htlp:
            tmp = json.load(htlp)
            for tlp in tmp:
                print(tlp)
                templates.append(HostTemplate(tlp))

        data = dict()
        data['action'] = 'addtemplate'
        data['object'] = 'HOST'
        data['values'] = [
            ""mail-uranus-frontend"",
            ""OS-Linux-SNMP-custom|OS-Linux-SNMP-Disk-/""]

        with patch('requests.post') as patched_post:
            host.addtemplate(templates)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
322,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_applytemplate,"def test_host_applytemplate(self, host_load_data):
        host = host_load_data
        data = dict()
        data['action'] = 'applytpl'
        data['object'] = 'HOST'
        data['values'] = ""mail-uranus-frontend""

        with patch('requests.post') as patched_post:
            host.applytemplate()
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
323,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_deletecontact,"def test_host_deletecontactgroup(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_contactgroup.json') as cg:
            cgs = ContactGroup(json.load(cg))

        data = dict()
        data['action'] = 'delcontactgroup'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""astreinte""]

        with patch('requests.post') as patched_post:
            host.deletecontactgroup(cgs)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    @responses.activate
    ",True
324,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_deletecontactgroup,"def test_host_deletecontactgroup(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_contactgroup.json') as cg:
            cgs = ContactGroup(json.load(cg))

        data = dict()
        data['action'] = 'delcontactgroup'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""astreinte""]

        with patch('requests.post') as patched_post:
            host.deletecontactgroup(cgs)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    @responses.activate
    ",True
325,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_deletehostgroup,"def test_host_deletehostgroup(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_hostgroup.json') as hg:
            hgs = HostGroup(json.load(hg))

        data = dict()
        data['action'] = 'delhostgroup'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""centreon-prod""]

        with patch('requests.post') as patched_post:
            host.deletehostgroup(hgs)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    @responses.activate
    ",True
326,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_delmacro,"def test_host_delmacro(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_macro.json') as m:
            macro = HostMacro(json.load(m))
        data = dict()
        data['action'] = 'delmacro'
        data['object'] = 'HOST'
        data['values'] = [host.name, 'NRPEPORT']

        with patch('requests.post') as patched_post:
            host.deletemacro(macro)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    @responses.activate
    ",True
327,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_deteletemplate,"def test_host_deteletemplate(self, host_load_data):
        host = host_load_data
        templates = list()
        with open(resource_dir / 'test_host_template.json') as htlp:
            tmp = json.load(htlp)
            for tlp in tmp:
                templates.append(HostTemplate(tlp))

        data = dict()
        data['action'] = 'deltemplate'
        data['object'] = 'HOST'
        data['values'] = [
            ""mail-uranus-frontend"",
            ""OS-Linux-SNMP-custom|OS-Linux-SNMP-Disk-/""]

        with patch('requests.post') as patched_post:
            host.deletetemplate(templates)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
328,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_disable,"def test_host_disable(self, host_load_data):
        host = host_load_data
        data = dict()
        data['action'] = 'disable'
        data['object'] = 'HOST'
        data['values'] = ""mail-uranus-frontend""

        with patch('requests.post') as patched_post:
            host.disable()
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
329,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_enable,"def test_host_enable(self, host_load_data):
        host = host_load_data
        data = dict()
        data['action'] = 'enable'
        data['object'] = 'HOST'
        data['values'] = ""mail-uranus-frontend""

        with patch('requests.post') as patched_post:
            host.enable()
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
330,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_getcontact,"def test_host_getcontactgroup(self, host_load_data):
        host = host_load_data
        with open(resource_dir / ""test_host_contactgroups.json"") as data:
            wsresponses = json.load(data)
        responses.add(
            responses.POST,
            self.clapi_url,
            json=wsresponses, status=200, content_type='application/json')
        _, res = host.getcontactgroup()
        assert res['astreinte'].id == ""9""

    ",True
331,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_getcontactgroup,"def test_host_getcontactgroup(self, host_load_data):
        host = host_load_data
        with open(resource_dir / ""test_host_contactgroups.json"") as data:
            wsresponses = json.load(data)
        responses.add(
            responses.POST,
            self.clapi_url,
            json=wsresponses, status=200, content_type='application/json')
        _, res = host.getcontactgroup()
        assert res['astreinte'].id == ""9""

    ",True
332,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_gethostgroup,"def test_host_gethostgroup(self, host_load_data):
        host = host_load_data
        with open(resource_dir / ""test_host_hostgroups.json"") as data:
            wsresponses = json.load(data)
        responses.add(responses.POST,
                          self.clapi_url,
                          json=wsresponses, status=200, content_type='application/json')
        _, res = host.gethostgroup()
        assert res['centreon-prj'].id == ""115""

    ",True
333,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_getmacro,"def test_host_getmacro(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_macros.json') as data:
            wsresponses = json.load(data)
        responses.add(responses.POST,
                      self.clapi_url,
                      json=wsresponses, status=200, content_type='application/json')
        _, res = host.getmacro()
        assert res[""$_HOSTMATTERMOST_CHAN$""].name == ""MATTERMOST_CHAN""

    ",True
334,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_getparents,"def test_host_getparents(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_parents.json') as data:
                wsresponses = json.load(data)
        responses.add(responses.POST,
                      self.clapi_url,
                      json=wsresponses, status=200, content_type='application/json')
        _, res = host.getparent()
        assert res['mail-neptune-frontend'].id == ""13""

    ",True
335,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_gettemplate,"def test_host_gettemplate(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_templates.json') as data:
            wsresponses = json.load(data)
        responses.add(responses.POST,
                      self.clapi_url,
                      json=wsresponses, status=200, content_type='application/json')
        _, res = host.gettemplate()
        print(res)
        assert res[""OS-Linux-SNMP-custom""].id == ""6""


    ",True
336,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_setcontact,"def test_host_setcontactgroup(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_contactgroup.json') as cg:
            cgs = ContactGroup(json.load(cg))

        data = dict()
        data['action'] = 'setcontactgroup'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""astreinte""]

        with patch('requests.post') as patched_post:
            host.setcontactgroup(cgs)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
337,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_setcontactgroup,"def test_host_setcontactgroup(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_contactgroup.json') as cg:
            cgs = ContactGroup(json.load(cg))

        data = dict()
        data['action'] = 'setcontactgroup'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""astreinte""]

        with patch('requests.post') as patched_post:
            host.setcontactgroup(cgs)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
338,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_setinstance,"def test_host_setinstance(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_poller.json') as instances:
            instance = Poller(json.load(instances))

        data = dict()
        data['action'] = 'setinstance'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""Central""]

        with patch('requests.post') as patched_post:
            host.setinstance(instance)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    @responses.activate
    ",True
339,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_setmacro,"def test_host_setmacro(self, host_load_data):
        host = host_load_data
        data = dict()
        data['action'] = 'setmacro'
        data['object'] = 'HOST'
        data['values'] = [host.name, 'MACRO_TEST', 'VALUE_TEST', '0', 'DESC']

        with patch('requests.post') as patched_post:
            host.setmacro('MACRO_TEST', 'VALUE_TEST', '0', 'DESC')
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
340,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_setparam,"def test_host_setparam(self, host_load_data):
        host = host_load_data

        data = dict()
        data['action'] = 'setparam'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""notes"", ""tested""]

        with patch('requests.post') as patched_post:
            host.setparam(""notes"", ""tested"")
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )",True
341,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_setparent,"def test_host_setparent(self, host_load_data):
        host = host_load_data
        with open(resource_dir / 'test_host_parent.json') as parent:
            parents = Host(json.load(parent))

        data = dict()
        data['action'] = 'setparent'
        data['object'] = 'HOST'
        data['values'] = [""mail-uranus-frontend"", ""mail-neptune-frontend""]

        with patch('requests.post') as patched_post:
            host.setparent(parents)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
342,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHost,test_host_settemplate,"def test_host_settemplate(self, host_load_data):
        host = host_load_data
        templates = list()
        with open(resource_dir / 'test_host_template.json') as htlp:
            tmp = json.load(htlp)
            for tlp in tmp:
                print(tlp)
                templates.append(HostTemplate(tlp))

        data = dict()
        data['action'] = 'settemplate'
        data['object'] = 'HOST'
        data['values'] = [
            ""mail-uranus-frontend"",
            ""OS-Linux-SNMP-custom|OS-Linux-SNMP-Disk-/""]

        with patch('requests.post') as patched_post:
            host.settemplate(templates)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
343,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHosts,test_hosts_add,"def test_hosts_add(self, centreon_con):
        values = [
            ""new_host.tld"",
            ""new_host"",
            ""127.0.0.7"",
            ""OS-Linux-SNMP-custom|OS-Linux-SNMP-disk"",
            ""Central"",
            ""hg""
        ]
        data = dict()
        data['action'] = 'add'
        data['object'] = 'HOST'
        data['values'] = values

        with patch('requests.post') as patched_post:
            centreon_con.hosts.add(
                ""new_host.tld"",
                ""new_host"",
                ""127.0.0.7"",
                ""Central"",
                [""OS-Linux-SNMP-custom"", ""OS-Linux-SNMP-disk""],
                [""hg""],
                post_refresh=False
            )
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    ",True
344,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHosts,test_hosts_delete,"def test_hosts_delete(self, centreon_con):
        data = dict()
        data['action'] = 'del'
        data['object'] = 'HOST'
        data['values'] = 'my_deleted_host'

        with patch('requests.post') as patched_post:
            centreon_con.hosts.delete('my_deleted_host', post_refresh=False)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )

    @pytest.fixture()
    ",True
345,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHosts,test_hosts_delete_with_obj,"def test_hosts_delete_with_obj(self, centreon_con, host_load_data):
        host = host_load_data
        data = dict()
        data['action'] = 'del'
        data['object'] = 'HOST'
        data['values'] = 'mail-uranus-frontend'

        with patch('requests.post') as patched_post:
            centreon_con.hosts.delete(host, post_refresh=False)
            patched_post.assert_called_with(
                self.clapi_url,
                headers=self.headers,
                data=json.dumps(data),
                verify=True
            )


class TestHost():
    clapi_url = 'http://api.domain.tld/centreon/api/index.php?action=action&object=centreon_clapi'
    headers = {
        'Content-Type': 'application/json',
        'centreon-auth-token': 'NTc1MDU3MGE3M2JiODIuMjA4OTA2OTc='
    }

    @pytest.fixture()
    @responses.activate
    ",True
346,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHosts,test_hosts_list,"def test_hosts_list(self, centreon_con):
        with open(resource_dir / 'test_hosts_list.json') as data:
            wsresponses = json.load(data)
        responses.add(
            responses.POST,
            self.clapi_url,
            json=wsresponses, status=200, content_type='application/json')
        _, res = centreon_con.hosts.get('mail-uranus-frontend')
        assert res.id == ""12""

    @responses.activate
    ",True
347,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_hosts.py,TestHosts,test_hosts_not_exist,"def test_hosts_not_exist(self, centreon_con):
        with open(resource_dir / 'test_hosts_list.json') as data:
            wsresponses = json.load(data)
        responses.add(
            responses.POST,
            self.clapi_url,
            json=wsresponses, status=200, content_type='application/json')
        state, res = centreon_con.hosts.get('empty')
        assert state == False
        assert res == None

    ",True
348,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_resourcecfg.py,TestResourceCFG,test_resourcecfg_add,"def test_resourcecfg_add(self, centreon_con):
        values = [
            'resource_test',
            'ressource_value',
            'Central',
            'comment'
        ]
        data = {}
        data['action'] = 'add'
        data['object'] = 'RESOURCECFG'
        data['values'] = values

        with patch('requests.post') as patched_post:
            centreon_con.resourcecfgs.add(""resource_test"",
                                          ""ressource_value"",
                                          ""Central"",
                                          ""comment"",
                                          post_refresh=False
                                          )
            patched_post.assert_called_with(self.clapi_url, headers=self.headers, data=json.dumps(data), verify=True)

    ",True
349,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_resourcecfg.py,TestResourceCFG,test_resourcecfg_building_line,"def test_resourcecfg_building_line(self, centreon_con):
        with open(resource_dir / 'test_resourcecfg_list.json') as data:
            wsresponses = json.load(data)
        responses.add(responses.POST,
                      'http://api.domain.tld/centreon/api/index.php?action=action&object=centreon_clapi',
                      json=wsresponses, status=200, content_type='application/json')

        _, res = centreon_con.resourcecfgs.get('_HOSTSNMPVERSION')
        assert res.name == ""$_HOSTSNMPVERSION$""

    @responses.activate
    ",True
350,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_resourcecfg.py,TestResourceCFG,test_resourcecfg_delete,"def test_resourcecfg_delete(self, centreon_con):
        data = {}
        data['action'] = 'del'
        data['object'] = 'RESOURCECFG'
        data['values'] = '42'

        with patch('requests.post') as patched_post:
            centreon_con.resourcecfgs.delete('42', post_refresh=False)
            patched_post.assert_called_with(self.clapi_url, headers=self.headers, data=json.dumps(data), verify=True)

    @responses.activate
    ",True
351,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_resourcecfg.py,TestResourceCFG,test_resourcecfg_get_one,"def test_resourcecfg_get_one(self, centreon_con):
        with open(resource_dir / 'test_resourcecfg_list.json') as data:
            wsresponses = json.load(data)
        responses.add(responses.POST,
                      'http://api.domain.tld/centreon/api/index.php?action=action&object=centreon_clapi',
                      json=wsresponses, status=200, content_type='application/json')

        _, res = centreon_con.resourcecfgs.get('$_HOSTSNMPVERSION$')
        assert res.name == ""$_HOSTSNMPVERSION$""

    @responses.activate
    ",True
352,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_resourcecfg.py,TestResourceCFG,test_resourcecfg_not_exist,"def test_resourcecfg_not_exist(self, centreon_con):
        with open(resource_dir / 'test_resourcecfg_list.json') as data:
            wsresponses = json.load(data)
        responses.add(responses.POST,
                      'http://api.domain.tld/centreon/api/index.php?action=action&object=centreon_clapi',
                      json=wsresponses, status=200, content_type='application/json')
        state, res = centreon_con.resourcecfgs.get('empty')
        assert state == False
        assert res == None


    clapi_url = 'http://api.domain.tld/centreon/api/index.php?action=action&object=centreon_clapi'
    headers = {
        'Content-Type': 'application/json',
        'centreon-auth-token': 'NTc1MDU3MGE3M2JiODIuMjA4OTA2OTc='
        }

    ",True
353,https://github.com/guillaumewatteeux/centreon-sdk-python/blob/9f207d5458afc3304e24f16988069467b19eab81/tests/test_resourcecfg.py,TestResourceCFG,test_resourcecfg_setparam,"def test_resourcecfg_setparam(self):
        with open(resource_dir / 'test_resourcecfg_1.json') as data:
            res = ResourceCFG(json.load(data))
        values = [
            res.id,
            'instance',
            'Central',
        ]
        data = {}
        data['action'] = 'setparam'
        data['object'] = 'RESOURCECFG'
        data['values'] = values

        with patch('requests.post') as patched_post:
            res.setparam('instance', 'Central')
            patched_post.assert_called_with(self.clapi_url, headers=self.headers, data=json.dumps(data), verify=True)


",True
354,https://github.com/prahladyeri/cfgsaver/blob/9654076b418c96bcddbf2fddc5fdb0f6f4117278/test/test_cfgsaver.py,,test_get,"def test_get():
	obj = cfgsaver.get(pkg_name)
	assert obj[0]['name'] == 'Sophie'


	
##print('hello')",False
355,https://github.com/Windsooon/cherry/blob/bc6ae1f0284d837fb95279098538530312313534/tests/test_base.py,BaseTest,test_load_data_found,"def test_load_data_found(self, mock_load_files):
        with UseModel(self.foo_model) as model:
            load_data(self.foo_model)
        mock_load_files.assert_called_once_with(
            self.foo_model, categories=None, encoding=None)

    @mock.patch('cherry.base._load_data_from_remote')
    ",False
356,https://github.com/Windsooon/cherry/blob/bc6ae1f0284d837fb95279098538530312313534/tests/test_base.py,BaseTest,test_load_local_data_from_local_with_cache,"def test_load_local_data_from_local_with_cache(self):
        with UseModel(self.foo_model) as model:
            res = cherry.base._load_data_from_local(self.foo_model)
        self.assertEqual(res['data'], 'bar')

    ",False
357,https://github.com/Windsooon/cherry/blob/bc6ae1f0284d837fb95279098538530312313534/tests/test_base.py,BaseTest,test_load_local_data_from_local_with_cache_failed,"def test_load_local_data_from_local_with_cache_failed(self):
        with UseModel(self.foo_model, cache_problem=True) as model:
            with self.assertRaises(cherry.exceptions.NotSupportError) as notFoundError:
                res = cherry.base._load_data_from_local(self.foo_model)
            self.assertEqual(
                str(notFoundError.exception),
                'Can\'t load cached data from foo. Please try again after delete cache files.')

    # _load_data_from_remote()
    @mock.patch('cherry.base._load_data_from_remote')
    ",False
358,https://github.com/Windsooon/cherry/blob/bc6ae1f0284d837fb95279098538530312313534/tests/test_base.py,BaseTest,test_load_local_data_from_local_without_cache,"def test_load_local_data_from_local_without_cache(self, mock_load_files):
        mock_load_files.return_value = None
        with UseModel(self.foo_model, cache=False) as model:
            res = cherry.base._load_data_from_local(self.foo_model)
            self.assertEqual(res, None)
            mock_load_files.assert_called_once_with(self.foo_model_path, categories=None, encoding=None)
            # Create new cache files
            cache_path = os.path.join(self.foo_model_path, self.foo_model + '.pkz')
            self.assertTrue(os.path.exists(cache_path))

    ",False
359,https://github.com/Windsooon/cherry/blob/bc6ae1f0284d837fb95279098538530312313534/tests/test_classify.py,ClassifyTest,test_init,"def test_init(self, mock_load, mock_classify):
        mock_load.return_value = ('foo', 'bar')
        cherry.classifyer.Classify(model='random', text=['random text'])
        mock_load.assert_called_once_with('random')
        mock_classify.assert_called_once_with(['random text'])

    # _load_cache()
    @mock.patch('cherry.classifyer.Classify._classify')
    @mock.patch('cherry.classifyer.load_cache')
    ",True
360,https://github.com/Windsooon/cherry/blob/bc6ae1f0284d837fb95279098538530312313534/tests/test_classify.py,ClassifyTest,test_load_cache,"def test_load_cache(self, mock_load, mock_classify):
        res = cherry.classifyer.Classify(model='foo', text=['random text'])
        mock_load.assert_not_called()
",True
361,https://github.com/Varkal/chuda/blob/bd4d30c0f809d5349752ab2f322f30b01ab6b4a4/tests/test_app.py,,test_output,"def test_output(capsys, argv):
    app = BasicApp()
    app.run()
    stdout, _ = capsys.readouterr()
    assert stdout == TEST_STRING+""\n""


@cli_args(
    [TEST_STRING, ""--quiet""],
    [TEST_STRING, ""-q""]
)
",True
362,https://github.com/dhermes/ci-diff-helper/blob/876affd3ba49d78c48708a12103d39ef3c7d5f1d/tests/test__utils.py,Test_check_output,test_bad_keywords,"def test_bad_keywords(self):
        with self.assertRaises(TypeError):
            self._call_function_under_test(huh='bad-kw')


class Test_pr_from_commit(unittest.TestCase):

    @staticmethod
    ",False
363,https://github.com/dhermes/ci-diff-helper/blob/876affd3ba49d78c48708a12103d39ef3c7d5f1d/tests/test__utils.py,Test_pr_from_commit,test_no_id,"def test_no_id(self):
        subject = 'No pound sign.'
        result = self._call_function_under_test(subject)
        self.assertIsNone(result)

    ",False
364,https://github.com/dhermes/ci-diff-helper/blob/876affd3ba49d78c48708a12103d39ef3c7d5f1d/tests/test__utils.py,Test_pr_from_commit,test_non_int_id,"def test_non_int_id(self):
        subject = '#x will not match the regex.'
        result = self._call_function_under_test(subject)
        self.assertIsNone(result)

    ",False
365,https://github.com/dhermes/ci-diff-helper/blob/876affd3ba49d78c48708a12103d39ef3c7d5f1d/tests/test__utils.py,Test_pr_from_commit,test_too_many_ids,"def test_too_many_ids(self):
        subject = '#1234 then #5678 too many.'
        result = self._call_function_under_test(subject)
        self.assertIsNone(result)

    ",False
366,https://github.com/dhermes/ci-diff-helper/blob/876affd3ba49d78c48708a12103d39ef3c7d5f1d/tests/test__utils.py,Test_pr_from_commit,test_valid_id,"def test_valid_id(self):
        expected = 88901
        subject = 'Merge pull request #{:d} from queso/cheese'.format(expected)
        result = self._call_function_under_test(subject)
        self.assertEqual(result, expected)
",False
367,https://github.com/dhermes/ci-diff-helper/blob/876affd3ba49d78c48708a12103d39ef3c7d5f1d/tests/test_git_tools.py,Test_get_checked_in_files,test_actual_call,"def test_actual_call(self):
        result = self._call_function_under_test()
        tests_dir = os.path.dirname(__file__)
        root_dir = os.path.abspath(os.path.join(tests_dir, '..'))
        self.assertLessEqual(set(result), self._all_files(root_dir))


class Test_get_changed_files(unittest.TestCase):

    @staticmethod
    ",False
368,https://github.com/dhermes/ci-diff-helper/blob/876affd3ba49d78c48708a12103d39ef3c7d5f1d/tests/test_git_tools.py,Test_git_root,test_actual_call,"def test_actual_call(self):
        result = self._call_function_under_test()
        result = os.path.abspath(result)  # Normalize path for Windows.
        tests_dir = os.path.dirname(__file__)
        root_dir = os.path.abspath(os.path.join(tests_dir, '..'))
        self.assertEqual(result, root_dir)


class Test_get_checked_in_files(unittest.TestCase):

    @staticmethod
    ",False
369,https://github.com/mehdisadeghi/clashogram/blob/5b8cc18adfc92ad381040ee25b750df462122939/test_everything.py,MessageFactoryTestCase,test_format_time_default,"def test_format_time_default(self):
        os.environ['LANGUAGE'] = 'en'
        timestr = self.msg_factory.format_time('20170603T191148.000Z')
        self.assertEqual(timestr, 'Sat, 03 Jun 2017 19:11:48')

    ",True
370,https://github.com/prometheus/client_python/blob/5b0a476489fc6a26c177683b539142c91005de06/tests/test_exposition.py,TestPushGateway,test_push_with_basic_auth_handler,"def test_push_with_basic_auth_handler(self):
        ",False
371,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/connector/test_snapshot_azure.py,,test_get_node_happy,"def test_get_node_happy(monkeypatch):
    monkeypatch.setattr('processor.connector.snapshot_azure.http_get_request', mock_http_get_request_happy)
    from processor.connector.snapshot_azure import get_node
    data = {
        'type': 'Microsoft.Network/virtualNetworks',
        'snapshotId': '1',
        'path': ""/resourceGroups/mno-nonprod-shared-cet-eastus2-networkWatcher/providers/""
                ""Microsoft.Compute/availabilitySets/mno-nonprod-shared-cet-eastus2-tab-as03""

    }
    ret = get_node(None, None, None, data, 'abc', 'azureStructure')
    assert True == isinstance(ret, dict)
    ret = get_node('abcd', 'devtest', 'xyz', data, 'abc', 'azureStructure')
    assert True == isinstance(ret, dict)
    assert {'a': 'b'} == ret['json']


",True
372,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/connector/test_snapshot_azure.py,,test_get_version_for_type,"def test_get_version_for_type(monkeypatch):
    from processor.connector.snapshot_azure import get_version_for_type
    assert None == get_version_for_type({})
    assert '2019-09-01' == get_version_for_type({'type': 'Microsoft.Network/virtualNetworks'})

    monkeypatch.setattr('processor.connector.snapshot_azure.json_source', mock_db_json_source)
    monkeypatch.setattr('processor.connector.snapshot_azure.config_value', mock_config_value)
    monkeypatch.setattr('processor.connector.snapshot_azure.get_documents', mock_api_version_get_document)
    assert '2017-07-01' == get_version_for_type({'type': 'Microsoft.RecoveryServices/locations/backupStatus'})


",True
373,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/helper/config/test_config_utils.py,,test_framework_config,"def test_framework_config():
    configini = '%s/config.ini' % TESTSDIR
    with open(configini) as f:
        tests_configini = f.read()
    configfile = framework_config()
    with open(configfile) as f:
        prod_configini = f.read()
    assert tests_configini == prod_configini


",True
374,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/helper/config/test_config_utils.py,,test_framework_dir,"def test_framework_dir():
    os.chdir(TESTSDIR)
    tests_curdir = os.getcwd()
    fw_dir = framework_dir()
    os.chdir(fw_dir)
    prod_curdir = os.getcwd()
    assert tests_curdir == prod_curdir


",True
375,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/helper/config/test_config_utils.py,,test_get_config_data,"def test_get_config_data():
    configdata = get_config_data(None)
    assert configdata is None
    configdata = get_config_data('/tmp/asdxz.ini')
    assert configdata is None
    tests_configini = '%s/config.ini' % TESTSDIR
    tests_configdata = get_config_data(tests_configini)
    assert tests_configdata is not None
    prod_configdata = get_config_data(framework_config())
    assert prod_configdata is not None
    assert tests_configdata == prod_configdata


",True
376,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/helper/config/test_config_utils.py,,test_get_solution_dir,"def test_get_solution_dir():
    os.chdir(TESTSDIR)
    tests_curdir = os.getcwd()
    os.chdir(framework_dir())
    prod_curdir = os.getcwd()
    assert tests_curdir == prod_curdir


",True
377,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/helper/config/test_config_utils.py,,test_get_test_json_dir,"def test_get_test_json_dir():
    test_dir = os.getenv('TESTDIR', '/realm/validation/')
    val_dir = '%s/%s' % (TESTSDIR, test_dir)
    os.chdir(val_dir)
    tests_curdir = os.getcwd()
    os.chdir(get_test_json_dir())
    prod_curdir = os.getcwd()
    assert tests_curdir == prod_curdir
",True
378,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/helper/config/test_rundata_utils.py,,test_init_config,"def test_init_config():
    runcfg = framework_currentdata()
    rundir = os.path.dirname(runcfg)
    # if os.path.exists(rundir):
    #    shutil.rmtree(rundir)
    # assert False == os.path.exists(rundir)
    assert True == os.path.exists(runcfg)
    init_currentdata()
    assert True == os.path.exists(rundir)
    assert True == os.path.exists(runcfg)
    os.remove(runcfg)
    assert True == os.path.exists(rundir)
    assert False == os.path.exists(runcfg)
    init_currentdata()
    assert True == os.path.exists(rundir)
    assert True == os.path.exists(runcfg)


",True
379,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/helper/httpapi/test_http_utils.py,,test_check_and_add_error,"def test_check_and_add_error():
    from processor.helper.httpapi.http_utils import check_and_add_error
    from processor.helper.config.rundata_utils import save_currentdata, get_from_currentdata
    save_currentdata(None)
    check_and_add_error(200, 'Failed http get')
    value = get_from_currentdata('errors')
    assert value is None
    check_and_add_error(400, 'Failed http get')
    value = get_from_currentdata('errors')
    assert value is not None
",False
380,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/helper/httpapi/test_restapi_azure.py,,test_web_client_data,"def test_web_client_data(monkeypatch):
    monkeypatch.setattr('processor.helper.httpapi.restapi_azure.get_from_currentdata',
                        mock_get_from_currentdata)
    monkeypatch.setattr(os, 'getenv', mock_empty_getenv)
    monkeypatch.setattr('processor.helper.httpapi.restapi_azure.input', mock_input)
    from processor.helper.httpapi.restapi_azure import get_client_secret, get_web_client_data
    assert 'clientSecret' == get_client_secret()
    client_id, client_secret, sub_name, sub_id, tenant_id = \
        get_web_client_data('azure', 'azureConnector.json', '<spn-name>')
    assert client_id is not None
    assert client_secret == '<client_secret>'
    assert sub_id is not None
    assert sub_name is not None
    assert tenant_id is not None


",True
381,https://github.com/prancer-io/cloud-validation-framework/blob/94522590d9881a5125d81da701a65f7f63383c0d/tests/processor/template_processor/base/test_base_template_processor.py,,test_populate_template_snapshot_false,"def test_populate_template_snapshot_false(monkeypatch):
    monkeypatch.setattr('processor.template_processor.base.base_template_processor.config_value', mock_config_value)
    monkeypatch.setattr('processor.template_processor.base.base_template_processor.get_collection_size', mock_get_collection_size)
    monkeypatch.setattr('processor.template_processor.base.base_template_processor.create_indexes', mock_create_indexes)
    monkeypatch.setattr('processor.template_processor.base.base_template_processor.insert_one_document', mock_insert_one_document)
    from processor.template_processor.base.base_template_processor import TemplateProcessor

    template_processor = TemplateProcessor(node_data, **template_processor_kwargs)
    snapshot_data = template_processor.populate_template_snapshot()
    assert snapshot_data == {
		'SNAPSHOT_1': False
	}

",True
382,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_classify.py,TestFindRain,test_1,"def test_1(self):
        result = np.zeros(len(self.time))
        assert_array_equal(classify._find_rain(self.z, self.time), result)

    ",True
383,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_classify.py,TestFindRain,test_3,"def test_3(self):
        self.z[5, 3] = 0.1
        result = np.ones(len(self.time))
        result[3:7] = 1
        assert_array_equal(classify._find_rain(self.z, self.time,
                                               time_buffer=1), result)

    ",True
384,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
385,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
386,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
387,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
388,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
389,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
390,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
391,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
392,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
393,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
394,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
395,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
396,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
397,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
398,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
399,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
400,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
401,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
402,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
403,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
404,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_append_data,"def test_append_data(class_objects, result, key):
    from cloudnetpy.products.drizzle import _append_data
    d_source, d_class, s_width = class_objects
    _append_data(d_source, result)
    assert key in d_source.data.keys()


@pytest.mark.parametrize(""x, result"", [
    (-1000, -1),
    (-100, -0.99999),
    (-10, -0.9),
    (-1, np.exp(-1 / 10 * np.log(10)) - 1),
])
",True
405,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_beta_z_ratio,"def test_calc_beta_z_ratio(class_objects):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    obj.data.beta = np.array([[1, 1, 2], [1, 1, 3]])
    obj.data.z = np.array([[2, 2, 1], [1, 1, 1]])
    compare = 2 / np.pi * obj.data.beta / obj.data.z
    testing.assert_array_almost_equal(obj._calc_beta_z_ratio(), compare)


",True
406,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_density,"def test_calc_density(class_objects, params_objects):
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    obj.data.z = np.array([1, 2, 3])
    compare = obj.data.z * 3.67 ** 6 / obj.parameters['Do'] ** 6
    testing.assert_array_almost_equal(obj._calc_density(), compare)


",True
407,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_derived_products,"def test_calc_derived_products(class_objects, params_objects, key):
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    dictio = obj._calc_derived_products()
    assert key in dictio.keys()


",True
408,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_derived_products,"def test_calc_derived_products(class_objects, params_objects, key):
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    dictio = obj._calc_derived_products()
    assert key in dictio.keys()


",True
409,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_derived_products,"def test_calc_derived_products(class_objects, params_objects, key):
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    dictio = obj._calc_derived_products()
    assert key in dictio.keys()


",True
410,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_derived_products,"def test_calc_derived_products(class_objects, params_objects, key):
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    dictio = obj._calc_derived_products()
    assert key in dictio.keys()


",True
411,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_derived_products,"def test_calc_derived_products(class_objects, params_objects, key):
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    dictio = obj._calc_derived_products()
    assert key in dictio.keys()


",True
412,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_dia,"def test_calc_dia(class_objects):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    beta_z = np.array([1, 2, 3])
    compare = (gamma(3) / gamma(7) * 3.67 ** 4 / beta_z) ** (1 / 4)
    testing.assert_array_almost_equal(obj._calc_dia(beta_z), compare)


# Create params object with class_objects
@pytest.fixture(scope='session')
",True
413,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_fall_velocity,"def test_calc_fall_velocity(class_objects, params_objects):
    # TODO: fix this
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    compare = np.array([[0, -7.11002091, -7.11002091],
                        [-7.11002091, -7.11002091, 0]])
    testing.assert_array_almost_equal(obj._calc_fall_velocity(), compare)


",True
414,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_lwc,"def test_calc_lwc(class_objects, params_objects):
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    dia, mu, s = [obj.parameters.get(key) for key in ('Do', 'mu', 'S')]
    gamma_ratio = gamma(4 + mu) / gamma(3 + mu) / (3.67 + mu)
    compare = 1000 / 3 * obj.data.beta * s * dia * gamma_ratio
    testing.assert_array_almost_equal(obj._calc_lwc(), compare)


",True
415,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_lwf,"def test_calc_lwf(class_objects, params_objects):
    # TODO: fix this
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    lwc_in = np.array([[0.001, 0.001, 0.002],
                       [0.003, 0.002, 0.001]])
    compare = np.array([[0.001, 0.005508, 0.011016],
                        [0.016524, 0.011016, 0.001]])
    testing.assert_array_almost_equal(obj._calc_lwf(lwc_in), compare)


",True
416,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_calc_v_air,"def test_calc_v_air(class_objects, params_objects):
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    d_v = np.array([[2.0, 2.0, 4.0], [1.0, 3.0, 5.0]])
    obj.ind_drizzle = (np.array([0, 1]), np.array([1, 2]))
    compare = np.array([[-2.0, 0.0, -4.0],
                        [-1.0, -3.0, -2.0]])
    testing.assert_array_almost_equal(obj._calc_v_air(d_v), compare)


@pytest.fixture(scope='session')
",True
417,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_find_indices,"def test_find_indices(class_objects, params_objects):
    d_source, d_class, s_width = class_objects
    obj = CalculateProducts(d_source, params_objects)
    obj.parameters['Do'] = np.array([[0.0, 1.0, 1.0],
                                     [1.0, 1.0, 0.0]])
    x, y = obj._find_indices()
    compare = (np.array([0, 0, 1, 1]),
               np.array([1, 2, 0, 1]))
    testing.assert_array_almost_equal(x, compare)


@pytest.mark.parametrize('key', [
    'drizzle_N', 'drizzle_lwc', 'drizzle_lwf', 'v_drizzle', 'v_air'])
",True
418,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_find_lut_indices,"def test_find_lut_indices(class_objects):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    ind = (1, 2)
    dia_init = np.array([[1, 3, 2], [3, 1, 2]])
    n_dia = 1
    n_width = 2
    ind_d = bisect_left(obj.data.mie['Do'], dia_init[ind], hi=n_dia - 1)
    ind_w = bisect_left(obj.width_lut[:, ind_d], -obj.width_ht[ind], hi=n_width - 1)
    compare = (ind_w, ind_d)
    testing.assert_almost_equal(obj._find_lut_indices
                                (ind, dia_init, n_dia, n_width), compare)


@pytest.mark.parametrize('key, value', [
    ('Do', 10),
    ('mu', -1),
    ('S', 93.7247943)])
",True
419,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_init_variables,"def test_init_variables(class_objects, key):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    result, x = obj._init_variables()
    assert key in result.keys()


",True
420,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_init_variables,"def test_init_variables(class_objects, key):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    result, x = obj._init_variables()
    assert key in result.keys()


",True
421,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_init_variables,"def test_init_variables(class_objects, key):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    result, x = obj._init_variables()
    assert key in result.keys()


",True
422,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_init_variables,"def test_init_variables(class_objects, key):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    result, x = obj._init_variables()
    assert key in result.keys()


",True
423,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_is_converged,"def test_is_converged(class_objects):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    ind = (1, 2)
    dia_init = np.array([[1, 3, 2], [3, 1, 2]])
    dia = 1
    compare = False
    assert obj._is_converged(ind, dia, dia_init) == compare


",True
424,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_screen_rain,"def test_screen_rain(class_objects, result):
    from cloudnetpy.products.drizzle import _screen_rain
    d_source, d_class, s_width = class_objects
    result = _screen_rain(result, d_class)
    compare = True
    for key in result.keys():
        if not utils.isscalar(result[key]):
            if not np.any(result[key][-1]) == np.any(np.array([0, 0, 0])):
                compare = False
    assert compare is True


@pytest.mark.parametrize(""key"", [
    ""Do"", ""mu"", ""S"", ""beta_corr"", ""drizzle_N"", ""drizzle_lwc"", ""drizzle_lwf"", ""v_drizzle"",
    ""v_air"", ""Do_error"", ""drizzle_lwc_error"", ""drizzle_lwf_error"", ""S_error"",
    ""Do_bias"", ""drizzle_lwc_bias"", ""drizzle_lwf_bias"", ""drizzle_N_error"",
    ""v_drizzle_error"", ""mu_error"", ""drizzle_N_bias"", ""v_drizzle_bias""])
",True
425,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_update_result_tables,"def test_update_result_tables(class_objects, key, value):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    ind = (0, 1)
    dia = 10
    lut = (0, 1)
    obj._update_result_tables(ind, dia, lut)
    testing.assert_almost_equal(obj.params[key][ind], value)


",True
426,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_update_result_tables,"def test_update_result_tables(class_objects, key, value):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    ind = (0, 1)
    dia = 10
    lut = (0, 1)
    obj._update_result_tables(ind, dia, lut)
    testing.assert_almost_equal(obj.params[key][ind], value)


",True
427,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_drizzle.py,,test_update_result_tables,"def test_update_result_tables(class_objects, key, value):
    d_source, d_class, s_width = class_objects
    obj = DrizzleSolving(d_source, d_class, s_width)
    ind = (0, 1)
    dia = 10
    lut = (0, 1)
    obj._update_result_tables(ind, dia, lut)
    testing.assert_almost_equal(obj.params[key][ind], value)


",True
428,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_lwc.py,,test_init_status,"def test_init_status(value):
    assert value in STATUS_OBJ._init_status()


@pytest.mark.parametrize(""key"", ['radar', 'lidar'])
",True
429,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_lwc.py,,test_remove_good_profiles,"def test_remove_good_profiles():
    top_c = np.asarray([[1, 1, 0], [1, 0, 1]], dtype=bool)
    compare = np.asarray([[1, 1, 0], [0, 0, 0]], dtype=bool)
    assert_array_equal(STATUS_OBJ._remove_good_profiles(top_c), compare)


",True
430,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_lwc.py,,test_update_status,"def test_update_status(value):
    time = np.array([0])
    STATUS_OBJ._update_status(time)
    assert value in STATUS_OBJ.status


@pytest.mark.parametrize(""value"", [0, 1, 2, 3])
",True
431,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_lwc.py,,test_update_status,"def test_update_status(value):
    time = np.array([0])
    STATUS_OBJ._update_status(time)
    assert value in STATUS_OBJ.status


@pytest.mark.parametrize(""value"", [0, 1, 2, 3])
",True
432,https://github.com/tukiains/cloudnetpy/blob/26f2607b890630146469cfa410fce99438ceee3f/tests/unit/test_rpg.py,TestReduceHeader,test_1,"def test_1(self):
        assert_array_equal(rpg._reduce_header(self.header),
                           {'a': 1, 'b': 2, 'c': 3})

    ",True
433,https://github.com/nir0s/clu/blob/77da967a4577ca4cf100cfe34e87b39ad88bf21c/tests/test_ghost.py,TestCLI,test_fail_init_two_stashes_passphrase_file_exists,"def test_fail_init_two_stashes_passphrase_file_exists(self,
                                                          stash_path,
                                                          temp_file_path):
        _invoke('init_stash ""{0}""'.format(stash_path))
        result = _invoke('init_stash ""{0}"" -b sqlalchemy'.format(
            temp_file_path))

        assert 'Overwriting might prevent you' in result.output
        assert result.exit_code == 1

    ",True
434,https://github.com/nir0s/clu/blob/77da967a4577ca4cf100cfe34e87b39ad88bf21c/tests/test_ghost.py,TestCLI,test_init_already_initialized,"def test_init_already_initialized(self, test_cli_stash):
        result = _invoke('init_stash ""{0}"" -p {1}'.format(
            os.environ['GHOST_STASH_PATH'], test_cli_stash.passphrase))
        assert 'Stash already initialized' in result.output
        assert result.exit_code == 0

    @pytest.mark.skipif(os.name == 'nt', reason='Irrelevant on Windows')
    @mock.patch('ghost._write_passphrase_file', _mock_write_passphrase_file)
    ",True
435,https://github.com/nir0s/clu/blob/77da967a4577ca4cf100cfe34e87b39ad88bf21c/tests/test_ghost.py,TestCLI,test_init_permission_denied_on_passphrase,"def test_init_permission_denied_on_passphrase(self):
        fd, temp_file = tempfile.mkstemp()
        os.close(fd)
        os.remove(temp_file)
        result = _invoke('init_stash ""{0}"" -p whatever'.format(temp_file))
        assert 'Expected OSError' in str(result.exception)
        assert 'Removing stale stash and passphrase' in str(result.output)
        assert type(result.exception) == SystemExit
        assert result.exit_code == 1
        # Since the invocation process both creates and deletes the stash
        # in case of failure, there's no way to verify that the file
        # exists in the middle of the test. This is a reasonable assumption
        # though as otherwise the removal statement will not be covered.
        assert not os.path.isfile(temp_file)

    @pytest.mark.skipif(os.name == 'nt', reason='Irrelevant on Windows')
    ",True
436,https://github.com/nir0s/clu/blob/77da967a4577ca4cf100cfe34e87b39ad88bf21c/tests/test_ghost.py,TestSQLAlchemyStorage,test_is_initialized,"def test_is_initialized(self, stash_path):
        storage = ghost.SQLAlchemyStorage(stash_path)
        stash = ghost.Stash(storage)
        assert storage.is_initialized is False
        stash.init()
        assert storage.is_initialized is True
        storage_tester.is_initialized(storage.is_initialized)

    ",True
437,https://github.com/nir0s/clu/blob/77da967a4577ca4cf100cfe34e87b39ad88bf21c/tests/test_ghost.py,TestStash,test_broken_is_initialized,"def test_broken_is_initialized(self, test_cli_stash):
        assert test_cli_stash.is_initialized is True
        test_cli_stash._storage.delete('stored_passphrase')
        assert test_cli_stash.is_initialized is False

    ",True
438,https://github.com/nir0s/clu/blob/77da967a4577ca4cf100cfe34e87b39ad88bf21c/tests/test_ghost.py,TestTinyDBStorage,test_init_stash_in_current_dir,"def test_init_stash_in_current_dir(self):
        """"""Test this because it depends on the ability
        of the storage to understand whether it should or should not create
        a directory.
        """"""
        prev_dir = os.getcwd()
        stash_dir = tempfile.mkdtemp()
        os.chdir(stash_dir)
        stash_path = os.path.join(stash_dir, 'stash.json')
        try:
            storage = ghost.TinyDBStorage(stash_path)
            stash = ghost.Stash(storage)
            assert os.path.isfile(stash_path) is False
            stash.init()
            assert os.path.isfile(stash_path) is True
        finally:
            os.chdir(prev_dir)
            shutil.rmtree(stash_dir, ignore_errors=True)

    ",True
439,https://github.com/nir0s/clu/blob/77da967a4577ca4cf100cfe34e87b39ad88bf21c/tests/test_ghost.py,TestTinyDBStorage,test_is_initialized,"def test_is_initialized(self, stash_path):
        storage = ghost.TinyDBStorage(stash_path)
        stash = ghost.Stash(storage)
        assert storage.is_initialized is False
        stash.init()
        assert storage.is_initialized is True
        storage_tester.is_initialized(storage.is_initialized)

    ",True
440,https://github.com/coinbase/coinbase-commerce-python/blob/d306fc562309edb909c8ace501c63327a7635975/tests/api_resources/base/test_create_api_resource.py,TestCreateAPIResource,test_create,"def test_create(self):
        self.stub_request('post', TestCreateResource.RESOURCE_PATH,
                          {'resource': 'checkout', 'foo': 'bar', })
        TestCreateResource._api_client = self.client
        api_obj = TestCreateResource.create()
        self.assert_requested('post', TestCreateResource.RESOURCE_PATH, data={})
        self.assertEqual('bar', api_obj.foo)
        self.assertIsInstance(api_obj, Checkout)
",True
441,https://github.com/coinbase/coinbase-commerce-python/blob/d306fc562309edb909c8ace501c63327a7635975/tests/api_resources/base/test_list_api_resource.py,TestListAPIResource,test_list,"def test_list(self):
        self.stub_request('get', TestDeleteResource.RESOURCE_PATH,
                          {'data': [{'resource': 'charge', 'name': 'foo', },
                                    {'resource': 'charge', 'name': 'bar', }], }, )
        TestDeleteResource._api_client = self.client
        res = TestDeleteResource.list()
        self.assert_requested('get', TestDeleteResource.RESOURCE_PATH, params={})
        self.assertEqual(2, len(res.data))
        self.assertTrue(all(isinstance(obj, Charge)
                            for obj in res.data))
        self.assertEqual('foo', res.data[0].name)
        self.assertEqual('bar', res.data[1].name)
",True
442,https://github.com/coinbase/coinbase-commerce-python/blob/d306fc562309edb909c8ace501c63327a7635975/tests/api_resources/test_charge.py,TestCharge,test_list_iter_mapping,"def test_list_iter_mapping(self):
        # arrange
        self.stub_request('get', 'charges', {'data': [{'resource': 'charge'} for _ in range(20)]})
        # act
        for charge in self.client.charge.list_paging_iter():
            # assert
            self.assertIsInstance(charge, Charge)

    ",True
443,https://github.com/coinbase/coinbase-commerce-python/blob/d306fc562309edb909c8ace501c63327a7635975/tests/api_resources/test_checkout.py,TestCheckout,test_list_iter_mapping,"def test_list_iter_mapping(self):
        # arrange
        self.stub_request('get', 'checkouts', {'data': [{'resource': 'checkout'} for _ in range(25)]})
        # act
        for checkout in self.client.checkout.list_paging_iter():
            # assert
            self.assertIsInstance(checkout, Checkout)

    ",True
444,https://github.com/coinbase/coinbase-commerce-python/blob/d306fc562309edb909c8ace501c63327a7635975/tests/api_resources/test_event.py,TestEvent,test_list_iter_mapping,"def test_list_iter_mapping(self):
        # arrange
        self.stub_request('get', 'events', {'data': [{'resource': 'event'} for _ in range(20)]})
        # act
        for event in self.client.event.list_paging_iter():
            # assert
            self.assertIsInstance(event, Event)

    ",True
445,https://github.com/coinbase/coinbase-commerce-python/blob/d306fc562309edb909c8ace501c63327a7635975/tests/test_api_client.py,TestApiClient,test_authentication_error,"def test_authentication_error(self, session_mock):
        mock.MagicMock.ok = PropertyMock(return_value=False)
        mock.MagicMock.status_code = PropertyMock(return_value=401)
        client = TestApiClient.mock_client()
        with self.assertRaises(AuthenticationError):
            client._request('get', 'foo')

    @mock.patch('requests.session', side_effect=mock.MagicMock)
    ",True
446,https://github.com/coinbase/coinbase-commerce-python/blob/d306fc562309edb909c8ace501c63327a7635975/tests/test_api_client.py,TestApiClient,test_invalid_request_error,"def test_invalid_request_error(self, session_mock):
        mock.MagicMock.ok = PropertyMock(return_value=False)
        mock.MagicMock.status_code = PropertyMock(return_value=400)
        client = TestApiClient.mock_client()
        with self.assertRaises(InvalidRequestError):
            client._request('get', 'foo')

    @mock.patch('requests.session', side_effect=mock.MagicMock)
    ",True
447,https://github.com/coinbase/coinbase-commerce-python/blob/d306fc562309edb909c8ace501c63327a7635975/tests/test_api_client.py,TestApiClient,test_resource_not_found_error,"def test_resource_not_found_error(self, session_mock):
        mock.MagicMock.ok = PropertyMock(return_value=False)
        mock.MagicMock.status_code = PropertyMock(return_value=404)
        client = TestApiClient.mock_client()
        with self.assertRaises(ResourceNotFoundError):
            client._request('get', 'foo')

    @mock.patch('requests.session', side_effect=mock.MagicMock)
    ",True
448,https://github.com/JakubTesarek/colltools/blob/e50f98ccda33ab409fcdba277a39f071824e24c7/tests/test_name_registry.py,,test_name_registry_has_no_instances,"def test_name_registry_has_no_instances():
    assert NameRegistry.__members__ == {}


",True
449,https://github.com/neulab/compare-mt/blob/92502b30b1f228773179a01dd86fe1b8dfd400e5/tests/test_cache.py,TestScoreCache,test_score_cache_bootstrap,"def test_score_cache_bootstrap(self):
    cached_stats1 = compare_mt_main.generate_score_report(self.ref, [self.out1], to_cache=True)
    cached_stats2 = compare_mt_main.generate_score_report(self.ref, [self.out2], to_cache=True)
    self.assertTrue('scores' in cached_stats1 and 'strs' in cached_stats1 and 'sign_stats' in cached_stats1)
    self.assertTrue('scores' in cached_stats2 and 'strs' in cached_stats2 and 'sign_stats' in cached_stats2)
    self.assertAlmostEqual(cached_stats1['scores'], 22.44, places=1)
    reporters.sys_names = [f'sys{i+1}' for i in range(2)]
    cached_report = compare_mt_main.generate_score_report(self.ref, [self.out1, self.out2], cache_dicts=[cached_stats1, cached_stats2], bootstrap=5, title='Aggregate Scores')
    ori_report = compare_mt_main.generate_score_report(self.ref, [self.out1, self.out2], bootstrap=5, title='Aggregate Scores')
    self.assertTrue(cached_report.scores == ori_report.scores)
    self.assertTrue(cached_report.strs == ori_report.strs)
    self.assertTrue(cached_report.wins == ori_report.wins)
    
class TestWordAccCache(unittest.TestCase):

  @classmethod
  ",True
450,https://github.com/neulab/compare-mt/blob/92502b30b1f228773179a01dd86fe1b8dfd400e5/tests/test_cache.py,TestSentBucketCache,test_sentbucket_cache,"def test_sentbucket_cache(self):
    cached_stats1 = compare_mt_main.generate_sentence_bucketed_report(self.ref, [self.out1], to_cache=True)
    cached_stats2 = compare_mt_main.generate_sentence_bucketed_report(self.ref, [self.out2], to_cache=True)
    self.assertTrue('stats' in cached_stats1)
    self.assertTrue('stats' in cached_stats2)
    ori_report = compare_mt_main.generate_sentence_bucketed_report(self.ref, [self.out1, self.out2])
    cached_report = compare_mt_main.generate_sentence_bucketed_report(self.ref, [self.out1, self.out2], cache_dicts=[cached_stats1, cached_stats2])
    self.assertTrue(cached_report.sys_stats == ori_report.sys_stats)

class TestNgramCache(unittest.TestCase):

  @classmethod
  ",True
451,https://github.com/neulab/compare-mt/blob/92502b30b1f228773179a01dd86fe1b8dfd400e5/tests/test_cache.py,TestSrcWordAccCache,test_src_wordacc_cache,"def test_src_wordacc_cache(self):
    cached_stats1 = compare_mt_main.generate_src_word_accuracy_report(self.ref, [self.out1], self.src, ref_align_file=self.ref_align_file, to_cache=True)
    cached_stats2 = compare_mt_main.generate_src_word_accuracy_report(self.ref, [self.out2], self.src, ref_align_file=self.ref_align_file, to_cache=True)
    self.assertTrue('statistics' in cached_stats1 and 'my_ref_total_list' in cached_stats1 and 'my_out_matches_list' in cached_stats1)
    self.assertTrue('statistics' in cached_stats2 and 'my_ref_total_list' in cached_stats2 and 'my_out_matches_list' in cached_stats2)
    ori_report = compare_mt_main.generate_src_word_accuracy_report(self.ref, [self.out1, self.out2], self.src, ref_align_file=self.ref_align_file)
    cached_report = compare_mt_main.generate_src_word_accuracy_report(self.ref, [self.out1, self.out2], self.src, ref_align_file=self.ref_align_file, cache_dicts=[cached_stats1, cached_stats2])
    self.assertTrue(cached_report.statistics == ori_report.statistics)
    self.assertTrue(cached_report.examples == ori_report.examples)

class TestSentBucketCache(unittest.TestCase):

  @classmethod
  ",True
452,https://github.com/neulab/compare-mt/blob/92502b30b1f228773179a01dd86fe1b8dfd400e5/tests/test_cache.py,TestWordAccCache,test_wordacc_cache,"def test_wordacc_cache(self):
    cached_stats1 = compare_mt_main.generate_word_accuracy_report(self.ref, [self.out1], to_cache=True)
    cached_stats2 = compare_mt_main.generate_word_accuracy_report(self.ref, [self.out2], to_cache=True)
    self.assertTrue('statistics' in cached_stats1 and 'my_ref_total_list' in cached_stats1 and 'my_out_matches_list' in cached_stats1)
    self.assertTrue('statistics' in cached_stats2 and 'my_ref_total_list' in cached_stats2 and 'my_out_matches_list' in cached_stats2)
    ori_report = compare_mt_main.generate_word_accuracy_report(self.ref, [self.out1, self.out2])
    cached_report = compare_mt_main.generate_word_accuracy_report(self.ref, [self.out1, self.out2], cache_dicts=[cached_stats1, cached_stats2])
    self.assertTrue(cached_report.statistics == ori_report.statistics)
    self.assertTrue(cached_report.examples == ori_report.examples)

class TestSrcWordAccCache(unittest.TestCase):

  @classmethod
  ",True
453,https://github.com/JGoutin/compilertools/blob/7b898cb6970f5f25c5356b15a2efd0cb2e54d566/tests/test___init__.py,,tests_init,"def tests_init():
    """"""Test __version__ presence and format""""""
    from pytest import raises
    from collections import namedtuple
    import sys

    sys_version_info = sys.version_info
    version_info = namedtuple(
        ""Version_Info"", [""major"", ""minor"", ""micro"", ""releaselevel"", ""serial""]
    )

    try:
        with raises(ImportError):
            sys.version_info = version_info(3, 3, 0, ""final"", 0)
            import compilertools  # noqa: F401

    # Cleaning
    finally:
        sys.version_info = sys_version_info


",True
454,https://github.com/JGoutin/compilertools/blob/7b898cb6970f5f25c5356b15a2efd0cb2e54d566/tests/test_build.py,,tests_patch___new__,"def tests_patch___new__():
    """"""Test _patch___new__""""""
    # Check if patched
    assert BUILD_EXT_NEW is not build_ext.__new__

    # Check build_ext instantiation
    from distutils.dist import Distribution

    build_ext(Distribution())
    assert GET_EXT_FULLNAME is not build_ext.get_ext_fullname
    assert GET_EXT_FILENAME is not build_ext.get_ext_filename
    assert BUILD_EXTENSION is not build_ext.build_extension
    assert GET_OUTPUTS is not build_ext.get_outputs
",True
455,https://github.com/Zomojo/compiletools/blob/e45c5ad452b86c1fe557961aa4ebefd3f34f6a58/ct/test_library.py,TestLibrary,test_build_and_link_static_library,"def test_build_and_link_static_library(self):
        # Setup
        origdir = os.getcwd()
        self._tmpdir = tempfile.mkdtemp()

        # Mimic the build.sh and create the library in a 'mylib' subdirectory
        # Copy the sample source files into the test build location
        mylibdir = os.path.join(self._tmpdir, ""mylib"")
        shutil.copytree(os.path.join(uth.samplesdir(), ""library/mylib""), mylibdir)

        # Build the library
        temp_config_name = uth.create_temp_config(self._tmpdir)
        uth.create_temp_ct_conf(self._tmpdir, defaultvariant=temp_config_name[:-5])
        argv = [
            ""--exemarkers=main"",
            ""--testmarkers=unittest.hpp"",
            ""--config="" + temp_config_name,
            ""--CTCACHE=None"",
            ""--static"",
            os.path.join(self._tmpdir, ""mylib/get_numbers.cpp""),
        ]
        os.chdir(mylibdir)
        uth.reset()
        ct.cake.main(argv)

        # Copy the main that will link to the library into the test build location
        relativepaths = [""library/main.cpp""]
        realpaths = [
            os.path.join(uth.samplesdir(), filename) for filename in relativepaths
        ]
        for ff in realpaths:
            shutil.copy2(ff, self._tmpdir)

        # Build the exe, linking agains the library
        argv = [""--config="" + temp_config_name, ""--CTCACHE=None""] + realpaths
        os.chdir(self._tmpdir)
        uth.reset()
        ct.cake.main(argv)

        # Check that an executable got built for each cpp
        actual_exes = set()
        for root, dirs, files in os.walk(self._tmpdir):
            for ff in files:
                if ct.utils.isexecutable(os.path.join(root, ff)):
                    actual_exes.add(ff)

        expected_exes = {
            os.path.splitext(os.path.split(filename)[1])[0]
            for filename in relativepaths
        }
        self.assertSetEqual(expected_exes, actual_exes)

        # Cleanup
        os.chdir(origdir)
        shutil.rmtree(self._tmpdir, ignore_errors=True)

    ",False
456,https://github.com/pypr/compyle/blob/f557e49c7e18a49efdb5807ac650ba590db81cb2/compyle/tests/test_array.py,,test_sort_by_keys,"def test_sort_by_keys(backend):
    check_import(backend)

    # Given
    nparr1 = np.random.randint(0, 100, 16, dtype=np.int32)
    nparr2 = np.random.randint(0, 100, 16, dtype=np.int32)
    dev_array1, dev_array2 = array.wrap(nparr1, nparr2, backend=backend)

    # When
    out_array1, out_array2 = array.sort_by_keys([dev_array1, dev_array2])

    # Then
    order = np.argsort(nparr1)
    act_result1 = np.take(nparr1, order)
    act_result2 = np.take(nparr2, order)
    assert np.all(out_array1.get() == act_result1)
    assert np.all(out_array2.get() == act_result2)


",False
457,https://github.com/pypr/compyle/blob/f557e49c7e18a49efdb5807ac650ba590db81cb2/compyle/tests/test_array.py,,test_sort_by_keys_with_output,"def test_sort_by_keys_with_output(backend):
    check_import(backend)

    # Given
    nparr1 = np.random.randint(0, 100, 16, dtype=np.int32)
    nparr2 = np.random.randint(0, 100, 16, dtype=np.int32)
    dev_array1, dev_array2 = array.wrap(nparr1, nparr2, backend=backend)
    out_arrays = [
        array.zeros_like(dev_array1),
        array.zeros_like(dev_array2)]

    # When
    array.sort_by_keys([dev_array1, dev_array2],
                       out_list=out_arrays, use_radix_sort=False)

    # Then
    order = np.argsort(nparr1)
    act_result1 = np.take(nparr1, order)
    act_result2 = np.take(nparr2, order)
    assert np.all(out_arrays[0].get() == act_result1)
    assert np.all(out_arrays[1].get() == act_result2)


@check_all_backends
",False
458,https://github.com/pypr/compyle/blob/f557e49c7e18a49efdb5807ac650ba590db81cb2/compyle/tests/test_ext_module.py,TestExtModule,test_that_multiple_writes_do_not_occur_for_same_source,"def test_that_multiple_writes_do_not_occur_for_same_source(self):
        # Given
        n_proc = 5
        p = Pool(n_proc)

        # When

        # Note that _create_extension cannot be defined here or even in the
        # class as a nested function or instance method cannot be pickled.

        result = p.map(_check_write_source, [self.root]*n_proc)
        p.close()

        # Then
        # The file should have been opened only once.
        self.assertEqual(sum(result), 1)

    ",False
459,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestLinuxNoXDG,test_noxdg_cache,"def test_noxdg_cache(self):
        checkcache = os.path.join(self.tempdir, '.cache', 'fakeapp')
        self.assertEqual(self.conf.cache, checkcache)


class TestMacNoXDG(unittest.TestCase):
    @classmethod
    ",True
460,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestLinuxNoXDG,test_noxdg_config,"def test_noxdg_config(self):
        checkconfig = os.path.join(self.tempdir, '.config', 'fakeapp')
        self.assertEqual(self.conf.config, checkconfig)

    ",True
461,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestLinuxNoXDG,test_noxdg_data,"def test_noxdg_data(self):
        checkdata = os.path.join(self.tempdir, '.local', 'share', 'fakeapp')
        self.assertEqual(self.conf.data, checkdata)

    ",True
462,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestMacForceUnix,test_noxdg_cache,"def test_noxdg_cache(self):
        checkcache = os.path.join(self.tempdir, '.cache', 'fakeapp')
        self.assertEqual(self.conf.cache, checkcache)


class TestXDG(unittest.TestCase):
    @classmethod
    ",True
463,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestMacForceUnix,test_noxdg_config,"def test_noxdg_config(self):
        checkconfig = os.path.join(self.tempdir, '.config', 'fakeapp')
        self.assertEqual(self.conf.config, checkconfig)

    ",True
464,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestMacForceUnix,test_noxdg_data,"def test_noxdg_data(self):
        checkdata = os.path.join(self.tempdir, '.local', 'share', 'fakeapp')
        self.assertEqual(self.conf.data, checkdata)

    ",True
465,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestMacNoXDG,test_noxdg_cache,"def test_noxdg_cache(self):
        checkcache = os.path.join(self.tempdir, 'Library', 'Caches', 'fakeapp')
        self.assertEqual(self.conf.cache, checkcache)
        
class TestMacForceUnix(unittest.TestCase):
    @classmethod
    ",True
466,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestMacNoXDG,test_noxdg_config,"def test_noxdg_config(self):
        checkconfig = os.path.join(self.tempdir, 'Library', 'Preferences', 'fakeapp')
        self.assertEqual(self.conf.config, checkconfig)

    ",True
467,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestMacNoXDG,test_noxdg_data,"def test_noxdg_data(self):
        checkdata = os.path.join(self.tempdir, 'Library', 'fakeapp')
        self.assertEqual(self.conf.data, checkdata)

    ",True
468,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestWindowsNoXDG,test_noxdg_cache,"def test_noxdg_cache(self):
        checkcache = os.path.join(self.tempdir, 'fakeapp', 'Cache')
        self.assertEqual(self.conf.cache, checkcache)


class TestLinuxNoXDG(unittest.TestCase):
    @classmethod
    ",True
469,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestWindowsNoXDG,test_noxdg_config,"def test_noxdg_config(self):
        checkconfig = os.path.join(self.tempdir, 'fakeapp', 'Config')
        self.assertEqual(self.conf.config, checkconfig)

    ",True
470,https://github.com/kade-robertson/config-better/blob/c14638da3fe95a669a04db2602e1f6ea15591c36/tests/test___init__.py,TestWindowsNoXDG,test_noxdg_data,"def test_noxdg_data(self):
        checkdata = os.path.join(self.tempdir, 'fakeapp', 'Data')
        self.assertEqual(self.conf.data, checkdata)

    ",True
471,https://github.com/mojochao/configaro/blob/d7b432fb2f99c4cb3c3208082f0afff62454c83d/tests/test_configaro.py,,test_get,"def test_get():
    from configaro import ConfigPropertyNotFoundError, get, init
    init('tests.config')
    expected = {
        'name': 'locals',
        'log': {
            'file': 'some-file.txt',
            'level': 'DEBUG'
        },
        'monitoring': {
            'haproxy': {
                'disabled': True
            },
            'nginx': {
                'disabled': True
            }
        }
    }
    config = get()
    assert config.log.level == 'DEBUG'
    assert config == munch.munchify(expected)
    log = get('log')
    assert log.level == 'DEBUG'
    log = munch.unmunchify(log)
    assert log == expected['log']
    assert get('name') == 'locals'
    assert get('log.level') == 'DEBUG'
    assert get('monitoring.haproxy.disabled') is True
    assert get('monitoring.nginx.disabled') is True
    with pytest.raises(ConfigPropertyNotFoundError):
        assert get('monitoring.nginx.disable') is True
    assert get('monitoring.nginx.disable', default=None) is None


",True
472,https://github.com/avature/confight/blob/be2d162c99cc3c709289913de137f8d8bfbd35d5/test_confight.py,TestLoad,test_it_should_load_and_merge_lists_of_paths,"def test_it_should_load_and_merge_lists_of_paths(self, examples):
        paths = sorted(examples.get_many(SORTED_FILES))

        config = load(paths)

        assert_that(config, has_entry('section', has_entry('key', 'second')))

    ",True
473,https://github.com/jyn514/configparse/blob/d7a4ee5b121de2be1858104723bdb7ac47df64ce/test/test_all.py,,test_positional,"def test_positional():
    ""make sure we didn't break existing functionality of argparse""
    p = configparse.Parser(prog=NAME)
    p.add_argument(""positional"")
    assert p.parse_args([""first arg""]).positional == 'first arg'
    with pytest.raises(SystemExit):
        p.parse_args([])

",True
474,https://github.com/wilfredinni/coo/blob/da9e75d46ed65599cd2223b029ac30c08496a80b/tests/test_coo.py,,test_tweet_none_media_TwitterError,"def test_tweet_none_media_TwitterError(coo_mock_instance):
    with pytest.raises(TwitterError):
        coo_mock_instance.tweet([""mock""], media=None)


# SCHEDULE
",True
475,https://github.com/Cornices/cornice.ext.swagger/blob/17a63e86751c7d8f1b2b75d49056161c80f4cef2/tests/test_app.py,AppSpecViewTest,test_validate_spec,"def test_validate_spec(self):
        spec = self.app.get('/api-explorer/swagger.json').json
        validate(spec)


class AppUIViewTest(unittest.TestCase):

    ",True
476,https://github.com/nmasahiro/crfmnes/blob/5fc9625c86135fb5e8824f867a08cc410d3638bd/tests/test_constraint_sphere.py,,test_run_d40_const_sphere,"def test_run_d40_const_sphere():
    print(""test_run_d40:"")
    dim = 40
    mean = np.ones([dim, 1]) * 10
    sigma = 2.0
    lamb = 16 # note that lamb (sample size) should be even number
    allowable_evals = (19.4 + 1.1*3) * 1e3 # 2 sigma
    iteration_number = int(allowable_evals / lamb) + 1

    cr = CRFMNES(dim, const_sphere, mean, sigma, lamb)
    x_best, f_best = cr.optimize(iteration_number)
    print(""f_best:{}"".format(f_best))
    assert f_best < 1e-12


",False
477,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_add_classification.py,TestAddClassification,test_add_classification,"def test_add_classification(self):
		amnt = model.MonetaryAmount(ident='')
		amnt.value = 7.0
		self.assertNotIn('Asking Price', factory.toString(amnt))
		vocab.add_classification(amnt, vocab.AskingPrice)
		self.assertIn('Asking Price', factory.toString(amnt))

",True
478,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_currency.py,TestCurrencyExtraction,test_extract_est,"def test_extract_est(self):
		e = extract_monetary_amount({
			'est_price': '12.0',
			'currency': 'pounds'
		})
		self.assertEqual(e.value, 12)
		c = e.currency
		self.assertEqual(e.classified_as[0]._label, 'Estimated Price')
		self.assertEqual(e.currency._label, 'British Pounds')

	",True
479,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_currency.py,TestCurrencyExtraction,test_extract_price_with_citation,"def test_extract_price_with_citation(self):
		d = {
			'price': '7',
			'currency': 'pounds',
			'citation': 'crom test suite'
		}
		e = extract_monetary_amount(d, add_citations=True)
		self.assertEqual(e.value, 7)
		self.assertEqual(e.currency._label, 'British Pounds')
		self.assertEqual(e.referred_to_by[0].content, 'crom test suite')


",True
480,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_currency.py,TestCurrencyExtraction,test_extract_start,"def test_extract_start(self):
		e = extract_monetary_amount({
			'start_price': '8.5',
			'currency': 'pounds'
		})
		self.assertEqual(e.value, 8.5)
		c = e.currency
		self.assertEqual(e.classified_as[0]._label, 'Starting Price')
		self.assertEqual(e.currency._label, 'British Pounds')

	",True
481,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestAutoIdentifiers,test_no_ident,"def test_no_ident(self):

		model.factory.auto_assign_id = True
		p1 = model.Person()	# auto assigned	 
		p2 = model.Person(ident=None) # auto assigned
		p3 = model.Person(ident="""") # bnode explicitly

		self.assertTrue(p1.id.startswith('http'))
		self.assertTrue(p2.id.startswith('http'))
		self.assertEqual(p3.id, '')

		model.factory.auto_assign_id = False
		p4 = model.Person() # bnode is default
		p5 = model.Person(ident=None) # bnode is default
		p6 = model.Person(ident="""") # bnode explicitly

		self.assertEqual(p4.id, '')
		self.assertEqual(p5.id, '')
		self.assertEqual(p6.id, '')

		
class TestBaseResource(unittest.TestCase):

	",True
482,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestBaseResource,test_allows_multiple,"def test_allows_multiple(self):
		p = model.Person()
		self.assertTrue(p.allows_multiple('classified_as'))
		self.assertFalse(p.allows_multiple('born'))
		self.assertRaises(model.DataError, p.allows_multiple, 'fish')

	",True
483,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestBaseResource,test_check_prop,"def test_check_prop(self):
		desc = self.artist._check_prop('_label', 'Jane Doe\'s Bio')
		self.assertEqual(desc, 1)
		parent = self.artist._check_prop('parent_of', self.son)
		self.assertEqual(parent, 2)

	",True
484,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestBaseResource,test_check_reference,"def test_check_reference(self):
		self.assertTrue(self.artist._check_reference('http'))
		self.assertFalse(self.artist._check_reference('xxx'))
		self.assertTrue(self.artist._check_reference({'id': 'xxx'}))
		self.assertFalse(self.artist._check_reference({'xxx': 'yyy'}))
		self.assertTrue(self.artist._check_reference(self.son))
		self.assertTrue(self.artist._check_reference(['http']))
		self.assertFalse(self.artist._check_reference(['xxx', 'yyy']))
		self.assertTrue(self.artist._check_reference(model.Person))

	",True
485,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestBaseResource,test_init_params,"def test_init_params(self):
		p1 = model.Person(ident=""urn:uuid:1234"")
		self.assertEqual(p1.id, ""urn:uuid:1234"")
		p2 = model.Person(ident=""http://schema.org/Foo"")
		self.assertEqual(p2.id, ""schema:Foo"")
		p3 = model.Name(content=""Test"")
		self.assertEqual(p3.content, ""Test"")
		c = model.MonetaryAmount(value=10)
		self.assertEqual(c.value, 10)
		n = model.Name(value=""Rob"")
		self.assertEqual(n.content, ""Rob"")
		i = model.Identifier(content=""xyz123"")
		self.assertEqual(i.content, ""xyz123"")
		i2 = model.Identifier(value=""abc"")
		self.assertEqual(i2.content, ""abc"")

	",True
486,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestBaseResource,test_list_my_props,"def test_list_my_props(self):
		p1 = model.Person()
		p1.classified_as = model.Type()
		props = p1.list_my_props()
		self.assertEqual(set(props), set(['classified_as', 'id']))
		props = p1.list_my_props(filter=model.Type)
		self.assertEqual(props, ['classified_as'])

	",True
487,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestBaseResource,test_multiplicity,"def test_multiplicity(self):
		model.factory.process_multiplicity = True
		who = model.Actor()
		mmo = model.HumanMadeObject()
		prod = model.Production()
		mmo.produced_by = prod
		who.current_owner_of = mmo
		mmo.current_owner = who
		self.assertEqual(mmo.current_owner, [who])
		self.assertEqual(who.current_owner_of, [mmo])		
		self.assertEqual(mmo.produced_by, prod)

	",True
488,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_breadth,"def test_breadth(self):
		x = model.TransferOfCustody()
		e = model.Activity()
		fr = model.Group()
		to = model.Group()
		w = model.HumanMadeObject()
		fr._label = ""From""
		to._label = ""To""
		x.transferred_custody_of = w
		x.transferred_custody_from = fr
		x.transferred_custody_to = to
		e.used_specific_object = w
		e.carried_out_by = to
		w.current_owner = fr
		x.specific_purpose = e
		js = model.factory.toJSON(x)
		# Okay ... if we're breadth first, then custody_from is a resource
		# And now it's the first in the list
		self.assertTrue(isinstance(js['transferred_custody_from'][0], OrderedDict))

	",True
489,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_collapse_json,"def test_collapse_json(self):
		model.factory.auto_id_type = ""uuid""
		model.factory.base_url = ""http://lod.example.org/museum/""
		model.factory.context_uri = ""https://linked.art/ns/v1/linked-art.json""
		p = model.Person()
		p.classified_as = model.Type(ident=""http://example.org/Type"", label=""Test"")
		res1 = model.factory.toString(p, compact=False, collapse=60) # all new lines
		res2 = model.factory.toString(p, compact=False, collapse=120) # compact list of type
		self.assertEqual(len(res1.splitlines()), 12)
		self.assertEqual(len(res2.splitlines()), 6)

	",True
490,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_ordering,"def test_ordering(self):
		p = model.Person(label=""Person"")
		p.classified_as = model.Type(ident=""type-uri"")
		p.referred_to_by = model.LinguisticObject(content=""text"")
		p.dimension = model.Dimension(value=1)

		outstr = model.factory.toString(p)
		lbl = outstr.index(""_label"")
		clsf = outstr.index(""classified_as"")
		r2b = outstr.index(""referred_to_by"")
		dim = outstr.index(""dimension"")
		self.assertTrue(lbl < clsf)
		self.assertTrue(clsf < r2b)
		self.assertTrue(r2b < dim)


class TestProcessTSV(unittest.TestCase):

	",True
491,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_pipe_scoped,"def test_pipe_scoped(self):
		x = model.Activity()
		y = model.Activity()
		x.part = y
		model.factory.pipe_scoped_contexts = True
		js = model.factory.toJSON(x)
		self.assertTrue('part|crm:P9_consists_of' in js)
		model.factory.pipe_scoped_contexts = False
		js = model.factory.toJSON(x)		
		self.assertTrue('part|crm:P9_consists_of' not in js)		
		self.assertTrue('part' in js)

	",True
492,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_production_mode,"def test_production_mode(self):

		# model.factory.production_mode()
		# Can't unset the cached hierarchy
		# and it causes the test for the hierarchy to fail
		model.factory.validate_profile = False
		model.factory.validate_properties = False
		model.factory.validate_range = False
		model.factory.validate_multiplicity = False

		p = model.Person()
		p.identified_by = model.Name(value=""abc"")
		p.part = model.HumanMadeObject()
		js = model.factory.toJSON(p)

		model.factory.production_mode(state=False)


	",True
493,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_recursion,"def test_recursion(self):
		x = model.Activity()
		x.part = x
		js = model.factory.toJSON(x)
		# If our recursion checks have regressed, this will barf right here
		self.assertTrue(1)

	",True
494,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_string_list,"def test_string_list(self):
		x = model.Activity()
		x._label = [""Label 1"", ""Label 2""]
		js = model.factory.toJSON(x)
		self.assertTrue(js['_label'] == x._label)

	",True
495,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_toFile,"def test_toFile(self):
		self.assertRaises(model.ConfigurationError, model.factory.toFile, self.collection)
		# Test auto filename determination
		model.factory.base_dir = 'tests'
		model.factory.toFile(self.collection)
		self.assertTrue(os.path.isfile('tests/InformationObject/collection.json'))
		# Test explicit filename setting
		model.factory.toFile(self.collection, filename='tests/fishbat.bar')
		self.assertTrue(os.path.isfile('tests/fishbat.bar'))
		# Tidy up
		shutil.rmtree('tests/InformationObject')

	",True
496,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_toJSON,"def test_toJSON(self):
		# model.factory.context_uri = 'http://lod.getty.edu/context.json'
		expect = OrderedDict([
			('@context', model.factory.context_uri),
			('id', u'http://lod.example.org/museum/InformationObject/collection'), 
			('type', 'InformationObject'), ('_label', 'Test Object')])
		outj = model.factory.toJSON(self.collection)
		self.assertEqual(expect, outj)

	",True
497,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_toJSON_fast,"def test_toJSON_fast(self):
		model.factory.json_serializer = ""fast""
		expect = {'@context': model.factory.context_uri, 
			'id': 'http://lod.example.org/museum/InformationObject/collection', 
			'type': 'InformationObject', 
			'_label': 'Test Object'}
		outj = model.factory.toJSON(self.collection)
		self.assertEqual(expect, outj)
		model.factory.json_serializer = ""normal""

	",True
498,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_toJSON_normal,"def test_toJSON_normal(self):
		expect = OrderedDict([(u'@context', model.factory.context_uri), 
			(u'@id', u'http://lod.example.org/museum/Person/1'), (u'@type', u'crm:E21_Person'),
			('rdfs:label', 'Test Person')])
		model.factory.full_names = True
		p = model.Person(""1"")
		p._label = ""Test Person""
		outj = model.factory.toJSON(p)
		self.assertEqual(expect, outj)
		# reset
		model.factory.full_names = False

	",True
499,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_toString,"def test_toString(self):
		expect = u'{""@context"":""'+model.factory.context_uri+'"",""id"":""http://lod.example.org/museum/InformationObject/collection"",""type"":""InformationObject"",""_label"":""Test Object""}'
		outs = model.factory.toString(self.collection)
		self.assertEqual(expect, outs)

	",True
500,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestFactorySerialization,test_toString_fast,"def test_toString_fast(self):
		# Should only be trusted in python 3
		if sys.version_info.major >= 3 and sys.version_info.minor >= 6:
			expect = u'{""@context"":""'+model.factory.context_uri+'"",""id"":""http://lod.example.org/museum/InformationObject/collection"",""type"":""InformationObject"",""_label"":""Test Object""}'
			model.factory.json_serializer = ""fast""		
			outs = model.factory.toString(self.collection)
			model.factory.json_serializer = ""normal""
			self.assertEqual(expect, outs)
		else:
			print(""Skipping toString_fast test in Python 2.x"")

	",True
501,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestMagicMethods,test_not_multiple_instance,"def test_not_multiple_instance(self):
		who = model.Person()
		n = model.Name(content=""Test"")
		who.identified_by = n

		model.factory.multiple_instances_per_property = ""error""
		self.assertRaises(model.DataError, who.__setattr__, 'identified_by', n)
		self.assertEqual(who.identified_by, [n])

		model.factory.multiple_instances_per_property = ""drop""
		who.identified_by = n
		self.assertEqual(who.identified_by, [n,n])		
		# and check that only serialized once
		js = model.factory.toJSON(who)
		self.assertEqual(len(js['identified_by']), 1)

		model.factory.multiple_instances_per_property = ""allow""
		js = model.factory.toJSON(who)
		self.assertEqual(len(js['identified_by']), 2)


class TestObjectEquality(unittest.TestCase):
	",True
502,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestMagicMethods,test_validate_multiplicity,"def test_validate_multiplicity(self):
		model.factory.validate_multiplicity = True
		who = model.Person()
		b1 = model.Birth()
		who.born = b1
		b2 = model.Birth()
		self.assertRaises(model.ProfileError, who.__setattr__, 'born', b2)
		model.factory.validate_multiplicity = False
		who.born = b2
		self.assertEqual(who.born, [b1, b2])

	",True
503,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestMagicMethods,test_validate_profile_off,"def test_validate_profile_off(self):
		model.factory.validate_profile = False
		ia = model.IdentifierAssignment()
		# If it's not turned off this should raise
		model.factory.validate_profile = True
		self.assertRaises(model.ProfileError, model.IdentifierAssignment)		
		p1 = model.Person()
		self.assertRaises(model.ProfileError, p1.__setattr__, 'documented_in', ""foo"")

	",True
504,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestMagicMethods,test_validation_wrong_type,"def test_validation_wrong_type(self):
		model.factory.validate_properties = True
		artist = model.Person('00001', 'Jane Doe')	
		self.assertRaises(model.DataError, artist.__setattr__, 'parent_of', 'Bad Value')

	",True
505,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_model.py,TestPropertyCache,test_cache_hierarchy,"def test_cache_hierarchy(self):
		o = model.HumanMadeObject()
		self.assertEqual(o._all_properties, {})
		model.factory.cache_hierarchy()
		self.assertTrue(len(o._all_properties) > 50)
		

class TestMagicMethods(unittest.TestCase):

	",True
506,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_reader.py,TestReader,test_read,"def test_read(self):
		self.assertRaises(DataError, self.reader.read, """")
		self.assertRaises(DataError, self.reader.read, ""This is not JSON"")
		self.assertRaises(DataError, self.reader.read, ""{}"")

		whostr = '{""type"": ""Person"", ""_label"": ""me""}'
		self.assertTrue(isinstance(self.reader.read(whostr), Person))

		whostr = '{""@context"": ""fishbat"", ""type"": ""Person"", ""_label"": ""me""}'
		self.assertTrue(isinstance(self.reader.read(whostr), Person))

		levelstr = '{""type"": ""Person"", ""parent_of"": {""type"": ""Person"", ""_label"": ""child""}}'
		self.assertTrue(isinstance(self.reader.read(levelstr).parent_of[0], Person))

		basestr = '{""_label"": ""base""}'
		self.assertTrue(isinstance(self.reader.read(basestr), BaseResource))

		unknown = '{""type"":""FishBat""}'
		self.assertRaises(DataError, self.reader.read, unknown)

		unknown2 = '{""type"":""Person"", ""fishbat"": ""bob""}'
		self.assertRaises(DataError, self.reader.read, unknown)

	",True
507,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_reader.py,TestReader,test_vocab_collision,"def test_vocab_collision(self):
		# Test that the algorithm picks the right vocab instance
		# if multiple have the same AAT term but different base class

		data = """"""
        {
          ""type"": ""LinguisticObject"",
          ""_label"": ""Sale recorded in catalog: B-267 0003 (1817) (record number 22947)"",
	      ""part_of"": [
            {
              ""type"": ""LinguisticObject"",
              ""_label"": ""Sale Catalog B-267"",
              ""classified_as"": [
                {
                  ""id"": ""http://vocab.getty.edu/aat/300026068"",
                  ""type"": ""Type"",
                  ""_label"": ""Auction Catalog""
                }
              ]
            }
          ]
        }
        """"""
		d = self.reader.read(data)
		self.assertTrue(isinstance(d.part_of[0], vocab.AuctionCatalogText))

",True
508,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_vocab.py,TestClassBuilder,test_aa_check,"def test_aa_check(self):

		# Make sure that some other test hasn't set it
		try:
			del model.AttributeAssignment.set_assigned_property
		except:
			pass

		t = model.Type()
		aa = model.AttributeAssignment()
		# First check that aa accepts a type
		aa.assigned_property = t
		# And will not accept a string
		self.assertRaises(model.DataError, aa.__setattr__, ""assigned_property"", ""classified_as"")

		# Check we can set anything to assigned / assigned_to
		aa.assigned_property = None
		aa.assigned = aa
		aa.assigned_to = aa
		self.assertEqual(aa.assigned, aa)
		self.assertEqual(aa.assigned_to, aa)

		vocab.add_attribute_assignment_check()

		# This should fail right now as can't classify as an AA
		self.assertRaises(model.DataError, aa.__setattr__, ""assigned_property"", ""classified_as"")
		aa.assigned = None
		aa.assigned_to = None
		aa.assigned = t
		aa.assigned_to = t
		aa.assigned_property = ""classified_as""
		self.assertEqual(aa.assigned_property, 'classified_as')


	",True
509,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_vocab.py,TestClassBuilder,test_boundary_setter,"def test_boundary_setter(self):
		vocab.add_linked_art_boundary_check()
		p = model.Person()
		p2 = model.Person()
		n = model.Name()
		n.content = ""Test""
		p2.identified_by = n
		p.exact_match = p2
		# Now, Test should not appear in the resulting JSON of p
		factory.linked_art_boundaries = True
		js = factory.toJSON(p)
		self.assertTrue(not 'identified_by' in js['exact_match'][0])
		factory.linked_art_boundaries = False
		js = factory.toJSON(p)
		self.assertTrue('identified_by' in js['exact_match'][0])		

	",True
510,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_vocab.py,TestClassBuilder,test_conceptual_parts,"def test_conceptual_parts(self):
		r = model.Right()
		r2 = model.Right()
		self.assertRaises(model.DataError, r.__setattr__, 'part', r2)
		r.c_part = r2
		self.assertTrue(r2 in r.c_part)

		vocab.conceptual_only_parts()
		r3 = model.Right()
		r4 = model.Right()
		r3.part = r4
		self.assertTrue(r4 in r3.c_part)
		self.assertTrue(""part"" in model.factory.toJSON(r3))
		self.assertTrue(r4 in r3.part)


	",True
511,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_vocab.py,TestClassBuilder,test_linguistic_object_boundary,"def test_linguistic_object_boundary(self):
		vocab.add_linked_art_boundary_check()
		jrnl = vocab.JournalText(label=""journal"")
		issue = vocab.IssueText(label=""issue"")
		issue.part_of = jrnl
		issue.referred_to_by = vocab.MaterialStatement(content=""Statement"")

		js = factory.toJSON(issue)
		# Have not embedded journal in issue
		self.assertTrue(not 'classified_as' in js['part_of'][0])
		# Have embedded statement in issue
		self.assertTrue('content' in js['referred_to_by'][0])
		self.assertTrue('type' in js['referred_to_by'][0]['classified_as'][0]['classified_as'][0])

",True
512,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_vocab.py,TestClassBuilder,test_metatype,"def test_metatype(self):
		vocab.register_instance(""example"", {""parent"": model.Type, ""id"": ""3"", ""label"": ""example type""}) 
		vocab.register_aat_class(""TestObject2"", 
			{""parent"": model.HumanMadeObject, ""id"": ""4"", ""label"": ""example typed object"", ""metatype"": ""example""})
		from cromulent.vocab import TestObject2
		self.assertEqual(TestObject2._classification[0].classified_as[0].id, 'http://vocab.getty.edu/aat/3')

	",True
513,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_vocab.py,TestClassBuilder,test_multitype,"def test_multitype(self):
		from cromulent.vocab import make_multitype_obj, Painting, Drawing
		inst = make_multitype_obj(Painting, Drawing)
		self.assertTrue(isinstance(inst, Painting))
		self.assertTrue(len(inst.classified_as) == 2)
		self.assertTrue(inst.classified_as[1].id == ""http://vocab.getty.edu/aat/300033973"")

		from cromulent.model import HumanMadeObject

		inst = make_multitype_obj(HumanMadeObject, Painting)
		self.assertTrue(len(inst.classified_as) == 1)
		self.assertTrue(inst.classified_as[0].id == ""http://vocab.getty.edu/aat/300033618"")

	",True
514,https://github.com/thegetty/crom/blob/98bb6be4e32b4c81eb7e0b5e841a915b015abaf0/tests/test_vocab.py,TestClassBuilder,test_procurement_boundary,"def test_procurement_boundary(self):
		vocab.add_linked_art_boundary_check()
		a = model.Activity()
		p = vocab.ProvenanceEntry()
		a.caused = p
		js = factory.toJSON(a)
		self.assertTrue(not 'classified_as' in js['caused'][0])		

	",True
515,https://github.com/hellock/cvbase/blob/e48d2f76aaeea6472b2175c37780f7b90ae7f1b6/tests/test_progress.py,,test_track_parallel_progress_iterator,"def test_track_parallel_progress_iterator(capsys):

    results = cvb.track_parallel_progress(
        sleep_1s, ((i for i in [1, 2, 3, 4]), 4), 2, bar_width=4)
    out, _ = capsys.readouterr()
    assert out == ('[    ] 0/4, elapsed: 0s, ETA:'
                   '\r[>   ] 1/4, 1.0 task/s, elapsed: 1s, ETA:     3s'
                   '\r[>>  ] 2/4, 2.0 task/s, elapsed: 1s, ETA:     1s'
                   '\r[>>> ] 3/4, 1.5 task/s, elapsed: 2s, ETA:     1s'
                   '\r[>>>>] 4/4, 2.0 task/s, elapsed: 2s, ETA:     0s\n')
    assert results == [1, 2, 3, 4]
",False
520,https://github.com/malpunek/dame/blob/d6568d3088dd0a8b87eb5d278e04ab857a622418/tests/test_versionable.py,,test_basic,"def test_basic():
    with tmp_module(""transformA"", make_versionable("""", {}, """")) as ta:
        tae1 = ta.TestT()
        tae2 = ta.TestT()

        assert tae1.version() == tae2.version()


",True
521,https://github.com/malpunek/dame/blob/d6568d3088dd0a8b87eb5d278e04ab857a622418/tests/test_versionable.py,,test_params,"def test_params():
    with tmp_module(""transformA"", make_versionable("""", {}, """")) as ta:

        tak1 = ta.TestT(ala=""kota"")
        tak2 = ta.TestT(basia=""kota"")
        tak3 = ta.TestT(ala=""psa"")
        tak4 = ta.TestT(ala=""kota"")

        assert tak1.version() == tak4.version()
        assert tak1.version() != tak2.version()
        assert tak1.version() != tak3.version()
        assert tak2.version() != tak3.version()


",True
522,https://github.com/isnok/data-pypes/blob/dcfe6feac2b617f9f8624cff81c44f72c0313ee6/pypes/logsetup.py,,pypes.logsetup.get_logconfig,"def get_logconfig(level=None):
    """""" Get logging configuration from environment.

        Returns:
            level, stdout_loglevel, files

        >>> get_logconfig()
        (20, 20, {})
        >>> get_logconfig(20)
        (20, 20, {})
        >>> get_logconfig('20')
        (20, 20, {})
        >>> get_logconfig('INFO')
        (20, 20, {})

        >>> import os
        >>> os.environ['STDOUT_LOGLEVEL'] = 'INFO'
        >>> get_logconfig()
        (20, 20, {})
    """"""

    if level is None:
        level = os.environ.get('LOGLEVEL')

    if level is None:
        level = logging.INFO
    elif isinstance(level, (int, float)):
        level = int(level)
    elif level == str(level) and level.isdigit():
        level = int(level)
    else:
        level = logging._checkLevel(level.upper())

    files = {}

    for levelname in levelnames:
        if levelname == str(levelname):
            env_varname = levelname.upper() + '_LOGFILE'
            if env_varname in os.environ:
                files[levelname] = os.environ[env_varname]

    if 'STDOUT_LOGLEVEL' in os.environ:
        stdout_loglevel = logging._checkLevel(
            os.environ['STDOUT_LOGLEVEL'].upper()
        )
    else:
        stdout_loglevel = level

    # color_stdout = 'COLOR_STDOUT' in os.environ

    return level, stdout_loglevel, files

reset_color = '\033[0m'
termcolors = dict(
    off=reset_color,
    black='\033[90m',
    red='\033[91m',
    green='\033[92m',
    yellow='\033[93m',
    blue='\033[94m',
    purple='\033[95m',
    cyan='\033[96m',
    white='\033[97m',
    grey='\033[98m',
    bold='\033[1m',
    underline='\033[4m',
)
",True
523,https://github.com/jjotterson/datapungibea/blob/fe3b262b7e2ceffd12621693c94af9b6cc43e408/datapungibea/tests/test_driversCI.py,,test_NIPAVintage,"def test_NIPAVintage():
    driver = dataBea.NIPAVintage(tableName = 'T10101', Title = 'Section 1',year = '2018', quarter ='Q1',vintage='Second',verbose = True)
    #execCode = executeCode(driver['code']) 
    #assert driver['request'].status_code == 200  #test if connection was stablished
    assert not driver['dataFrame'][0].empty         #cleaned up output is not empty
    #assert execCode['codeRun']           #try to execute the code.       
    #assert execCode['codeOutput'].equals(driver['dataFrame']) #test if the output of the code equals the output of the      


",False
524,https://github.com/khufkens/daymetpy/blob/539f8d47315f0f68f86875d7805541dadcb76604/tests/test_timeseries.py,TimeseriesTest,test_ornl_df,"def test_ornl_df(self):
        ornl_lat, ornl_long = 35.9313167, -84.3104124
        df = daymet_timeseries(lon=ornl_long, lat=ornl_lat, start_year=2012, end_year=2012)

        self.assertTrue(df.year.count() == 365)
        self.assertTrue(""tmax"" in df.columns)
        self.assertTrue(""tmin"" in df.columns)
        self.assertTrue(""prcp"" in df.columns)

    ",False
525,https://github.com/leVirve/dcard-spider/blob/ac64cbcfe7ef6be7e554cef422b1a8a6bb968d46/tests/test_forums.py,TestForums,test_with_none_name_in_dcard_instance,"def test_with_none_name_in_dcard_instance(self, dcard):
        f = dcard.forums
        assert f.name is None

    ",True
526,https://github.com/leVirve/dcard-spider/blob/ac64cbcfe7ef6be7e554cef422b1a8a6bb968d46/tests/test_posts.py,TestPosts,test_with_none_in_dcard_instance,"def test_with_none_in_dcard_instance(self, dcard):
        posts = dcard.posts
        assert not posts.ids
        assert not posts.metas
        assert not posts.only_id

    ",True
527,https://github.com/nMustaki/debinterface/blob/abd30a55dcbadc30fd66143adc196034b663054f/test/test_hostapd.py,TestHostapd,test_read,"def test_read(self):
        self.maxDiff = None
        with tempfile.NamedTemporaryFile() as source:
            source.write(DEFAULT_CONTENT.encode(""ascii""))
            source.flush()
            dns = Hostapd(source.name)
            dns.read()
            self.assertDictEqual(dns.config, DEFAULT_CONFIG)

    ",True
528,https://github.com/vanyakosmos/deezload/blob/8a25f4657d648a3c70b6287a9828cec724c8fa0e/tests/test_base.py,BaseTests,test_playlist_writer,"def test_playlist_writer_no_name(self):
        output_dir = THIS_DIR
        pw = PlaylistWriter(output_dir, None)
        pw.write(os.path.join(output_dir, 'track.mp3'))
        pw.close()
        self.assertTrue(len(glob.glob('*.m3u')) == 0)

    ",False
529,https://github.com/ConSou/devtracker/blob/ea892d6d48aa5d4627b429469b59ae3f0ce7f10f/devtracker/test_devtracker.py,,test_add_start,"def test_add_start():
    start_time(""test"")

",True
530,https://github.com/ConSou/devtracker/blob/ea892d6d48aa5d4627b429469b59ae3f0ce7f10f/devtracker/test_devtracker.py,,test_current_status,"def test_current_status(capsys):
    current_status(""test"")
    captured = capsys.readouterr()
    assert captured.out == ""[+] Status report for 'test':  You have not started work on this project yet.\n""



# report test
# -----------------------------------------------------------------------------------
",True
531,https://github.com/ConSou/devtracker/blob/ea892d6d48aa5d4627b429469b59ae3f0ce7f10f/devtracker/test_devtracker.py,,test_full_report,"def test_full_report(capsys):
    next_line = ['1999-01-01', '00:00:00', '1999-01-01', '00:00:00', '00:00:00']
    following_line = ['1999-01-02', '00:00:01', '1999-01-02', '00:00:02', '00:00:01']

    with open(path, 'r', newline='') as myFile:
        reader = list(csv.reader(myFile))
        reader.pop()
        reader.pop()
        with open(path, 'w', newline='') as myfile:
            wr = csv.writer(myfile, delimiter=',', quotechar='""', quoting=csv.QUOTE_ALL)
            for i in reader:
                wr.writerow(i)
            wr.writerow(next_line)
            wr.writerow(following_line)

    full_report(""test"")
    captured = capsys.readouterr()
    assert captured.out == """"""[+] Generating Full Report
-------------------------------------------------------------------------
start_date       | start_time | end_date         | end_time | total    | 
-------------------------------------------------------------------------
January  1, 1999 | 12:00 AM   | January  1, 1999 | 12:00 AM | 00:00:00 | 
-------------------------------------------------------------------------
January  2, 1999 | 12:00 AM   | January  2, 1999 | 12:00 AM | 00:00:01 | 


[+] You have worked on test for a total of 0:00:01.  Way to go!
""""""


",True
532,https://github.com/ConSou/devtracker/blob/ea892d6d48aa5d4627b429469b59ae3f0ce7f10f/devtracker/test_devtracker.py,,test_make_project_csv,"def test_make_project_csv():
    assert os.path.isfile(path) == True

",True
533,https://github.com/ConSou/devtracker/blob/ea892d6d48aa5d4627b429469b59ae3f0ce7f10f/devtracker/test_devtracker.py,,test_make_project_csv_initalize,"def test_make_project_csv_initalize():
    initalize_list = [""start_date"", ""start_time"", ""end_date"", ""end_time"", ""total""]
    with open(path, 'r') as myfile:
        reader = csv.reader(myfile)
        headers = next(reader)

    assert initalize_list == headers

",True
534,https://github.com/ConSou/devtracker/blob/ea892d6d48aa5d4627b429469b59ae3f0ce7f10f/devtracker/test_devtracker.py,,test_start_time,"def test_start_time():
    with open(path, 'r') as myfile:
        reader = csv.reader(myfile)
        next(reader)
        start_info = next(reader)

    assert start_info == [new_start_date, new_start_time]

",True
535,https://github.com/ConSou/devtracker/blob/ea892d6d48aa5d4627b429469b59ae3f0ce7f10f/devtracker/test_devtracker.py,,test_today_report_err_one,"def test_today_report_err_one(capsys):
    today_report(""test"")
    captured = capsys.readouterr()
    assert captured.out == ""[+] Generating daily report for test...\n[-] You are in the middle of tracking, end this session with `devtracker stop` before generation a report.\n""

",True
536,https://github.com/wufeifei/dict/blob/89e730dbc035da6b5ceb598833d2eafc5343864d/tests/test_dict.py,,test_c2e_sentences,"def test_c2e_sentences(capfd):
    Dict(['我爱你'])
    out, err = capfd.readouterr()
    assert 'I love you' in out
",False
537,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_contrib_reversion.py,,test_revision_is_visible_in_list,"def test_revision_is_visible_in_list(django_user_model):
    alpha = Dragonfly.objects.create(name=""alpha"", age=47)

    request = RequestFactory().get(""/"", {})
    request.user = user_with_perms(django_user_model, [""testapp.view_dragonfly""])

    with VersionedDragonflyViewSet().create_revision(request):
        set_comment(""number one"")
        alpha.save()

    with VersionedDragonflyViewSet().create_revision(request):
        set_comment(""number two"")
        alpha.save()

    with VersionedDragonflyViewSet().create_revision(request):
        set_comment(""number three"")
        alpha.save()

    assert Version.objects.get_for_object_reference(Dragonfly, alpha.pk).count() == 3

    view = VersionedDragonflyViewSet()._get_view(
        VersionedDragonflyViewSet().components[""version_list""]
    )

    response = view(request, pk=alpha.pk)
    response_content = response.rendered_content

    assert ""number one"" in response_content
    assert ""number two"" in response_content
    assert ""number three"" in response_content


@mark.django_db
",True
538,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_contrib_reversion.py,,test_show_detail_from_previous_version,"def test_show_detail_from_previous_version(django_user_model):
    alpha = Dragonfly.objects.create(name=""alpha"", age=47)
    sighting = Sighting.objects.create(name=""Berlin"", dragonfly=alpha)

    request = RequestFactory().get(""/"", {})
    request.user = user_with_perms(django_user_model, [""testapp.view_dragonfly""])

    with VersionedDragonflyViewSet().create_revision(request):
        alpha.save()

    version = Version.objects.get_for_object_reference(Dragonfly, alpha.pk).latest(
        ""revision__created_date""
    )

    alpha.name = ""beta""
    alpha.save()

    sighting.name = ""Tokyo""
    sighting.save()

    detail_view = VersionedDragonflyViewSet()._get_view(
        VersionedDragonflyViewSet().components[""detail""]
    )
    detail_content = detail_view(request, pk=alpha.pk).rendered_content

    assert ""beta"" in detail_content
    assert ""Tokyo"" in detail_content

    version_view = VersionedDragonflyViewSet()._get_view(
        VersionedDragonflyViewSet().components[""version_detail""]
    )

    version_content = version_view(
        request, pk=alpha.pk, version_id=version.pk
    ).content.decode(""utf-8"")

    assert ""alpha"" in version_content
    assert ""Berlin"" in version_content

    assert ""beta"" not in version_content
    assert ""Tokyo"" not in version_content


@mark.django_db
",True
539,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_views.py,,test_delete,"def test_delete(client_with_perms):
    client = client_with_perms(""testapp.delete_dragonfly"")
    alpha = Dragonfly.objects.create(name=""alpha"", age=47)
    delete_url = DragonflyViewSet().links[""delete""].reverse(alpha)
    response = client.get(delete_url)
    assert b""Are you sure you want to delete"" in response.content
    assert b""alpha"" in response.content

    response = client.post(delete_url)

    assert response.status_code == 302
    assert response[""location""] == DragonflyViewSet().links[""list""].reverse()

    assert not Dragonfly.objects.filter(name=""alpha"").exists()


@mark.django_db
",True
540,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_views.py,,test_delete_protected_not_allowed,"def test_delete_protected_not_allowed(client_with_perms):
    client = client_with_perms(""testapp.delete_dragonfly"")
    alpha = Dragonfly.objects.create(name=""alpha"", age=47)
    ProtectedSighting.objects.create(dragonfly=alpha, name=""A related sighting"")

    delete_url = DragonflyViewSet().links[""delete""].reverse(alpha)
    response = client.get(delete_url)

    assert b""You can't delete"" in response.content
    assert b""the following objects depend"" in response.content
    assert b""sighting"" in response.content

    response = client.post(delete_url)

    assert response.status_code == 403

    assert Dragonfly.objects.filter(name=""alpha"").exists()


@mark.django_db
",True
541,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_views.py,,test_delete_shows_related,"def test_delete_shows_related(client_with_perms):
    client = client_with_perms(""testapp.delete_dragonfly"")
    alpha = Dragonfly.objects.create(name=""alpha"", age=47)
    CascadingSighting.objects.create(dragonfly=alpha, name=""A related sighting"")

    delete_url = DragonflyViewSet().links[""delete""].reverse(alpha)
    response = client.get(delete_url)

    assert b""The following objects"" in response.content
    assert b""sighting"" in response.content

    response = client.post(delete_url)

    assert response.status_code == 302
    assert response[""location""] == DragonflyViewSet().links[""list""].reverse()

    assert not Dragonfly.objects.filter(name=""alpha"").exists()


@mark.django_db
",True
542,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_views.py,,test_detail,"def test_detail(client_with_perms):
    client = client_with_perms(
        ""testapp.view_dragonfly"", ""testapp.change_dragonfly"", ""testapp.delete_dragonfly""
    )
    alpha = Dragonfly.objects.create(name=""alpha"", age=47)
    Sighting.objects.create(name=""Berlin"", dragonfly=alpha)
    Sighting.objects.create(name=""Paris"", dragonfly=alpha)

    links = DragonflyViewSet().links

    response_content = client.get(links[""detail""].reverse(alpha)).content.decode(
        ""utf-8""
    )

    assert ""alpha"" in response_content
    assert ""Title of sightings""
    assert ""Berlin"" in response_content
    assert ""Paris"" in response_content

    assert 'href=""{}""'.format(links[""list""].reverse(alpha)) in response_content
    assert 'href=""{}""'.format(links[""update""].reverse(alpha)) in response_content
    assert 'href=""{}""'.format(links[""delete""].reverse(alpha)) in response_content


@mark.django_db
",True
543,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_views.py,,test_list,"def test_list(client_with_perms):
    client = client_with_perms(""testapp.view_dragonfly"")
    Dragonfly.objects.create(name=""alpha"", age=12)
    Dragonfly.objects.create(name=""omega"", age=99)
    response = client.get(DragonflyViewSet().links[""list""].reverse())
    assert b""alpha"" in response.content
    assert b""omega"" in response.content


@mark.django_db
",True
544,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_views.py,,test_list_search,"def test_list_search(client_with_perms):
    client = client_with_perms(""testapp.view_dragonfly"")
    Dragonfly.objects.create(name=""alpha"", age=12)
    Dragonfly.objects.create(name=""omega"", age=99)
    response = client.get(DragonflyViewSet().links[""list""].reverse() + ""?q=alpha"")
    assert b""alpha"" in response.content
    assert b""omega"" not in response.content


@mark.django_db
",True
545,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_views.py,,test_list_sort,"def test_list_sort(client_with_perms):
    client = client_with_perms(""testapp.view_dragonfly"")
    Dragonfly.objects.create(name=""alpha"", age=12)
    Dragonfly.objects.create(name=""omega"", age=99)

    response = client.get(DragonflyViewSet().links[""list""].reverse() + ""?o=-name"")
    assert response.content.index(b""alpha"") > response.content.index(b""omega"")

    response = client.get(DragonflyViewSet().links[""list""].reverse() + ""?o=name"")
    assert response.content.index(b""alpha"") < response.content.index(b""omega"")


@mark.django_db
",True
546,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_views.py,,test_only_popup_param_is_preserved_in_detail_links,"def test_only_popup_param_is_preserved_in_detail_links(client_with_perms):
    client = client_with_perms(""testapp.view_dragonfly"", ""testapp.change_dragonfly"")
    instance = Dragonfly.objects.create(name=""alpha"", age=12)
    response = client.get(
        DragonflyViewSet().links[""list""].reverse(),
        data={""_popup"": ""id_test"", ""not_preserved"": ""nope""},
    )

    response_content = response.content.decode(""utf-8"")

    detail_url = DragonflyViewSet().links[""update""].reverse(instance)
    assert detail_url in response_content
    assert detail_url + ""?_popup=id_test"" in response_content
    assert detail_url + ""?_popup=id_test&not_preserved"" not in response_content
",True
547,https://github.com/django-beam/django-beam/blob/43b2111f5c65937aa1e2cc9704b59796e982a805/tests/test_views.py,,test_update,"def test_update(client_with_perms):
    client = client_with_perms(""testapp.change_dragonfly"")
    alpha = Dragonfly.objects.create(name=""alpha"", age=47)
    response = client.get(DragonflyViewSet().links[""update""].reverse(alpha))
    assert b""alpha"" in response.content
    assert ""form"" in response.context
    assert response.context[""form""][""name""].value() == ""alpha""


@mark.django_db
",True
548,https://github.com/jounderwood/django-hug/blob/778b16f568ce9fdb01f360b7bff89c9d8b6c2ef7/tests/test_api.py,,test_simple_post_ok,"def test_simple_post_ok(client, with_urlpatterns, routes: djhug.Routes):
    @routes.post(""<str:name>/"")
    ",True
549,https://github.com/jounderwood/django-hug/blob/778b16f568ce9fdb01f360b7bff89c9d8b6c2ef7/tests/test_api.py,,test_whole_body_post_ok,"def test_whole_body_post_ok(client, with_urlpatterns, routes: djhug.Routes):
    class RespModel(Body):
        product_id: int
        quantity: int

    @routes.post(""<str:name>/"")
    ",True
550,https://github.com/politeauthority/docker-pretty-ps/blob/2fcc9db4e391df2b96ccc2e967b41b6263fdcc2d/tests/test_dockerprettyps.py,TestDockerPrettyPs,test_container_display_name,"def test_container_display_name(self):
        """"""
        Tests the dockerprettyps.container_display_name() method to see if we create the right console formatting for a
        container, with potential bolding to highlight search items.

        """"""
        containers = test_ps_data.ps_containers
        container = containers[0]
        container_display = dockerprettyps.container_display_name(container, CliArgs())
        assert container_display == container[""color""] + container[""name""] + dockerprettyps.ENDC

        # Test that we bold the portion of a container name that matches a search if we have one.
        args = CliArgs()
        args.search = [""post""]
        for container in containers:
            if container[""name""] == ""some-postgres"":
                assert dockerprettyps.container_display_name(container, args) == \
                    ""\x1b[91msome-\x1b[1m\x1b[91mpost\x1b[0m\x1b[91mgres\x1b[0m""

    ",True
551,https://github.com/politeauthority/docker-pretty-ps/blob/2fcc9db4e391df2b96ccc2e967b41b6263fdcc2d/tests/test_dockerprettyps.py,TestDockerPrettyPs,test_get_container_colors,"def test_get_container_colors(self):
        """"""
        Tests the dockerprettyps.get_container_colors() method which runs all containers throuh the get_color method(),
        to try and assign a semi unique color to an instance based on it's container name.

        """"""
        containers = test_ps_data.ps_containers
        colorless_containers = []
        for c in containers:
            c.pop('color')
            colorless_containers.append(c)

        color_containers = dockerprettyps.get_container_colors(colorless_containers)
        for c in color_containers:
            assert 'color' in c
            assert isinstance(c['color'], str)

    ",True
552,https://github.com/politeauthority/docker-pretty-ps/blob/2fcc9db4e391df2b96ccc2e967b41b6263fdcc2d/tests/test_dockerprettyps.py,TestDockerPrettyPs,test_print_format,"def test_print_format(self):
        """"""
        Tests the dockerprettyps.print_format() method, primarily checking that the method doesnt fail, since it mostly
        just prints to the console.

        """"""
        assert dockerprettyps.print_format(test_ps_data.ps_containers, 6, 5, CliArgs())

    ",True
553,https://github.com/shin-/dockerpy-creds/blob/9c0b66d2e445a838e1518f2c3273df7ddc7ec0d4/tests/store_test.py,TestStore,test_execute_with_env_override,"def test_execute_with_env_override(self):
        self.store.exe = 'env'
        self.store.environment = {'FOO': 'bar'}
        data = self.store._execute('--null', '')
        assert b'\0FOO=bar\0' in data
        assert 'FOO' not in os.environ
",False
554,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_cli.py,TestCLI,test_domain,"def test_domain(self):
        """"""
        This method will test domain2idna.domain()
        """"""

        BaseStdout.setUp(self)

        expected = self.domain_to_test[-1]

        subjects(self.domain_to_test[0], None)
        actual = sys.stdout.getvalue()

        self.assertEqual(expected, actual)

    ",True
555,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_cli.py,TestCLI,test_file,"def test_file(self):
        """"""
        This method will test domain2idna.file().
        """"""

        file_to_pass = ""this_file_is_a_ghost""
        BaseStdout.setUp(self)

        expected = False
        actual = path.isfile(file_to_pass)

        self.assertEqual(expected, actual)

        File(file_to_pass).write(""\n"".join(self.domains_to_test))

        expected = True
        actual = path.isfile(file_to_pass)

        self.assertEqual(expected, actual)

        expected = ""\n"".join(self.domains_to_test)
        actual = File(file_to_pass).read()

        self.assertEqual(expected, actual)

        expected = ""\n"".join(self.converted) + ""\n""
        file(file_to_pass, None)
        actual = sys.stdout.getvalue()

        self.assertEqual(expected, actual)

        File(file_to_pass).delete()

        expected = False
        actual = path.isfile(file_to_pass)

        self.assertEqual(expected, actual)

    ",True
556,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_converter.py,TestConverter,test_commented_line,"def test_commented_line(self):
        """"""
        Tests that the comments are returned normally.
        """"""

        comments = [
            ""# Hello, World!"",
            ""# This is another commented line"",
            ""cryptopiạ.com  # This is a comment at the end of a line."",
            ""# This is a commented line with bittréẋ.com"",
            ""# cryptopiạ.com"",
        ]

        expected = [
            ""# Hello, World!"",
            ""# This is another commented line"",
            ""xn--cryptopi-ux0d.com # This is a comment at the end of a line."",
            ""# This is a commented line with bittréẋ.com"",
            ""# cryptopiạ.com"",
        ]

        actual = Converter(comments).get_converted()

        self.assertEqual(expected, actual)

    ",True
557,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_converter.py,TestConverter,test_hosts_file_format,"def test_hosts_file_format(self):
        """"""
        Tests that the hosts file format is always respected.
        """"""

        given = [
            ""0.0.0.0 bịllogram.com"",
            ""127.0.0.1 bittréẋ.com"",
            ""0.0.0.0 cryptopiạ.com"",
            ""127.0.0.1 coinbȧse.com"",
            ""0.0.0.0 cṙyptopia.com"",
        ]

        expected = [
            ""0.0.0.0 xn--bllogram-g80d.com"",
            ""127.0.0.1 xn--bittr-fsa6124c.com"",
            ""0.0.0.0 xn--cryptopi-ux0d.com"",
            ""127.0.0.1 xn--coinbse-30c.com"",
            ""0.0.0.0 xn--cyptopia-4e0d.com"",
        ]

        actual = Converter(given).get_converted()

        self.assertEqual(expected, actual)

        given = ""0.0.0.0 bịllogram.com""

        expected = ""0.0.0.0 xn--bllogram-g80d.com""

        actual = Converter(given).get_converted()

        self.assertEqual(expected, actual)


if __name__ == ""__main__"":
    launch_tests()
",True
558,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_converter.py,TestConverter,test_to_idna_multiple,"def test_to_idna_multiple(self):
        """"""
        Runs and tests Converter.
        """"""

        domains_to_test = [
            ""bịllogram.com"",
            ""bittréẋ.com"",
            ""cryptopiạ.com"",
            ""coinbȧse.com"",
            ""cṙyptopia.com"",
            ""0.0.0.0 ṁỵetherwallet.com"",
            ""0.0.0.0/8"",
        ]

        expected = [
            ""xn--bllogram-g80d.com"",
            ""xn--bittr-fsa6124c.com"",
            ""xn--cryptopi-ux0d.com"",
            ""xn--coinbse-30c.com"",
            ""xn--cyptopia-4e0d.com"",
            ""0.0.0.0 xn--etherwallet-tv8eq7f.com"",
            ""0.0.0.0/8"",
        ]
        actual = Converter(domains_to_test).get_converted()

        self.assertEqual(expected, actual)

    ",True
559,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_converter.py,TestConverter,test_to_idna_multiple_urls,"def test_to_idna_multiple_urls(self):
        """"""
        Runs and tests Converter.
        """"""

        domains_to_test = [
            ""http://bịllogram.com"",
            ""https://bittréẋ.com/path;parameters?query#fragment"",
            ""ftp://cryptopiạ.com"",
            ""git://coinbȧse.com"",
            ""://coinbȧse.com/hello_world"",
        ]

        expected = [
            ""http://xn--bllogram-g80d.com"",
            ""https://xn--bittr-fsa6124c.com/path;parameters?query#fragment"",
            ""ftp://xn--cryptopi-ux0d.com"",
            ""git://xn--coinbse-30c.com"",
            ""://xn--coinbse-30c.com/hello_world"",
        ]
        actual = Converter(domains_to_test).get_converted()

        self.assertEqual(expected, actual)

    ",True
560,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_converter.py,TestConverter,test_to_idna_single,"def test_to_idna_single(self):
        """"""
        Runs and tests Converter
        """"""

        domain_to_test = ""ṁỵetherwallet.com""

        expected = ""xn--etherwallet-tv8eq7f.com""
        actual = Converter(domain_to_test).get_converted()

        self.assertEqual(expected, actual)

    ",True
561,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_helpers.py,TestFile,test_delete_not_exist,"def test_delete_not_exist(self):
        """"""
        Tests helpers.File.delete for the case that the file does
        not exists.
        """"""

        filename = ""this_file_is_a_ghost""

        expected = False
        actual = path.isfile(filename)

        self.assertEqual(expected, actual)

        File(filename).delete()

        expected = False
        actual = path.isfile(filename)

        self.assertEqual(expected, actual)


if __name__ == ""__main__"":
    launch_tests()
",True
562,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_helpers.py,TestFile,test_read_delete,"def test_read_delete(self):
        """"""
        Tests helpers.File.read along with helpers.File.delete.
        """"""

        expected = ""Hello, World! This has been written by Fun Ilrys.""
        File(""hi"").write(expected)
        actual = File(""hi"").read()

        self.assertEqual(expected, actual)

        expected = False
        File(""hi"").delete()
        actual = path.isfile(""hi"")

        self.assertEqual(expected, actual)

    ",True
563,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_helpers.py,TestFile,test_write_delete,"def test_write_delete(self):
        """"""
        Tests helpers.File.write along with helpers.File.delete.
        """"""

        expected = ""Hello, World! I'm PyFunceble""
        File(""hi"").write(expected)

        with open(""hi"") as file:
            actual = file.read()

        self.assertEqual(expected, actual)

        expected = False
        File(""hi"").delete()
        actual = path.isfile(""hi"")

        self.assertEqual(expected, actual)

    ",True
564,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_helpers.py,TestFile,test_write_overwrite_delete,"def test_write_overwrite_delete(self):
        """"""
        Tests helpers.File.write along with helpers.File.delete.
        """"""

        expected = ""Hello, World! I'm PyFunceble""
        File(""hi"").write(expected)

        with open(""hi"") as file:
            actual = file.read()

        self.assertEqual(expected, actual)

        expected = ""Hello, World! Python is great, you should consider learning it!""
        File(""hi"").write(expected)

        with open(""hi"") as file:
            actual = file.read()

        self.assertEqual(expected, actual)

        expected = False
        File(""hi"").delete()
        actual = path.isfile(""hi"")

        self.assertEqual(expected, actual)

    ",True
565,https://github.com/PyFunceble/domain2idna/blob/39a1c4e1ebb877ed511e53b618fbe437a685c970/tests/test_init.py,TestInit,test_get,"def test_get(self):
        """"""
        This method will test domain2idna.get
        """"""

        expected = self.converted
        actual = domain2idna(self.domains_to_test)
        self.assertEqual(expected, actual)

        expected = self.empty_inputs
        actual = domain2idna(self.empty_inputs)
        self.assertEqual(expected, actual)

        expected = None
        actual = domain2idna(None)
        self.assertEqual(expected, actual)


if __name__ == ""__main__"":
    launch_tests()
",True
566,https://github.com/edelgm6/draft/blob/bdd813dfeb914b91c857f8a6675c86c7972555b3/tests/test_cli.py,TestGenerateProject,test_generate_file_tree,"def test_generate_file_tree(self):

        runner = CliRunner()
        result = runner.invoke(create_project, [""Gatsby""], input=""y\n"")
        self.assertEqual(result.exit_code, 0)

        self.assertTrue(os.path.isdir(""gatsby/project/Gatsby/""))
        rmtree(""gatsby"")

class TestCleanSpaces(TestCase):

    ",False
567,https://github.com/edelgm6/draft/blob/bdd813dfeb914b91c857f8a6675c86c7972555b3/tests/test_generator.py,TestFileTree,test_generate_file_tree,"def test_generate_file_tree_does_not_overwrite_existing_files(self):

        os.mkdir(""gatsby"")
        os.mkdir(""gatsby/project"")
        os.mkdir(""gatsby/project/arbitrary"")
        with open(""gatsby/project/arbitrary/whatever.txt"", ""w"") as test:
            test.write(""whatever"")

        generator = Generator()
        generator.generate_project(""Gatsby2"")

        self.assertTrue(os.path.isdir(""gatsby/project/arbitrary/""))
        self.assertTrue(os.path.isfile(""gatsby/project/arbitrary/whatever.txt""))

        with self.assertRaises(FileExistsError):
            generator.generate_project(""Gatsby"")

        rmtree(""gatsby2"")

    ",False
568,https://github.com/mtkennerly/dunamai/blob/0f35675e96835726d8e9dbd3901d9f7b029154d3/tests/unit/test_main.py,,test__parse_args__check,"def test__parse_args__check():
    assert parse_args([""check"", ""0.1.0""]) == Namespace(
        command=""check"", version=""0.1.0"", style=""pep440""
    )
    assert parse_args([""check"", ""0.1.0"", ""--style"", ""semver""]).style == ""semver""
    assert parse_args([""check"", ""0.1.0"", ""--style"", ""pvp""]).style == ""pvp""

    with pytest.raises(SystemExit):
        parse_args([""check"", ""0.1.0"", ""--style"", ""unknown""])


",False
569,https://github.com/jnoortheen/dynamic-conf/blob/42257f06a66765ac4f5de1c6a4637f4db779c5ab/tests/test_conf.py,,test_cofig_writing,"def test_cofig_writing(file, result, create_conf_file, monkeypatch):
    monkeypatch.setenv(""ARG1"", ""VAL1"")
    from dynamic_conf import _main

    conf_file = create_conf_file(_file_name=repr(file), ARG1=1)
    _main([conf_file, ""ARG2=VAL2""])  # start write

    env_file = os.path.join(os.path.dirname(conf_file), file)
    assert os.path.exists(env_file)
    with open(env_file) as f:
        content = f.read()
        assert content == result

    with pytest.raises(Exception) as ex:
        _main([conf_file, ""ARG2=VAL2""])  # start write again
        assert ""Found"" in str(ex)


@pytest.mark.parametrize(
    ""file, result"",
    [(""env.py"", ""ARG1 = 'VAL1'\nARG2 = 'VAL2'""), ("".env"", ""ARG1=VAL1\nARG2=VAL2""),],
)
",True
570,https://github.com/jnoortheen/dynamic-conf/blob/42257f06a66765ac4f5de1c6a4637f4db779c5ab/tests/test_conf.py,,test_cofig_writing,"def test_cofig_writing(file, result, create_conf_file, monkeypatch):
    monkeypatch.setenv(""ARG1"", ""VAL1"")
    from dynamic_conf import _main

    conf_file = create_conf_file(_file_name=repr(file), ARG1=1)
    _main([conf_file, ""ARG2=VAL2""])  # start write

    env_file = os.path.join(os.path.dirname(conf_file), file)
    assert os.path.exists(env_file)
    with open(env_file) as f:
        content = f.read()
        assert content == result

    with pytest.raises(Exception) as ex:
        _main([conf_file, ""ARG2=VAL2""])  # start write again
        assert ""Found"" in str(ex)


@pytest.mark.parametrize(
    ""file, result"",
    [(""env.py"", ""ARG1 = 'VAL1'\nARG2 = 'VAL2'""), ("".env"", ""ARG1=VAL1\nARG2=VAL2""),],
)
",True
571,https://github.com/jnoortheen/dynamic-conf/blob/42257f06a66765ac4f5de1c6a4637f4db779c5ab/tests/test_conf.py,,test_cofig_writing_with_dump,"def test_cofig_writing_with_dump(file, result, create_conf_file, monkeypatch):
    monkeypatch.setenv(""ARG1"", ""VAL1"")
    monkeypatch.setenv(""VARS_DUMP"", ""True"")
    from dynamic_conf import _main

    conf_file = create_conf_file(_file_name=repr(file), ARG1=1, ARG3=3)

    _main([conf_file, ""ARG2=VAL2""])

    env_file = os.path.join(os.path.dirname(conf_file), file)
    assert os.path.exists(env_file)
    with open(env_file) as f:
        content = f.read()
        assert content == result


",True
572,https://github.com/jnoortheen/dynamic-conf/blob/42257f06a66765ac4f5de1c6a4637f4db779c5ab/tests/test_conf.py,,test_cofig_writing_with_dump,"def test_cofig_writing_with_dump(file, result, create_conf_file, monkeypatch):
    monkeypatch.setenv(""ARG1"", ""VAL1"")
    monkeypatch.setenv(""VARS_DUMP"", ""True"")
    from dynamic_conf import _main

    conf_file = create_conf_file(_file_name=repr(file), ARG1=1, ARG3=3)

    _main([conf_file, ""ARG2=VAL2""])

    env_file = os.path.join(os.path.dirname(conf_file), file)
    assert os.path.exists(env_file)
    with open(env_file) as f:
        content = f.read()
        assert content == result


",True
573,https://github.com/jnoortheen/dynamic-conf/blob/42257f06a66765ac4f5de1c6a4637f4db779c5ab/tests/test_conf.py,,test_cofig_writing_with_filter_prefix,"def test_cofig_writing_with_filter_prefix(file, result, create_conf_file, monkeypatch):
    monkeypatch.setenv(""PRE_ARG1"", ""VAL1"")
    monkeypatch.setenv(""VARS_PREFIX"", ""PRE_"")
    from dynamic_conf import _main

    conf_file = create_conf_file(_file_name=repr(file), ARG1=1)

    _main([conf_file, ""ARG2=VAL2""])

    env_file = os.path.join(os.path.dirname(conf_file), file)
    assert os.path.exists(env_file)
    with open(env_file) as f:
        content = f.read()
        assert content == result


@pytest.mark.parametrize(
    ""file, result"",
    [
        (""env.py"", ""ARG1 = 'VAL1'\nARG3 = 3\nARG2 = 'VAL2'""),
        ("".env"", ""ARG1=VAL1\nARG3=3\nARG2=VAL2""),
    ],
)
",True
574,https://github.com/jnoortheen/dynamic-conf/blob/42257f06a66765ac4f5de1c6a4637f4db779c5ab/tests/test_conf.py,,test_cofig_writing_with_filter_prefix,"def test_cofig_writing_with_filter_prefix(file, result, create_conf_file, monkeypatch):
    monkeypatch.setenv(""PRE_ARG1"", ""VAL1"")
    monkeypatch.setenv(""VARS_PREFIX"", ""PRE_"")
    from dynamic_conf import _main

    conf_file = create_conf_file(_file_name=repr(file), ARG1=1)

    _main([conf_file, ""ARG2=VAL2""])

    env_file = os.path.join(os.path.dirname(conf_file), file)
    assert os.path.exists(env_file)
    with open(env_file) as f:
        content = f.read()
        assert content == result


@pytest.mark.parametrize(
    ""file, result"",
    [
        (""env.py"", ""ARG1 = 'VAL1'\nARG3 = 3\nARG2 = 'VAL2'""),
        ("".env"", ""ARG1=VAL1\nARG3=3\nARG2=VAL2""),
    ],
)
",True
575,https://github.com/jnoortheen/dynamic-conf/blob/42257f06a66765ac4f5de1c6a4637f4db779c5ab/tests/test_conf.py,,test_config_reading,"def test_config_reading(file, config_factory):
    CONF = config_factory(file)
    assert CONF.NUM == 1  # check type casting
    assert CONF.BOOL == False  # check type casting
    assert CONF.NONE_VAL is None
    assert CONF.VAR == ""variable""
    assert CONF.OVERLOADED == ""over-loaded""
    assert CONF.FROM_FILE == ""file""
    with pytest.raises(LookupError):
        print(CONF.MISSING)


@pytest.mark.parametrize(
    ""file, result"",
    [(""env.py"", ""ARG1 = 'VAL1'\nARG2 = 'VAL2'""), ("".env"", ""ARG1=VAL1\nARG2=VAL2""),],
)
",True
576,https://github.com/jnoortheen/dynamic-conf/blob/42257f06a66765ac4f5de1c6a4637f4db779c5ab/tests/test_conf.py,,test_config_reading,"def test_config_reading(file, config_factory):
    CONF = config_factory(file)
    assert CONF.NUM == 1  # check type casting
    assert CONF.BOOL == False  # check type casting
    assert CONF.NONE_VAL is None
    assert CONF.VAR == ""variable""
    assert CONF.OVERLOADED == ""over-loaded""
    assert CONF.FROM_FILE == ""file""
    with pytest.raises(LookupError):
        print(CONF.MISSING)


@pytest.mark.parametrize(
    ""file, result"",
    [(""env.py"", ""ARG1 = 'VAL1'\nARG2 = 'VAL2'""), ("".env"", ""ARG1=VAL1\nARG2=VAL2""),],
)
",True
577,https://github.com/oskar456/dzonegit/blob/8f952086aa41aee4ebb7432926ed8c6a9211ac9f/test_dzonegit.py,,test_get_altered_files,"def test_get_altered_files(git_dir):
    git_dir.chdir()
    git_dir.join(""dummy"").write(""dummy2\n"")
    git_dir.join(""new"").write(""newfile\n"")
    subprocess.call([""git"", ""add"", ""dummy"", ""new""])
    files = set(dzonegit.get_altered_files(""HEAD"", ""AM""))
    assert files == {Path(""dummy""), Path(""new"")}
    # Refers to test_check_whitespace_errors
    files = set(dzonegit.get_altered_files(""HEAD~"", ""D"", ""HEAD""))
    assert files == {Path(""whitespace"")}
    subprocess.call([""git"", ""checkout"", ""-f"", ""HEAD""])
    assert set(dzonegit.get_altered_files(""HEAD"", ""AM"")) == set()


",True
578,https://github.com/oskar456/dzonegit/blob/8f952086aa41aee4ebb7432926ed8c6a9211ac9f/test_dzonegit.py,,test_get_file_contents,"def test_get_file_contents(git_dir):
    git_dir.chdir()
    assert dzonegit.get_file_contents(""dummy"") == b""dummy\n""
    with pytest.raises(subprocess.CalledProcessError):
        dzonegit.get_file_contents('nonexistent')


",True
579,https://github.com/oskar456/dzonegit/blob/8f952086aa41aee4ebb7432926ed8c6a9211ac9f/test_dzonegit.py,,test_get_head,"def test_get_head(git_dir):
    git_dir.chdir()
    assert dzonegit.get_head() == ""4b825dc642cb6eb9a060e54bf8d69288fbee4904""
    git_dir.join(""dummy"").write(""dummy\n"")
    subprocess.call([""git"", ""add"", ""dummy""])
    subprocess.call([""git"", ""commit"", ""-m"", ""dummy""])
    assert dzonegit.get_head() != ""4b825dc642cb6eb9a060e54bf8d69288fbee4904""


",True
580,https://github.com/oskar456/dzonegit/blob/8f952086aa41aee4ebb7432926ed8c6a9211ac9f/test_dzonegit.py,,test_post_receive,"def test_post_receive(git_dir):
    git_dir.chdir()
    head = dzonegit.get_head()
    revisions = ""{} {} refs/heads/master\n"".format(
        ""0000000000000000000000000000000000000000"",
        head,
    )
    stdin = StringIO(revisions)
    codir = git_dir.join(""co"")
    subprocess.call([""git"", ""config"", ""dzonegit.checkoutpath"", str(codir)])
    subprocess.call([
        ""git"", ""config"", ""dzonegit.reconfigcmd"",
        ""echo TEST >{}/test"".format(codir),
    ])
    dzonegit.post_receive(stdin)
    assert codir.join(""dummy.zone"").check()
    assert codir.join(""test"").read() == ""TEST\n""
    # Test reconfig after renaming the file
    codir.join(""test"").write("""")
    subprocess.call([""git"", ""mv"", ""dummy.zone"", ""dummy.zone.old""])
    subprocess.call([""git"", ""commit"", ""-m"", ""rename dummy zone""])
    revisions = ""{} {} refs/heads/master\n"".format(
        head,
        dzonegit.get_head(),
    )
    stdin = StringIO(revisions)
    dzonegit.post_receive(stdin)
    assert codir.join(""test"").read() == ""TEST\n""


",True
581,https://github.com/oskar456/dzonegit/blob/8f952086aa41aee4ebb7432926ed8c6a9211ac9f/test_dzonegit.py,,test_pre_receive,"def test_pre_receive(git_dir):
    git_dir.chdir()
    revisions = ""{} {} "".format(
        ""4b825dc642cb6eb9a060e54bf8d69288fbee4904"",
        dzonegit.get_head(),
    )
    stdin = StringIO(revisions + ""refs/heads/slave\n"")
    with pytest.raises(SystemExit):
        dzonegit.pre_receive(stdin)
    stdin = StringIO(revisions + ""refs/heads/master\n"")
    dzonegit.pre_receive(stdin)


",True
582,https://github.com/oskar456/dzonegit/blob/8f952086aa41aee4ebb7432926ed8c6a9211ac9f/test_dzonegit.py,,test_template_config,"def test_template_config(git_dir):
    template = r""""""{
  ""header"": ""# Managed by dzonegit on $datetime, do not edit.\n"",
  ""footer"": ""# This is the end"",
  ""item"": "" - zone: \""$zonename\""\n   file: \""$zonefile\""\n   $zonevar\n"",
  ""defaultvar"": ""template: default"",
  ""zonevars"": {
    ""example.com"": ""template: signed"",
    ""*"": ""template: dummy""
  }
}""""""
    output = dzonegit.template_config(str(git_dir), template)
    assert output.startswith(""# Managed by dzonegit"")
    assert "" - zone: \""dummy\""\n   file: \"""" in output
    assert ""   template: dummy"" in output
    assert output.endswith(""# This is the end"")
    output = dzonegit.template_config(
        str(git_dir),
        template,
        whitelist=set(""a""),
    )
    assert "" - zone: \""dummy\""\n   file: \"""" not in output
    output = dzonegit.template_config(
        str(git_dir),
        template,
        blacklist=set(""*""),
    )
    assert "" - zone: \""dummy\""\n   file: \"""" not in output
    output = dzonegit.template_config(str(git_dir), ""{}"")
    assert len(output) == 0


",True
583,https://github.com/oskar456/dzonegit/blob/8f952086aa41aee4ebb7432926ed8c6a9211ac9f/test_dzonegit.py,,test_update,"def test_update(git_dir):
    git_dir.chdir()
    os.environ.update({""GIT_DIR"": str(git_dir.join("".git""))})
    with pytest.raises(SystemExit):
        dzonegit.update([""update"", ""refs/heads/slave"", ""0"", ""0""])
    dzonegit.update([
        ""update"", ""refs/heads/master"",
        ""0""*40, dzonegit.get_head(),
    ])


",True
584,https://github.com/tjdevries/easy_python_requirements/blob/2bf905f34065637cbc781d17d8e5806892fb66d5/test/test_mock_functions.py,,test_mock_class_update,"def test_mock_class_update():
    with FileCleaner('./mock_functions/test_module_stuff.py'):
        from mock_functions.test_module_stuff import SecondClass

        update_class(SecondClass)

        with open('./mock_functions/test_module_stuff.py', 'r') as reader:
            desired_line = -1
            index = 0
            for line in reader.readlines():
                if 'SecondClass' in line:
                    desired_line = index + 2

                if index == desired_line:
                    print(line)
                    json_info = read_json_info(line)
                    assert(json_info['test_id'] > 1)

                index += 1
",True
585,https://github.com/tjdevries/easy_python_requirements/blob/2bf905f34065637cbc781d17d8e5806892fb66d5/test/test_mock_functions.py,,test_mock_module_with_two_updates,"def test_mock_module_with_two_updates():
    """"""
    This test should demonstrate adding two INFOs, one to the class and one to its function.
    It should add the module one first, and then the function.

    It should make sure that it uses the highest id found.
    """"""
    with FileCleaner('./mock_functions/test_module_stuff.py'):
        # Pretend we just ran into this when cycling through the files
        files_to_check = ['mock_functions/test_module_stuff.py']

        for f in files_to_check:
            update_file(f)

        for f in files_to_check:
            index = 0
            with open(f, 'r') as reader:
                for line in reader.readlines():
                    if index == 27:
                        print(line)
                        json_info = read_json_info(line)
                        assert(json_info['test_id'] == 6)

                    index += 1


",True
586,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_caching.py,,test_resilient_between_timecaches,"def test_resilient_between_timecaches():
    class ExceptionLeakedThroughResilient(Exception):
        pass

    @timecache(1)
    @resilient(acceptable=ExceptionLeakedThroughResilient, default='default')
    @timecache(1)
    ",True
587,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_concurrent_done_status,"def test_concurrent_done_status(throw):
    from threading import Event

    continue_func = Event()

    ",True
588,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_concurrent_done_status,"def test_concurrent_done_status(throw):
    from threading import Event

    continue_func = Event()

    ",True
589,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_multiexception_api,"def test_multiexception_api():
    with pytest.raises(MultiException) as exc:
        MultiObject([0, 5]).call(lambda i: 10 // i)

    failed, sucsessful = exc.value.futures

    assert failed.done()
    with pytest.raises(ZeroDivisionError):
        failed.result()
    assert isinstance(failed.exception(), ZeroDivisionError)

    assert sucsessful.done()
    assert sucsessful.result() == 2
    assert sucsessful.exception() is None


",True
590,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_multiexception_api,"def test_multiexception_api():
    with pytest.raises(MultiException) as exc:
        MultiObject([0, 5]).call(lambda i: 10 // i)

    failed, sucsessful = exc.value.futures

    assert failed.done()
    with pytest.raises(ZeroDivisionError):
        failed.result()
    assert isinstance(failed.exception(), ZeroDivisionError)

    assert sucsessful.done()
    assert sucsessful.result() == 2
    assert sucsessful.exception() is None


",True
591,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_multiexception_pickling,"def test_multiexception_pickling():
    import pickle
    import multiprocessing

    ",True
592,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_multiexception_types,"def test_multiexception_types():

    class OK(Exception):
        pass

    class BAD(object):
        pass

    class OKBAD(OK, BAD):
        pass

    with pytest.raises(AssertionError):
        MultiException[BAD]

    ",True
593,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_multiobject_1,"def test_multiobject_1():
    m = MultiObject(range(10))

    ",True
594,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_multiobject_exceptions,"def test_multiobject_exceptions():

    assert MultiException[ValueError] is MultiException[ValueError]
    assert issubclass(MultiException[UnicodeDecodeError], MultiException[UnicodeError])
    assert issubclass(MultiException[UnicodeDecodeError], MultiException[ValueError])

    with pytest.raises(AssertionError):
        MultiException[0]

    with pytest.raises(MultiException):
        MultiObject(range(5)).call(lambda n: 1 / n)

    with pytest.raises(MultiException[Exception]):
        MultiObject(range(5)).call(lambda n: 1 / n)

    with pytest.raises(MultiException[ZeroDivisionError]):
        MultiObject(range(5)).call(lambda n: 1 / n)

    try:
        MultiObject(range(5)).call(lambda n: 1 / n)
    except MultiException[ValueError] as exc:
        assert False
    except MultiException[ZeroDivisionError] as exc:
        assert len(exc.actual) == 1
        assert isinstance(exc.one, ZeroDivisionError)
    else:
        assert False

    with pytest.raises(MultiException[ArithmeticError]):
        try:
            MultiObject(range(5)).call(lambda n: 1 / n)
        except ZeroDivisionError:
            assert False  # shouldn't be here
        except MultiException[ValueError]:
            assert False  # shouldn't be here


class ExceptionForPicklingTest(ArithmeticError):
    pass


",True
595,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_multiobject_logging,"def test_multiobject_logging():
    m = MultiObject(range(4), log_ctx=""abcd"", initial_log_interval=0.1)

    ",True
596,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_thread_context_stacks,"def test_thread_context_stacks():
    TC = ThreadContexts(stacks=('i', 'j'))
    assert TC.i == TC.j == []

    with TC(i='a'):
        ",True
597,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_thread_contexts_counters,"def test_thread_contexts_counters():
    TC = ThreadContexts(counters=('i', 'j'))
    assert TC.i == TC.j == 0

    with TC(i=1):
        ",True
598,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_concurrency.py,,test_thread_stacks,"def test_thread_stacks():
    with concurrent(sleep, .1, threadname='sleep'):
        print(get_thread_stacks().render())


",True
599,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_exceptions.py,,test_pickle_texception,"def test_pickle_texception():
    import pickle

    t1 = T(what=""happened"", a=1, b=Bunch(x=[1, 2, 3], y=range(5)))
    t2 = pickle.loads(pickle.dumps(t1))

    assert t1.render() == t2.render()
    assert t1._params == t2._params
",True
600,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_logging.py,,test_indent_around_ctx,"def test_indent_around_ctx(get_log):

    @logger.indented(""hey"")
    @contextmanager
    ",True
601,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_logging.py,,test_indent_around_function,"def test_indent_around_function(get_log):

    @logger.indented(""hey"")
    ",True
602,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_logging.py,,test_indent_around_generator,"def test_indent_around_generator(get_log):

    @logger.indented(""hey"")
    ",True
603,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_rwlock.py,,test_rwlock,"def test_rwlock():

    main_ctrl = threading.Event()
    reader_ctrl = threading.Event()
    writer_ctrl = threading.Event()
    lock = RWLock(""test"")

    state = Bunch(reading=False, writing=False)

    ",True
604,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_async,"def test_async():
    from threading import get_ident

    main = get_ident()

    @on_async_test.register(asynchronous=True)
    ",True
605,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_ctx,"def test_ctx():
    result = []

    class Foo:
        @contextmanager
        ",True
606,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_ctx_with_identifier,"def test_ctx_with_identifier():
    class Foo():
        @contextmanager
        ",True
607,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_priorities,"def test_priorities():

    l = []

    @on_test.register(priority=PRIORITIES.LAST)
    ",True
608,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_priorities_async,"def test_priorities_async():

    l = []
    import time

    @on_test.register(asynchronous=True, priority=PRIORITIES.FIRST)
    ",True
609,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_registration_context,"def test_registration_context():

    ",True
610,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_signal_weakref,"def test_signal_weakref():
    """"""
    Test that signals handlers of methods are deleted when their objects get collected
    """"""
    import gc

    class Foo:
        ",True
611,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_signal_weakref_complex_descriptors,"def test_signal_weakref_complex_descriptors():
    import gc
    from easypy.lockstep import lockstep

    class Foo:
        @lockstep
        ",True
612,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_signal_weakref_context_manager_delete_after,"def test_signal_weakref_context_manager_delete_after():
    import gc

    result = []

    class Foo:
        @contextmanager
        ",True
613,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_signal_weakref_context_manager_delete_after_with_identifier,"def test_signal_weakref_context_manager_delete_after_with_identifier():
    import gc

    result = []

    class Foo:
        @contextmanager
        ",True
614,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_signal_weakref_context_manager_delete_during,"def test_signal_weakref_context_manager_delete_during():
    import gc

    result = []

    class Foo:
        @contextmanager
        ",True
615,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_signal_weakref_context_manager_delete_during_with_identifier,"def test_signal_weakref_context_manager_delete_during_with_identifier():
    import gc

    result = []

    class Foo:
        @contextmanager
        ",True
616,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_signal_weakref_with_identifier,"def test_signal_weakref_with_identifier():
    import gc

    class Foo:
        ",True
617,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_simple_signal_object_identifier,"def test_simple_signal_object_identifier():

    on_test_identifier(obj='xxx')

    class Foo():
        ",True
618,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_simple_signal_object_identifier_attribute,"def test_simple_signal_object_identifier_attribute():

    class Foo():
        ",True
619,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_simple_signal_object_registration,"def test_simple_signal_object_registration():

    class Foo():
        ",True
620,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_simple_signal_object_wo_identifier,"def test_simple_signal_object_wo_identifier():

    class Foo():
        ",True
621,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_signals.py,,test_simple_signal_registration,"def test_simple_signal_registration():

    @on_test.register
    ",True
622,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_sync.py,,test_logged_condition,"def test_logged_condition():
    cond = LoggedCondition('test', log_interval=.1)

    progress = 0
    executed = []

    ",True
623,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_sync.py,,test_logged_condition_exception,"def test_logged_condition_exception():
    cond = LoggedCondition('test', log_interval=.2)

    should_throw = False

    class TestException(Exception):
        pass

    ",True
624,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_sync.py,,test_logged_condition_waited_for,"def test_logged_condition_waited_for():
    cond = LoggedCondition('test', log_interval=15)
    progress = 0
    executed = []

    ",True
625,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_sync.py,,test_logged_lock,"def test_logged_lock():
    lock = LoggedRLock(""test"", lease_expiration=1, log_interval=.2)

    step1 = threading.Event()
    step2 = threading.Event()

    ",True
626,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_sync.py,,test_synchronization_coordinator_failing_context_manager,"def test_synchronization_coordinator_failing_context_manager():
    class MyException(Exception):
        pass

    @contextmanager
    ",True
627,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_sync.py,,test_synchronization_coordinator_timeout,"def test_synchronization_coordinator_timeout():
    mo = MultiObject(range(3))

    ",True
628,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_sync.py,,test_synchronization_coordinator_with_multiobject_exception,"def test_synchronization_coordinator_with_multiobject_exception():
    mo = MultiObject(range(3))

    executed = []

    class MyException(Exception):
        pass

    ",True
629,https://github.com/weka-io/easypy/blob/9501c3ee03dcb1630e58cbb73b1647056907bcea/tests/test_sync.py,,test_wait_log_predicate,"def test_wait_log_predicate(get_log):
    ",True
630,https://github.com/brucehe3/ebaipy/blob/2fc6740ee5355948ca2e7f2874ee5edb9acbd578/tests/test_client.py,EbaiClientTestCase,test_sku_brand_list,"def test_sku_brand_list(self):

        res = self.client.sku.brand_list('apple')

        self.assertEqual(res['errno'], 0)

    ",False
631,https://github.com/brucehe3/ebaipy/blob/2fc6740ee5355948ca2e7f2874ee5edb9acbd578/tests/test_client.py,EbaiClientTestCase,test_sku_category_list,"def test_sku_category_list(self):

        res = self.client.sku.category_list(depth=2, parent_id='151301831159451')

        self.assertEqual(res['errno'], 0)

    ",False
632,https://github.com/econ-ark/HARK/blob/c9138af45fd0a0d97c718c8558f3ea8d9f2ae820/HARK/ConsumptionSaving/tests/test_ConsAggShockModel.py,testAggShockMarkovConsumerType,test_agent,"def test_agent(self):
        # Have one consumer type inherit relevant objects from the economy,
        # then solve their microeconomic problem
        self.agent.getEconomyData(self.economy)
        self.agent.solve()
        self.assertAlmostEqual(self.agent.solution[0].cFunc[0](10., self.economy.MSS),
                               2.5635896520991377)

    ",True
633,https://github.com/econ-ark/HARK/blob/c9138af45fd0a0d97c718c8558f3ea8d9f2ae820/HARK/ConsumptionSaving/tests/test_ConsAggShockModel.py,testKrusellSmith,test_agent,"def test_agent(self):
        self.agent.getEconomyData(self.economy)
        self.agent.solve()
        self.assertAlmostEqual(self.agent.solution[0].cFunc[0](10., self.economy.MSS),
                               1.23867751)
        
    ",True
634,https://github.com/econ-ark/HARK/blob/c9138af45fd0a0d97c718c8558f3ea8d9f2ae820/HARK/ConsumptionSaving/tests/test_IndShockConsumerType.py,testIndShockConsumerType,test_getShocks,"def test_getShocks(self):
        self.agent.initializeSim()
        self.agent.simBirth(np.array([True,False]))
        self.agent.simOnePeriod()
        self.agent.simBirth(np.array([False,True]))

        self.agent.getShocks()

        self.assertEqual(self.agent.PermShkNow[0],
                         1.0427376294215103)
        self.assertEqual(self.agent.PermShkNow[1],
                         0.9278094171517413)
        self.assertEqual(self.agent.TranShkNow[0],
                         0.881761797501595)

    ",False
635,https://github.com/econ-ark/HARK/blob/c9138af45fd0a0d97c718c8558f3ea8d9f2ae820/HARK/ConsumptionSaving/tests/test_IndShockConsumerType.py,testIndShockConsumerType,test_simulated_values,"def test_simulated_values(self):
        self.agent.initializeSim()
        self.agent.simulate()

        self.assertAlmostEqual(self.agent.MPCnow[1],
                               0.5711503906043797)

        self.assertAlmostEqual(self.agent.aLvlNow[1],
                               0.18438326264597635)


class testBufferStock(unittest.TestCase):
    """""" Tests of the results of the BufferStock REMARK.
    """"""
    
    ",True
636,https://github.com/AdventielFr/ecs-crd-cli/blob/7b296c64086a204d3540da272e3d8dd74721c6c4/tests/test_prepareDeploymentServiceDefinitionStep.py,,test_process_application_autoscaling_scalable_target_max_capacity_invalid,"def test_process_application_autoscaling_scalable_target_max_capacity_invalid():
    source = {}
    source['max_capacity'] = 'a'
    target = {}
    with pytest.raises(ValueError):
        step._process_application_autoscaling_scalable_target_max_capacity(source, target)

",True
637,https://github.com/tianocore/edk2-pytool-library/blob/ab6bac82f297b4e8fe0a0d4dcde4711b3cb1bc88/edk2toollib/acpi/ivrs_parser_test.py,IvrsParserTest,test_ivrs_parser_ivrs_full,"def test_ivrs_parser_ivrs_full(self):
        # finally the big daddy... load it up!
        IvrsParserTest.ivhd_10h.addDTEEntry(IvrsParserTest.dte_01h)
        IvrsParserTest.ivhd_10h.addDTEEntry(IvrsParserTest.dte_02h)
        IvrsParserTest.ivhd_10h.addDTEEntry(IvrsParserTest.dte_03h)
        IvrsParserTest.ivhd_10h.addDTEEntry(IvrsParserTest.dte_00h)

        IvrsParserTest.ivhd_11h.addDTEEntry(IvrsParserTest.dte_42h)
        IvrsParserTest.ivhd_11h.addDTEEntry(IvrsParserTest.dte_43h)
        IvrsParserTest.ivhd_11h.addDTEEntry(IvrsParserTest.dte_46h)
        IvrsParserTest.ivhd_11h.addDTEEntry(IvrsParserTest.dte_47h)
        IvrsParserTest.ivhd_11h.addDTEEntry(IvrsParserTest.dte_48h)

        IvrsParserTest.ivhd_40h.addDTEEntry(IvrsParserTest.dte_f0h_0)
        IvrsParserTest.ivhd_40h.addDTEEntry(IvrsParserTest.dte_f0h_1)
        IvrsParserTest.ivhd_40h.addDTEEntry(IvrsParserTest.dte_f0h_2)

        IvrsParserTest.ivrs.addIVHDEntry(IvrsParserTest.ivhd_10h)
        IvrsParserTest.ivrs.addIVMDEntry(IvrsParserTest.ivmd_20h)
        IvrsParserTest.ivrs.addIVHDEntry(IvrsParserTest.ivhd_11h)
        IvrsParserTest.ivrs.addIVMDEntry(IvrsParserTest.ivmd_21h)
        IvrsParserTest.ivrs.addIVHDEntry(IvrsParserTest.ivhd_40h)
        IvrsParserTest.ivrs.addIVMDEntry(IvrsParserTest.ivmd_22h)

        IvrsParserTest.ivrs.DumpInfo()
        IvrsParserTest.ivrs.ToXmlElementTree()

        ivrs_byte = IvrsParserTest.ivrs.Encode()
        ivrs2 = IVRS_TABLE(ivrs_byte)
        self.assertEqual(ivrs2.Encode(), ivrs_byte)


",True
638,https://github.com/cbsinteractive/elemental/blob/ca570c9f5fc43e20a4db23fc0137380f87be63f0/elemental/client_test.py,,test_send_request_should_call_request_as_expected,"def test_send_request_should_call_request_as_expected(mock_request):
    mock_request.return_value = mock_response(status=200)
    client = ElementalLive(ELEMENTAL_ADDRESS, USER, API_KEY)
    client.send_request(
        'POST', f'{ELEMENTAL_ADDRESS}/live_events', HEADERS, REQUEST_BODY)

    request_to_elemental = mock_request.call_args_list[0][1]
    assert request_to_elemental['url'] == f'{ELEMENTAL_ADDRESS}/live_events'
    assert request_to_elemental['method'] == 'POST'
    assert request_to_elemental['headers']['Accept'] == 'application/xml'
    assert request_to_elemental['headers']['Content-Type'] == 'application/xml'


@mock.patch('requests.request')
",True
639,https://github.com/elifesciences/elife-tools/blob/a5b93afbe4db7852bf1aa12265090d60140fca8e/elifetools/tests/test_xmlio.py,TestXmlio,test_input_output_1_elife_02833_v2_xml,"def test_input_output(self, filename):
        """"""test parsing a file while retaining the doctype""""""
        with open(sample_xml(filename), ""rb"") as xml_file:
            xml_output_expected = xml_file.read()
        root, doctype_dict = xmlio.parse(sample_xml(filename), return_doctype_dict=True)
        self.assertEqual(xmlio.output(root, None, doctype_dict), xml_output_expected)

    @data(""elife-02833-v2.xml"")
    ",False
640,https://github.com/elifesciences/elife-tools/blob/a5b93afbe4db7852bf1aa12265090d60140fca8e/elifetools/tests/test_xmlio.py,TestXmlio,test_input_output_forcing_jats_doctype_1_elife_02833_v2_xml,"def test_input_output_forcing_jats_doctype(self, filename):
        with open(sample_xml(filename), ""rb"") as xml_file:
            xml_output_expected = xml_file.read()
        root, doctype_dict = xmlio.parse(sample_xml(filename), return_doctype_dict=True)
        self.assertEqual(xmlio.output(root, 'JATS'), xml_output_expected)

    @unpack
    @data(
        (""xmlio_input.xml"", ""inline-graphic"", 2),
        (""xmlio_input.xml"", ""italic"", None))
    ",False
641,https://github.com/kenkundert/engfmt/blob/b908ef69aa7941e561019e24f969703f3234753b/test_constants.py,,test_constants,"def test_constants():
    assert '{:.12q}'.format(Quantity('h')) == '662.606957e-36 J-s'
    assert '{:.12q}'.format(Quantity('k')) == '13.806488e-24 J/K'
    assert '{:.12q}'.format(Quantity('q')) == '160.2176565e-21 C'
    assert '{:.12q}'.format(Quantity('c')) == '299.792458 Mm/s'
    assert '{:.12q}'.format(Quantity('C0')) == '273.15 K'
    assert '{:.12q}'.format(Quantity('eps0')) == '8.854187817 pF/m'
    assert '{:.12q}'.format(Quantity('mu0')) == '1.256637061436 uH/m'
    assert '{:.12q}'.format(Quantity('Z0')) == '376.730313461 Ohms'

    assert quant_to_eng('h') == '662.61e-36 J-s'
    assert quant_to_eng('k') == '13.806e-24 J/K'
    assert quant_to_eng('q') == '160.22e-21 C'
    assert quant_to_eng('c') == '299.79 Mm/s'
    assert quant_to_eng('C0') == '273.15 K'
    assert quant_to_eng('eps0') == '8.8542 pF/m'
    assert quant_to_eng('mu0') == '1.2566 uH/m'
    assert quant_to_eng('Z0') == '376.73 Ohms'
",True
642,https://github.com/kenkundert/engfmt/blob/b908ef69aa7941e561019e24f969703f3234753b/test_format.py,,test_format,"def test_format():
    q=Quantity('1420.405751786 MHz')
    q.add_name('f')
    q.add_desc('frequency of hydrogen line')
    assert '{}'.format(q) == '1.4204 GHz'
    assert '{:.8q}'.format(q) == '1.42040575 GHz'
    assert '{:.8}'.format(q) == '1.42040575 GHz'
    assert '{:r}'.format(q) == '1.4204G'
    assert '{:u}'.format(q) == 'Hz'
    assert '{:f}'.format(q) == '1420405751.786000'
    assert '{:e}'.format(q) == '1.420406e+09'
    assert '{:g}'.format(q) == '1.42041e+09'
    assert '{:n}'.format(q) == 'f'
    assert '{:d}'.format(q) == 'frequency of hydrogen line'
    assert '{:Q}'.format(q) == 'f = 1.4204 GHz'
    assert '{:R}'.format(q) == 'f = 1.4204G'
    assert '{:X}'.format(q) == '1.4204 GHz'

    q=Quantity('2n')
    assert float(q) == 2e-9
",True
643,https://github.com/kenkundert/engfmt/blob/b908ef69aa7941e561019e24f969703f3234753b/test_misc.py,,test_misc,"def test_misc():
    q=Quantity(1420405751.786, 'Hz')
    assert q.strip() == '1.42040575e+09'

    t=quant_to_tuple('1420405751.786 Hz')
    assert t == (1420405751.786, 'Hz')

    t=quant_to_eng('1420405751.786 Hz')
    assert t == '1.4204 GHz'

    s=quant_to_str('1420405751.786 Hz')
    assert s == '1420405751.786 Hz'

    f=quant_to_float('1420405751.786 Hz')
    assert f == 1420405751.786

    t=quant_to_unitless_eng('1420405751.786 Hz')
    assert t == '1.4204G'

    s=quant_to_unitless_str('1420405751.786 Hz')
    assert s == '1420405751.786'

    s=quant_to_unitless_str(1420405751.786, 'Hz')
    assert s == '1.42040575e+09'

    f=quant_strip('1420405751.786 Hz')
    assert f == '1420405751.786'

    f=quant_strip('14204.05751786MHz')
    assert f == '14204.05751786M'

    q=Quantity('1420405751.786 Hz', 'Hz')
    assert q.strip() == '1420405751.786'

    q=Quantity('1420405751.786 Hz')
    assert q.is_nan() == False

    q=Quantity('1420405751.786 Hz')
    assert q.is_infinite() == False

    q=Quantity('NaN Hz')
    assert q.is_nan() == True

    q=Quantity('NaN Hz')
    assert q.is_infinite() == False

    q=Quantity('inf Hz')
    assert q.is_nan() == False

    q=Quantity('inf Hz')
    assert q.is_infinite() == True

    with pytest.raises(AssertionError):
        q=Quantity('1420405751.786 Hz', 'Ohms')

    with pytest.raises(ValueError):
        add_to_namespace('1ns')

    with pytest.raises(ValueError):
        add_to_namespace('x*y = z')
",True
644,https://github.com/kenkundert/engfmt/blob/b908ef69aa7941e561019e24f969703f3234753b/test_namespace.py,,test_namespace,"def test_namespace():
    add_to_namespace('''
        h_line = 1420.405751786 MHz -- Frequency of the hydrogen line
        k = 13.806488e-24 J/K -- Boltzmann's constant
        Temp = 300_K -- Temperature
        M = 2  -- Divide ratio of HF divider
        N = 8  -- Divide ratio of MF divider
        F = 2  -- Divide ratio of LF divider
        Fref = 156MHz  -- Reference frequency
        Kdet = 88.3uA  -- Gain of phase detector (Imax)
        Kvco = 9.07GHz/V  -- Gain of VCO
        Cs = 1.41pF  -- Shunt capacitance
        Cp = 59.7pF  -- Pole capacitance
        Rz = 2.24KOhms  -- Zero resistance
        Fstart = 1KHz  -- Lower frequency bound
        Fstop = 1GHz  -- Upper frequency bound
        Spd = 1.47E-24 A^2/Hz  -- Spectral density of the output noise of the PFD/CP
        FcorPD = 1.5MHz  -- PFD/CP flicker noise corner frequency
        JdivM = 2.43E-18 s/rt(Hz)  -- Spectral density of the output jitter of divM
        FcorDivM = 7MHz  -- divM flicker noise corner frequency
        JdivN = 4.47E-18 s/rt(Hz)  -- Spectral density of the output jitter of divN
        FcorDivN = 1.5MHz  -- divN flicker noise corner frequency
        JdivF = 1.82E-17 s/rt(Hz)  -- Spectral density of the output jitter of divF
        FcorDivF = 2MHz  -- divF flicker noise corner frequency
        Jbuf = 3.70E-18 s/rt(Hz)  -- Spectral density of the output jitter of output buffer
        FcorBuf = 2.5MHz  -- buf flicker noise corner frequency
        Lvco = -125.00 dBc/Hz -- Oscillator phase noise injected after VCO
        FcorVCO = 3MHz  -- VCO flicker noise corner frequency
        Lref = -110.00 dbc/Hz -- Oscillator phase noise injected at reference input
        FcorRef = 0_Hz  -- Freq. reference flicker noise corner frequency
        FmaskLFcor = 12kHz  -- Jitter generation mask low frequency corner
        FmaskHFbound = 5MHz  -- Jitter generation mask high frequency bound

        -- The remainder are built in constants
        plank = h  -- Plank's constant
        boltz = k  -- Boltzmann's constant
        ec = q  -- Elementary charge
        speed_of_light = c -- Speed of light
        zero_celsius = C0 -- Zero degree Celcius in Kelvin
        epsilon0 = eps0 -- Permittivity of free space
        mu0 = mu0 -- Permeability of free space
        Z0 = Z0 -- Characteristic impedance of free space
        c = c  -- speed of light
    ''')

    assert str(h_line) == '1.4204 GHz'
    assert str(k) == '13.806e-24 J/K'
    assert str(Temp) == '300 K'
    assert str(M) == '2'
    assert str(N) == '8'
    assert str(F) == '2'
    assert str(Fref) == '156 MHz'
    assert str(Kdet) == '88.3 uA'
    assert str(Kvco) == '9.07 GHz/V'
    assert str(Cs) == '1.41 pF'
    assert str(Cp) == '59.7 pF'
    assert str(Rz) == '2.24 kOhms'
    assert str(Fstart) == '1 kHz'
    assert str(Fstop) == '1 GHz'
    assert str(Spd) == '1.47e-24 A^2/Hz'
    assert str(FcorPD) == '1.5 MHz'
    assert str(JdivM) == '2.43 as/rt(Hz)'
    assert str(FcorDivM) == '7 MHz'
    assert str(JdivN) == '4.47 as/rt(Hz)'
    assert str(FcorDivN) == '1.5 MHz'
    assert str(JdivF) == '18.2 as/rt(Hz)'
    assert str(FcorDivF) == '2 MHz'
    assert str(Jbuf) == '3.7 as/rt(Hz)'
    assert str(FcorBuf) == '2.5 MHz'
    assert str(Lvco) == '-125 dBc/Hz'
    assert str(FcorVCO) == '3 MHz'
    assert str(Lref) == '-110 dbc/Hz'
    assert str(FcorRef) == '0 Hz'
    assert str(FmaskLFcor) == '12 kHz'
    assert str(FmaskHFbound) == '5 MHz'
    assert str(plank) == '662.61e-36 J-s'
    assert str(boltz) == '13.806e-24 J/K'
    assert str(ec) == '160.22e-21 C'
    assert str(speed_of_light) == '299.79 Mm/s'
    assert str(zero_celsius) == '273.15 K'
    assert str(epsilon0) == '8.8542 pF/m'
    assert str(mu0) == '1.2566 uH/m'
    assert str(Z0) == '376.73 Ohms'
",True
645,https://github.com/thesimj/envyaml/blob/79a220cabb69d71397310d941de205610cf5e4cb/tests/test_envyaml.py,,test_it_should_not_fail_when_try_load_non_exist_default_file,"def test_it_should_not_fail_when_try_load_non_exist_default_file():
    del os.environ[""ENV_YAML_FILE""]
    del os.environ[""ENV_FILE""]

    env = EnvYAML()

    assert isinstance(env, EnvYAML)


",True
646,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_IDF.py,TestIDF,test_popidfobject,"def test_popidfobject(self):
        idftxt = """"
        idfhandle = StringIO(idftxt)
        idf = IDF(idfhandle)
        key = ""BUILDING""
        idf.newidfobject(key, Name=""Building_remove"")
        idf.newidfobject(key, Name=""Building1"")
        idf.newidfobject(key, Name=""Building_remove"")
        idf.newidfobject(key, Name=""Building2"")
        buildings = idf.idfobjects[""building""]
        removethis = buildings[-2]
        idf.popidfobject(key, 2)
        assert buildings[2].Name == ""Building2""
        assert idf.model.dt[key][2][1] == ""Building2""
",True
647,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_IDF.py,TestIDF,test_removeidfobject,"def test_removeidfobject(self):
        """"""py.test for IDF.removeidfobject """"""
        idftxt = """"
        idfhandle = StringIO(idftxt)
        idf = IDF(idfhandle)
        key = ""BUILDING""
        idf.newidfobject(key, Name=""Building_remove"")
        idf.newidfobject(key, Name=""Building1"")
        idf.newidfobject(key, Name=""Building_remove"")
        idf.newidfobject(key, Name=""Building2"")
        buildings = idf.idfobjects[""building""]
        removethis = buildings[-2]
        idf.removeidfobject(removethis)
        assert buildings[2].Name == ""Building2""
        assert idf.model.dt[key][2][1] == ""Building2""

    ",True
648,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_bunch_subclass.py,TestEpBunch,test_get_referenced_object,"def test_get_referenced_object(self):
        """"""py.test for get_referenced_object""""""
        idf = IDF()
        idf.initnew(""test.idf"")
        idf.newidfobject(""VERSION"")  # does not have a field ""Name""

        # construction material
        construction = idf.newidfobject(""CONSTRUCTION"", Name=""construction"")
        construction.Outside_Layer = ""TestMaterial""

        expected = idf.newidfobject(""MATERIAL"", Name=""TestMaterial"")

        fetched = idf.getobject(""MATERIAL"", ""TestMaterial"")
        assert fetched == expected

        material = construction.get_referenced_object(""Outside_Layer"")
        assert material == expected

        # window material
        glazing_group = idf.newidfobject(
            ""WINDOWMATERIAL:GLAZINGGROUP:THERMOCHROMIC"", Name=""glazing_group""
        )
        glazing_group.Window_Material_Glazing_Name_1 = ""TestWindowMaterial""

        expected = idf.newidfobject(
            ""WINDOWMATERIAL:GLAZING"", Name=""TestWindowMaterial""
        )  # has several \references

        fetched = idf.getobject(""WINDOWMATERIAL:GLAZING"", ""TestWindowMaterial"")
        assert fetched == expected

        material = glazing_group.get_referenced_object(""Window_Material_Glazing_Name_1"")
        assert material == expected


bldfidf = """"""
Version,
    6.0;

BUILDING,
    Empire State Building,    !- Name
    30.0,                     !- North Axis
    City,                     !- Terrain
    0.04,                     !- Loads Convergence Tolerance Value
    0.4,                      !- Temperature Convergence Tolerance Value
    FullExterior,             !- Solar Distribution
    25,                       !- Maximum Number of Warmup Days
    6;                        !- Minimum Number of Warmup Days

BuildingSurface:Detailed,
  Zn001:Wall001,           !- Name
  Wall,                    !- Surface Type
  EXTWALL80,               !- Construction Name
  West Zone,               !- Zone Name
  Outdoors,                !- Outside Boundary Condition
  ,                        !- Outside Boundary Condition Object
  SunExposed,              !- Sun Exposure
  WindExposed,             !- Wind Exposure
  0.5000000,               !- View Factor to Ground
  4,                       !- Number of Vertices
  0,0,3.048000,  !- X,Y,Z ==> Vertex 1 {m}
  0,0,0,  !- X,Y,Z ==> Vertex 2 {m}
  6.096000,0,0,  !- X,Y,Z ==> Vertex 3 {m}
  6.096000,0,3.048000;  !- X,Y,Z ==> Vertex 4 {m}
""""""
# test_EpBunch1()
# import idfreader


",True
649,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_bunch_subclass.py,TestEpBunch,test_getreferingobjs,"def test_getreferingobjs(self):
        """"""py.test for getreferingobjs""""""
        thedata = (
            (
                """"""  Zone,
        Box,  !- Name
        0.0,  !- Direction of Relative North {deg}
        0.288184,  !- X Origin {m}
        0.756604,  !- Y Origin {m}
        0.0,  !- Z Origin {m}
        ,  !- Type
        1;  !- Multiplier

      BuildingSurface:Detailed,
        N_Wall,  !- Name
        Wall,  !- Surface Type
        Exterior Wall,  !- Construction Name
        Box,  !- Zone Name
        Outdoors,  !- Outside Boundary Condition
        ,  !- Outside Boundary Condition Object
        SunExposed,  !- Sun Exposure
        WindExposed,  !- Wind Exposure
        ,  !- View Factor to Ground
        1,  !- Number of Vertices
        5.000000000000,  !- Vertex 1 X-coordinate {m}
        6.000000000000,  !- Vertex 1 Y-coordinate {m}
        3.000000000000;  !- Vertex 1 Z-coordinate {m}

      WALL:EXTERIOR,
          WallExterior,                    !- Name
          ,                         !- Construction Name
          Box,                         !- Zone Name
          ,                         !- Azimuth Angle
          90;                       !- Tilt Angle

        BUILDINGSURFACE:DETAILED,
            EWall,                    !- Name
            ,                         !- Surface Type
            ,                         !- Construction Name
            BOX,                         !- Zone Name
            OtherBox,                         !- Outside Boundary Condition
            ,                         !- Outside Boundary Condition Object
            SunExposed,               !- Sun Exposure
            WindExposed,              !- Wind Exposure
            autocalculate,            !- View Factor to Ground
            autocalculate;            !- Number of Vertices

        BUILDINGSURFACE:DETAILED,
            EWall1,                    !- Name
            ,                         !- Surface Type
            ,                         !- Construction Name
            BOX_other,                         !- Zone Name
            OtherBox,                         !- Outside Boundary Condition
            ,                         !- Outside Boundary Condition Object
            SunExposed,               !- Sun Exposure
            WindExposed,              !- Wind Exposure
            autocalculate,            !- View Factor to Ground
            autocalculate;            !- Number of Vertices
      HVACTemplate:Thermostat,
        Constant Setpoint Thermostat,  !- Name
        ,                        !- Heating Setpoint Schedule Name
        20,                      !- Constant Heating Setpoint {C}
        ,                        !- Cooling Setpoint Schedule Name
        25;                      !- Constant Cooling Setpoint {C}

    FENESTRATIONSURFACE:DETAILED,
        Window1,                  !- Name
        ,                         !- Surface Type
        ,                         !- Construction Name
        EWall1,                         !- Building Surface Name
        ,                         !- Outside Boundary Condition Object
        autocalculate,            !- View Factor to Ground
        ,                         !- Shading Control Name
        ,                         !- Frame and Divider Name
        1.0,                      !- Multiplier
        autocalculate;            !- Number of Vertices
      """""",
                ""Box"",
                [""N_Wall"", ""EWall"", ""WallExterior""],
            ),  # idftxt, zname, surfnamelst
        )
        for idftxt, zname, surfnamelst in thedata:
            # import pdb; pdb.set_trace()
            idf = IDF(StringIO(idftxt))
            zone = idf.getobject(""zone"", zname)
            kwargs = {}
            result = zone.getreferingobjs(**kwargs)
            rnames = [item.Name for item in result]
            rnames.sort()
            surfnamelst.sort()
            assert rnames == surfnamelst
        for idftxt, zname, surfnamelst in thedata:
            idf = IDF(StringIO(idftxt))
            zone = idf.getobject(""zone"", zname)
            kwargs = {""iddgroups"": [""Thermal Zones and Surfaces""]}
            result = zone.getreferingobjs(**kwargs)
            rnames = [item.Name for item in result]
            rnames.sort()
            surfnamelst.sort()
            assert rnames == surfnamelst
        for idftxt, zname, surfnamelst in thedata:
            idf = IDF(StringIO(idftxt))
            zone = idf.getobject(""zone"", zname)
            kwargs = {""fields"": [""Zone_Name""]}
            result = zone.getreferingobjs(**kwargs)
            rnames = [item.Name for item in result]
            rnames.sort()
            surfnamelst.sort()
            assert rnames == surfnamelst
        for idftxt, zname, surfnamelst in thedata:
            idf = IDF(StringIO(idftxt))
            zone = idf.getobject(""zone"", zname)
            kwargs = {
                ""fields"": [""Zone_Name""],
                ""iddgroups"": [""Thermal Zones and Surfaces""],
            }
            result = zone.getreferingobjs(**kwargs)
            rnames = [item.Name for item in result]
            rnames.sort()
            surfnamelst.sort()
            assert rnames == surfnamelst
        # use the above idftxt and try other to get other references.
        for idftxt, zname, surfnamelst in thedata:
            idf = IDF(StringIO(idftxt))
            wname = ""EWall1""
            windownamelist = [""Window1""]
            wall = idf.getobject(""BUILDINGSURFACE:DETAILED"", wname)
            kwargs = {
                ""fields"": [""Building_Surface_Name""],
                ""iddgroups"": [""Thermal Zones and Surfaces""],
            }
            result = wall.getreferingobjs(**kwargs)
            rnames = [item.Name for item in result]
            rnames.sort()
            surfnamelst.sort()
            assert rnames == windownamelist

    ",True
650,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_contains,"def test_contains(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    assert key in idf.idfobjects


@pytest.mark.parametrize(""key"", [""BUILDING"", ""Building"", ""building"", ""BuIlDiNg""])
",True
651,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_contains,"def test_contains(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    assert key in idf.idfobjects


@pytest.mark.parametrize(""key"", [""BUILDING"", ""Building"", ""building"", ""BuIlDiNg""])
",True
652,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_contains,"def test_contains(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    assert key in idf.idfobjects


@pytest.mark.parametrize(""key"", [""BUILDING"", ""Building"", ""building"", ""BuIlDiNg""])
",True
653,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_contains,"def test_contains(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    assert key in idf.idfobjects


@pytest.mark.parametrize(""key"", [""BUILDING"", ""Building"", ""building"", ""BuIlDiNg""])
",True
654,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_del,"def test_del(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    assert key in idf.idfobjects
    del idf.idfobjects[""building""]
    assert key not in idf.idfobjects
",True
655,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_del,"def test_del(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    assert key in idf.idfobjects
    del idf.idfobjects[""building""]
    assert key not in idf.idfobjects
",True
656,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_del,"def test_del(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    assert key in idf.idfobjects
    del idf.idfobjects[""building""]
    assert key not in idf.idfobjects
",True
657,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_del,"def test_del(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    assert key in idf.idfobjects
    del idf.idfobjects[""building""]
    assert key not in idf.idfobjects
",True
658,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_get_and_set,"def test_get_and_set(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    buildings = idf.idfobjects[""building""]
    assert len(buildings) == 1


@pytest.mark.parametrize(""key"", [""BUILDING"", ""Building"", ""building"", ""BuIlDiNg""])
",True
659,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_get_and_set,"def test_get_and_set(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    buildings = idf.idfobjects[""building""]
    assert len(buildings) == 1


@pytest.mark.parametrize(""key"", [""BUILDING"", ""Building"", ""building"", ""BuIlDiNg""])
",True
660,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_get_and_set,"def test_get_and_set(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    buildings = idf.idfobjects[""building""]
    assert len(buildings) == 1


@pytest.mark.parametrize(""key"", [""BUILDING"", ""Building"", ""building"", ""BuIlDiNg""])
",True
661,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_case_insensitive.py,,test_get_and_set,"def test_get_and_set(base_idf, key):
    idf = base_idf
    idf.newidfobject(key, Name=""Building"")
    buildings = idf.idfobjects[""building""]
    assert len(buildings) == 1


@pytest.mark.parametrize(""key"", [""BUILDING"", ""Building"", ""building"", ""BuIlDiNg""])
",True
662,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_examples.py,,test_pythonic,"def test_pythonic():
    """"""py.test for ex_pythonic.py""""""
    zones = bunchdt[""zone""]  # all the zones
    zone0 = zones[0]
    # -
    printout = ""PLENUM-1""
    assert zone0.Name == printout
    # -
    printout = [
        ""PLENUM-1"",
        ""SPACE1-1"",
        ""SPACE2-1"",
        ""SPACE3-1"",
        ""SPACE4-1"",
        ""SPACE5-1"",
        ""Sup-PLENUM-1"",
    ]
    zonenames = [zone.Name for zone in zones]
    assert printout == zonenames
    # -
    printout = [
        ""283.2"",
        ""239.247360229"",
        ""103.311355591"",
        ""239.247360229"",
        ""103.311355591"",
        ""447.682556152"",
        ""208.6"",
    ]
    zonevolumes = [zone.Volume for zone in zones]
    for item1, item2 in zip(printout, zonevolumes):
        item1, item2 = float(item1), float(item2)
        assert pytest_helpers.almostequal(item1, item2)
    # -
    printout = [(""SPACE2-1"", ""103.311355591""), (""SPACE4-1"", ""103.311355591"")]
    smallzones = [zn for zn in zones if float(zn.Volume) < 150]
    namevolume = [(zn.Name, zn.Volume) for zn in smallzones]
    for (n1, v1), (n2, v2) in zip(printout, namevolume):
        (n1, v1) = (n1, float(v1))
        (n2, v2) = (n2, float(v2))
        assert n1 == n2
        assert pytest_helpers.almostequal(v1, v2)
    # -
    printout = 2
    assert printout == len(smallzones)
    # -
    printout = [
        ""PLENUM-1"",
        ""SPACE1-1"",
        ""FIRST-SMALL-ZONE"",
        ""SPACE3-1"",
        ""SECOND-SMALL-ZONE"",
        ""SPACE5-1"",
        ""Sup-PLENUM-1"",
    ]
    smallzones[0].Name = ""FIRST-SMALL-ZONE""
    smallzones[1].Name = ""SECOND-SMALL-ZONE""
    # now the zone names are:
    zonenames = [zone.Name for zone in zones]
    assert printout == zonenames


",True
663,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_fanpower.py,,test_fan_maxcfm,"def test_fan_maxcfm():
    """"""py.test for fan_maxcfm in idf""""""
    idf = IDF(StringIO(vavfan))
    thefans = idf.idfobjects[""Fan:VariableVolume"".upper()]
    thefan = thefans[0]
    cfm = thefan.f_fan_maxcfm
    assert almostequal(cfm, 12000, places=5)
    # test autosize
    thefan.Maximum_Flow_Rate = ""autosize""
    watts = thefan.f_fanpower_watts
    assert watts == ""autosize""


",True
664,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_fanpower.py,,testfanpower_bhp,"def testfanpower_bhp():
    """"""py.test for fanpower_bhp in idf""""""
    idf = IDF(StringIO(vavfan))
    thefans = idf.idfobjects[""Fan:VariableVolume"".upper()]
    thefan = thefans[0]
    bhp = thefan.f_fanpower_bhp
    assert almostequal(bhp, 2.40306611606)
    # test autosize
    thefan.Maximum_Flow_Rate = ""autosize""
    bhp = thefan.f_fanpower_bhp
    assert bhp == ""autosize""


",True
665,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_fanpower.py,,testfanpower_watts,"def testfanpower_watts():
    """"""py.test for fanpower_watts in idf""""""
    idf = IDF(StringIO(vavfan))
    thefans = idf.idfobjects[""Fan:VariableVolume"".upper()]
    thefan = thefans[0]
    watts = thefan.f_fanpower_watts
    assert almostequal(watts, 1791.9664027495671)
    # test autosize
    thefan.Maximum_Flow_Rate = ""autosize""
    watts = thefan.f_fanpower_watts
    assert watts == ""autosize""


",True
666,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_componentsintobranch,"def test_componentsintobranch():
    """"""py.test for componentsintobranch""""""
    tdata = (
        (
            """"""BRANCH,
             sb0,
             0.0,
             ,
             Pipe:Adiabatic,
             sb0_pipe,
             p_loop Supply Inlet,
             sb0_pipe_outlet,
             Bypass;
             """""",
            [(""PIPE:ADIABATIC"", ""pipe1"", None), (""PIPE:ADIABATIC"", ""pipe2"", None)],
            """",
            [
                ""PIPE:ADIABATIC"",
                ""pipe1"",
                ""pipe1_Inlet_Node_Name"",
                ""pipe1_Outlet_Node_Name"",
                """",
                ""PIPE:ADIABATIC"",
                ""pipe2"",
                ""pipe2_Inlet_Node_Name"",
                ""pipe2_Outlet_Node_Name"",
                """",
            ],
        ),
        # idftxt, complst, fluid, branchcomps
        (
            """"""BRANCH,
            sb0,
            0.0,
            ,
            Pipe:Adiabatic,
            sb0_pipe,
            p_loop Supply Inlet,
            sb0_pipe_outlet,
            Bypass;
            """""",
            [
                (""PIPE:ADIABATIC"", ""pipe1"", None),
                (""CHILLER:ELECTRIC"", ""chiller"", ""Chilled_Water_""),
            ],
            """",
            [
                ""PIPE:ADIABATIC"",
                ""pipe1"",
                ""pipe1_Inlet_Node_Name"",
                ""pipe1_Outlet_Node_Name"",
                """",
                ""CHILLER:ELECTRIC"",
                ""chiller"",
                ""chiller_Chilled_Water_Inlet_Node_Name"",
                ""chiller_Chilled_Water_Outlet_Node_Name"",
                """",
            ],
        ),
        # idftxt, complst, fluid, branchcomps
    )
    for ii, (idftxt, complst, fluid, branchcomps) in enumerate(tdata):
        fhandle = StringIO(idftxt)
        idf = IDF(fhandle)
        components_thisnodes = [
            (idf.newidfobject(key, Name=nm), thisnode) for key, nm, thisnode in complst
        ]
        fnc = hvacbuilder.initinletoutlet
        components_thisnodes = [
            (fnc(idf, cp, thisnode), thisnode) for cp, thisnode in components_thisnodes
        ]
        branch = idf.idfobjects[""BRANCH""][0]
        branch = hvacbuilder.componentsintobranch(
            idf, branch, components_thisnodes, fluid
        )
        assert branch.obj[4:] == branchcomps


",True
667,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_connectcomponents,"def test_connectcomponents():
    """"""py.test for connectcomponents""""""
    fhandle = StringIO("""")
    idf = IDF(fhandle)

    tdata = (
        (
            [
                (idf.newidfobject(""PIPE:ADIABATIC"", Name=""pipe1""), None),
                (idf.newidfobject(""PIPE:ADIABATIC"", Name=""pipe2""), None),
            ],
            [""pipe1_Inlet_Node_Name"", [""pipe2_Inlet_Node_Name"", ""pipe1_pipe2_node""]],
            [[""pipe1_Outlet_Node_Name"", ""pipe1_pipe2_node""], ""pipe2_Outlet_Node_Name""],
            """",
        ),
        # components_thisnodes, inlets, outlets, fluid
        (
            [
                (idf.newidfobject(""Coil:Cooling:Water"", Name=""pipe1""), ""Water_""),
                (idf.newidfobject(""Coil:Cooling:Water"", Name=""pipe2""), ""Water_""),
            ],
            [
                ""pipe1_Water_Inlet_Node_Name"",
                """",
                ""pipe2_Water_Inlet_Node_Name"",
                ["""", ""pipe1_pipe2_node""],
            ],
            [
                [""pipe1_Water_Outlet_Node_Name"", ""pipe1_pipe2_node""],
                """",
                ""pipe2_Water_Outlet_Node_Name"",
                """",
            ],
            ""Air"",
        ),
        # components_thisnodes, inlets, outlets, fluid
        (
            [
                (idf.newidfobject(""PIPE:ADIABATIC"", Name=""pipe1""), None),
                (idf.newidfobject(""Coil:Cooling:Water"", Name=""pipe2""), ""Water_""),
            ],
            [
                ""pipe1_Inlet_Node_Name"",
                ""pipe2_Water_Inlet_Node_Name"",
                [""pipe2_Air_Inlet_Node_Name"", ""pipe1_pipe2_node""],
            ],
            [
                [""pipe1_Outlet_Node_Name"", ""pipe1_pipe2_node""],
                ""pipe2_Water_Outlet_Node_Name"",
                """",
            ],
            ""Air"",
        ),
        # components_thisnodes, inlets, outlets, fluid
    )
    for components_thisnodes, inlets, outlets, fluid in tdata:
        # init the nodes in the new components
        for component, thisnode in components_thisnodes:
            hvacbuilder.initinletoutlet(idf, component, thisnode)
        hvacbuilder.connectcomponents(idf, components_thisnodes, fluid)
        inresult = []
        for component, thisnode in components_thisnodes:
            fldnames = hvacbuilder.getfieldnamesendswith(component, ""Inlet_Node_Name"")
            for name in fldnames:
                inresult.append(component[name])
        assert inresult == inresult
        outresult = []
        for component, thisnode in components_thisnodes:
            fldnames = hvacbuilder.getfieldnamesendswith(component, ""Outlet_Node_Name"")
            for name in fldnames:
                outresult.append(component[name])
        assert outresult == outlets


",True
668,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_getbranchcomponents,"def test_getbranchcomponents():
    """"""py.test for getbranchcomponents""""""
    tdata = (
        (
            """"""BRANCH,
            sb1,
            0.0,
            ,
            PIPE:ADIABATIC,
            np1,
            np1_inlet,
            np1_np2_node,
            ,
            PIPE:ADIABATIC,
            np2,
            np1_np2_node,
            np2_outlet,
            ;
            """""",
            True,
            [(""PIPE:ADIABATIC"", ""np1""), (""PIPE:ADIABATIC"", ""np2"")],
        ),  # idftxt, utest, componentlist
        (
            """"""BRANCH,
            sb1,
            0.0,
            ,
            PIPE:ADIABATIC,
            np1,
            np1_inlet,
            np1_np2_node,
            ,
            PIPE:ADIABATIC,
            np2,
            np1_np2_node,
            np2_outlet,
            ;
            PIPE:ADIABATIC,
            np1,
            np1_inlet,
            np1_np2_node;

            PIPE:ADIABATIC,
            np2,
            np1_np2_node,
            np2_outlet;

            """""",
            False,
            [
                [""PIPE:ADIABATIC"", ""np1"", ""np1_inlet"", ""np1_np2_node""],
                [""PIPE:ADIABATIC"", ""np2"", ""np1_np2_node"", ""np2_outlet""],
            ],
        ),
        # idftxt, utest, componentlist
    )
    for idftxt, utest, componentlist in tdata:
        fhandle = StringIO(idftxt)
        idf = IDF(fhandle)
        branch = idf.idfobjects[""BRANCH""][0]
        result = hvacbuilder.getbranchcomponents(idf, branch, utest=utest)
        if utest:
            assert result == componentlist
        else:
            lresult = [item.obj for item in result]
            assert lresult == componentlist


",True
669,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_getfieldnamesendswith,"def test_getfieldnamesendswith():
    """"""py.test for getfieldnamesendswith""""""
    idftxt = """"""PIPE:ADIABATIC,
        np2,                      !- Name
        np1_np2_node,             !- Inlet Node Name
        np2_outlet;               !- Outlet Node Name

    """"""
    tdata = (
        (""Inlet_Node_Name"", [""Inlet_Node_Name""]),  # endswith, fieldnames
        (""Node_Name"", [""Inlet_Node_Name"", ""Outlet_Node_Name""]),  # endswith, fieldnames
        (
            ""Name"",
            [""Name"", ""Inlet_Node_Name"", ""Outlet_Node_Name""],
        ),  # endswith, fieldnames
    )
    fhandle = StringIO(idftxt)
    idf = IDF(fhandle)
    idfobject = idf.idfobjects[""PIPE:ADIABATIC""][0]
    for endswith, fieldnames in tdata:
        result = hvacbuilder.getfieldnamesendswith(idfobject, endswith)
        assert result == fieldnames


",True
670,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_getnodefieldname,"def test_getnodefieldname():
    """"""py.test for getnodefieldname""""""
    tdata = (
        (""PIPE:ADIABATIC"", ""pipe1"", ""Inlet_Node_Name"", """", ""Inlet_Node_Name""),
        # objtype, objname, endswith, fluid, nodefieldname
        (
            ""CHILLER:ELECTRIC"",
            ""pipe1"",
            ""Inlet_Node_Name"",
            """",
            ""Chilled_Water_Inlet_Node_Name"",
        ),
        # objtype, objname, endswith, fluid, nodefieldname
        (
            ""COIL:COOLING:WATER"",
            ""pipe1"",
            ""Inlet_Node_Name"",
            ""Water"",
            ""Water_Inlet_Node_Name"",
        ),
        # objtype, objname, endswith, fluid, nodefieldname
        (
            ""COIL:COOLING:WATER"",
            ""pipe1"",
            ""Inlet_Node_Name"",
            ""Air"",
            ""Air_Inlet_Node_Name"",
        ),
        # objtype, objname, endswith, fluid, nodefieldname
        (
            ""COIL:COOLING:WATER"",
            ""pipe1"",
            ""Outlet_Node_Name"",
            ""Air"",
            ""Air_Outlet_Node_Name"",
        ),
        # objtype, objname, endswith, fluid, nodefieldname
    )
    for objtype, objname, endswith, fluid, nodefieldname in tdata:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        idfobject = idf.newidfobject(objtype, Name=objname)
        result = hvacbuilder.getnodefieldname(idfobject, endswith, fluid)
        assert result == nodefieldname


",True
671,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_initinletoutlet,"def test_initinletoutlet():
    """"""py.test for initinletoutlet""""""
    tdata = (
        (
            ""PIPE:ADIABATIC"",
            ""apipe"",
            None,
            True,
            [""apipe_Inlet_Node_Name""],
            [""apipe_Outlet_Node_Name""],
        ),
        # idfobjectkey, idfobjname, thisnode, force, inlets, outlets
        (""PIPE:ADIABATIC"", ""apipe"", None, False, [""Gumby""], [""apipe_Outlet_Node_Name""]),
        # idfobjectkey, idfobjname, thisnode, force, inlets, outlets
        (
            ""Coil:Cooling:Water"",
            ""acoil"",
            ""Water_"",
            True,
            [""acoil_Water_Inlet_Node_Name"", """"],
            [""acoil_Water_Outlet_Node_Name"", """"],
        ),
        # idfobjectkey, idfobjname, thisnode, force, inlets, outlets
    )
    fhandle = StringIO("""")
    idf = IDF(fhandle)
    for idfobjectkey, idfobjname, thisnode, force, inlets, outlets in tdata:
        idfobject = idf.newidfobject(idfobjectkey, Name=idfobjname)
        inodefields = hvacbuilder.getfieldnamesendswith(idfobject, ""Inlet_Node_Name"")
        idfobject[inodefields[0]] = ""Gumby""
        hvacbuilder.initinletoutlet(idf, idfobject, thisnode, force=force)
        inodefields = hvacbuilder.getfieldnamesendswith(idfobject, ""Inlet_Node_Name"")
        for nodefield, inlet in zip(inodefields, inlets):
            result = idfobject[nodefield]
            assert result == inlet
        onodefields = hvacbuilder.getfieldnamesendswith(idfobject, ""Outlet_Node_Name"")
        for nodefield, outlet in zip(onodefields, outlets):
            result = idfobject[nodefield]
            assert result == outlet


",True
672,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_makecondenserloop,"def test_makecondenserloop():
    """"""pytest for makecondenserloop""""""
    tdata = (
        (
            """",
            ""c_loop"",
            [""sb0"", [""sb1"", ""sb2"", ""sb3""], ""sb4""],
            [""db0"", [""db1"", ""db2"", ""db3""], ""db4""],
            """"""BRANCH, sb0, 0.0, , Pipe:Adiabatic, sb0_pipe,
        c_loop Cond_Supply Inlet, sb0_pipe_outlet, Bypass;  BRANCH, sb1, 0.0,
        , Pipe:Adiabatic, sb1_pipe, sb1_pipe_inlet, sb1_pipe_outlet,
        Bypass;  BRANCH, sb2, 0.0, , Pipe:Adiabatic, sb2_pipe,
        sb2_pipe_inlet, sb2_pipe_outlet, Bypass;  BRANCH, sb3, 0.0, ,
        Pipe:Adiabatic, sb3_pipe, sb3_pipe_inlet, sb3_pipe_outlet,
        Bypass;  BRANCH, sb4, 0.0, , Pipe:Adiabatic, sb4_pipe,
        sb4_pipe_inlet, c_loop Cond_Supply Outlet, Bypass;  BRANCH,
        db0, 0.0, , Pipe:Adiabatic, db0_pipe, c_loop Demand Inlet,
        db0_pipe_outlet, Bypass;  BRANCH, db1, 0.0, , Pipe:Adiabatic, db1_pipe,
        db1_pipe_inlet, db1_pipe_outlet, Bypass;  BRANCH, db2, 0.0, ,
        Pipe:Adiabatic, db2_pipe, db2_pipe_inlet, db2_pipe_outlet, Bypass;
        BRANCH, db3, 0.0, , Pipe:Adiabatic, db3_pipe, db3_pipe_inlet,
        db3_pipe_outlet, Bypass;  BRANCH, db4, 0.0, , Pipe:Adiabatic,
        db4_pipe, db4_pipe_inlet, c_loop Demand Outlet, Bypass;
        BRANCHLIST, c_loop Cond_Supply Branchs, sb0, sb1, sb2, sb3, sb4;
        BRANCHLIST, c_loop Condenser Demand Branchs, db0, db1, db2, db3,
        db4;  CONNECTOR:SPLITTER, c_loop_supply_splitter, sb0, sb1,
        sb2, sb3;  CONNECTOR:SPLITTER, c_loop_demand_splitter, db0, db1, db2,
        db3;  CONNECTOR:MIXER, c_loop_supply_mixer, sb4, sb1, sb2, sb3;
        CONNECTOR:MIXER, c_loop_demand_mixer, db4, db1, db2, db3;
        CONNECTORLIST, c_loop Cond_Supply Connectors, Connector:Splitter,
        c_loop_supply_splitter, Connector:Mixer, c_loop_supply_mixer;
        CONNECTORLIST, c_loop Condenser Demand Connectors,
        Connector:Splitter, c_loop_demand_splitter, Connector:Mixer,
        c_loop_demand_mixer;  PIPE:ADIABATIC, sb0_pipe,
        c_loop Cond_Supply Inlet, sb0_pipe_outlet;  PIPE:ADIABATIC,
        sb1_pipe, sb1_pipe_inlet, sb1_pipe_outlet;  PIPE:ADIABATIC, sb2_pipe,
        sb2_pipe_inlet, sb2_pipe_outlet;  PIPE:ADIABATIC, sb3_pipe,
        sb3_pipe_inlet, sb3_pipe_outlet;  PIPE:ADIABATIC, sb4_pipe,
        sb4_pipe_inlet, c_loop Cond_Supply Outlet;  PIPE:ADIABATIC,
        db0_pipe, c_loop Demand Inlet, db0_pipe_outlet;  PIPE:ADIABATIC,
        db1_pipe, db1_pipe_inlet, db1_pipe_outlet;  PIPE:ADIABATIC,
        db2_pipe, db2_pipe_inlet, db2_pipe_outlet;  PIPE:ADIABATIC,
        db3_pipe, db3_pipe_inlet, db3_pipe_outlet;  PIPE:ADIABATIC, db4_pipe,
        db4_pipe_inlet, c_loop Demand Outlet;  CONDENSERLOOP, c_loop, Water, ,
        , , , , , 0.0, Autocalculate, c_loop Cond_Supply Inlet,
        c_loop Cond_Supply Outlet, c_loop Cond_Supply Branchs,
        c_loop Cond_Supply Connectors, c_loop Demand Inlet,
        c_loop Demand Outlet, c_loop Condenser Demand Branchs,
        c_loop Condenser Demand Connectors, Sequential, None;  """""",
        ),  # blankidf, loopname, sloop, dloop, nidf
    )
    for blankidf, loopname, sloop, dloop, nidf in tdata:

        fhandle = StringIO("""")
        idf1 = IDF(fhandle)
        loopname = ""c_loop""
        sloop = [""sb0"", [""sb1"", ""sb2"", ""sb3""], ""sb4""]
        dloop = [""db0"", [""db1"", ""db2"", ""db3""], ""db4""]
        hvacbuilder.makecondenserloop(idf1, loopname, sloop, dloop)
        idf2 = IDF(StringIO(nidf))
        assert str(idf1.model) == str(idf2.model)


",True
673,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_makeductbranch,"def test_makeductbranch():
    """"""py.test for makeductbranch""""""
    tdata = (
        (
            ""d_branch"",
            [
                ""BRANCH"",
                ""d_branch"",
                0.0,
                """",
                ""duct"",
                ""d_branch_duct"",
                ""d_branch_duct_inlet"",
                ""d_branch_duct_outlet"",
                ""Bypass"",
            ],
            [""DUCT"", ""d_branch_duct"", ""d_branch_duct_inlet"", ""d_branch_duct_outlet""],
        ),  # db_name, branch_obj, duct_obj
    )
    for db_name, branch_obj, duct_obj in tdata:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        result = hvacbuilder.makeductbranch(idf, db_name)
        assert result.obj == branch_obj
        theduct = idf.getobject(""DUCT"", result.Component_1_Name)
        assert theduct.obj == duct_obj


",True
674,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_makeductcomponent,"def test_makeductcomponent():
    """"""py.test for makeductcomponent""""""
    tdata = (
        (""aduct"", [""DUCT"", ""aduct"", ""aduct_inlet"", ""aduct_outlet""]),  # dname, duct_obj
    )
    for dname, duct_obj in tdata:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        result = hvacbuilder.makeductcomponent(idf, dname)
        assert result.obj == duct_obj


",True
675,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_makepipebranch,"def test_makepipebranch():
    """"""py.test for makepipebranch""""""
    tdata = (
        (
            ""p_branch"",
            [
                ""BRANCH"",
                ""p_branch"",
                0.0,
                """",
                ""Pipe:Adiabatic"",
                ""p_branch_pipe"",
                ""p_branch_pipe_inlet"",
                ""p_branch_pipe_outlet"",
                ""Bypass"",
            ],
            [
                ""PIPE:ADIABATIC"",
                ""p_branch_pipe"",
                ""p_branch_pipe_inlet"",
                ""p_branch_pipe_outlet"",
            ],
        ),  # pb_name, branch_obj, pipe_obj
    )
    for pb_name, branch_obj, pipe_obj in tdata:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        result = hvacbuilder.makepipebranch(idf, pb_name)
        assert result.obj == branch_obj
        thepipe = idf.getobject(""PIPE:ADIABATIC"", result.Component_1_Name)
        assert thepipe.obj == pipe_obj


",True
676,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_makepipecomponent,"def test_makepipecomponent():
    """"""py.test for makepipecomponent""""""
    tdata = (
        (
            ""apipe"",
            [""PIPE:ADIABATIC"", ""apipe"", ""apipe_inlet"", ""apipe_outlet""],
        ),  # pname, pipe_obj
        (
            ""bpipe"",
            [""PIPE:ADIABATIC"", ""bpipe"", ""bpipe_inlet"", ""bpipe_outlet""],
        ),  # pname, pipe_obj
    )
    for pname, pipe_obj in tdata:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        result = hvacbuilder.makepipecomponent(idf, pname)
        assert result.obj == pipe_obj


",True
677,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_makeplantloop,"def test_makeplantloop():
    """"""pytest for makeplantloop""""""
    tdata = (
        (
            """",
            ""p_loop"",
            [""sb0"", [""sb1"", ""sb2"", ""sb3""], ""sb4""],
            [""db0"", [""db1"", ""db2"", ""db3""], ""db4""],
            """"""BRANCH, sb0, 0.0, , Pipe:Adiabatic, sb0_pipe, p_loop Supply Inlet,
        sb0_pipe_outlet, Bypass;BRANCH, sb1, 0.0, , Pipe:Adiabatic, sb1_pipe,
        sb1_pipe_inlet, sb1_pipe_outlet, Bypass;BRANCH, sb2, 0.0, ,
        Pipe:Adiabatic, sb2_pipe, sb2_pipe_inlet, sb2_pipe_outlet,
        Bypass;BRANCH, sb3, 0.0, , Pipe:Adiabatic, sb3_pipe, sb3_pipe_inlet,
        sb3_pipe_outlet, Bypass;BRANCH, sb4, 0.0, , Pipe:Adiabatic, sb4_pipe,
        sb4_pipe_inlet, p_loop Supply Outlet, Bypass;BRANCH, db0, 0.0, ,
        Pipe:Adiabatic, db0_pipe, p_loop Demand Inlet, db0_pipe_outlet,
        Bypass;BRANCH, db1, 0.0, , Pipe:Adiabatic, db1_pipe, db1_pipe_inlet,
        db1_pipe_outlet, Bypass;BRANCH, db2, 0.0, , Pipe:Adiabatic, db2_pipe,
        db2_pipe_inlet, db2_pipe_outlet, Bypass;BRANCH, db3, 0.0, ,
        Pipe:Adiabatic, db3_pipe, db3_pipe_inlet, db3_pipe_outlet,
        Bypass;BRANCH, db4, 0.0, , Pipe:Adiabatic, db4_pipe, db4_pipe_inlet,
        p_loop Demand Outlet, Bypass;BRANCHLIST, p_loop Supply Branchs,
        sb0, sb1, sb2, sb3, sb4;BRANCHLIST, p_loop Demand Branchs, db0,
        db1, db2, db3, db4;CONNECTOR:SPLITTER, p_loop_supply_splitter,
        sb0, sb1, sb2, sb3;CONNECTOR:SPLITTER, p_loop_demand_splitter,
        db0, db1, db2, db3;CONNECTOR:MIXER, p_loop_supply_mixer, sb4,
        sb1, sb2, sb3;CONNECTOR:MIXER, p_loop_demand_mixer, db4, db1,
        db2, db3;CONNECTORLIST, p_loop Supply Connectors, Connector:Splitter,
        p_loop_supply_splitter, Connector:Mixer,
        p_loop_supply_mixer;CONNECTORLIST, p_loop Demand Connectors,
        Connector:Splitter, p_loop_demand_splitter, Connector:Mixer,
        p_loop_demand_mixer;PIPE:ADIABATIC, sb0_pipe, p_loop Supply Inlet,
        sb0_pipe_outlet;PIPE:ADIABATIC, sb1_pipe, sb1_pipe_inlet,
        sb1_pipe_outlet;PIPE:ADIABATIC, sb2_pipe, sb2_pipe_inlet,
        sb2_pipe_outlet;PIPE:ADIABATIC, sb3_pipe, sb3_pipe_inlet,
        sb3_pipe_outlet;PIPE:ADIABATIC, sb4_pipe, sb4_pipe_inlet,
        p_loop Supply Outlet;PIPE:ADIABATIC, db0_pipe,
        p_loop Demand Inlet, db0_pipe_outlet;PIPE:ADIABATIC, db1_pipe,
        db1_pipe_inlet, db1_pipe_outlet;PIPE:ADIABATIC, db2_pipe,
        db2_pipe_inlet, db2_pipe_outlet;PIPE:ADIABATIC, db3_pipe,
        db3_pipe_inlet, db3_pipe_outlet;PIPE:ADIABATIC, db4_pipe,
        db4_pipe_inlet, p_loop Demand Outlet;PLANTLOOP, p_loop, Water, , ,
        , , , , 0.0, Autocalculate, p_loop Supply Inlet,
        p_loop Supply Outlet, p_loop Supply Branchs,
        p_loop Supply Connectors, p_loop Demand Inlet, p_loop Demand Outlet,
        p_loop Demand Branchs, p_loop Demand Connectors, Sequential, ,
        SingleSetpoint, None, None;"""""",
        ),  # blankidf, loopname, sloop, dloop, nidf
    )
    for blankidf, loopname, sloop, dloop, nidf in tdata:
        fhandle = StringIO("""")
        idf1 = IDF(fhandle)
        loopname = ""p_loop""
        sloop = [""sb0"", [""sb1"", ""sb2"", ""sb3""], ""sb4""]
        dloop = [""db0"", [""db1"", ""db2"", ""db3""], ""db4""]
        hvacbuilder.makeplantloop(idf1, loopname, sloop, dloop)
        idf2 = IDF(StringIO(nidf))
        # print('=' * 15)
        # print(idf1.model)
        # print('-' * 15)
        # print(idf2.model)
        # print('=' * 15)
        assert str(idf1.model) == str(idf2.model)


",True
678,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_renamenodes,"def test_renamenodes():
    """"""py.test for renamenodes""""""
    idftxt = """"""PIPE:ADIABATIC,
         np1,
         np1_inlet,
         np1_outlet;
         !- ['np1_outlet', 'np1_np2_node'];

    BRANCH,
         sb0,
         0.0,
         ,
         Pipe:Adiabatic,
         np1,
         np1_inlet,
         np1_outlet,
         Bypass;
    """"""
    outtxt = """"""PIPE:ADIABATIC,
         np1,
         np1_inlet,
         np1_np2_node;
         !- ['np1_outlet', 'np1_np2_node'];

    BRANCH,
         sb0,
         0.0,
         ,
         Pipe:Adiabatic,
         np1,
         np1_inlet,
         np1_np2_node,
         Bypass;
    """"""
    # !- ['np1_outlet', 'np1_np2_node'];
    fhandle = StringIO(idftxt)
    idf = IDF(fhandle)
    pipe = idf.idfobjects[""PIPE:ADIABATIC""][0]
    pipe.Outlet_Node_Name = [
        ""np1_outlet"",
        ""np1_np2_node"",
    ]  # this is the first step of the replace
    hvacbuilder.renamenodes(idf, fieldtype=""node"")
    outidf = IDF(StringIO(outtxt))
    result = idf.idfobjects[""PIPE:ADIABATIC""][0].obj
    assert result == outidf.idfobjects[""PIPE:ADIABATIC""][0].obj


",True
679,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_hvacbuilder.py,,test_replacebranch,"def test_replacebranch():
    """"""py.test for replacebranch""""""
    tdata = (
        (
            ""p_loop"",
            [""sb0"", [""sb1"", ""sb2"", ""sb3""], ""sb4""],
            [""db0"", [""db1"", ""db2"", ""db3""], ""db4""],
            ""sb0"",
            [
                (""Chiller:Electric"", ""Central_Chiller"", ""Chilled_Water_""),
                (""PIPE:ADIABATIC"", ""np1"", None),
                (""PIPE:ADIABATIC"", ""np2"", None),
            ],
            ""Water"",
            [
                ""BRANCH"",
                ""sb0"",
                0.0,
                """",
                ""CHILLER:ELECTRIC"",
                ""Central_Chiller"",
                ""p_loop Supply Inlet"",
                ""Central_Chiller_np1_node"",
                """",
                ""PIPE:ADIABATIC"",
                ""np1"",
                ""Central_Chiller_np1_node"",
                ""np1_np2_node"",
                """",
                ""PIPE:ADIABATIC"",
                ""np2"",
                ""np1_np2_node"",
                ""np2_Outlet_Node_Name"",
                """",
            ],
        ),  # loopname, sloop, dloop, branchname, componenttuple, fluid, outbranch
    )
    for (loopname, sloop, dloop, branchname, componenttuple, fluid, outbranch) in tdata:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        loop = hvacbuilder.makeplantloop(idf, loopname, sloop, dloop)
        components_thisnodes = [
            (idf.newidfobject(key, Name=nm), thisnode)
            for key, nm, thisnode in componenttuple
        ]
        branch = idf.getobject(""BRANCH"", branchname)
        newbr = hvacbuilder.replacebranch(
            idf, loop, branch, components_thisnodes, fluid=fluid
        )
        assert newbr.obj == outbranch


",True
680,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_idf_helpers.py,,test_copyidfintoidf,"def test_copyidfintoidf():
    """"""py.test for copyidfintoidf""""""
    tonames = [""a"", ""b"", ""c""]
    fromnames = [""d"", ""e""]
    allnames = [""a"", ""b"", ""c"", ""d"", ""e""]
    toidf = IDF(StringIO(""""))
    toidf.newidfobject(""building"", Name=""a"")
    toidf.newidfobject(""building"", Name=""b"")
    toidf.newidfobject(""Site:Location"", Name=""c"")
    result = idf_helpers.getidfobjectlist(toidf)
    assert [res.Name for res in result] == tonames
    fromidf = IDF(StringIO(""""))
    fromidf.newidfobject(""ScheduleTypeLimits"", Name=""d"")
    fromidf.newidfobject(""ScheduleTypeLimits"", Name=""e"")
    result = idf_helpers.getidfobjectlist(fromidf)
    assert [res.Name for res in result] == fromnames
    idf_helpers.copyidfintoidf(toidf, fromidf)
    result = idf_helpers.getidfobjectlist(toidf)
    assert [res.Name for res in result] == allnames
",True
681,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_idf_helpers.py,,test_getanymentions,"def test_getanymentions():
    """"""py.test for getanymentions""""""
    idf = IDF(StringIO(""""))
    mat = idf.newidfobject(""MATERIAL"", Name=""mat"")
    aconst = idf.newidfobject(""CONSTRUCTION"", Name=""const"")
    foundobjs = idf_helpers.getanymentions(idf, mat)
    assert len(foundobjs) == 1
    assert foundobjs[0] == mat


",True
682,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_idf_helpers.py,,test_getidfkeyswithnodes,"def test_getidfkeyswithnodes():
    """"""py.test for getidfkeyswithnodes""""""
    nodekeys = idf_helpers.getidfkeyswithnodes()
    # print(len(nodekeys))
    assert ""PLANTLOOP"" in nodekeys
    assert ""ZONE"" not in nodekeys


# ",True
683,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_idf_helpers.py,,test_getidfobjectlist,"def test_getidfobjectlist():
    """"""py.test for getidfobjectlist""""""
    names = [""a"", ""b"", ""c"", ""d"", ""e""]
    idf = IDF(StringIO(""""))
    idf.newidfobject(""building"", Name=""a"")
    idf.newidfobject(""building"", Name=""b"")
    idf.newidfobject(""Site:Location"", Name=""c"")
    idf.newidfobject(""ScheduleTypeLimits"", Name=""d"")
    idf.newidfobject(""ScheduleTypeLimits"", Name=""e"")
    result = idf_helpers.getidfobjectlist(idf)
    assert [res.Name for res in result] == names


",True
684,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_idf_helpers.py,,test_getobject_use_prevfield,"def test_getobject_use_prevfield():
    """"""py.test for getobject_use_prevfield""""""
    idf = IDF(StringIO(""""))
    branch = idf.newidfobject(
        ""BRANCH"",
        Name=""CW Pump Branch"",
        Component_1_Object_Type=""Pump:VariableSpeed"",
        Component_1_Name=""CW Circ Pump"",
    )
    pump = idf.newidfobject(""PUMP:VARIABLESPEED"", Name=""CW Circ Pump"")
    foundobject = idf_helpers.getobject_use_prevfield(idf, branch, ""Component_1_Name"")
    assert foundobject == pump
    # test for all times it should return None
    foundobject = idf_helpers.getobject_use_prevfield(idf, branch, ""Name"")
    foundobject = None  # prev field not end with Object_Type
    foundobject = idf_helpers.getobject_use_prevfield(
        idf, branch, ""Component_11_Object_Type""
    )
    foundobject = None  # field does not end with ""Name""
    foundobject = idf_helpers.getobject_use_prevfield(idf, branch, ""Component_3_Name"")
    foundobject = None  # bad idfobject key


",True
685,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_idf_helpers.py,,test_getobjectswithnode,"def test_getobjectswithnode():
    """"""py.test for getobjectswithnode""""""
    idf = IDF(StringIO(""""))
    nodekeys = idf_helpers.getidfkeyswithnodes()
    plantloop = idf.newidfobject(
        ""PlantLoop"",
        Name=""Chilled Water Loop"",
        Plant_Side_Inlet_Node_Name=""CW Supply Inlet Node"",
    )
    branch = idf.newidfobject(
        ""Branch"",
        Name=""CW Pump Branch"",
        Component_1_Inlet_Node_Name=""CW Supply Inlet Node"",
    )
    pump = idf.newidfobject(
        ""Pump:VariableSpeed"",
        Name=""CW Circ Pump"",
        Inlet_Node_Name=""CW Supply Inlet Node"",
    )
    zone = idf.newidfobject(""zone"")
    foundobjs = idf_helpers.getobjectswithnode(idf, nodekeys, ""CW Supply Inlet Node"")
    expected = [plantloop, branch, pump]
    expectedset = set([item.key for item in expected])
    resultset = set([item.key for item in foundobjs])
    assert resultset == expectedset
    expectedset = set([item.Name for item in expected])
    resultset = set([item.Name for item in foundobjs])
    assert resultset == expectedset


",True
686,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_idf_helpers.py,,test_idfobjectkeys,"def test_idfobjectkeys():
    """"""py.test for idfobjectkeys""""""
    expected = [
        ""LEAD INPUT"",
        ""SIMULATION DATA"",
        ""VERSION"",
        ""SIMULATIONCONTROL"",
        ""BUILDING"",
    ]
    idf = IDF(StringIO(""""))
    result = idf_helpers.idfobjectkeys(idf)
    assert result[:5] == expected


",True
687,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_idf_helpers.py,,test_name2idfobject,"def test_name2idfobject():
    """"""py.test for name2idfobject""""""
    idf = IDF(StringIO(""""))
    plantloopname = ""plantloopname""
    branchname = ""branchname""
    pumpname = ""pumpname""
    zonename = ""zonename""
    plantloop = idf.newidfobject(
        ""PlantLoop"",
        Name=plantloopname,
        Plant_Side_Inlet_Node_Name=""CW Supply Inlet Node"",
    )
    branch = idf.newidfobject(
        ""Branch"", Name=branchname, Component_1_Inlet_Node_Name=""CW Supply Inlet Node""
    )
    pump = idf.newidfobject(
        ""Pump:VariableSpeed"", Name=pumpname, Inlet_Node_Name=""CW Supply Inlet Node""
    )
    zone = idf.newidfobject(""zone"", Name=zonename)
    simulation = idf.newidfobject(""SimulationControl"")
    # - test
    names = [plantloopname, branchname, pumpname, zonename]
    idfobjs = [plantloop, branch, pump, zone]
    for name, idfobj in zip(names, idfobjs):
        result = idf_helpers.name2idfobject(idf, Name=name)
        assert result == idfobj
    # test when objkeys!=None
    objkey = ""ZoneHVAC:EquipmentConnections""
    equipconnections = idf.newidfobject(objkey, Zone_Name=zonename)
    result = idf_helpers.name2idfobject(idf, Zone_Name=zonename, objkeys=[objkey])
    assert result == equipconnections


",True
688,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_json_functions.py,,test_updateidf,"def test_updateidf():
    """"""py.test for updateidf""""""
    iddtxt = """"""!IDD_Version 8.4.0""""""
    data = (
        (
            """"""Version,
        8.3;                     !- Version Identifier

    """""",
            {""idf.version..Version_Identifier"": ""0.1""},
            ""version"",
            ""Version_Identifier"",
            ""0.1"",
        ),  # idftxt, dct, key, field, fieldval
        (
            """"""SimulationControl,
    No,                      !- Do Zone Sizing Calculation
    No,                      !- Do System Sizing Calculation
    No,                      !- Do Plant Sizing Calculation
    No,                      !- Run Simulation for Sizing Periods
    Yes;                     !- Run Simulation for Weather File Run Periods
    """""",
            {""idf.SimulationControl..Do_Zone_Sizing_Calculation"": ""Yes""},
            ""SimulationControl"",
            ""Do_Zone_Sizing_Calculation"",
            ""Yes"",
        ),  # idftxt, dct, key, field, fieldval
        (
            """"""Building,
    Untitled,                !- Name
    0.0,                     !- North Axis {deg}
    City,                    !- Terrain
    0.04,                    !- Loads Convergence Tolerance Value
    0.4,                     !- Temperature Convergence Tolerance Value {deltaC}
    FullInteriorAndExterior, !- Solar Distribution
    25,                      !- Maximum Number of Warmup Days
    ;                        !- Minimum Number of Warmup Days
    """""",
            {""idf.BUilding.Untitled.Terrain"": ""Rural""},
            ""Building"",
            ""Terrain"",
            ""Rural"",
        ),  # idftxt, dct, key, field, fieldval
        # make a new object
        (
            """"""
    """""",
            {""idf.BUilding.Taj.Terrain"": ""Rural""},
            ""Building"",
            ""Terrain"",
            ""Rural"",
        ),  # idftxt, dct, key, field, fieldval
        # make a new object with no Name field
        (
            """"""
    """""",
            {""idf.GlobalGeometryRules..Starting_Vertex_Position"": ""UpperLeftCorner""},
            ""GlobalGeometryRules"",
            ""Starting_Vertex_Position"",
            ""UpperLeftCorner"",
        ),  # idftxt, dct, key, field, fieldval
        (
            """"""Building,
    Name.name,                !- Name
    0.0,                     !- North Axis {deg}
    City,                    !- Terrain
    0.04,                    !- Loads Convergence Tolerance Value
    0.4,                     !- Temperature Convergence Tolerance Value {deltaC}
    FullInteriorAndExterior, !- Solar Distribution
    25,                      !- Maximum Number of Warmup Days
    ;                        !- Minimum Number of Warmup Days
    """""",
            {""idf.BUilding.Name.name.Terrain"": ""Rural""},
            ""Building"",
            ""Terrain"",
            ""Rural"",
        ),  # idftxt, dct, key, field, fieldval
        (
            """"""Building,
    Name.name,                !- Name
    0.0,                     !- North Axis {deg}
    City,                    !- Terrain
    0.04,                    !- Loads Convergence Tolerance Value
    0.4,                     !- Temperature Convergence Tolerance Value {deltaC}
    FullInteriorAndExterior, !- Solar Distribution
    25,                      !- Maximum Number of Warmup Days
    ;                        !- Minimum Number of Warmup Days
    """""",
            {""idf.BUilding.'Name.name'.Terrain"": ""Rural""},
            ""Building"",
            ""Terrain"",
            ""Rural"",
        ),  # idftxt, dct, key, field, fieldval
    )
    for idftxt, dct, key, field, fieldval in data:
        idfhandle = StringIO(idftxt)
        idf = IDF(idfhandle)
        json_functions.updateidf(idf, dct)
        assert idf.idfobjects[key][0][field] == fieldval
",True
689,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_getallobjlists,"def test_getallobjlists():
    """"""py.test for getallobjlists""""""
    tdata = (
        (
            ""TransformerNames"",
            [(""ElectricLoadCenter:Distribution"".upper(), ""TransformerNames"", [10])],
        ),  # refname, objlists
    )
    for refname, objlists in tdata:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        result = modeleditor.getallobjlists(idf, refname)
        assert result == objlists


",True
690,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_getiddgroupdict,"def test_getiddgroupdict():
    """"""py.test for IDF.getiddgroupdict()""""""
    data = (({None: [""Lead Input"", ""Simulation Data""]},),)  # gdict,
    for (gdict,) in data:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        result = idf.getiddgroupdict()
        assert result[None] == gdict[None]


",True
691,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_getrefnames,"def test_getrefnames():
    """"""py.test for getrefnames""""""
    tdata = (
        (
            ""ZONE"",
            [
                ""ZoneNames"",
                ""OutFaceEnvNames"",
                ""ZoneAndZoneListNames"",
                ""AirflowNetworkNodeAndZoneNames"",
            ],
        ),  # objkey, therefs
        (
            ""FluidProperties:Name"".upper(),
            [""FluidNames"", ""FluidAndGlycolNames""],
        ),  # objkey, therefs
        (""Building"".upper(), []),  # objkey, therefs
    )
    for objkey, therefs in tdata:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        result = modeleditor.getrefnames(idf, objkey)
        assert result == therefs


",True
692,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_idd_index,"def test_idd_index():
    """"""py.test to see if idd_index is returned""""""
    idftxt = """"""""""""
    idf = IDF(StringIO(idftxt))
    assert idf.idd_index == {}
",True
693,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_idfinmsequence,"def test_idfinmsequence():
    """"""py.test for setting of theidf in Idf_MSequence""""""
    idftxt = """"""Version, 6.0;""""""
    # theidf set in Idf_MSequence.__init__
    idf = IDF(StringIO(idftxt))
    versions = idf.idfobjects[""version"".upper()]
    assert versions.theidf == idf
    assert versions[0].theidf == idf
    # theidf set in Idf_MSequence.insert()
    material = idf.newidfobject(""material"".upper())
    assert material.theidf == idf
    # theidf set when you pop an item
    newmaterial = idf.newidfobject(""material"".upper())
    materials = idf.idfobjects[""material"".upper()]
    material = materials.pop(0)
    assert material.theidf == None
    assert materials[0].theidf == idf


",True
694,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_idfstr,"def test_idfstr():
    """"""Test all outputtype options in IDF.idfstr().
    """"""
    idf = IDF()
    idf.initreadtxt(idfsnippet)
    assert idf.outputtype == ""standard""  # start with the default
    original = idf.idfstr()
    assert ""!-"" in original  # has comment
    assert ""\n"" in original  # has line break
    assert ""\n\n"" in original  # has empty line

    idf.outputtype = ""standard""
    s = idf.idfstr()
    assert ""!-"" in s  # has comment
    assert ""\n"" in s  # has line break
    assert ""\n\n"" in s  # has empty line
    assert s == original  # is unchanged

    idf.outputtype = ""nocomment""
    s = idf.idfstr()
    assert ""!-"" not in s  # has no comments
    assert ""\n"" in s  # has line break
    assert ""\n\n"" in s  # has empty line
    assert s != original  # is changed

    idf.outputtype = ""nocomment1""
    s = idf.idfstr()
    assert ""!-"" not in s  # has no comments
    assert ""\n"" in s  # has line break
    assert ""\n\n"" in s  # has empty lines
    assert s != original  # is changed

    idf.outputtype = ""nocomment2""
    s = idf.idfstr()
    assert ""!-"" not in s  # has no comments
    assert ""\n"" in s  # has line break
    assert ""\n\n"" not in s  # has no empty lines
    assert s != original  # is changed

    idf.outputtype = ""compressed""
    s = idf.idfstr()
    assert ""!-"" not in s  # has no comments
    assert ""\n"" not in s  # has no line breaks
    assert ""\n\n"" not in s  # has no empty lines
    assert s != original  # is changed


",True
695,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_initread,"def test_initread():
    """"""Test for IDF.initread() with filename in unicode and as python str.
    """"""
    # setup
    idf = IDF()
    idf.initreadtxt(idfsnippet)
    idf.saveas(""tmp.idf"")

    # test fname as unicode
    fname = ""tmp.idf""
    assert isinstance(fname, string_types)
    idf = IDF()
    idf.initread(fname)
    assert idf.getobject(""BUILDING"", ""Building"")

    # test fname as str
    fname = str(""tmp.idf"")
    assert isinstance(fname, string_types)
    idf = IDF()
    idf.initread(fname)
    assert idf.getobject(""BUILDING"", ""Building"")

    # test that a nonexistent file raises an IOError
    fname = ""notarealfilename.notreal""
    idf = IDF()
    try:
        idf.initread(fname)
        assert False  # shouldn't reach here
    except IOError:
        pass

    # teardown
    os.remove(""tmp.idf"")


",True
696,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_initreadtxt,"def test_initreadtxt():
    """"""Test for IDF.initreadtxt().
    """"""
    idftxt = """"""
        Material,
          G01a 19mm gypsum board,  !- Name
          MediumSmooth,            !- Roughness
          0.019,                   !- Thickness {m}
          0.16,                    !- Conductivity {W/m-K}
          800,                     !- Density {kg/m3}
          1090;                    !- Specific Heat {J/kg-K}

        Construction,
          Interior Wall,           !- Name
          G01a 19mm gypsum board,  !- Outside Layer
          F04 Wall air space resistance,  !- Layer 2
          G01a 19mm gypsum board;  !- Layer 3
        """"""
    idf = IDF()
    idf.initreadtxt(idftxt)
    assert idf.getobject(""MATERIAL"", ""G01a 19mm gypsum board"")


",True
697,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_new,"def test_new():
    """"""py.test for IDF.new()""""""
    idf = IDF()
    idf.new()
    # assert idf.idfobjects['building'.upper()] == Idf_MSequence()
    assert idf.idfobjects[""building"".upper()].list1 == []
    assert idf.idfobjects[""building"".upper()].list2 == []


",True
698,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_newidfobject,"def test_newidfobject():
    """"""py.test for newidfobject""""""
    # make a blank idf
    # make a function for this and then continue.
    idf = IDF()
    idf.new()
    objtype = ""material:airgap"".upper()
    obj = idf.newidfobject(objtype, Name=""Argon"")
    obj = idf.newidfobject(objtype, Name=""Krypton"")
    obj = idf.newidfobject(objtype, Name=""Xenon"")
    assert idf.model.dt[objtype] == [
        [""MATERIAL:AIRGAP"", ""Argon""],
        [""MATERIAL:AIRGAP"", ""Krypton""],
        [""MATERIAL:AIRGAP"", ""Xenon""],
    ]
    # remove an object
    idf.popidfobject(objtype, 1)
    assert idf.model.dt[objtype] == [
        [""MATERIAL:AIRGAP"", ""Argon""],
        [""MATERIAL:AIRGAP"", ""Xenon""],
    ]
    lastobject = idf.idfobjects[objtype][-1]
    idf.removeidfobject(lastobject)
    assert idf.model.dt[objtype] == [[""MATERIAL:AIRGAP"", ""Argon""]]
    # copyidfobject
    onlyobject = idf.idfobjects[objtype][0]
    idf.copyidfobject(onlyobject)

    assert idf.model.dt[objtype] == [
        [""MATERIAL:AIRGAP"", ""Argon""],
        [""MATERIAL:AIRGAP"", ""Argon""],
    ]
    # test some functions
    objtype = ""FENESTRATIONSURFACE:DETAILED""
    obj = idf.newidfobject(objtype, Name=""A Wall"")
    assert obj.coords == []
    assert obj.fieldvalues[1] == ""A Wall""

    # test defaultvalues=True and defaultvalues=False
    sim_deftrue = idf.newidfobject(""SimulationControl"".upper(), defaultvalues=True)
    assert sim_deftrue.Do_Zone_Sizing_Calculation == ""No""
    sim_deffalse = idf.newidfobject(""SimulationControl"".upper(), defaultvalues=False)
    assert sim_deffalse.Do_Zone_Sizing_Calculation == """"


",True
699,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_newidfobject_warning,"def test_newidfobject_warning():
    """"""Test that the warning for newidfobject created with `aname` is working.

    Fails if the warning is not issued when `aname` is used, or if the warning
    is issued when `aname` is not used.
    """"""
    # make a blank idf
    # make a function for this and then continue.
    idf = IDF()
    idf.new()
    objtype = ""material:airgap"".upper()
    # expect warnings here
    with pytest.warns(UserWarning):
        idf.newidfobject(objtype, aname=""Krypton"")
    with pytest.warns(UserWarning):
        idf.newidfobject(objtype, ""Krypton"")

    # expect no warnings here - we pass None so as not to trigger the `Failed: DID NOT WARN` message from pytest
    with pytest.warns(None) as captured_warnings:
        idf.newidfobject(objtype, Name=""Krypton"")
    assert len(captured_warnings) == 0


",True
700,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_refname2key,"def test_refname2key():
    """"""py.test for refname2key""""""
    tdata = (
        (
            ""TransformerNames"",
            [""ElectricLoadCenter:Distribution"".upper()],
        ),  # refname, key
        (
            ""AllCurves"",
            [
                ""PUMP:VARIABLESPEED"",
                ""PUMP:CONSTANTSPEED"",
                ""BOILER:HOTWATER"",
                ""ENERGYMANAGEMENTSYSTEM:CURVEORTABLEINDEXVARIABLE"",
            ],
        ),  # refname, key
    )
    for refname, key in tdata:
        fhandle = StringIO("""")
        idf = IDF(fhandle)
        result = modeleditor.refname2key(idf, refname)
        assert result == key


",True
701,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_rename,"def test_rename():
    """"""py.test for rename""""""
    idftxt = """"""Material,
      G01a 19mm gypsum board,  !- Name
      MediumSmooth,            !- Roughness
      0.019,                   !- Thickness {m}
      0.16,                    !- Conductivity {W/m-K}
      800,                     !- Density {kg/m3}
      1090;                    !- Specific Heat {J/kg-K}

      Construction,
        Interior Wall,           !- Name
        G01a 19mm gypsum board,  !- Outside Layer
        F04 Wall air space resistance,  !- Layer 2
        G01a 19mm gypsum board;  !- Layer 3

      Construction,
        Other Wall,           !- Name
        G01a 19mm gypsum board,  !- Outside Layer
        G01a 19mm gypsum board,  !- Layer 2
        G01a 19mm gypsum board;  !- Layer 3

    """"""
    ridftxt = """"""Material,
      peanut butter,  !- Name
      MediumSmooth,            !- Roughness
      0.019,                   !- Thickness {m}
      0.16,                    !- Conductivity {W/m-K}
      800,                     !- Density {kg/m3}
      1090;                    !- Specific Heat {J/kg-K}

      Construction,
        Interior Wall,           !- Name
        peanut butter,  !- Outside Layer
        F04 Wall air space resistance,  !- Layer 2
        peanut butter;  !- Layer 3

      Construction,
        Other Wall,           !- Name
        peanut butter,  !- Outside Layer
        peanut butter,  !- Layer 2
        peanut butter;  !- Layer 3

    """"""
    fhandle = StringIO(idftxt)
    idf = IDF(fhandle)
    result = modeleditor.rename(
        idf, ""Material"".upper(), ""G01a 19mm gypsum board"", ""peanut butter""
    )
    assert result.Name == ""peanut butter""
    assert idf.idfobjects[""CONSTRUCTION""][0].Outside_Layer == ""peanut butter""
    assert idf.idfobjects[""CONSTRUCTION""][0].Layer_3 == ""peanut butter""


",True
702,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_save,"def test_save():
    """"""
    Test the IDF.save() function using a filehandle to avoid external effects.
    """"""
    file_text = ""Material,TestMaterial,  !- Name""
    idf = IDF(StringIO(file_text))
    # test save with just a filehandle
    file_handle = StringIO()
    idf.save(file_handle)
    expected = ""TestMaterial""
    file_handle.seek(0)
    result = file_handle.read()
    # minimal test that TestMaterial is being written to the file handle
    assert expected in result


",True
703,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_save_with_lineendings_and_encodings,"def test_save_with_lineendings_and_encodings():
    """"""
    Test the IDF.save() function with combinations of encodings and line
    endings.

    """"""
    file_text = ""Material,TestMaterial,  !- Name""
    idf = IDF(StringIO(file_text))
    lineendings = (""windows"", ""unix"", ""default"")
    encodings = (""ascii"", ""latin-1"", ""UTF-8"")

    for le, enc in product(lineendings, encodings):
        file_handle = StringIO()
        idf.save(file_handle, encoding=enc, lineendings=le)
        file_handle.seek(0)
        result = file_handle.read().encode(enc)
        if le == ""windows"":
            assert b""\r\n"" in result
        elif le == ""unix"":
            assert b""\r\n"" not in result
        elif le == ""default"":
            assert os.linesep.encode(enc) in result


",True
704,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_saveas,"def test_saveas():
    """"""Test the IDF.saveas() function.
    """"""
    file_text = ""Material,TestMaterial,  !- Name""
    idf = IDF(StringIO(file_text))
    idf.idfname = ""test.idf""

    try:
        idf.saveas()  # this should raise an error as no filename is passed
        assert False
    except TypeError:
        pass

    file_handle = StringIO()
    idf.saveas(file_handle)  # save with a filehandle
    expected = ""TestMaterial""
    file_handle.seek(0)
    result = file_handle.read()
    assert expected in result

    # test the idfname attribute has been changed
    assert idf.idfname != ""test.idf""


",True
705,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_savecopy,"def test_savecopy():
    """"""Test the IDF.savecopy() function.
    """"""
    file_text = ""Material,TestMaterial,  !- Name""
    idf = IDF(StringIO(file_text))
    idf.idfname = ""test.idf""

    try:
        idf.savecopy()  # this should raise an error as no filename is passed
        assert False
    except TypeError:
        pass

    file_handle = StringIO()
    idf.savecopy(file_handle)  # save a copy with a different filename
    expected = ""TestMaterial""
    file_handle.seek(0)
    result = file_handle.read()
    assert expected in result

    # test the idfname attribute has not been changed
    assert idf.idfname == ""test.idf""


",True
706,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_modeleditor.py,,test_zonearea_zonevolume,"def test_zonearea_zonevolume():
    """"""py.test for zonearea and zonevolume""""""
    idftxt = """"""Zone, 473222, 0.0, 0.0, 0.0, 0.0, , 1;
        BuildingSurface:Detailed, F7289B, Floor, Exterior Floor, 473222,
        Ground, ,
        NoSun, NoWind, , 4, 2.23, 2.56, 0.0, 2.23, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
        2.56, 0.0;  BuildingSurface:Detailed, F3659B, Wall, Exterior Wall,
        473222, Outdoors, , SunExposed, WindExposed, , 4, 2.23, 2.56, 1.49,
        2.23, 2.56, 0.0, 0.0, 2.56, 0.0, 0.0, 2.56, 1.49;
        BuildingSurface:Detailed, 46C6C9, Wall, Exterior Wall, 473222,
        Outdoors, , SunExposed, WindExposed, , 4, 2.23, 0.0, 1.49, 2.23,
        0.0, 0.0, 2.23, 1.02548139464, 0.0, 2.23, 1.02548139464, 1.49;
        BuildingSurface:Detailed, 4287DD, Wall, Exterior Wall, 473222,
        Outdoors, , SunExposed, WindExposed, , 4, 0.0, 2.56, 1.49, 0.0,
        2.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.49;
        BuildingSurface:Detailed, 570C2E, Wall, Exterior Wall, 473222,
        Outdoors, , SunExposed, WindExposed, , 4, 0.0, 0.0, 1.49, 0.0, 0.0,
        0.0, 2.23, 0.0, 0.0, 2.23, 0.0, 1.49;  BuildingSurface:Detailed,
        BAEA99, Roof, Exterior Roof, 473222, Outdoors, , SunExposed,
        WindExposed, , 4, 0.0, 2.56, 1.49, 0.0, 0.0, 1.49, 2.23, 0.0, 1.49,
        2.23, 2.56, 1.49;  BuildingSurface:Detailed, C879FE, Floor,
        Exterior Floor, 473222, Ground, , NoSun, NoWind, , 4, 3.22,
        2.52548139464, 0.0, 3.22, 1.02548139464, 0.0, 2.23,
        1.02548139464, 0.0, 2.23, 2.52548139464, 0.0;
        BuildingSurface:Detailed, 25B601, Wall, Exterior Wall, 473222,
        Outdoors, , SunExposed, WindExposed, , 4, 2.23,
        1.02548139464, 1.49, 2.23, 1.02548139464, 0.0, 2.23, 2.52548139464,
        0.0, 2.23, 2.52548139464, 1.49;  BuildingSurface:Detailed, F5EADC,
        Wall, Exterior Wall, 473222, Outdoors, , SunExposed, WindExposed, ,
        4, 2.23, 1.02548139464, 1.49, 2.23, 1.02548139464, 0.0, 3.22,
        1.02548139464, 0.0, 3.22, 1.02548139464, 1.49;
        BuildingSurface:Detailed, D0AABE, Wall, Exterior Wall, 473222,
        Outdoors, , SunExposed, WindExposed, , 4, 3.22, 1.02548139464,
        1.49, 3.22, 1.02548139464, 0.0, 3.22, 2.52548139464, 0.0, 3.22,
        2.52548139464, 1.49;  BuildingSurface:Detailed, B0EA02, Wall,
        Exterior Wall, 473222, Outdoors, , SunExposed, WindExposed, ,
        4, 3.22, 2.52548139464, 1.49, 3.22, 2.52548139464, 0.0, 2.23,
        2.52548139464, 0.0, 2.23, 2.52548139464, 1.49;
        BuildingSurface:Detailed, E6DF3B, Roof, Exterior Roof, 473222,
        Outdoors, , SunExposed, WindExposed, , 4, 2.23, 2.52548139464, 1.49,
        2.23, 1.02548139464, 1.49, 3.22, 1.02548139464, 1.49, 3.22,
        2.52548139464, 1.49;  BuildingSurface:Detailed, 4F8681, Wall,
        Exterior Wall, 473222, Outdoors, , SunExposed, WindExposed, , 4,
        2.23, 2.52548139464, 1.49, 2.23, 2.52548139464, 0.0, 2.23, 2.56,
        0.0, 2.23, 2.56, 1.49;  """"""
    idf = IDF(StringIO(idftxt))
    result = modeleditor.zonearea(idf, ""473222"")
    assert almostequal(result, 7.1938)
    result = modeleditor.zonearea_floor(idf, ""473222"")
    assert almostequal(result, 7.1938)
    result = modeleditor.zonearea_roofceiling(idf, ""473222"")
    assert almostequal(result, 7.1938)
    result = modeleditor.zone_floor2roofheight(idf, ""473222"")
    assert almostequal(result, 1.49)
    result = modeleditor.zoneheight(idf, ""473222"")
    assert almostequal(result, 1.49)
    result = modeleditor.zone_floor2roofheight(idf, ""473222"")
    assert almostequal(result, 1.49)
    result = modeleditor.zonevolume(idf, ""473222"")
    assert almostequal(result, 10.718762)
    # remove floor
    zone = idf.getobject(""ZONE"", ""473222"")
    surfs = idf.idfobjects[""BuildingSurface:Detailed"".upper()]
    zone_surfs = [s for s in surfs if s.Zone_Name == zone.Name]
    floors = [s for s in zone_surfs if s.Surface_Type.upper() == ""FLOOR""]
    for floor in floors:
        idf.removeidfobject(floor)
    result = modeleditor.zonearea_floor(idf, ""473222"")
    assert almostequal(result, 0)
    result = modeleditor.zonearea_roofceiling(idf, ""473222"")
    assert almostequal(result, 7.1938)
    result = modeleditor.zonearea(idf, ""473222"")
    assert almostequal(result, 7.1938)
    result = modeleditor.zoneheight(idf, ""473222"")
    assert almostequal(result, 1.49)
    result = modeleditor.zonevolume(idf, ""473222"")
    assert almostequal(result, 10.718762)
    # reload idf and remove roof/ceiling
    idf = IDF(StringIO(idftxt))
    zone = idf.getobject(""ZONE"", ""473222"")
    surfs = idf.idfobjects[""BuildingSurface:Detailed"".upper()]
    zone_surfs = [s for s in surfs if s.Zone_Name == zone.Name]
    roofs = [s for s in zone_surfs if s.Surface_Type.upper() == ""ROOF""]
    ceilings = [s for s in zone_surfs if s.Surface_Type.upper() == ""CEILING""]
    topsurfaces = roofs + ceilings
    for surf in topsurfaces:
        idf.removeidfobject(surf)
    result = modeleditor.zonearea_roofceiling(idf, ""473222"")
    assert almostequal(result, 0)
    result = modeleditor.zonearea(idf, ""473222"")
    assert almostequal(result, 7.1938)
    result = modeleditor.zoneheight(idf, ""473222"")
    assert almostequal(result, 1.49)
    result = modeleditor.zonevolume(idf, ""473222"")
    assert almostequal(result, 10.718762)


",True
707,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_simpleread.py,,test_idfreadtest,"def test_idfreadtest():
    """"""py.test for idfreadtest""""""
    data = (
        (
            """"""!IDD_Version 7.2.0.006
Version,
      \\unique-object
      \\format singleLine
  A1 ; \\field Version Identifier

SimulationControl,
      \\unique-object
  A1, \\field Do Zone Sizing Calculation
  A2, \\field Do System Sizing Calculation
  A3, \\field Do Plant Sizing Calculation
  A4, \\field Run Simulation for Sizing Periods
  A5; \\field Run Simulation for Weather File Run Periods

Building,
       \\unique-object
  A1 , \\field Name
  N1 , \\field North Axis
  A2 , \\field Terrain
  N2 , \\field Loads Convergence Tolerance Value
  N3 , \\field Temperature Convergence Tolerance Value
  A3 , \\field Solar Distribution
  N4 , \\field Maximum Number of Warmup Days
  N5 ; \\field Minimum Number of Warmup Days

Site:Location,
       \\unique-object
  A1 , \\field Name
  N1 , \\field Latitude
  N2 , \\field Longitude
  N3 , \\field Time Zone
  N4 ; \\field Elevation

"""""",
            """"""
VERSION,
    7.3;                      !- Version Identifier

SIMULATIONCONTROL,
    Yes,                      !- Do Zone Sizing Calculation
    Yes,                      !- Do System Sizing Calculation
    Yes,                      !- Do Plant Sizing Calculation
    No,                       !- Run Simulation for Sizing Periods
    Yes;                      !- Run Simulation for Weather File Run Periods

BUILDING,
    Empire State Building,    !- Name
    30.0,                     !- North Axis
    City,                     !- Terrain
    0.04,                     !- Loads Convergence Tolerance Value
    0.4,                      !- Temperature Convergence Tolerance Value
    FullExterior,             !- Solar Distribution
    25,                       !- Maximum Number of Warmup Days
    6;                        !- Minimum Number of Warmup Days

SITE:LOCATION,
    CHICAGO_IL_USA TMY2-94846,    !- Name
    41.78,                    !- Latitude
    -87.75,                   !- Longitude
    -6.0,                     !- Time Zone
    190.0;                    !- Elevation
"""""",
        ),  # iddtxt, idftxt
    )
    for iddtxt, idftxt in data:
        iddhandle = StringIO(iddtxt)
        idfhandle1 = StringIO(idftxt)
        idfhandle2 = StringIO(idftxt)
        result = simpleread.idfreadtest(iddhandle, idfhandle1, idfhandle2)
        assert result == True
",True
708,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_heatcapacity_1_layer_construction,"def test_heatcapacity_1_layer_construction(self):
        self.idf.initreadtxt(single_layer)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = m.Thickness * m.Specific_Heat * m.Density * 0.001
        assert c.heatcapacity == expected
        assert c.heatcapacity == 120

    ",True
709,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_heatcapacity_2_layer_construction,"def test_heatcapacity_2_layer_construction(self):
        self.idf.initreadtxt(double_layer)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = m.Thickness * m.Specific_Heat * m.Density * 0.001 * 2
        assert c.heatcapacity == expected
        assert c.heatcapacity == 240

    ",True
710,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_heatcapacity_airgap_construction,"def test_heatcapacity_airgap_construction(self):
        self.idf.initreadtxt(air_gap)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = m.Thickness * m.Specific_Heat * m.Density * 0.001 * 2
        assert almostequal(c.heatcapacity, expected, places=2)
        assert almostequal(c.heatcapacity, 240, places=2)

    ",True
711,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_heatcapacity_infraredtransparent_construction,"def test_heatcapacity_infraredtransparent_construction(self):
        self.idf.initreadtxt(infrared_transparent)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = m.Thickness * m.Specific_Heat * m.Density * 0.001 * 2
        assert almostequal(c.heatcapacity, expected, places=2)
        assert almostequal(c.heatcapacity, 240, places=2)

    ",True
712,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_heatcapacity_material,"def test_heatcapacity_material(self):
        self.idf.initreadtxt(single_layer)
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = m.Thickness * m.Specific_Heat * m.Density * 0.001
        assert m.heatcapacity == expected
        assert m.heatcapacity == 120
",True
713,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_heatcapacity_nomass_construction,"def test_heatcapacity_nomass_construction(self):
        self.idf.initreadtxt(no_mass)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = m.Thickness * m.Specific_Heat * m.Density * 0.001 * 2
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter(""always"")
            assert almostequal(c.heatcapacity, expected, places=2)
            assert almostequal(c.heatcapacity, 240, places=2)
            assert issubclass(w[-1].category, UserWarning)

    ",True
714,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_heatcapacity_roofvegetation_construction,"def test_heatcapacity_roofvegetation_construction(self):
        self.idf.initreadtxt(roof_vegetation)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL:ROOFVEGETATION"", ""RoofVegetation"")
        expected = (
            m.Thickness * m.Specific_Heat_of_Dry_Soil * m.Density_of_Dry_Soil * 0.001
        )
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter(""always"")
            # check that a UserWarning is raised
            assert almostequal(c.heatcapacity, expected, places=2)
            assert almostequal(c.heatcapacity, 120, places=2)
            assert issubclass(w[-1].category, UserWarning)

    ",True
715,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_rvalue_1_layer_construction,"def test_rvalue_1_layer_construction(self):
        self.idf.initreadtxt(single_layer)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = INSIDE_FILM_R + m.Thickness / m.Conductivity + OUTSIDE_FILM_R
        assert c.rvalue == expected
        assert c.rvalue == 0.35

    ",True
716,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_rvalue_2_layer_construction,"def test_rvalue_2_layer_construction(self):
        self.idf.initreadtxt(double_layer)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = (
            INSIDE_FILM_R
            + m.Thickness / m.Conductivity
            + m.Thickness / m.Conductivity
            + OUTSIDE_FILM_R
        )
        assert c.rvalue == expected
        assert c.rvalue == 0.55

    ",True
717,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_rvalue_airgap_construction,"def test_rvalue_airgap_construction(self):
        self.idf.initreadtxt(air_gap)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        a = self.idf.getobject(""MATERIAL:AIRGAP"", ""AirGap"")
        expected = (
            INSIDE_FILM_R
            + m.Thickness / m.Conductivity
            + a.Thermal_Resistance
            + m.Thickness / m.Conductivity
            + OUTSIDE_FILM_R
        )
        assert almostequal(c.rvalue, expected, places=2)
        assert almostequal(c.rvalue, 0.65, places=2)

    ",True
718,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_rvalue_fails,"def test_rvalue_fails(self):
        self.idf.initreadtxt(expected_failure)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        try:
            c.rvalue
            assert False
        except AttributeError as e:
            assert str(e) == ""Skyhooks material not found in IDF""

    ",True
719,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_rvalue_infraredtransparent_construction,"def test_rvalue_infraredtransparent_construction(self):
        self.idf.initreadtxt(infrared_transparent)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = (
            INSIDE_FILM_R
            + m.Thickness / m.Conductivity
            + m.Thickness / m.Conductivity
            + OUTSIDE_FILM_R
        )
        assert almostequal(c.rvalue, expected, places=2)
        assert almostequal(c.rvalue, 0.55, places=2)

    ",True
720,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_rvalue_material,"def test_rvalue_material(self):
        self.idf.initreadtxt(single_layer)
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = m.Thickness / m.Conductivity
        assert m.rvalue == expected
        assert m.rvalue == 0.2

    ",True
721,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_rvalue_nomass_construction,"def test_rvalue_nomass_construction(self):
        self.idf.initreadtxt(no_mass)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        n = self.idf.getobject(""MATERIAL:NOMASS"", ""NoMass"")
        expected = (
            INSIDE_FILM_R
            + m.Thickness / m.Conductivity
            + n.Thermal_Resistance
            + m.Thickness / m.Conductivity
            + OUTSIDE_FILM_R
        )
        assert almostequal(c.rvalue, expected, places=2)
        assert almostequal(c.rvalue, 0.65, places=2)

    ",True
722,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_rvalue_roofvegetation_construction,"def test_rvalue_roofvegetation_construction(self):
        self.idf.initreadtxt(roof_vegetation)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL:ROOFVEGETATION"", ""RoofVegetation"")
        expected = (
            INSIDE_FILM_R + m.Thickness / m.Conductivity_of_Dry_Soil + OUTSIDE_FILM_R
        )
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter(""always"")
            assert c.rvalue == expected
            assert c.rvalue == 0.35
            # check that a UserWarning is raised
            assert issubclass(w[-1].category, UserWarning)

    ",True
723,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_ufactor_1_layer_construction,"def test_ufactor_1_layer_construction(self):
        self.idf.initreadtxt(single_layer)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = 1 / (INSIDE_FILM_R + m.Thickness / m.Conductivity + OUTSIDE_FILM_R)
        assert c.ufactor == expected
        assert c.ufactor == 1 / 0.35

    ",True
724,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_ufactor_2_layer_construction,"def test_ufactor_2_layer_construction(self):
        self.idf.initreadtxt(double_layer)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = 1 / (
            INSIDE_FILM_R
            + m.Thickness / m.Conductivity
            + m.Thickness / m.Conductivity
            + OUTSIDE_FILM_R
        )
        assert c.ufactor == expected
        assert c.ufactor == 1 / 0.55

    ",True
725,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_ufactor_airgap_construction,"def test_ufactor_airgap_construction(self):
        self.idf.initreadtxt(air_gap)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        a = self.idf.getobject(""MATERIAL:AIRGAP"", ""AirGap"")
        expected = 1 / (
            INSIDE_FILM_R
            + m.Thickness / m.Conductivity
            + a.Thermal_Resistance
            + m.Thickness / m.Conductivity
            + OUTSIDE_FILM_R
        )
        assert almostequal(c.ufactor, expected, places=2)
        assert almostequal(c.ufactor, 1 / 0.65, places=2)

    ",True
726,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_ufactor_infraredtransparent_construction,"def test_ufactor_infraredtransparent_construction(self):
        self.idf.initreadtxt(infrared_transparent)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = 1 / (
            INSIDE_FILM_R
            + m.Thickness / m.Conductivity
            + m.Thickness / m.Conductivity
            + OUTSIDE_FILM_R
        )
        assert almostequal(c.ufactor, expected, places=2)
        assert almostequal(c.ufactor, 1 / 0.55, places=2)

    ",True
727,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_ufactor_material,"def test_ufactor_material(self):
        self.idf.initreadtxt(single_layer)
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        expected = 1 / (m.Thickness / m.Conductivity)
        assert m.ufactor == expected
        assert m.ufactor == 1 / 0.2

    ",True
728,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_ufactor_nomass_construction,"def test_ufactor_nomass_construction(self):
        self.idf.initreadtxt(no_mass)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL"", ""TestMaterial"")
        n = self.idf.getobject(""MATERIAL:NOMASS"", ""NoMass"")
        expected = 1 / (
            INSIDE_FILM_R
            + m.Thickness / m.Conductivity
            + n.Thermal_Resistance
            + m.Thickness / m.Conductivity
            + OUTSIDE_FILM_R
        )
        assert almostequal(c.ufactor, expected, places=2)
        assert almostequal(c.ufactor, 1 / 0.65, places=2)

    ",True
729,https://github.com/santoshphilip/eppy/blob/98e58583dce6c0fcec9c7b1ff1142bae0a67ddc7/eppy/tests/test_thermal_properties.py,Test_ThermalProperties,test_ufactor_roofvegetation_construction,"def test_ufactor_roofvegetation_construction(self):
        self.idf.initreadtxt(roof_vegetation)
        c = self.idf.getobject(""CONSTRUCTION"", ""TestConstruction"")
        m = self.idf.getobject(""MATERIAL:ROOFVEGETATION"", ""RoofVegetation"")
        expected = 1 / (
            INSIDE_FILM_R + m.Thickness / m.Conductivity_of_Dry_Soil + OUTSIDE_FILM_R
        )
        with warnings.catch_warnings(record=True) as w:
            warnings.simplefilter(""always"")
            assert c.ufactor == expected
            assert c.ufactor == 1 / 0.35
            # check that a UserWarning is raised
            assert issubclass(w[-1].category, UserWarning)

    ",True
730,https://github.com/epsagon/epsagon-python/blob/b985d8412848f9a0c98e2f15ae0967a6dba3517f/tests/test_trace.py,,test_runner_duration,"def test_runner_duration(_wrapped_post):
    runner = RunnerEventMock()
    runner.terminated = False
    trace = trace_factory.get_or_create_trace()
    trace.token = 'a'
    trace.set_runner(runner)
    time.sleep(0.2)
    trace_factory.send_traces()

    assert 0.2 < runner.duration < 0.3


@mock.patch('urllib3.PoolManager.request')
",False
731,https://github.com/epsagon/epsagon-python/blob/b985d8412848f9a0c98e2f15ae0967a6dba3517f/tests/wrappers/test_python_function.py,,test_function_wrapper_function_exception,"def test_function_wrapper_function_exception(trace_transport):
    @epsagon.python_wrapper()
    ",True
732,https://github.com/epsagon/epsagon-python/blob/b985d8412848f9a0c98e2f15ae0967a6dba3517f/tests/wrappers/test_python_function.py,,test_function_wrapper_sanity,"def test_function_wrapper_sanity(trace_transport, ):
    retval = 'success'

    @epsagon.python_wrapper(name='test-func')
    ",True
733,https://github.com/epsagon/epsagon-python/blob/b985d8412848f9a0c98e2f15ae0967a6dba3517f/tests/wrappers/test_python_function.py,,test_python_wrapper_python_runner_factory_failed,"def test_python_wrapper_python_runner_factory_failed(_):
    @epsagon.python_wrapper
    ",True
734,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_components_bars.py,,test_bar,"def test_bar():
    bar = Bar()

    assert '[          ]' == bar.bar(12, 0)
    assert '[          ]' == bar.bar(12, 9)
    assert '[#         ]' == bar.bar(12, 10)
    assert '[#         ]' == bar.bar(12, 15)
    assert '[##        ]' == bar.bar(12, 20)
    assert '[#####     ]' == bar.bar(12, 50)
    assert '[######### ]' == bar.bar(12, 99)
    assert '[##########]' == bar.bar(12, 100)


",False
735,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_components_bars_undefined.py,,test_animated,"def test_animated():
    bar = BarUndefinedAnimated()

    assert '[?       ]' == bar.bar(10)
    assert '[ ?      ]' == bar.bar(10)
    assert '[  ?     ]' == bar.bar(10)
    assert '[   ?    ]' == bar.bar(10)
    assert '[    ?   ]' == bar.bar(10)
    assert '[     ?  ]' == bar.bar(10)
    assert '[      ? ]' == bar.bar(10)
    assert '[       ?]' == bar.bar(10)
    assert '[      ? ]' == bar.bar(10)
    assert '[     ?  ]' == bar.bar(10)
    assert '[    ?   ]' == bar.bar(10)
    assert '[   ?    ]' == bar.bar(10)
    assert '[  ?     ]' == bar.bar(10)
    assert '[ ?      ]' == bar.bar(10)
    assert '[?       ]' == bar.bar(10)
    assert '[ ?      ]' == bar.bar(10)
    assert '[  ?     ]' == bar.bar(10)


",False
736,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_components_bars_undefined.py,,test_undefined_animated_resize,"def test_undefined_animated_resize():
    bar = BarUndefinedAnimated()

    assert '[?       ]' == bar.bar(10)
    assert '[ ?      ]' == bar.bar(10)
    assert '[  ?     ]' == bar.bar(10)
    assert '[   ?    ]' == bar.bar(10)
    assert '[    ?   ]' == bar.bar(10)
    assert '[     ?  ]' == bar.bar(10)
    assert '[ ? ]' == bar.bar(5)
    assert '[?       ]' == bar.bar(10)
    assert '[ ?      ]' == bar.bar(10)


",False
737,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbar.py,,test_defined_hour,"def test_defined_hour():
    progress_bar = ProgressBar(2000)

    assert '  0% (    0/2,000) [       ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1
    assert '  0% (    1/2,000) [       ] eta --:-- -' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 2
    assert '  0% (    2/2,000) [     ] eta 1:06:36 \\' == str(progress_bar)


",False
738,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbar.py,,test_defined_wont_fit,"def test_defined_wont_fit():
    progress_bar = ProgressBar(2000, max_width=33)
    assert '  0% (    0/2,000) [] eta --:-- |' == str(progress_bar)

    progress_bar = ProgressBar(2000, max_width=30)
    assert '  0% (    0/2,000) [] eta --:-- /' == str(progress_bar)


",False
739,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbar.py,,test_terminal_width,"def test_terminal_width():
    assert 80 == misc.terminal_width()


",False
740,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbar.py,,test_undefined,"def test_undefined():
    misc.terminal_width = lambda: 40
    progress_bar = ProgressBar(None, max_width=30)

    assert '0 [?             ] eta --:-- /' == str(progress_bar)
    assert '0 [ ?            ] eta --:-- -' == str(progress_bar)
    assert '0 [  ?           ] eta --:-- \\' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 10
    assert '10 [   ?         ] eta --:-- |' == str(progress_bar)
    assert '10 [    ?        ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 100
    assert '100 [     ?      ] eta --:-- -' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 1954727
    assert '1,954,727 [    ? ] eta --:-- \\' == str(progress_bar)
    assert '1,954,727 [   ?  ] eta --:-- |' == str(progress_bar)


",False
741,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbits.py,,test_defined,"def test_defined():
    progress_bar = ProgressBarBits(2000)

    assert '  0% (0.00/2.00 kb) [                ] eta --:-- /' == str(progress_bar)
    assert '  0% (0.00/2.00 kb) [                ] eta --:-- -' == str(progress_bar)
    assert '  0% (0.00/2.00 kb) [                ] eta --:-- \\' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 102
    assert '  5% (0.10/2.00 kb) [                ] eta --:-- |' == str(progress_bar)
    assert '  5% (0.10/2.00 kb) [                ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 281
    assert ' 14% (0.28/2.00 kb) [##              ] eta 00:05 -' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 593
    assert ' 29% (0.59/2.00 kb) [####            ] eta 00:03 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868723.5
    progress_bar.numerator = 1925
    assert ' 96% (1.92/2.00 kb) [############### ] eta 00:01 |' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 1999
    assert ' 99% (1.99/2.00 kb) [############### ] eta 00:01 /' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 2000
    assert '100% (2.00/2.00 kb) [################] eta 00:00 -' == str(progress_bar)
    assert '100% (2.00/2.00 kb) [################] eta 00:00 \\' == str(progress_bar)
    assert '100% (2.00/2.00 kb) [################] eta 00:00 |' == str(progress_bar)


",False
742,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbits.py,,test_defined_hour,"def test_defined_hour():
    progress_bar = ProgressBarBits(2000)

    assert '  0% (0.00/2.00 kb) [                ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1
    assert '  0% (0.00/2.00 kb) [                ] eta --:-- -' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 2
    assert '  0% (0.00/2.00 kb) [              ] eta 1:06:36 \\' == str(progress_bar)


",False
743,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbits.py,,test_defined_long,"def test_defined_long():
    misc.terminal_width = lambda: 42
    progress_bar = ProgressBarBits(20)

    assert '  0% ( 0/20 b) [             ] eta --:-- -' == str(progress_bar)
    assert '  0% ( 0/20 b) [             ] eta --:-- \\' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1
    assert '  5% ( 1/20 b) [             ] eta --:-- |' == str(progress_bar)
    assert '  5% ( 1/20 b) [             ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 2
    assert ' 10% ( 2/20 b) [#            ] eta 00:09 -' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 3
    assert ' 15% ( 3/20 b) [#            ] eta 00:09 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868723.5
    progress_bar.numerator = 4
    assert ' 20% ( 4/20 b) [##           ] eta 00:08 |' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 5
    assert ' 25% ( 5/20 b) [###          ] eta 00:08 /' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 6
    assert ' 30% ( 6/20 b) [###          ] eta 00:07 -' == str(progress_bar)

    eta._NOW = lambda: 1411868725.0
    progress_bar.numerator = 7
    assert ' 35% ( 7/20 b) [####         ] eta 00:07 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868725.5
    progress_bar.numerator = 8
    assert ' 40% ( 8/20 b) [#####        ] eta 00:06 |' == str(progress_bar)

    eta._NOW = lambda: 1411868726.0
    progress_bar.numerator = 9
    assert ' 45% ( 9/20 b) [#####        ] eta 00:06 /' == str(progress_bar)

    eta._NOW = lambda: 1411868726.5
    progress_bar.numerator = 10
    assert ' 50% (10/20 b) [######       ] eta 00:05 -' == str(progress_bar)

    eta._NOW = lambda: 1411868727.0
    progress_bar.numerator = 11
    assert ' 55% (11/20 b) [#######      ] eta 00:05 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868727.5
    progress_bar.numerator = 12
    assert ' 60% (12/20 b) [#######      ] eta 00:04 |' == str(progress_bar)

    eta._NOW = lambda: 1411868728.0
    progress_bar.numerator = 13
    assert ' 65% (13/20 b) [########     ] eta 00:04 /' == str(progress_bar)

    eta._NOW = lambda: 1411868728.5
    progress_bar.numerator = 14
    assert ' 70% (14/20 b) [#########    ] eta 00:03 -' == str(progress_bar)

    eta._NOW = lambda: 1411868729.0
    progress_bar.numerator = 15
    assert ' 75% (15/20 b) [#########    ] eta 00:03 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868729.5
    progress_bar.numerator = 16
    assert ' 80% (16/20 b) [##########   ] eta 00:02 |' == str(progress_bar)

    eta._NOW = lambda: 1411868730.0
    progress_bar.numerator = 17
    assert ' 85% (17/20 b) [###########  ] eta 00:02 /' == str(progress_bar)

    eta._NOW = lambda: 1411868730.5
    progress_bar.numerator = 18
    assert ' 90% (18/20 b) [###########  ] eta 00:01 -' == str(progress_bar)

    eta._NOW = lambda: 1411868731.0
    progress_bar.numerator = 19
    assert ' 95% (19/20 b) [############ ] eta 00:01 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868731.5
    progress_bar.numerator = 20
    assert '100% (20/20 b) [#############] eta 00:00 |' == str(progress_bar)
",False
744,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbits.py,,test_defined_rounded,"def test_defined_rounded():
    progress_bar = ProgressBarBits(1999)

    assert '  0% (0.00/2.00 kb) [                ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 1998
    assert ' 99% (1.99/2.00 kb) [############### ] eta --:-- -' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 1999
    assert '100% (2.00/2.00 kb) [################] eta --:-- \\' == str(progress_bar)
    assert '100% (2.00/2.00 kb) [################] eta --:-- |' == str(progress_bar)


",False
745,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbits.py,,test_defined_wont_fit,"def test_defined_wont_fit():
    progress_bar = ProgressBarBits(2000, max_width=33)
    assert '  0% (0.00/2.00 kb) [] eta --:-- |' == str(progress_bar)

    progress_bar = ProgressBarBits(2000, max_width=30)
    assert '  0% (0.00/2.00 kb) [] eta --:-- /' == str(progress_bar)


",False
746,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbits.py,,test_undefined,"def test_undefined():
    misc.terminal_width = lambda: 50
    progress_bar = ProgressBarBits(None, max_width=30)

    assert '0 b [?           ] eta --:-- /' == str(progress_bar)
    assert '0 b [ ?          ] eta --:-- -' == str(progress_bar)
    assert '0 b [  ?         ] eta --:-- \\' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 10
    assert '10 b [   ?       ] eta --:-- |' == str(progress_bar)
    assert '10 b [    ?      ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 100
    assert '100 b [     ?    ] eta --:-- -' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 1954727
    assert '1.95 mb [      ? ] eta --:-- \\' == str(progress_bar)
    assert '1.95 mb [       ?] eta --:-- |' == str(progress_bar)


",False
747,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbytes.py,,test_defined,"def test_defined():
    progress_bar = ProgressBarBytes(2000)

    assert '  0% (0.00/1.95 KiB) [               ] eta --:-- /' == str(progress_bar)
    assert '  0% (0.00/1.95 KiB) [               ] eta --:-- -' == str(progress_bar)
    assert '  0% (0.00/1.95 KiB) [               ] eta --:-- \\' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 102
    assert '  5% (0.09/1.95 KiB) [               ] eta --:-- |' == str(progress_bar)
    assert '  5% (0.09/1.95 KiB) [               ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 281
    assert ' 14% (0.27/1.95 KiB) [##             ] eta 00:05 -' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 593
    assert ' 29% (0.57/1.95 KiB) [####           ] eta 00:03 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868723.5
    progress_bar.numerator = 1925
    assert ' 96% (1.87/1.95 KiB) [############## ] eta 00:01 |' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 1999
    assert ' 99% (1.95/1.95 KiB) [############## ] eta 00:01 /' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 2000
    assert '100% (1.95/1.95 KiB) [###############] eta 00:00 -' == str(progress_bar)
    assert '100% (1.95/1.95 KiB) [###############] eta 00:00 \\' == str(progress_bar)
    assert '100% (1.95/1.95 KiB) [###############] eta 00:00 |' == str(progress_bar)


",False
748,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbytes.py,,test_defined_hour,"def test_defined_hour():
    progress_bar = ProgressBarBytes(2000)

    assert '  0% (0.00/1.95 KiB) [               ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1
    assert '  0% (0.00/1.95 KiB) [               ] eta --:-- -' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 2
    assert '  0% (0.00/1.95 KiB) [             ] eta 1:06:36 \\' == str(progress_bar)


",False
749,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbytes.py,,test_defined_long,"def test_defined_long():
    misc.terminal_width = lambda: 42
    progress_bar = ProgressBarBytes(20)

    assert '  0% ( 0/20 B) [             ] eta --:-- -' == str(progress_bar)
    assert '  0% ( 0/20 B) [             ] eta --:-- \\' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1
    assert '  5% ( 1/20 B) [             ] eta --:-- |' == str(progress_bar)
    assert '  5% ( 1/20 B) [             ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 2
    assert ' 10% ( 2/20 B) [#            ] eta 00:09 -' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 3
    assert ' 15% ( 3/20 B) [#            ] eta 00:09 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868723.5
    progress_bar.numerator = 4
    assert ' 20% ( 4/20 B) [##           ] eta 00:08 |' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 5
    assert ' 25% ( 5/20 B) [###          ] eta 00:08 /' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 6
    assert ' 30% ( 6/20 B) [###          ] eta 00:07 -' == str(progress_bar)

    eta._NOW = lambda: 1411868725.0
    progress_bar.numerator = 7
    assert ' 35% ( 7/20 B) [####         ] eta 00:07 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868725.5
    progress_bar.numerator = 8
    assert ' 40% ( 8/20 B) [#####        ] eta 00:06 |' == str(progress_bar)

    eta._NOW = lambda: 1411868726.0
    progress_bar.numerator = 9
    assert ' 45% ( 9/20 B) [#####        ] eta 00:06 /' == str(progress_bar)

    eta._NOW = lambda: 1411868726.5
    progress_bar.numerator = 10
    assert ' 50% (10/20 B) [######       ] eta 00:05 -' == str(progress_bar)

    eta._NOW = lambda: 1411868727.0
    progress_bar.numerator = 11
    assert ' 55% (11/20 B) [#######      ] eta 00:05 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868727.5
    progress_bar.numerator = 12
    assert ' 60% (12/20 B) [#######      ] eta 00:04 |' == str(progress_bar)

    eta._NOW = lambda: 1411868728.0
    progress_bar.numerator = 13
    assert ' 65% (13/20 B) [########     ] eta 00:04 /' == str(progress_bar)

    eta._NOW = lambda: 1411868728.5
    progress_bar.numerator = 14
    assert ' 70% (14/20 B) [#########    ] eta 00:03 -' == str(progress_bar)

    eta._NOW = lambda: 1411868729.0
    progress_bar.numerator = 15
    assert ' 75% (15/20 B) [#########    ] eta 00:03 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868729.5
    progress_bar.numerator = 16
    assert ' 80% (16/20 B) [##########   ] eta 00:02 |' == str(progress_bar)

    eta._NOW = lambda: 1411868730.0
    progress_bar.numerator = 17
    assert ' 85% (17/20 B) [###########  ] eta 00:02 /' == str(progress_bar)

    eta._NOW = lambda: 1411868730.5
    progress_bar.numerator = 18
    assert ' 90% (18/20 B) [###########  ] eta 00:01 -' == str(progress_bar)

    eta._NOW = lambda: 1411868731.0
    progress_bar.numerator = 19
    assert ' 95% (19/20 B) [############ ] eta 00:01 \\' == str(progress_bar)

    eta._NOW = lambda: 1411868731.5
    progress_bar.numerator = 20
    assert '100% (20/20 B) [#############] eta 00:00 |' == str(progress_bar)
",False
750,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbytes.py,,test_defined_rounded,"def test_defined_rounded():
    progress_bar = ProgressBarBytes(1023)

    assert '  0% (    0/1,023 B) [               ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 1022
    assert ' 99% (1,022/1,023 B) [############## ] eta --:-- -' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 1023
    assert '100% (1,023/1,023 B) [###############] eta --:-- \\' == str(progress_bar)
    assert '100% (1,023/1,023 B) [###############] eta --:-- |' == str(progress_bar)


",False
751,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbytes.py,,test_defined_wont_fit,"def test_defined_wont_fit():
    progress_bar = ProgressBarBytes(2000, max_width=33)
    assert '  0% (0.00/1.95 KiB) [] eta --:-- |' == str(progress_bar)

    progress_bar = ProgressBarBytes(2000, max_width=30)
    assert '  0% (0.00/1.95 KiB) [] eta --:-- /' == str(progress_bar)


",False
752,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarbytes.py,,test_undefined,"def test_undefined():
    misc.terminal_width = lambda: 50
    progress_bar = ProgressBarBytes(None, max_width=30)

    assert '0 B [?           ] eta --:-- /' == str(progress_bar)
    assert '0 B [ ?          ] eta --:-- -' == str(progress_bar)
    assert '0 B [  ?         ] eta --:-- \\' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 10
    assert '10 B [   ?       ] eta --:-- |' == str(progress_bar)
    assert '10 B [    ?      ] eta --:-- /' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 100
    assert '100 B [     ?    ] eta --:-- -' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 1954727
    assert '1.86 MiB [      ?] eta --:-- \\' == str(progress_bar)
    assert '1.86 MiB [     ? ] eta --:-- |' == str(progress_bar)


",False
753,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarwget.py,,test_defined,"def test_defined():
    eta._NOW = lambda: 1411868721.5
    progress_bar = ProgressBarWget(2000)

    assert ' 0% [                  ] 0           --.-KiB/s              ' == str(progress_bar)
    assert ' 0% [                  ] 0           --.-KiB/s              ' == str(progress_bar)
    assert ' 0% [                  ] 0           --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 102
    assert ' 5% [                  ] 102         --.-KiB/s              ' == str(progress_bar)
    assert ' 5% [                  ] 102         --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 281
    assert '14% [=>                ] 281            358B/s  eta 5s      ' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 593
    assert '29% [====>             ] 593            491B/s  eta 3s      ' == str(progress_bar)

    eta._NOW = lambda: 1411868723.5
    progress_bar.numerator = 1925
    assert '96% [================> ] 1,925       1.13KiB/s  eta 1s      ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 1999
    assert '99% [================> ] 1,999       1.06KiB/s  eta 1s      ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 2000
    assert '100%[=================>] 2,000          666B/s   in 3s      ' == str(progress_bar)


",False
754,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarwget.py,,test_defined_hour,"def test_defined_hour():
    progress_bar = ProgressBarWget(2000)

    assert ' 0% [                  ] 0           --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1
    assert ' 0% [                  ] 1           --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 2
    assert ' 0% [                  ] 2             0.50B/s  eta 1h 6m   ' == str(progress_bar)


",False
755,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarwget.py,,test_defined_rounded,"def test_defined_rounded():
    eta._NOW = lambda: 1411868723.5
    progress_bar = ProgressBarWget(1023)

    assert ' 0% [                  ] 0           --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 1022
    assert '99% [================> ] 1,022       --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 1023
    assert '100%[=================>] 1,023       --.-KiB/s   in 1s      ' == str(progress_bar)


",False
756,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarwget.py,,test_defined_weeks,"def test_defined_weeks():
    progress_bar = ProgressBarWget(2000000000)

    assert ' 0% [                  ] 0           --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1
    assert ' 0% [                  ] 1           --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 2
    assert ' 0% [                  ] 2             0.50B/s  eta 6613w 5d' == str(progress_bar)


",False
757,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbarwget.py,,test_overflow_eta_caching,"def test_overflow_eta_caching():
    eta._NOW = lambda: 1411868721.5
    progress_bar = ProgressBarWget(500000000000, eta_every=4)
    assert ' 0% [                  ] 0           --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1000000
    assert ' 0% [                  ] 1,000,000   --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 3000000
    assert ' 0% [                  ] 3,000,000   --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 6000000
    assert ' 0% [                  ] 6,000,000   --.-KiB/s              ' == str(progress_bar)

    eta._NOW = lambda: 1411868723.5
    progress_bar.numerator = 13000000
    assert ' 0% [                  ] 13,000,000  13.4MiB/s  eta 17h 48m ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 93000000
    assert ' 0% [                  ] 93,000,000   152MiB/s  eta 17h 48m ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 193000000
    assert ' 0% [                  ] 193,000,000  190MiB/s  eta 17h 48m ' == str(progress_bar)

    eta._NOW = lambda: 1411868725.0
    progress_bar.numerator = 300000000
    assert ' 0% [                  ] 300,000,000  204MiB/s  eta 17h 48m ' == str(progress_bar)

    eta._NOW = lambda: 1411868725.5
    progress_bar.numerator = 700000000
    assert ' 0% [                  ] 700,000,000  762MiB/s  eta 49m 50s ' == str(progress_bar)

    eta._NOW = lambda: 1411868726.0
    progress_bar.numerator = 1400000000
    assert ' 0% [                ] 1,400,000,000 1.30GiB/s  eta 49m 50s ' == str(progress_bar)

    eta._NOW = lambda: 1411868726.5
    progress_bar.numerator = 2500000000
    assert ' 0% [                ] 2,500,000,000 2.05GiB/s  eta 49m 50s ' == str(progress_bar)

    eta._NOW = lambda: 1411868727.0
    progress_bar.numerator = 9999999999
    assert ' 1% [                ] 9,999,999,999 14.0GiB/s  eta 49m 50s ' == str(progress_bar)

    eta._NOW = lambda: 1411868727.5
    progress_bar.numerator = 10000000000
    assert ' 2% [               ] 10,000,000,000   2.00B/s  eta 5m 12s  ' == str(progress_bar)

    eta._NOW = lambda: 1411868728.0
    progress_bar.numerator = 10000000001
    assert ' 2% [               ] 10,000,000,001   2.00B/s  eta 5m 12s  ' == str(progress_bar)

    eta._NOW = lambda: 1411868728.5
    progress_bar.numerator = 10000000002
    assert ' 2% [               ] 10,000,000,002   2.00B/s  eta 5m 12s  ' == str(progress_bar)

    eta._NOW = lambda: 1411868729.0
    progress_bar.numerator = 100000000002
    assert '20% [=>            ] 100,000,000,002  167GiB/s  eta 5m 12s  ' == str(progress_bar)

    eta._NOW = lambda: 1411868729.0
    progress_bar.numerator = 400000000002
    assert '80% [==========>   ] 400,000,000,002  726GiB/s  eta 8s      ' == str(progress_bar)

    eta._NOW = lambda: 1411868729.0
    progress_bar.numerator = 500000000000
    assert '100%[=============>] 500,000,000,000 62.1GiB/s   in 8s      ' == str(progress_bar)


",False
758,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbaryum.py,,test_defined,"def test_defined():
    eta._NOW = lambda: 1411868721.5
    progress_bar = ProgressBarYum(2000, 'file.iso')

    assert 'file.iso   0% [          ] --- KiB/s |   0.0 B              ' == str(progress_bar)
    assert 'file.iso   0% [          ] --- KiB/s |   0.0 B              ' == str(progress_bar)
    assert 'file.iso   0% [          ] --- KiB/s |   0.0 B              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 102
    assert 'file.iso   5% [-         ] --- KiB/s |   102 B              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.5
    progress_bar.numerator = 281
    assert 'file.iso  14% [=         ]   358 B/s |   281 B  00:00:05 ETA' == str(progress_bar)

    eta._NOW = lambda: 1411868723.0
    progress_bar.numerator = 593
    assert 'file.iso  29% [==-       ]   491 B/s |   593 B  00:00:03 ETA' == str(progress_bar)

    eta._NOW = lambda: 1411868723.5
    progress_bar.numerator = 1925
    assert 'file.iso  96% [=========-] 1.1 KiB/s | 1.9 KiB  00:00:01 ETA' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 1999
    assert 'file.iso  99% [=========-] 1.1 KiB/s | 2.0 KiB  00:00:01 ETA' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 2000
    assert 'file.iso                             | 2.0 KiB  00:00:03    ' == str(progress_bar)


",False
759,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbaryum.py,,test_defined_hour,"def test_defined_hour():
    progress_bar = ProgressBarYum(2000, 'file.iso')

    assert 'file.iso   0% [          ] --- KiB/s |   0.0 B              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1
    assert 'file.iso   0% [          ] --- KiB/s |   1.0 B              ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 2
    assert 'file.iso   0% [          ]   0.5 B/s |   2.0 B  01:06:36 ETA' == str(progress_bar)


",False
760,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbaryum.py,,test_defined_rounded,"def test_defined_rounded():
    eta._NOW = lambda: 1411868723.5
    progress_bar = ProgressBarYum(1023, 'long_file_name.iso')

    assert 'long_fil   0% [          ] --- KiB/s |   0.0 B              ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 1022
    assert 'long_fil  99% [=========-] --- KiB/s | 1.0 KiB              ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.5
    progress_bar.numerator = 1023
    assert 'long_file_name.iso                   | 1.0 KiB  00:00:01    ' == str(progress_bar)


",False
761,https://github.com/Robpol86/etaprogress/blob/224e8a248c2bf820bad218763281914ad3983fff/tests/test_progress_progressbaryum.py,,test_defined_weeks,"def test_defined_weeks():
    progress_bar = ProgressBarYum(2000000000, 'file.iso')

    assert 'file.iso   0% [          ] --- KiB/s |   0.0 B              ' == str(progress_bar)

    eta._NOW = lambda: 1411868722.0
    progress_bar.numerator = 1
    assert 'file.iso   0% [          ] --- KiB/s |   1.0 B              ' == str(progress_bar)

    eta._NOW = lambda: 1411868724.0
    progress_bar.numerator = 2
    assert 'file.i   0% [       ]   0.5 B/s |   2.0 B  1111111:06:36 ETA' == str(progress_bar)


",False
762,https://github.com/malongge/exceltojson/blob/6724c7de5153a7b125011e879419273589206d0d/tests/test_excel_2_json.py,TestProcessExcel,test_excel_process_not_patch_sheet_names,"def test_excel_process_not_patch_sheet_names(self):
        excel = self.process_excel(show_row=False, name_sheets={u'名字': {
                u'头部': 'header3'
            }}, patch_sheet_alias=False)
        excel(10)
        assert os.path.exists(get_data_path(u'名字.json'))
        assert os.path.exists(get_data_path('Sheet2.json')) is False

    ",True
763,https://github.com/malongge/exceltojson/blob/6724c7de5153a7b125011e879419273589206d0d/tests/test_excel_2_json.py,TestProcessExcel,test_excel_process_with_sheet_names,"def test_excel_process_with_sheet_names(self):
        excel = self.process_excel(show_row=False, name_sheets={u'名字': {
                u'头部': 'header3'
            }}, patch_sheet_alias=True)
        excel(10)
        # json file name should be sheet name
        assert os.path.exists(get_data_path(u'名字.json'))
        assert os.path.exists(get_data_path('Sheet2.json'))
        assert os.path.exists(get_data_path('Sheet3.json'))

    ",True
764,https://github.com/hbradleyiii/ext_pylib/blob/15a9b5a80db87b5f20e03ef6bfa015acf4bf8543/tests/files/test_node.py,,test_node_repr,"def test_node_repr(atts, expected):
    """"""Test Node repr.""""""
    node = Node(atts)
    assert node.__repr__() == ""Node("" + expected + "")""

@pytest.mark.parametrize((""atts"", ""expected""), REPR_ARGS)
",True
765,https://github.com/hbradleyiii/ext_pylib/blob/15a9b5a80db87b5f20e03ef6bfa015acf4bf8543/tests/files/test_node.py,,test_node_repr,"def test_node_repr(atts, expected):
    """"""Test Node repr.""""""
    node = Node(atts)
    assert node.__repr__() == ""Node("" + expected + "")""

@pytest.mark.parametrize((""atts"", ""expected""), REPR_ARGS)
",True
766,https://github.com/hbradleyiii/ext_pylib/blob/15a9b5a80db87b5f20e03ef6bfa015acf4bf8543/tests/files/test_node.py,,test_node_repr,"def test_node_repr(atts, expected):
    """"""Test Node repr.""""""
    node = Node(atts)
    assert node.__repr__() == ""Node("" + expected + "")""

@pytest.mark.parametrize((""atts"", ""expected""), REPR_ARGS)
",True
767,https://github.com/n8henrie/eyeflask/blob/0fc6b042aac6e30885ecb2d6817fb67fad6e07d4/tests/test_eyeflask.py,,test_photostatus,"def test_photostatus(client):
    """"""Test the GetPhotoStatus SOAPAction.

    Generates `credential` from the test_config upload_key and macaddress and
    snonce obtained in in `test_startsession` above.
    """"""

    headers = {'SOAPAction': '""urn:GetPhotoStatus""'}

    credential = create_credential(""0a1b2c3d4e5f"", snonce, ""abcd"",
                                   from_eyefi=True)
    response = client.post(""/api/soap/eyefilm/v1"", headers=headers,
                           data=get_photo_status.format(credential=credential))
    assert response.status_code == 200


",False
768,https://github.com/MiCHiLU/fanstatic-tools/blob/c075a2195c8138d103b72ef8445ef08f2a865984/fanstatic/test_core.py,,test_convenience_clear_not_initialized,"def test_convenience_clear_not_initialized():
    # This test is put near the top of this module, or at least before
    # the very first time ``init_needed()`` is called.
    dummy = get_needed()
    with pytest.raises(NotImplementedError):
        dummy.clear()
    with pytest.raises(NotImplementedError):
        clear_needed()

    # Initialize a needed resources object.
    needed = init_needed()
    assert get_needed() == needed
    assert thread_local_needed_data.__dict__[NEEDED] == needed

    # Clear it.
    del_needed()

    # It is gone, really.
    with pytest.raises(KeyError):
        thread_local_needed_data.__dict__[NEEDED]

    # Clearing it again is OK.
    del_needed()

    # get_needed still work, dummy-style.
    dummy2 = get_needed()
    assert dummy2 != needed
    with pytest.raises(NotImplementedError):
        dummy.clear()
    with pytest.raises(NotImplementedError):
        clear_needed()

",True
769,https://github.com/MiCHiLU/fanstatic-tools/blob/c075a2195c8138d103b72ef8445ef08f2a865984/fanstatic/test_core.py,,test_convenience_need_not_initialized,"def test_convenience_need_not_initialized():
    foo = Library('foo', '')
    x1 = Resource(foo, 'a.js')
    x2 = Resource(foo, 'b.css')
    y1 = Resource(foo, 'c.js', depends=[x1, x2])

    dummy = get_needed()
    assert not isinstance(dummy, NeededResources)

    # We return a new dummy instance for every get_needed:
    dummy2 = get_needed()
    assert dummy != dummy2

    # A dummy never has resources:
    assert not dummy.has_resources()

    dummy.need(y1)
    with pytest.raises(NotImplementedError):
        dummy.render()


",True
770,https://github.com/MiCHiLU/fanstatic-tools/blob/c075a2195c8138d103b72ef8445ef08f2a865984/fanstatic/test_core.py,,test_inclusion_renderers,"def test_inclusion_renderers():
    assert sorted(
        [(order, key) for key, (order, _) in inclusion_renderers.items()]) == [
        (10, '.css'), (20, '.js'), (30, '.ico')]
    _, renderer = inclusion_renderers['.js']
    assert renderer('http://localhost/script.js') == (
         '<script type=""text/javascript"" src=""http://localhost/script.js""></script>')


",True
771,https://github.com/mfreeborn/fastapi-sqlalchemy/blob/8ddf0edab22873365441757107ce21234bc09f8f/tests/test_session.py,,test_inside_route_without_middleware_fails,"def test_inside_route_without_middleware_fails(app, client, db):
    @app.get(""/"")
    ",True
772,https://github.com/mfreeborn/fastapi-sqlalchemy/blob/8ddf0edab22873365441757107ce21234bc09f8f/tests/test_session.py,,test_outside_of_route_without_middleware_fails,"def test_outside_of_route_without_middleware_fails(db):
    with pytest.raises(SessionNotInitialisedError):
        db.session

    with pytest.raises(SessionNotInitialisedError):
        with db():
            pass


",True
773,https://github.com/solegalli/feature_engine/blob/ba4d7050b3923d620c1773b66cd4c51ed24498dd/tests/test_missing_data_imputer.py,,test_ArbitraryNumberImputer,"def test_ArbitraryNumberImputer(dataframe_na):

    # test case 1: automatically select variables
    imputer = ArbitraryNumberImputer(arbitrary_number=99, variables=None)
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['Age'] = ref_df['Age'].fillna(99)
    ref_df['Marks'] = ref_df['Marks'].fillna(99)

    # init params
    assert imputer.arbitrary_number == 99
    assert imputer.variables == ['Age', 'Marks']
    # fit params
    assert imputer.input_shape_ == (8, 6)
    assert imputer.imputer_dict_ == {'Age': 99, 'Marks': 99}
    # transform params
    assert X_transformed[['Age', 'Marks']].isnull().sum().sum() == 0
    assert X_transformed[['Name', 'City']].isnull().sum().sum() > 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    # test case 2: user indicates variables
    imputer = ArbitraryNumberImputer(arbitrary_number=-1, variables=['Age'])
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['Age'] = ref_df['Age'].fillna(-1)

    # init params
    assert imputer.arbitrary_number == -1
    assert imputer.variables == ['Age']
    # fit params
    assert imputer.input_shape_ == (8, 6)
    assert imputer.imputer_dict_ == {'Age': -1}
    # transform output
    assert X_transformed['Age'].isnull().sum() == 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    with pytest.raises(ValueError):
        ArbitraryNumberImputer(arbitrary_number='arbitrary')

    with pytest.raises(NotFittedError):
        imputer = ArbitraryNumberImputer()
        imputer.transform(dataframe_na)

    # test case 3: arbitrary numbers passed as dict
    imputer = ArbitraryNumberImputer(imputer_dict={'Age': -42, 'Marks': -999})
    X_transformed = imputer.fit_transform(dataframe_na)
    ref_df = dataframe_na.copy()
    ref_df['Age'] = ref_df['Age'].fillna(-42)
    ref_df['Marks'] = ref_df['Marks'].fillna(-999)

    # fit params
    assert imputer.input_shape_ == (8, 6)
    assert imputer.imputer_dict_ == {'Age': -42, 'Marks': -999}
    # transform params
    assert X_transformed[['Age', 'Marks']].isnull().sum().sum() == 0
    assert X_transformed[['Name', 'City']].isnull().sum().sum() > 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    with pytest.raises(ValueError):
        ArbitraryNumberImputer(imputer_dict={'Age': 'arbitrary_number'})

",True
774,https://github.com/solegalli/feature_engine/blob/ba4d7050b3923d620c1773b66cd4c51ed24498dd/tests/test_missing_data_imputer.py,,test_CategoricalVariableImputer,"def test_CategoricalVariableImputer(dataframe_na):

    # test case 1: imputation with missing + automatically select variables
    imputer = CategoricalVariableImputer(imputation_method='missing', variables=None)
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['Name'] = ref_df['Name'].fillna('Missing')
    ref_df['City'] = ref_df['City'].fillna('Missing')
    ref_df['Studies'] = ref_df['Studies'].fillna('Missing')

    # init params
    assert imputer.imputation_method == 'missing'
    assert imputer.variables == ['Name', 'City', 'Studies']
    # fit params
    assert imputer.input_shape_ == (8, 6)
    assert imputer.imputer_dict_ == {'Name': 'Missing', 'City': 'Missing', 'Studies': 'Missing'}
    # transform output
    assert X_transformed[['Name', 'City', 'Studies']].isnull().sum().sum() == 0
    assert X_transformed[['Age', 'Marks']].isnull().sum().sum() > 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)
    
    # test case 2: imputing custom user-defined string + automatically select variables
    imputer = CategoricalVariableImputer(imputation_method='missing', fill_value='Unknown', variables=None)
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['Name'] = ref_df['Name'].fillna('Unknown')
    ref_df['City'] = ref_df['City'].fillna('Unknown')
    ref_df['Studies'] = ref_df['Studies'].fillna('Unknown')

    # init params
    assert imputer.imputation_method == 'missing'
    assert imputer.fill_value == 'Unknown'
    assert imputer.variables == ['Name', 'City', 'Studies']
    # fit params
    assert imputer.input_shape_ == (8, 6)
    assert imputer.imputer_dict_ == {'Name': 'Unknown', 'City': 'Unknown', 'Studies': 'Unknown'}
    # transform output
    assert X_transformed[['Name', 'City', 'Studies']].isnull().sum().sum() == 0
    assert X_transformed[['Age', 'Marks']].isnull().sum().sum() > 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    # test case 3: mode imputation + user indicates 1 variable ONLY
    imputer = CategoricalVariableImputer(imputation_method='frequent', variables='City')
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['City'] = ref_df['City'].fillna('London')

    assert imputer.imputation_method == 'frequent'
    assert imputer.variables == ['City']
    assert imputer.input_shape_ == (8, 6)
    assert imputer.imputer_dict_ == {'City': 'London'}
    assert X_transformed['City'].isnull().sum() == 0
    assert X_transformed[['Age', 'Marks']].isnull().sum().sum() > 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    # test case 4: mode imputation + user indicates multiple variables
    imputer = CategoricalVariableImputer(imputation_method='frequent', variables=['Studies', 'City'])
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['City'] = ref_df['City'].fillna('London')
    ref_df['Studies'] = ref_df['Studies'].fillna('Bachelor')

    assert imputer.imputer_dict_ == {'Studies': 'Bachelor', 'City': 'London'}
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    # test case 5: imputing of numerical variables cast as object + return numeric
    dataframe_na['Marks'] = dataframe_na['Marks'].astype('O')
    imputer = CategoricalVariableImputer(imputation_method='frequent', variables=['City', 'Studies', 'Marks'])
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['Marks'] = ref_df['Marks'].fillna(0.8)
    ref_df['City'] = ref_df['City'].fillna('London')
    ref_df['Studies'] = ref_df['Studies'].fillna('Bachelor')
    assert imputer.variables == ['City', 'Studies', 'Marks']
    assert imputer.imputer_dict_ == {'Studies': 'Bachelor', 'City': 'London', 'Marks': 0.8}
    assert X_transformed['Marks'].dtype == 'float'
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    # test case 6: imputing of numerical variables cast as object + return as object after imputation
    dataframe_na['Marks'] = dataframe_na['Marks'].astype('O')
    imputer = CategoricalVariableImputer(imputation_method='frequent', variables=['City', 'Studies', 'Marks'],
                                         return_object=True)
    X_transformed = imputer.fit_transform(dataframe_na)
    assert X_transformed['Marks'].dtype == 'O'

    with pytest.raises(ValueError):
        imputer = CategoricalVariableImputer(imputation_method='arbitrary')

    with pytest.raises(ValueError):
        imputer = CategoricalVariableImputer(imputation_method='frequent')
        imputer.fit(dataframe_na)

    with pytest.raises(NotFittedError):
        imputer = CategoricalVariableImputer()
        imputer.transform(dataframe_na)


",True
775,https://github.com/solegalli/feature_engine/blob/ba4d7050b3923d620c1773b66cd4c51ed24498dd/tests/test_missing_data_imputer.py,,test_EndTailImputer,"def test_EndTailImputer(dataframe_na):

    # test case 1: automatically find variables + gaussian limits + right tail
    imputer = EndTailImputer(distribution='gaussian', tail='right', fold=3, variables=None)
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['Age'] = ref_df['Age'].fillna(58.94908118478389)
    ref_df['Marks'] = ref_df['Marks'].fillna(1.3244261503263175)

    # init params
    assert imputer.distribution == 'gaussian'
    assert imputer.tail == 'right'
    assert imputer.fold == 3
    assert imputer.variables == ['Age', 'Marks']
    # fit params
    assert imputer.input_shape_ == (8, 6)
    assert imputer.imputer_dict_ == {'Age': 58.94908118478389, 'Marks': 1.3244261503263175}
    # transform params: indicated vars ==> no NA, not indicated vars with NA
    assert X_transformed[['Age', 'Marks']].isnull().sum().sum() == 0
    assert X_transformed[['City', 'Name']].isnull().sum().sum() > 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    # test case 2: selected variables + IQR rule + right tail
    imputer = EndTailImputer(distribution='skewed', tail='right', fold=1.5, variables=['Age', 'Marks'])
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['Age'] = ref_df['Age'].fillna(65.5)
    ref_df['Marks'] = ref_df['Marks'].fillna(1.0625)
    # fit  and transform params
    assert imputer.imputer_dict_ == {'Age': 65.5, 'Marks': 1.0625}
    assert X_transformed[['Age', 'Marks']].isnull().sum().sum() == 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    # test case 3: selected variables + maximum value
    imputer = EndTailImputer(distribution='max', tail='right', fold=2, variables=['Age', 'Marks'])
    imputer.fit(dataframe_na)
    assert imputer.imputer_dict_ == {'Age': 82.0, 'Marks': 1.8}

    # test case 4: automatically select variables + gaussian limits + left tail
    imputer = EndTailImputer(distribution='gaussian', tail='left', fold=3)
    imputer.fit(dataframe_na)
    assert imputer.imputer_dict_ == {'Age': -1.520509756212462, 'Marks': 0.04224051634034898}

    # test case 5: IQR + left tail
    imputer = EndTailImputer(distribution='skewed', tail='left', fold=1.5, variables=['Age', 'Marks'])
    imputer.fit(dataframe_na)
    assert imputer.imputer_dict_ == {'Age': -6.5, 'Marks': 0.36249999999999993}

    with pytest.raises(ValueError):
        EndTailImputer(distribution='arbitrary')

    with pytest.raises(ValueError):
        EndTailImputer(tail='arbitrary')

    with pytest.raises(ValueError):
        EndTailImputer(fold=-1)

    with pytest.raises(NotFittedError):
        imputer = EndTailImputer()
        imputer.transform(dataframe_na)


",True
776,https://github.com/solegalli/feature_engine/blob/ba4d7050b3923d620c1773b66cd4c51ed24498dd/tests/test_missing_data_imputer.py,,test_MeanMedianImputer,"def test_MeanMedianImputer(dataframe_na):

    # test case 1: automatically finds numerical variables
    imputer = MeanMedianImputer(imputation_method='mean', variables=None)
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['Age'] = ref_df['Age'].fillna(28.714285714285715)
    ref_df['Marks'] = ref_df['Marks'].fillna(0.6833333333333332)

    # check init params
    assert imputer.imputation_method == 'mean'
    assert imputer.variables == ['Age', 'Marks']

    # check fit attributes
    assert imputer.imputer_dict_ == {'Age': 28.714285714285715, 'Marks': 0.6833333333333332}
    assert imputer.input_shape_ == (8, 6)

    # check transform output: indicated variables no NA
    # Not indicated variables still have NA
    assert X_transformed[['Age', 'Marks']].isnull().sum().sum() == 0
    assert X_transformed[['Name', 'City']].isnull().sum().sum() > 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    # test case 2: single user determined variable
    imputer = MeanMedianImputer(imputation_method='median', variables=['Age'])
    X_transformed = imputer.fit_transform(dataframe_na)

    ref_df = dataframe_na.copy()
    ref_df['Age'] = ref_df['Age'].fillna(23.0)

    # init params
    assert imputer.imputation_method == 'median'
    assert imputer.variables == ['Age']

    # fit params
    assert imputer.input_shape_ == (8, 6)
    assert imputer.imputer_dict_ == {'Age': 23.0}

    # transform params
    assert X_transformed['Age'].isnull().sum() == 0
    pd.testing.assert_frame_equal(X_transformed, ref_df)

    with pytest.raises(ValueError):
        MeanMedianImputer(imputation_method='arbitrary')

    with pytest.raises(NotFittedError):
        imputer = MeanMedianImputer()
        imputer.transform(dataframe_na)


",True
777,https://github.com/tmaslen/featureflagclient-python/blob/05cd5705d3d51488da9ce5a4d1ade65d8fd49e82/tests/integration_tests.py,,test_actual_http_request,"def test_actual_http_request():

    f2c = Featureflagclient(""https://featureflag.tech/node/exampleflag.json"")

    assert f2c.get(""text"") == ""laserwolf""


",False
778,https://github.com/tmaslen/featureflagclient-python/blob/05cd5705d3d51488da9ce5a4d1ade65d8fd49e82/tests/integration_tests.py,,test_actual_http_request_with_override,"def test_actual_http_request_with_override():

    f2c = Featureflagclient(
        ""https://featureflag.tech/node/exampleflag.json"",
        {
            ""text"": ""overridden""
        }
    )

    assert f2c.get(""trueBoolean"") is True
    assert f2c.get(""text"") == ""overridden""
",False
779,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardClassDecorator,test_decorated_class_restores_file_contents,"def test_decorated_class_restores_file_contents(self):
        the_codeumentary = TestFileGuardClassDecorator.TheCodeumentary('value_1', 'value_2', self)
        self._assert_file_content_equals(TestFileGuardClassDecorator.TEST_FILE_CONTENTS)

        the_codeumentary.change_the_file()
        self._assert_file_content_equals(TestFileGuardClassDecorator.TEST_FILE_CONTENTS)

        the_codeumentary.change_the_file_again()
        self._assert_file_content_equals(TestFileGuardClassDecorator.TEST_FILE_CONTENTS)

        the_codeumentary.do_not_change_the_file('hello')
        self._assert_file_content_equals(TestFileGuardClassDecorator.TEST_FILE_CONTENTS)

        the_codeumentary.value_1
        self._assert_file_content_equals(TestFileGuardClassDecorator.TEST_FILE_CONTENTS)

        the_codeumentary._value_2 = 'value_3'
        self._assert_file_content_equals(TestFileGuardClassDecorator.TEST_FILE_CONTENTS)

    ",False
780,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardClassDecorator,test_fileguarded_callables_calling_fileguarded_callables,"def test_fileguarded_callables_calling_fileguarded_callables(self):
        """"""
        Make sure that the when a decorated callable calls a decorated callable
        within a class everything works as expectected. Internally, a stack is
        used.
        """"""
        the_codeumentary = TestFileGuardClassDecorator.TheCodeumentary('value_1', 'value_2', self)
        the_codeumentary.nested_write_call()
        self._assert_file_content_equals(TestFileGuardClassDecorator.TEST_FILE_CONTENTS)

class TestFileGuardDecoratorWithBinaryFiles(unittest.TestCase):
    """"""
    Make sure that non-text files are guarded as well.
    """"""

    RESOURCES_PATH = './tests/resources/'
    FROZEN_RESOURCES_PATH = './tests/frozen_resources/'
    EXECUTABLE_BINARY_NAME = 'encrypt_harddrive_with_ransomware'
    IMAGE_NAME = 'kitty_cent.jpg'


    ",False
781,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardContextManager,test_guard_change_text_file,"def test_guard_change_text_file(self):

        with guard(TestFileGuardContextManager.TEST_TEXT_FILE_PATH):
            lines_to_write = ['of course\n', 'I would\n']
            self._assert_file_content_equals(TestFileGuardContextManager.TEST_FILE_CONTENTS)

            with open(TestFileGuardContextManager.TEST_TEXT_FILE_PATH, 'w') as file:
                file.writelines(lines_to_write)

            self._assert_file_content_equals(lines_to_write)

        self._assert_file_content_equals(TestFileGuardContextManager.TEST_FILE_CONTENTS)


class TestFileGuardClassDecorator(unittest.TestCase):

    TEST_TEXT_FILE_PATH = './tests/resources/test_text_file.txt'
    TEST_FILE_CONTENTS = ['would\n', 'you do it\n', 'if my name was\n', 'dre\n']

    @guard('./tests/resources/test_text_file.txt')
    class TheCodeumentary(object):

        TEXT_1 = ['The\n', 'Documentary\n']
        TEXT_2 = ['The\n', 'Doctor\'s\n', 'Advocate']
        TEXT_3 = ['appended\n', 'content\n']

        ",False
782,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecorator,test_guard_change_text_file,"def test_guard_change_text_file(self):
        @guard(TestFileGuardDecorator.TEST_TEXT_FILE_PATH)
        ",False
783,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecorator,test_guard_deleted_file_restores_contents_test_file,"def test_guard_deleted_file_restores_contents_test_file(self):
        @guard(TestFileGuardDecorator.TEST_TEXT_FILE_PATH)
        ",False
784,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecorator,test_guard_if_function_not_changes_text_file,"def test_guard_if_function_not_changes_text_file(self):

        @guard(TestFileGuardDecorator.TEST_TEXT_FILE_PATH)
        ",False
785,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecorator,test_guard_if_function_throws_exception_text_file,"def test_guard_if_function_throws_exception_text_file(self):
        @guard(TestFileGuardDecorator.TEST_TEXT_FILE_PATH)
        ",False
786,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecorator,test_that_decorator_calls_funcion,"def test_that_decorator_calls_funcion(self):
        value_1 = 'uno'
        value_2 = 'dos'

        mocked_func = Mock()

        pre_decorated = guard(TestFileGuardDecorator.TEST_TEXT_FILE_PATH)
        decorated = pre_decorated(mocked_func)
        result = decorated(value_1, value_2)

        mocked_func.assert_called_once_with(value_1, value_2)


class TestFileGuardContextManager(unittest.TestCase):

    TEST_TEXT_FILE_PATH = './tests/resources/test_text_file.txt'
    TEST_FILE_CONTENTS = ['would\n', 'you do it\n', 'if my name was\n', 'dre\n']

    ",False
787,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecoratorMultipleFiles,test_guard_change_two_text_files,"def test_guard_change_two_text_files(self):
        @guard(TestFileGuardDecoratorMultipleFiles.TEST_TEXT_FILE_2_PATH)
        @guard(TestFileGuardDecoratorMultipleFiles.TEST_TEXT_FILE_1_PATH)
        ",False
788,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecoratorMultipleFiles,test_guard_change_two_text_files_multiple_arguments,"def test_guard_change_two_text_files_multiple_arguments(self):
        @guard(TestFileGuardDecoratorMultipleFiles.TEST_TEXT_FILE_1_PATH, TestFileGuardDecoratorMultipleFiles.TEST_TEXT_FILE_2_PATH)
        ",False
789,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecoratorWithBinaryFiles,test_binary_file_content_restored_on_change,"def test_binary_file_content_restored_on_change(self):

        binary_frozen = os.path.join(self.FROZEN_RESOURCES_PATH, self.EXECUTABLE_BINARY_NAME)
        binary_path = os.path.join(self.RESOURCES_PATH, self.EXECUTABLE_BINARY_NAME)

        self._assert_files_equal(binary_path, binary_frozen)

        @guard(binary_path)
        ",False
790,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecoratorWithBinaryFiles,test_binary_file_content_restored_on_delete,"def test_binary_file_content_restored_on_delete(self):

        binary_frozen = os.path.join(self.FROZEN_RESOURCES_PATH, self.EXECUTABLE_BINARY_NAME)
        binary_path = os.path.join(self.RESOURCES_PATH, self.EXECUTABLE_BINARY_NAME)

        self._assert_files_equal(binary_path, binary_frozen)

        @guard(binary_path)
        ",False
791,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecoratorWithBinaryFiles,test_image_file_content_restored_on_change,"def test_image_file_content_restored_on_change(self):

        image_frozen = os.path.join(self.FROZEN_RESOURCES_PATH, self.IMAGE_NAME)
        image_path = os.path.join(self.RESOURCES_PATH, self.IMAGE_NAME)

        self._assert_files_equal(image_path, image_frozen)

        @guard(image_path)
        ",False
792,https://github.com/iluxonchik/fileguard/blob/73854b783faadb8e5370c407b897049131a42e50/tests/test_fileguard.py,TestFileGuardDecoratorWithBinaryFiles,test_image_file_content_restored_on_delete,"def test_image_file_content_restored_on_delete(self):

        image_frozen = os.path.join(self.FROZEN_RESOURCES_PATH, self.IMAGE_NAME)
        image_path = os.path.join(self.RESOURCES_PATH, self.IMAGE_NAME)

        self._assert_files_equal(image_path, image_frozen)

        @guard(image_path)
        ",False
793,https://github.com/filestack/filestack-python/blob/1bd6749735e5c78dde767e0685ddfdf0cd7423e2/tests/intelligent_ingestion_test.py,,test_upload_part_success,"def test_upload_part_success(post_mock, put_mock):
    post_mock.side_effect = [
        DummyHttpResponse(json_dict={'url': 'http://upload.url', 'headers': {'upload': 'headers'}}),
        DummyHttpResponse()
    ]

    put_mock.return_value = DummyHttpResponse()

    part = {'seek_point': 0, 'num': 1}
    upload_part(
        'Aaaaapikey', 'file.txt', 'tests/data/doom.mp4', 1234, 's3', defaultdict(lambda: 'fs-upload.com'), part
    )
    assert post_mock.call_args_list == [
        call(
            'https://fs-upload.com/multipart/upload',
            json={
                'apikey': 'Aaaaapikey', 'uri': 'fs-upload.com', 'region': 'fs-upload.com',
                'upload_id': 'fs-upload.com', 'store': {'location': 's3'},
                'part': 1, 'size': 5415034, 'md5': 'IuNjhgPo2wbzGFo6f7WhUA==', 'offset': 0, 'fii': True
            },
        ),
        call(
            'https://fs-upload.com/multipart/commit',
            json={
                'apikey': 'Aaaaapikey', 'uri': 'fs-upload.com', 'region': 'fs-upload.com',
                'upload_id': 'fs-upload.com', 'store': {'location': 's3'}, 'part': 1, 'size': 1234
            },
        )
    ]
    put_mock.assert_called_once_with(
        'http://upload.url',
        data=ANY,
        headers={'upload': 'headers'}
    )


@patch('filestack.uploads.intelligent_ingestion.requests.put')
@patch('filestack.uploads.intelligent_ingestion.requests.post')
",True
794,https://github.com/filestack/filestack-python/blob/1bd6749735e5c78dde767e0685ddfdf0cd7423e2/tests/intelligent_ingestion_test.py,,test_upload_part_with_resize,"def test_upload_part_with_resize(post_mock, put_mock):
    # this mock will work fine for commit request too
    post_mock.return_value = DummyHttpResponse(
        ok=True, json_dict={'url': 'http://upload.url', 'headers': {'upload': 'headers'}}
    )

    put_mock.side_effect = [
        DummyHttpResponse(ok=False),  # fail first attempt, should split file part
        DummyHttpResponse(),  # part 1, chunk 1
        DummyHttpResponse(),  # part 1, chunk 2
    ]

    part = {'seek_point': 0, 'num': 1}
    upload_part(
        'Aaaaapikey', 'file.txt', 'tests/data/doom.mp4', 5415034, 's3', defaultdict(lambda: 'fs-upload.com'), part
    )

    assert post_mock.call_count == 4  # 3x upload, 1 commit
    # 1st attempt
    req_args, req_kwargs = post_mock.call_args_list[0]
    assert req_kwargs['json']['size'] == 5415034
    # 2nd attempt
    req_args, req_kwargs = post_mock.call_args_list[1]
    assert req_kwargs['json']['size'] == 4194304
    # 3rd attempt
    req_args, req_kwargs = post_mock.call_args_list[2]
    assert req_kwargs['json']['size'] == 1220730


@patch('filestack.uploads.intelligent_ingestion.requests.put')
@patch('filestack.uploads.intelligent_ingestion.requests.post')
",True
795,https://github.com/tomerten/findatabroker/blob/204c433d51e2d2de5c132a4607cd504809fd4a71/FinDataBroker/tests/test_mongo.py,,test__load___ok,"def test__load___ok():
    db = 'testdb'
    col = 'testcol'
    objs = [
        {
            'name': 'boe',
            'year': 2019
        }
    ]
    index = [('name', ASCENDING), ('year', ASCENDING)]

    broker.save(objs, db, col, index, unique=True)
    assert broker.get_number_of_documents(db, col) == 1

    data = broker.load(db, col, {'year': 2019})
    assert objs == data
",True
796,https://github.com/workenvoy/firestore/blob/4933f1a9f307539a8cef4ea80869c8821a92bc8d/tests/containers/collection_test.py,DocumentTest,test_collection_name,"def test_collection_name(self):
        self.assertEqual(self.cd.collection, YDS)
    
    ",True
797,https://github.com/workenvoy/firestore/blob/4933f1a9f307539a8cef4ea80869c8821a92bc8d/tests/containers/collection_test.py,DocumentTest,test_dbpath,"def test_dbpath(self):
        _ = ""gherkin""
        self.cd.name = _
        self.assertEqual(self.cd.dbpath, ""{}/{}"".format(YDS, _))
    
    ",True
798,https://github.com/chinapnr/fish_base/blob/1615ccff9106bf42fc6ae862cd13353c12c1b76d/test/test_logger.py,TestFishLogging,test_format3,"def test_format3(self):
        set_log_file(self.log_filename, file_name_format='%date-%project_name-%log')
        log.info('test_format3')
        assert 'unittest.log.{}'.format(self.suffix_time) in os.listdir(self.log_path)

    ",True
799,https://github.com/chinapnr/fishbase/blob/1615ccff9106bf42fc6ae862cd13353c12c1b76d/test/test_logger.py,TestFishLogging,test_format3,"def test_format3(self):
        set_log_file(self.log_filename, file_name_format='%date-%project_name-%log')
        log.info('test_format3')
        assert 'unittest.log.{}'.format(self.suffix_time) in os.listdir(self.log_path)

    ",True
800,https://github.com/rochefort-lab/fissa/blob/2077a8c8a029948dcf1d4c352f785700f42aff9f/fissa/tests/test_core.py,TestExperimentA,test_imagelistloaded_roizip,"def test_imagelistloaded_roizip(self):
        image_paths = [
            os.path.join(self.resources_dir, self.images_dir, img)
            for img in self.image_names
        ]
        images = [datahandler.image2array(pth) for pth in image_paths]
        roi_path = os.path.join(self.resources_dir, self.roi_zip_path)
        exp = core.Experiment(images, roi_path, self.output_dir)
        exp.separate()
        actual = exp.result
        self.assert_equal(len(actual), 1)
        self.assert_equal(len(actual[0]), 1)
        self.assert_allclose(actual[0][0], self.expected_00)

    @unittest.expectedFailure
    ",True
801,https://github.com/vitalk/flask-apify/blob/f486d2616575be0e460ccf354d22badb7d68b387/tests/test_apify.py,,test_apify_init,"def test_apify_init(app, apify):
    assert 'apify' in app.extensions
    assert apify.blueprint is not None
    assert apify.logger is logging.getLogger('flask-apify')
    assert apify.preprocessor_funcs == [set_best_serializer,]
    assert apify.postprocessor_funcs == []
    assert apify.finalizer_funcs == []
    assert apify.serializers['text/html'] is to_html
    assert apify.serializers['application/json'] is to_json
    assert apify.serializers['application/javascript'] is to_javascript
    assert apify.serializers['application/json-p'] is to_javascript
    assert apify.serializers['text/json-p'] is to_javascript


",True
802,https://github.com/vitalk/flask-apify/blob/f486d2616575be0e460ccf354d22badb7d68b387/tests/test_serializers.py,TestJSONPSerializer,test_support_custom_callback_name,"def test_support_custom_callback_name(self, app):
        serializer = JSONPSerializer(callback_name='jsonp')
        with app.test_request_context('?jsonp=console.log'):
            assert serializer('42') == 'console.log(42);'
",True
803,https://github.com/vitalk/flask-apify/blob/f486d2616575be0e460ccf354d22badb7d68b387/tests/test_serializers.py,TestJSONPSerializer,test_use_callback_function_from_request_arguments_to_wrap_output,"def test_use_callback_function_from_request_arguments_to_wrap_output(self, app):
        with app.test_request_context('?callback=console.log'):
            assert self.serializer('42') == 'console.log(42);'

    ",True
804,https://github.com/Martlark/flask-ipban/blob/882a25495be55609e5d9a058b8139b78836d64d4/flask_ipban/test_persistence.py,IpBanPersistence2,runTest,"def runTest(self):
        self.assertTrue('123.456.765.111' in self.ip_ban._ip_ban_list)


",False
805,https://github.com/BbsonLin/flask-request-logger/blob/26b87d56cf1dffb3f8d6a2ca8c2b1873b9d6a65e/tests/test_api.py,,test_req_log,"def test_req_log(client):
    resp = client.get('/req-log/')

    assert resp.status_code == 200
    assert type(resp.get_json().get('data')) is list


@pytest.mark.last
",False
806,https://github.com/BbsonLin/flask-request-logger/blob/26b87d56cf1dffb3f8d6a2ca8c2b1873b9d6a65e/tests/test_api.py,,test_resp_log,"def test_resp_log(client):
    resp = client.get('/resp-log/')

    assert resp.status_code == 200
    assert type(resp.get_json().get('data')) is list


@pytest.mark.last
",False
807,https://github.com/BbsonLin/flask-request-logger/blob/26b87d56cf1dffb3f8d6a2ca8c2b1873b9d6a65e/tests/test_database.py,,test_db_exist,"def test_db_exist(app):
    request_logger = get_request_logger(app)
    if request_logger.db_info.drivername == 'sqlite':
        assert os.path.exists(request_logger.db_info.database)
",False
808,https://github.com/BbsonLin/flask-request-logger/blob/26b87d56cf1dffb3f8d6a2ca8c2b1873b9d6a65e/tests/test_logging.py,,test_logging,"def test_logging(app, client):
    @app.route('/test', methods=['GET'])
    ",False
809,https://github.com/miLibris/flask-rest-jsonapi/blob/b44bc08b11213d49fadae873650d3555889052ec/tests/test_sqlalchemy_data_layer.py,,test_sqlalchemy_data_layer_get_relationship_field_not_found,"def test_sqlalchemy_data_layer_get_relationship_field_not_found(session, person_model):
    with pytest.raises(RelationNotFound):
        dl = SqlalchemyDataLayer(dict(session=session, model=person_model))
        dl.get_relationship('error', '', '', dict(id=1))


",False
810,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_max_page_size,"def test_pagination_max_page_size(self, app_fixture):
        client = app_fixture.client
        # default: page_size > 100 => 422
        # custom: page_size > 10 => 422
        response = client.get('/test/', query_string={'page_size': 101})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': 11})
        if app_fixture.custom_params is False:
            assert response.status_code == 200
        else:
            assert response.status_code == 422

    ",True
811,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_max_page_size,"def test_pagination_max_page_size(self, app_fixture):
        client = app_fixture.client
        # default: page_size > 100 => 422
        # custom: page_size > 10 => 422
        response = client.get('/test/', query_string={'page_size': 101})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': 11})
        if app_fixture.custom_params is False:
            assert response.status_code == 200
        else:
            assert response.status_code == 422

    ",True
812,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_max_page_size,"def test_pagination_max_page_size(self, app_fixture):
        client = app_fixture.client
        # default: page_size > 100 => 422
        # custom: page_size > 10 => 422
        response = client.get('/test/', query_string={'page_size': 101})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': 11})
        if app_fixture.custom_params is False:
            assert response.status_code == 200
        else:
            assert response.status_code == 422

    ",True
813,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_max_page_size,"def test_pagination_max_page_size(self, app_fixture):
        client = app_fixture.client
        # default: page_size > 100 => 422
        # custom: page_size > 10 => 422
        response = client.get('/test/', query_string={'page_size': 101})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': 11})
        if app_fixture.custom_params is False:
            assert response.status_code == 200
        else:
            assert response.status_code == 422

    ",True
814,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_max_page_size,"def test_pagination_max_page_size(self, app_fixture):
        client = app_fixture.client
        # default: page_size > 100 => 422
        # custom: page_size > 10 => 422
        response = client.get('/test/', query_string={'page_size': 101})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': 11})
        if app_fixture.custom_params is False:
            assert response.status_code == 200
        else:
            assert response.status_code == 422

    ",True
815,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_max_page_size,"def test_pagination_max_page_size(self, app_fixture):
        client = app_fixture.client
        # default: page_size > 100 => 422
        # custom: page_size > 10 => 422
        response = client.get('/test/', query_string={'page_size': 101})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': 11})
        if app_fixture.custom_params is False:
            assert response.status_code == 200
        else:
            assert response.status_code == 422

    ",True
816,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_max_page_size,"def test_pagination_max_page_size(self, app_fixture):
        client = app_fixture.client
        # default: page_size > 100 => 422
        # custom: page_size > 10 => 422
        response = client.get('/test/', query_string={'page_size': 101})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': 11})
        if app_fixture.custom_params is False:
            assert response.status_code == 200
        else:
            assert response.status_code == 422

    ",True
817,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_max_page_size,"def test_pagination_max_page_size(self, app_fixture):
        client = app_fixture.client
        # default: page_size > 100 => 422
        # custom: page_size > 10 => 422
        response = client.get('/test/', query_string={'page_size': 101})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': 11})
        if app_fixture.custom_params is False:
            assert response.status_code == 200
        else:
            assert response.status_code == 422

    ",True
818,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_min_page_page_size,"def test_pagination_min_page_page_size(self, app_fixture):
        client = app_fixture.client
        # page < 1 => 422
        response = client.get('/test/', query_string={'page': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page': -42})
        assert response.status_code == 422
        # page_size < 1 => 422
        response = client.get('/test/', query_string={'page_size': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': -42})
        assert response.status_code == 422

    @pytest.mark.parametrize('collection', [1000, ], indirect=True)
    ",True
819,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_min_page_page_size,"def test_pagination_min_page_page_size(self, app_fixture):
        client = app_fixture.client
        # page < 1 => 422
        response = client.get('/test/', query_string={'page': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page': -42})
        assert response.status_code == 422
        # page_size < 1 => 422
        response = client.get('/test/', query_string={'page_size': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': -42})
        assert response.status_code == 422

    @pytest.mark.parametrize('collection', [1000, ], indirect=True)
    ",True
820,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_min_page_page_size,"def test_pagination_min_page_page_size(self, app_fixture):
        client = app_fixture.client
        # page < 1 => 422
        response = client.get('/test/', query_string={'page': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page': -42})
        assert response.status_code == 422
        # page_size < 1 => 422
        response = client.get('/test/', query_string={'page_size': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': -42})
        assert response.status_code == 422

    @pytest.mark.parametrize('collection', [1000, ], indirect=True)
    ",True
821,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_min_page_page_size,"def test_pagination_min_page_page_size(self, app_fixture):
        client = app_fixture.client
        # page < 1 => 422
        response = client.get('/test/', query_string={'page': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page': -42})
        assert response.status_code == 422
        # page_size < 1 => 422
        response = client.get('/test/', query_string={'page_size': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': -42})
        assert response.status_code == 422

    @pytest.mark.parametrize('collection', [1000, ], indirect=True)
    ",True
822,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_min_page_page_size,"def test_pagination_min_page_page_size(self, app_fixture):
        client = app_fixture.client
        # page < 1 => 422
        response = client.get('/test/', query_string={'page': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page': -42})
        assert response.status_code == 422
        # page_size < 1 => 422
        response = client.get('/test/', query_string={'page_size': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': -42})
        assert response.status_code == 422

    @pytest.mark.parametrize('collection', [1000, ], indirect=True)
    ",True
823,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_min_page_page_size,"def test_pagination_min_page_page_size(self, app_fixture):
        client = app_fixture.client
        # page < 1 => 422
        response = client.get('/test/', query_string={'page': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page': -42})
        assert response.status_code == 422
        # page_size < 1 => 422
        response = client.get('/test/', query_string={'page_size': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': -42})
        assert response.status_code == 422

    @pytest.mark.parametrize('collection', [1000, ], indirect=True)
    ",True
824,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_min_page_page_size,"def test_pagination_min_page_page_size(self, app_fixture):
        client = app_fixture.client
        # page < 1 => 422
        response = client.get('/test/', query_string={'page': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page': -42})
        assert response.status_code == 422
        # page_size < 1 => 422
        response = client.get('/test/', query_string={'page_size': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': -42})
        assert response.status_code == 422

    @pytest.mark.parametrize('collection', [1000, ], indirect=True)
    ",True
825,https://github.com/marshmallow-code/flask-smorest/blob/02e9e84def5ace80522c76b830fbef9930a28771/tests/test_pagination.py,TestPagination,test_pagination_min_page_page_size,"def test_pagination_min_page_page_size(self, app_fixture):
        client = app_fixture.client
        # page < 1 => 422
        response = client.get('/test/', query_string={'page': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page': -42})
        assert response.status_code == 422
        # page_size < 1 => 422
        response = client.get('/test/', query_string={'page_size': 0})
        assert response.status_code == 422
        response = client.get('/test/', query_string={'page_size': -42})
        assert response.status_code == 422

    @pytest.mark.parametrize('collection', [1000, ], indirect=True)
    ",True
826,https://github.com/SuryaSankar/flask-sqlalchemy-booster/blob/e43980e29a18e725d791b87ce1b677470bbaf22c/tests/test_view_boosters/test_todo_list_api/test_api_endpoints.py,,test_task_filtering,"def test_task_filtering(todolist_app):
	with todolist_app.test_client() as client:
		resp = client.jget('/tasks?user_email=tweety@acme.com')
		assert resp['status'] == 'success'
		assert resp['result'][0]['title'] == ""Solve a mystery""

",False
827,https://github.com/SuryaSankar/flask-sqlalchemy-booster/blob/e43980e29a18e725d791b87ce1b677470bbaf22c/tests/test_view_boosters/test_todo_list_api/test_api_endpoints.py,,test_task_get,"def test_task_get(todolist_app):
	with todolist_app.test_client() as client:
		resp = client.jget('/tasks/1')
		assert resp['status'] == 'success'

",True
828,https://github.com/SuryaSankar/flask-sqlalchemy-booster/blob/e43980e29a18e725d791b87ce1b677470bbaf22c/tests/test_view_boosters/test_todo_list_api/test_api_endpoints.py,,test_task_updation,"def test_task_updation(todolist_app):
	with todolist_app.test_client() as client:
		modified_title = ""Eat spinach from tin""
		resp = client.jput(
			'/tasks/1', {
				""title"": modified_title
			}
		)
		assert resp['status'] == 'success'
		assert 'id' in resp['result']
		assert resp['result']['title'] == modified_title

",True
829,https://github.com/kipe/fmi/blob/c567622ad29a14a03645b8bc8c7565f315b53480/tests/test_observation.py,TestObservations,test_lappeenranta,"def test_lappeenranta(self):
        now = datetime.now(tz=tzutc())

        f = FMI(place='Lappeenranta')
        for point in f.observations():
            assert point.time < now
            assert isinstance(point.temperature, float)
",False
830,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/core/test_io.py,,test_load_file_contents,"def test_load_file_contents():
    """"""Check that loaded files contain the contents they should.
    Note that is this test fails, it likely stems from an issue from saving.
    """"""

    file_name = 'test_fooof_all'
    loaded_data = load_json(file_name, TEST_DATA_PATH)

    # Check settings
    for setting in OBJ_DESC['settings']:
        assert setting in loaded_data.keys()

    # Check results
    for result in OBJ_DESC['results']:
        assert result in loaded_data.keys()

    # Check results
    for datum in OBJ_DESC['data']:
        assert datum in loaded_data.keys()
",True
831,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/core/test_io.py,,test_load_json_fobj,"def test_load_json_fobj():
    """"""Test loading JSON file, with file object file specifier.
    Loads files from test_save_fm_str.
    """"""

    file_name = 'test_fooof_all'

    with open(os.path.join(TEST_DATA_PATH, file_name + '.json'), 'r') as f_obj:
        data = load_json(f_obj, '')

    assert data

",True
832,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/core/test_io.py,,test_load_json_str,"def test_load_json_str():
    """"""Test loading JSON file, with str file specifier.
    Loads files from test_save_fm_str.
    """"""

    file_name = 'test_fooof_all'

    data = load_json(file_name, TEST_DATA_PATH)

    assert data

",True
833,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/core/test_io.py,,test_load_jsonlines,"def test_load_jsonlines():
    """"""Test loading JSONlines file.
    Loads files from test_save_fg.
    """"""

    res_file_name = 'test_fooofgroup_res'

    for data in load_jsonlines(res_file_name, TEST_DATA_PATH):
        assert data

",True
834,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/objs/test_fit.py,,test_fooof_fit_knee,"def test_fooof_fit_knee():
    """"""Test FOOOF fit, with a knee.""""""

    ap_params = [50, 10, 1]
    gauss_params = [10, 0.3, 2, 20, 0.1, 4, 60, 0.3, 1]
    nlv = 0.0025

    xs, ys = gen_power_spectrum([1, 150], ap_params, gauss_params, nlv)

    tfm = FOOOF(aperiodic_mode='knee', verbose=False)
    tfm.fit(xs, ys)

    # Check model results - aperiodic parameters
    assert np.allclose(ap_params, tfm.aperiodic_params_, [1, 2, 0.2])

    # Check model results - gaussian parameters
    for ii, gauss in enumerate(group_three(gauss_params)):
        assert np.allclose(gauss, tfm.gaussian_params_[ii], [2.0, 0.5, 1.0])

",True
835,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/objs/test_fit.py,,test_fooof_fit_nk,"def test_fooof_fit_nk():
    """"""Test FOOOF fit, no knee.""""""

    ap_params = [50, 2]
    gauss_params = [10, 0.5, 2, 20, 0.3, 4]
    nlv = 0.0025

    xs, ys = gen_power_spectrum([3, 50], ap_params, gauss_params, nlv)

    tfm = FOOOF(verbose=False)
    tfm.fit(xs, ys)

    # Check model results - aperiodic parameters
    assert np.allclose(ap_params, tfm.aperiodic_params_, [0.5, 0.1])

    # Check model results - gaussian parameters
    for ii, gauss in enumerate(group_three(gauss_params)):
        assert np.allclose(gauss, tfm.gaussian_params_[ii], [2.0, 0.5, 1.0])

",True
836,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/objs/test_fit.py,,test_fooof_load,"def test_fooof_load():
    """"""Test load into FOOOF. Note: loads files from test_core_io.""""""

    # Test loading just results
    tfm = FOOOF(verbose=False)
    file_name_res = 'test_fooof_res'
    tfm.load(file_name_res, TEST_DATA_PATH)
    # Check that result attributes get filled
    for result in OBJ_DESC['results']:
        assert not np.all(np.isnan(getattr(tfm, result)))
    # Test that settings and data are None
    #   Except for aperiodic mode, which can be inferred from the data
    for setting in OBJ_DESC['settings']:
        if setting is not 'aperiodic_mode':
            assert getattr(tfm, setting) is None
    assert getattr(tfm, 'power_spectrum') is None

    # Test loading just settings
    tfm = FOOOF(verbose=False)
    file_name_set = 'test_fooof_set'
    tfm.load(file_name_set, TEST_DATA_PATH)
    for setting in OBJ_DESC['settings']:
        assert getattr(tfm, setting) is not None
    # Test that results and data are None
    for result in OBJ_DESC['results']:
        assert np.all(np.isnan(getattr(tfm, result)))
    assert tfm.power_spectrum is None

    # Test loading just data
    tfm = FOOOF(verbose=False)
    file_name_dat = 'test_fooof_dat'
    tfm.load(file_name_dat, TEST_DATA_PATH)
    assert tfm.power_spectrum is not None
    # Test that settings and results are None
    for setting in OBJ_DESC['settings']:
        assert getattr(tfm, setting) is None
    for result in OBJ_DESC['results']:
        assert np.all(np.isnan(getattr(tfm, result)))

    # Test loading all elements
    tfm = FOOOF(verbose=False)
    file_name_all = 'test_fooof_all'
    tfm.load(file_name_all, TEST_DATA_PATH)
    for result in OBJ_DESC['results']:
        assert not np.all(np.isnan(getattr(tfm, result)))
    for setting in OBJ_DESC['settings']:
        assert getattr(tfm, setting) is not None
    for data in OBJ_DESC['data']:
        assert getattr(tfm, data) is not None
    for meta_dat in OBJ_DESC['meta_data']:
        assert getattr(tfm, meta_dat) is not None

",True
837,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/objs/test_group.py,,test_fg_load,"def test_fg_load():
    """"""Test load into FOOOFGroup. Note: loads files from test_core_io.""""""

    file_name_res = 'test_fooofgroup_res'
    file_name_set = 'test_fooofgroup_set'
    file_name_dat = 'test_fooofgroup_dat'

    # Test loading just results
    tfg = FOOOFGroup(verbose=False)
    tfg.load(file_name_res, TEST_DATA_PATH)
    assert len(tfg.group_results) > 0
    # Test that settings and data are None
    #   Except for aperiodic mode, which can be inferred from the data
    for setting in OBJ_DESC['settings']:
        if setting is not 'aperiodic_mode':
            assert getattr(tfg, setting) is None
    assert tfg.power_spectra is None

    # Test loading just settings
    tfg = FOOOFGroup(verbose=False)
    tfg.load(file_name_set, TEST_DATA_PATH)
    for setting in OBJ_DESC['settings']:
        assert getattr(tfg, setting) is not None
    # Test that results and data are None
    for result in OBJ_DESC['results']:
        assert np.all(np.isnan(getattr(tfg, result)))
    assert tfg.power_spectra is None

    # Test loading just data
    tfg = FOOOFGroup(verbose=False)
    tfg.load(file_name_dat, TEST_DATA_PATH)
    assert tfg.power_spectra is not None
    # Test that settings and results are None
    for setting in OBJ_DESC['settings']:
        assert getattr(tfg, setting) is None
    for result in OBJ_DESC['results']:
        assert np.all(np.isnan(getattr(tfg, result)))

    # Test loading all elements
    tfg = FOOOFGroup(verbose=False)
    file_name_all = 'test_fooofgroup_all'
    tfg.load(file_name_all, TEST_DATA_PATH)
    assert len(tfg.group_results) > 0
    for setting in OBJ_DESC['settings']:
        assert getattr(tfg, setting) is not None
    assert tfg.power_spectra is not None
    for meta_dat in OBJ_DESC['meta_data']:
        assert getattr(tfg, meta_dat) is not None

",True
838,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/utils/test_download.py,,test_check_data_file,"def test_check_data_file():

    filename = 'freqs.npy'

    check_data_file(filename, TEST_FOLDER)
    assert os.path.isfile(os.path.join(TEST_FOLDER, filename))

",True
839,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/utils/test_io.py,,test_load_fooof,"def test_load_fooof():

    file_name = 'test_fooof_all'

    tfm = load_fooof(file_name, TEST_DATA_PATH)

    assert isinstance(tfm, FOOOF)

    # Check that all elements get loaded
    for result in OBJ_DESC['results']:
        assert not np.all(np.isnan(getattr(tfm, result)))
    for setting in OBJ_DESC['settings']:
        assert getattr(tfm, setting) is not None
    for data in OBJ_DESC['data']:
        assert getattr(tfm, data) is not None
    for meta_dat in OBJ_DESC['meta_data']:
        assert getattr(tfm, meta_dat) is not None

",True
840,https://github.com/voytekresearch/fooof/blob/7a520c4f8ac3a44f4f18dc025b5e5d40049c9f2b/fooof/tests/utils/test_io.py,,test_load_fooofgroup,"def test_load_fooofgroup():

    file_name = 'test_fooofgroup_all'
    tfg = load_fooofgroup(file_name, TEST_DATA_PATH)

    assert isinstance(tfg, FOOOFGroup)

    # Check that all elements get loaded
    assert len(tfg.group_results) > 0
    for setting in OBJ_DESC['settings']:
        assert getattr(tfg, setting) is not None
    assert tfg.power_spectra is not None
    for meta_dat in OBJ_DESC['meta_data']:
        assert getattr(tfg, meta_dat) is not None
",True
841,https://github.com/stfc/fparser/blob/4be91d2e1078fa5588e84a3299131f297afba675/src/fparser/one/tests/test_block_stmts.py,,test_implicit_topyf,"def test_implicit_topyf(monkeypatch):
    ''' Tests for the topyf() method of HasImplicitStmt. '''
    # We can't just create a HasImplicitStmt object so we get the parser
    # to create a module object as that sub-classes HasImplicitStmt (amongst
    # other things).
    string = '''\
module some_block
  implicit real (a-e)
  implicit integer (f-z)
end module some_block
'''
    reader = FortranStringReader(string)
    reader.set_format(FortranFormat(True, False))
    parser = FortranParser(reader)
    parser.parse()
    # Get the module object
    mod = parser.block.content[0]
    code = mod.topyf()
    assert ""! default IMPLICIT rules apply"" not in code
    mod.content[0].analyze()
    mod.content[1].analyze()
    code = mod.topyf()
    assert ""REAL (a, b, c, d, e)"" in code
    assert ""INTEGER (f, g, h"" in code
    monkeypatch.setattr(mod.a, ""implicit_rules"", None)
    code = mod.topyf()
    assert ""IMPLICIT NONE"" in code
",True
842,https://github.com/AuraiProject/freesia/blob/16834c17725edac74eb50fc5ce2ff1db6f3f4840/tests/test_route.py,RouteTestCase,test_url_match,"def test_url_match(self):
        for r in test_rules:
            route = Route(r.rule, [""GET""], temp, {
                ""checking_param"": False
            })
            with self.subTest(matching=r.matching):
                t, _ = route.match(r.matching, ""GET"")
                self.assertIsNotNone(t)
            with self.subTest(not_matching=r.not_matching):
                t, _ = route.match(r.not_matching, ""GET"")
                self.assertIsNone(t)

    ",True
843,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_class_import.py,,test_can_ignore_email_module,"def test_can_ignore_email_module():
    from email.utils import formatdate
    with freeze_time('2012-01-14'):
        faked_date_str = formatdate()

    before_date_str = formatdate()
    with freeze_time('2012-01-14', ignore=['email']):
        date_str = formatdate()

    after_date_str = formatdate()
    assert date_str != faked_date_str
    assert before_date_str <= date_str <= after_date_str


@freeze_time('2011-01-01')
",True
844,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_class_import.py,,test_fake_uses_real_when_ignored,"def test_fake_uses_real_when_ignored():
    real_time_before = time.time()
    with freeze_time('2012-01-14', ignore=['tests.fake_module']):
        real_time = fake_time_function()
    real_time_after = time.time()
    assert real_time_before <= real_time <= real_time_after


",True
845,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_class_import.py,,test_import_after_start,"def test_import_after_start():
    with freeze_time('2012-01-14'):
        assert 'tests.another_module' not in sys.modules.keys()
        from tests import another_module

        # Reals
        assert another_module.get_datetime() is datetime.datetime
        assert another_module.get_datetime() is FakeDatetime
        assert another_module.get_date() is datetime.date
        assert another_module.get_date() is FakeDate
        assert another_module.get_time() is time.time
        assert another_module.get_time() is fake_time
        assert another_module.get_localtime() is time.localtime
        assert another_module.get_localtime() is fake_localtime
        assert another_module.get_gmtime() is time.gmtime
        assert another_module.get_gmtime() is fake_gmtime
        assert another_module.get_strftime() is time.strftime
        assert another_module.get_strftime() is fake_strftime

        # Fakes
        assert another_module.get_fake_datetime() is FakeDatetime
        assert another_module.get_fake_date() is FakeDate
        assert another_module.get_fake_time() is fake_time
        assert another_module.get_fake_localtime() is fake_localtime
        assert another_module.get_fake_gmtime() is fake_gmtime
        assert another_module.get_fake_strftime() is fake_strftime

    # Reals
    assert another_module.get_datetime() is datetime.datetime
    assert not another_module.get_datetime() is FakeDatetime
    assert another_module.get_date() is datetime.date
    assert not another_module.get_date() is FakeDate
    assert another_module.get_time() is time.time
    assert not another_module.get_time() is fake_time
    assert another_module.get_localtime() is time.localtime
    assert not another_module.get_localtime() is fake_localtime
    assert another_module.get_gmtime() is time.gmtime
    assert not another_module.get_gmtime() is fake_gmtime
    assert another_module.get_strftime() is time.strftime
    assert not another_module.get_strftime() is fake_strftime

    # Fakes
    assert another_module.get_fake_datetime() is FakeDatetime
    assert another_module.get_fake_date() is FakeDate
    assert another_module.get_fake_time() is fake_time
    assert another_module.get_fake_localtime() is fake_localtime
    assert another_module.get_fake_gmtime() is fake_gmtime
    assert another_module.get_fake_strftime() is fake_strftime


",True
846,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_datetimes.py,,test_context_manager,"def test_context_manager():
    with freeze_time(""2012-01-14""):
        assert datetime.datetime.now() == datetime.datetime(2012, 1, 14)
    assert datetime.datetime.now() != datetime.datetime(2012, 1, 14)


",True
847,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_datetimes.py,,test_min_and_max,"def test_min_and_max():
    freezer = freeze_time(""2012-01-14"")
    real_datetime = datetime.datetime
    real_date = datetime.date

    freezer.start()
    assert datetime.datetime.min.__class__ == FakeDatetime
    assert datetime.datetime.max.__class__ == FakeDatetime
    assert datetime.date.min.__class__ == FakeDate
    assert datetime.date.max.__class__ == FakeDate
    assert datetime.datetime.min.__class__ != real_datetime
    assert datetime.datetime.max.__class__ != real_datetime
    assert datetime.date.min.__class__ != real_date
    assert datetime.date.max.__class__ != real_date

    freezer.stop()
    assert datetime.datetime.min.__class__ == datetime.datetime
    assert datetime.datetime.max.__class__ == datetime.datetime
    assert datetime.date.min.__class__ == datetime.date
    assert datetime.date.max.__class__ == datetime.date
    assert datetime.datetime.min.__class__ != FakeDatetime
    assert datetime.datetime.max.__class__ != FakeDatetime
    assert datetime.date.min.__class__ != FakeDate
    assert datetime.date.max.__class__ != FakeDate


@freeze_time(""2014-07-30T01:00:00Z"")
",True
848,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_datetimes.py,,test_nested_context_manager,"def test_nested_context_manager():
    with freeze_time(""2012-01-14""):
        with freeze_time(""2012-12-25""):
            _assert_datetime_date_and_time_are_all_equal(datetime.datetime(2012, 12, 25))
        _assert_datetime_date_and_time_are_all_equal(datetime.datetime(2012, 1, 14))
    assert datetime.datetime.now() > datetime.datetime(2013, 1, 1)


",True
849,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_datetimes.py,,test_nested_context_manager_with_tz_offsets,"def test_nested_context_manager_with_tz_offsets():
    with freeze_time(""2012-01-14 23:00:00"", tz_offset=2):
        with freeze_time(""2012-12-25 19:00:00"", tz_offset=6):
            assert datetime.datetime.now() == datetime.datetime(2012, 12, 26, 1)
            assert datetime.date.today() == datetime.date(2012, 12, 26)
            # no assertion for time.time() since it's not affected by tz_offset
        assert datetime.datetime.now() == datetime.datetime(2012, 1, 15, 1)
        assert datetime.date.today() == datetime.date(2012, 1, 15)
    assert datetime.datetime.now() > datetime.datetime(2013, 1, 1)


@freeze_time(""Jan 14th, 2012"")
",True
850,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_datetimes.py,,test_should_use_real_time,"def test_should_use_real_time():
    frozen = datetime.datetime(2015, 3, 5)
    expected_frozen = 1425513600.0
    # TODO: local time seems to leak the local timezone, so this test fails in CI
    # expected_frozen_local = (2015, 3, 5, 1, 0, 0, 3, 64, -1)
    expected_frozen_gmt = (2015, 3, 5, 0, 0, 0, 3, 64, -1)
    expected_clock = 0

    from freezegun import api
    api.call_stack_inspection_limit = 100  # just to increase coverage

    timestamp_to_convert = 1579602312
    time_tuple = time.gmtime(timestamp_to_convert)

    with freeze_time(frozen):
        assert time.time() == expected_frozen
        # assert time.localtime() == expected_frozen_local
        assert time.gmtime() == expected_frozen_gmt
        if HAS_CLOCK:
            assert time.clock() == expected_clock
        if HAS_TIME_NS:
            assert time.time_ns() == expected_frozen * 1e9

        assert calendar.timegm(time.gmtime()) == expected_frozen
        assert calendar.timegm(time_tuple) == timestamp_to_convert

    with freeze_time(frozen, ignore=['_pytest', 'nose']):
        assert time.time() != expected_frozen
        # assert time.localtime() != expected_frozen_local
        assert time.gmtime() != expected_frozen_gmt
        if HAS_CLOCK:
            assert time.clock() != expected_clock
        if HAS_TIME_NS:
            assert time.time_ns() != expected_frozen * 1e9

        assert calendar.timegm(time.gmtime()) != expected_frozen
        assert calendar.timegm(time_tuple) == timestamp_to_convert


@pytest.mark.skipif(not HAS_TIME_NS,
                    reason=""time.time_ns is present only on 3.7 and above"")
",False
851,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_datetimes.py,,test_simple_api,"def test_simple_api():
    # time to freeze is always provided in UTC
    freezer = freeze_time(""2012-01-14"")
    # expected timestamp must be a timestamp, corresponding to 2012-01-14 UTC
    local_time = datetime.datetime(2012, 1, 14)
    utc_time = local_time - datetime.timedelta(seconds=time.timezone)
    expected_timestamp = time.mktime(utc_time.timetuple())

    freezer.start()
    assert time.time() == expected_timestamp
    assert datetime.datetime.now() == datetime.datetime(2012, 1, 14)
    assert datetime.datetime.utcnow() == datetime.datetime(2012, 1, 14)
    assert datetime.date.today() == datetime.date(2012, 1, 14)
    assert datetime.datetime.now().today() == datetime.datetime(2012, 1, 14)
    freezer.stop()
    assert time.time() != expected_timestamp
    assert datetime.datetime.now() != datetime.datetime(2012, 1, 14)
    assert datetime.datetime.utcnow() != datetime.datetime(2012, 1, 14)
    freezer = freeze_time(""2012-01-10 13:52:01"")
    freezer.start()
    assert datetime.datetime.now() == datetime.datetime(2012, 1, 10, 13, 52, 1)
    freezer.stop()


",True
852,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_datetimes.py,,test_time_clock,"def test_time_clock():
    with freeze_time('2012-01-14 03:21:34'):
        assert time.clock() == 0

        with freeze_time('2012-01-14 03:21:35'):
            assert time.clock() == 1

        with freeze_time('2012-01-14 03:21:36'):
            assert time.clock() == 2


class modify_timezone(object):

    ",False
853,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_datetimes.py,,test_time_localtime,"def test_time_localtime():
    with modify_timezone(-3600):  # Set this for UTC-1
        with freeze_time('2012-01-14 03:21:34'):
            time_struct = time.localtime()
            assert time_struct.tm_year == 2012
            assert time_struct.tm_mon == 1
            assert time_struct.tm_mday == 14
            assert time_struct.tm_hour == 4  # offset of 1 hour due to time zone
            assert time_struct.tm_min == 21
            assert time_struct.tm_sec == 34
            assert time_struct.tm_wday == 5
            assert time_struct.tm_yday == 14
            assert time_struct.tm_isdst == -1
    assert time.localtime().tm_year != 2012


",True
854,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_datetimes.py,,test_time_ns,"def test_time_ns():
    freezer = freeze_time(""2012-01-14"")
    local_time = datetime.datetime(2012, 1, 14)
    utc_time = local_time - datetime.timedelta(seconds=time.timezone)
    expected_timestamp = time.mktime(utc_time.timetuple())

    freezer.start()
    assert time.time() == expected_timestamp
    assert time.time_ns() == expected_timestamp * 1e9
    freezer.stop()
    assert time.time() != expected_timestamp
    assert time.time_ns() != expected_timestamp * 1e9


",True
855,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_errors.py,,test_ignore_errors_in_start,"def test_ignore_errors_in_start(error_type):
    with assert_module_with_raised_error(error_type):
        freezer = freeze_time(datetime.datetime(2019, 1, 11, 9, 34))

        try:
            freezer.start()
        finally:
            freezer.stop()
",True
856,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_errors.py,,test_ignore_errors_in_start,"def test_ignore_errors_in_start(error_type):
    with assert_module_with_raised_error(error_type):
        freezer = freeze_time(datetime.datetime(2019, 1, 11, 9, 34))

        try:
            freezer.start()
        finally:
            freezer.stop()
",True
857,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_uuid.py,,test_uuid1_future,"def test_uuid1_future():
    """"""
    Test that we can go back in time after setting a future date.
    Normally UUID1 would disallow this, since it keeps track of
    the _last_timestamp, but we override that now.
    """"""
    future_target = datetime.datetime(2056, 2, 6, 14, 3, 21)
    with freeze_time(future_target):
        assert time_from_uuid(uuid.uuid1()) == future_target

    past_target = datetime.datetime(1978, 7, 6, 23, 6, 31)
    with freeze_time(past_target):
        assert time_from_uuid(uuid.uuid1()) == past_target


",True
858,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_warnings.py,,test_ignore_warnings_in_start,"def test_ignore_warnings_in_start():
    """"""Make sure that modules being introspected in start() does not emit warnings.""""""
    with assert_module_with_emitted_warning():
        freezer = freeze_time(datetime.datetime(2016, 10, 27, 9, 56))

        try:
            with assert_no_warnings():
                freezer.start()

        finally:
            freezer.stop()


",True
859,https://github.com/spulec/freezegun/blob/b46da782a7a051081fd51577749cfc0074db0cc6/tests/test_warnings.py,,test_ignore_warnings_in_stop,"def test_ignore_warnings_in_stop():
    """"""Make sure that modules that was loaded after start() does not trigger
    warnings in stop()""""""
    freezer = freeze_time(datetime.datetime(2016, 10, 27, 9, 56))
    freezer.start()

    with assert_module_with_emitted_warning():
        with assert_no_warnings():
            freezer.stop()
",True
860,https://github.com/danielmichaels/fuelwatcher/blob/1d2aa12016c227edfd47f3e2ca3e72db32000de6/tests/test_fuelwatch.py,,test_empty_query_return_data,"def test_empty_query_return_data(empty_query):
    assert empty_query is not None

",False
861,https://github.com/danielmichaels/fuelwatcher/blob/1d2aa12016c227edfd47f3e2ca3e72db32000de6/tests/test_fuelwatch.py,,test_xml_returns_data,"def test_xml_returns_data(get_xml):
    assert get_xml is not None

",False
862,https://github.com/bcliang/gamry-parser/blob/0e1f81fb8fd3e433e0df945a85b133ed70a416e4/tests/test_chronoamperometry.py,TestChronoAmperometry,test_getters,"def test_getters(self):
        gp = parser.ChronoAmperometry(filename='tests/chronoa_data.dta')
        self.assertRaises(AssertionError, gp.get_sample_time)
        self.assertRaises(AssertionError, gp.get_sample_count)

        gp.load()
        curve = gp.get_curve_data()
        self.assertTrue((curve.columns == ['T', 'Vf', 'Im']).all())

        self.assertEqual(gp.get_sample_time(), 30)
        self.assertEqual(gp.get_sample_count(), 10)
",False
863,https://github.com/bcliang/gamry-parser/blob/0e1f81fb8fd3e433e0df945a85b133ed70a416e4/tests/test_cyclicvoltammetry.py,TestCyclicVoltammetry,test_getters,"def test_getters(self):
        gp = parser.CyclicVoltammetry(filename='tests/cv_data.dta')
        gp.load()
        vrange = gp.get_v_range()
        self.assertEqual(vrange[0], 0.1)
        self.assertEqual(vrange[1], 0.9)

        scanrate = gp.get_scan_rate()
        self.assertEqual(scanrate, 1.23456)
        curve = gp.get_curve_data(1)
        self.assertTrue((curve.columns == ['Vf', 'Im']).all())
",False
864,https://github.com/bcliang/gamry-parser/blob/0e1f81fb8fd3e433e0df945a85b133ed70a416e4/tests/test_gamryparser.py,TestGamryParser,test_read_header,"def test_read_header(self):
        gp = parser.GamryParser(filename='tests/cv_data.dta')
        blob, count = gp.read_header()
        self.assertEqual(count, 789)
        self.assertEqual(gp.header, blob)
        self.assertEqual(gp.header['DATE'], '3/6/2019')
        self.assertEqual(gp.header['CHECKPSTAT'], 'potentiostat-id')
        self.assertEqual(gp.header['CHECKPOTEN'], 0.5)
        self.assertEqual(gp.header['CHECKQUANT'], 1.2345)
        self.assertEqual(gp.header['CHECKIQUANT'], 5)
        self.assertEqual(gp.header['CHECKSELECTOR'], 0)
        self.assertFalse(gp.header['CHECKTOGGLE'])
        self.assertTrue(isinstance(gp.header['CHECK2PARAM'], dict))
        self.assertTrue(gp.header['CHECK2PARAM']['enable'])
        self.assertEqual(gp.header['CHECK2PARAM']['start'], 300)
        self.assertEqual(gp.header['CHECK2PARAM']['finish'], 0.5)

    ",False
865,https://github.com/bcliang/gamry-parser/blob/0e1f81fb8fd3e433e0df945a85b133ed70a416e4/tests/test_vfp600.py,TestVFP600,test_getters,"def test_getters(self):
        gp = parser.VFP600()
        gp.load('tests/vfp600_data.dta')

        curve = gp.get_curve_data()
        self.assertTrue((curve.columns == ['T', 'Voltage', 'Current']).all())

        self.assertEqual(curve['T'][0], 0)
        self.assertEqual(round(curve['T'].iloc[-1] * 100), 127)
        self.assertEqual(curve['Voltage'].iloc[-1], 0.033333)
        self.assertEqual(round(curve['Current'].iloc[-1] * 1E13), 5125)
",False
866,https://github.com/bcliang/gamry-parser/blob/0e1f81fb8fd3e433e0df945a85b133ed70a416e4/tests/test_vfp600.py,TestVFP600,test_load,"def test_load(self):
        gp = parser.VFP600()
        self.assertFalse(gp.loaded)

        gp.load('tests/vfp600_data.dta')
        self.assertEqual(gp.fname, 'tests/vfp600_data.dta')
        self.assertTrue('VFP600' in gp.get_header()['TAG'])
        # data file acq frequency = 15hz
        self.assertEqual(gp.get_sample_time(), 1 / 15)
        self.assertEqual(gp.get_curve_count(), 1)
        self.assertEqual(gp.get_sample_count(), 20)
        self.assertTrue(gp.loaded)

    ",False
867,https://github.com/josiest/geom/blob/d12b381706ee620cba1c6a6cb45ab7815e5a1dc9/test_geom.py,,test_epsilon,"def test_epsilon():
    assert(abs(geom.eps - 0.0001) < 0.0001)
    geom.set_tolerance(0.01)
    assert(abs(geom.eps - 0.01) < 0.00001)
    with pytest.raises(TypeError):
        geom.set_tolerance('0.001')
    with pytest.raises(ValueError):
        geom.set_tolerance(0)
    with pytest.raises(ValueError):
        geom.set_tolerance(-1)

",True
868,https://github.com/josiest/geom/blob/d12b381706ee620cba1c6a6cb45ab7815e5a1dc9/test_geom.py,,test_veceq,"def test_veceq():
    A = ((0,), (3.33334,), (-12000, -57.42))
    B = ((0,), (3.33333,), (-12000, -57.42))
    for a, b in zip(A, B):
        assert(geom.Vector(a) == geom.Vector(b))
    geom.set_tolerance(0.000001)
    A = ((-10000, 10000), (3.33334,), (2, 3, 4))
    B = ((10000, -10000), (3.33333,), (3, 3, 3))
    for a, b in zip(A, B):
        assert(geom.Vector(a) != geom.Vector(b))

",True
869,https://github.com/googkit/googkit/blob/cacb37bf65e5ac19379b329beb02af907240aa60/test/commands/test_candidates.py,TestCandidatesCommand,test_run_internal,"def test_run_internal(self):
        self.env.argument = self._arg('googkit.py _candidates deps')
        with mock.patch('sys.stdout', new_callable=StubStdout) as mock_stdout:
            self.cmd.run_internal()
        candidates = mock_stdout.getvalue().split('\n')
        self.assertFalse('deps' in candidates)
        self.assertTrue('update' in candidates)
        self.assertFalse('--verbose' in candidates)

        self.env.argument = self._arg('googkit.py _candidates deps update')
        with mock.patch('sys.stdout', new_callable=StubStdout) as mock_stdout:
            self.cmd.run_internal()
        candidates = mock_stdout.getvalue().split('\n')
        self.assertFalse('deps' in candidates)
        self.assertFalse('update' in candidates)
        self.assertTrue('--verbose' in candidates)

        self.env.argument = self._arg('googkit.py _candidates deps update --verbose')
        with mock.patch('sys.stdout', new_callable=StubStdout) as mock_stdout:
            self.cmd.run_internal()
        candidates = mock_stdout.getvalue().split('\n')
        self.assertFalse('deps' in candidates)
        self.assertFalse('update' in candidates)
        self.assertFalse('--verbose' in candidates)
",True
870,https://github.com/matlink/gplaycli/blob/b161dbffa64ddc7081ca7c880ce27f84c2f0a0d8/tests/test_init.py,,test_default_settings,"def test_default_settings():
	assert gpc.yes == False
	assert gpc.verbose == False
	assert gpc.progress_bar == False
	assert gpc.device_codename == 'bacon'

",True
871,https://github.com/grabbles/grabbit/blob/83ff93df36019eaaee9d4e31f816a518e46cae07/grabbit/tests/test_core.py,TestLayout,test_init_with_exclude_arg,"def test_init_with_exclude_arg(self, bids_layout):
        root = join(DIRNAME, 'data', '7t_trt')
        config = join(DIRNAME, 'specs', 'test.json')
        layout = Layout([(root, config)], regex_search=True, exclude='sub-\d*')
        target = join(root, ""dataset_description.json"")
        assert target in bids_layout.files
        assert target in layout.files
        sub_file = join(root, ""sub-01"", ""sub-01_sessions.tsv"")
        assert sub_file in bids_layout.files
        assert sub_file not in layout.files

    ",True
872,https://github.com/grabbles/grabbit/blob/83ff93df36019eaaee9d4e31f816a518e46cae07/grabbit/tests/test_core.py,TestLayout,test_init_with_include_arg,"def test_init_with_include_arg(self, bids_layout):
        root = join(DIRNAME, 'data', '7t_trt')
        config = join(DIRNAME, 'specs', 'test.json')
        layout = Layout([(root, config)], regex_search=True, include='sub-\d*')
        target = join(root, ""dataset_description.json"")
        assert target in bids_layout.files
        assert target not in layout.files
        assert join(root, ""sub-01"", ""sub-01_sessions.tsv"") in layout.files
        with pytest.raises(ValueError):
            layout = Layout([(root, config)], include='sub-\d*', exclude=""meh"")

    ",True
873,https://github.com/grabbles/grabbit/blob/83ff93df36019eaaee9d4e31f816a518e46cae07/grabbit/tests/test_core.py,TestLayout,test_natsort,"def test_natsort(self, bids_layout):
        result = bids_layout.get(target='subject', return_type='id')
        assert result[:5] == list(map(""%02d"".__mod__, range(1, 6)))

    ",True
874,https://github.com/grabbles/grabbit/blob/83ff93df36019eaaee9d4e31f816a518e46cae07/grabbit/tests/test_core.py,TestLayout,test_querying,"def test_querying(self, bids_layout):

        # With regex_search = True (as set in Layout())
        result = bids_layout.get(subject=1, run=1, session=1,
                                 extensions='nii.gz')
        assert len(result) == 8
        result = bids_layout.get(subject='01', run=1, session=1,
                                 type='phasediff', extensions='.json')
        assert len(result) == 1
        assert 'phasediff.json' in result[0].filename
        assert hasattr(result[0], 'run')
        assert result[0].run == 1

        # With exact matching...
        result = bids_layout.get(subject='1', run=1, session=1,
                                 extensions='nii.gz', regex_search=False)
        assert len(result) == 0

        result = bids_layout.get(target='subject', return_type='id')
        assert len(result) == 10
        assert '03' in result
        result = bids_layout.get(target='subject', return_type='dir')

        if hasattr(bids_layout, '_hdfs_client'):
            assert bids_layout._hdfs_client.list(bids_layout.root)
        else:
            assert os.path.exists(join(bids_layout.root, result[0]))
            assert os.path.isdir(join(bids_layout.root, result[0]))

        result = bids_layout.get(target='subject', type='phasediff',
                                 return_type='file')

        if hasattr(bids_layout, '_hdfs_client'):
            assert all([bids_layout._hdfs_client.content(f) for f in result])
        else:
            assert all([os.path.exists(join(bids_layout.root, f))
                        for f in result])

    ",True
875,https://github.com/grabbles/grabbit/blob/83ff93df36019eaaee9d4e31f816a518e46cae07/grabbit/tests/test_core.py,TestLayout,test_unique_and_count,"def test_unique_and_count(self, bids_layout):
        result = bids_layout.unique('subject')
        assert len(result) == 10
        assert '03' in result
        assert bids_layout.count('run') == 2
        assert bids_layout.count('run', files=True) > 2

    ",True
876,https://github.com/OrBin/gramhopper/blob/9396533d10bb469c77985ad931033f400479809b/tests/responses/test_preset_responses.py,TestPresetResponsesWithParameterMatrices,test_preset_document_response,"def test_preset_document_response(self, bot, bot_chat_id, generate_new_update, payload):
        response = _PresetDocumentResponse(self.DOCUMENT_URL)
        update = generate_new_update(chat_id=bot_chat_id)

        message = response.respond(bot, update, payload)
        assert message
        assert message.document


class TestPresetTextResponse:

    SINGLE_PRESET_TEXT = 'one'
    MULTIPLE_PRESET_TEXTS = ['two', 'three']
    FLAKY_MAX_RUNS_FOR_RANDOMNESS = 20
    FLAKY_MIN_PASSES_FOR_RANDOMNESS = 1

    ",False
877,https://github.com/OrBin/gramhopper/blob/9396533d10bb469c77985ad931033f400479809b/tests/responses/test_preset_responses.py,TestPresetResponsesWithParameterMatrices,test_preset_document_response,"def test_preset_document_response(self, bot, bot_chat_id, generate_new_update, payload):
        response = _PresetDocumentResponse(self.DOCUMENT_URL)
        update = generate_new_update(chat_id=bot_chat_id)

        message = response.respond(bot, update, payload)
        assert message
        assert message.document


class TestPresetTextResponse:

    SINGLE_PRESET_TEXT = 'one'
    MULTIPLE_PRESET_TEXTS = ['two', 'three']
    FLAKY_MAX_RUNS_FOR_RANDOMNESS = 20
    FLAKY_MIN_PASSES_FOR_RANDOMNESS = 1

    ",False
878,https://github.com/OrBin/gramhopper/blob/9396533d10bb469c77985ad931033f400479809b/tests/responses/test_preset_responses.py,TestPresetResponsesWithParameterMatrices,test_preset_message_response,"def test_preset_message_response(self, bot, bot_chat_id, generate_new_update, payload, preset_response):
        response = _PresetMessageResponse(preset_response)
        update = generate_new_update(chat_id=bot_chat_id)

        message = response.respond(bot, update, payload)
        assert message
        assert is_acceptable(message.text, preset_response)

    @pytest.mark.parametrize('preset_response', RESPONSE_PRESET_TEXTS)
    ",False
879,https://github.com/OrBin/gramhopper/blob/9396533d10bb469c77985ad931033f400479809b/tests/responses/test_preset_responses.py,TestPresetResponsesWithParameterMatrices,test_preset_message_response,"def test_preset_message_response(self, bot, bot_chat_id, generate_new_update, payload, preset_response):
        response = _PresetMessageResponse(preset_response)
        update = generate_new_update(chat_id=bot_chat_id)

        message = response.respond(bot, update, payload)
        assert message
        assert is_acceptable(message.text, preset_response)

    @pytest.mark.parametrize('preset_response', RESPONSE_PRESET_TEXTS)
    ",False
880,https://github.com/OrBin/gramhopper/blob/9396533d10bb469c77985ad931033f400479809b/tests/responses/test_preset_responses.py,TestPresetResponsesWithParameterMatrices,test_preset_message_response,"def test_preset_message_response(self, bot, bot_chat_id, generate_new_update, payload, preset_response):
        response = _PresetMessageResponse(preset_response)
        update = generate_new_update(chat_id=bot_chat_id)

        message = response.respond(bot, update, payload)
        assert message
        assert is_acceptable(message.text, preset_response)

    @pytest.mark.parametrize('preset_response', RESPONSE_PRESET_TEXTS)
    ",False
881,https://github.com/OrBin/gramhopper/blob/9396533d10bb469c77985ad931033f400479809b/tests/responses/test_preset_responses.py,TestPresetResponsesWithParameterMatrices,test_preset_message_response,"def test_preset_message_response(self, bot, bot_chat_id, generate_new_update, payload, preset_response):
        response = _PresetMessageResponse(preset_response)
        update = generate_new_update(chat_id=bot_chat_id)

        message = response.respond(bot, update, payload)
        assert message
        assert is_acceptable(message.text, preset_response)

    @pytest.mark.parametrize('preset_response', RESPONSE_PRESET_TEXTS)
    ",False
882,https://github.com/OrBin/gramhopper/blob/9396533d10bb469c77985ad931033f400479809b/tests/responses/test_preset_responses.py,TestPresetResponsesWithParameterMatrices,test_preset_reply_response,"def test_preset_reply_response(self, bot, bot_chat_id, generate_new_update, payload, preset_response):
        response = _PresetReplyResponse(preset_response)
        message_to_reply_to = bot.send_message(chat_id=bot_chat_id, text='Message to reply to')
        update = generate_new_update(chat_id=bot_chat_id, message_id=message_to_reply_to.message_id)

        message = response.respond(bot, update, payload)
        assert message
        assert is_acceptable(message.text, preset_response)
        assert message.reply_to_message.message_id == message_to_reply_to.message_id

    ",False
883,https://github.com/OrBin/gramhopper/blob/9396533d10bb469c77985ad931033f400479809b/tests/responses/test_preset_responses.py,TestPresetResponsesWithParameterMatrices,test_preset_reply_response,"def test_preset_reply_response(self, bot, bot_chat_id, generate_new_update, payload, preset_response):
        response = _PresetReplyResponse(preset_response)
        message_to_reply_to = bot.send_message(chat_id=bot_chat_id, text='Message to reply to')
        update = generate_new_update(chat_id=bot_chat_id, message_id=message_to_reply_to.message_id)

        message = response.respond(bot, update, payload)
        assert message
        assert is_acceptable(message.text, preset_response)
        assert message.reply_to_message.message_id == message_to_reply_to.message_id

    ",False
890,https://github.com/narfman0/gtsrvd/blob/af78aa061c910658dfbc89d24171dff334b087f9/tests/test_nginx.py,TestNginx,test_create_proxy,"def test_create_proxy(self, call):
        with mock.patch(""gtsrvd.nginx.NGINX_CONF_ROOT"", self.temp_dir):
            conf_path = nginx.proxy_conf_path(self.subdomain)
            nginx.create_proxy(""blastedstudios.com"", self.subdomain, 8081)
            self.assertTrue(os.path.exists(conf_path))

    @mock.patch(""gtsrvd.nginx.call"")
    @mock.patch(""gtsrvd.nginx.os"")
    ",False
891,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_api.py,,test_fetch_catalog_json,"def test_fetch_catalog_json():
    out = api.fetch_catalog_json(""GWTC-1-confident"")
    events = out[""events""]
    assert events[""GW170817-v3""][""GPS""] == 1187008882.4


@mock.patch(""gwosc.api.fetch_json"")
",False
892,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_api.py,,test_fetch_cataloglist_json,"def test_fetch_cataloglist_json():
    out = api.fetch_cataloglist_json()
    assert ""description"" in out[""GWTC-1-confident""]
    assert ""url"" in out[""GWTC-1-confident""]


@mock.patch(""gwosc.api.fetch_json"")
",False
893,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_api.py,,test_fetch_event_json,"def test_fetch_event_json():
    out = api.fetch_event_json(""GW150914"")
    meta = out[""events""][""GW150914-v3""]
    assert int(meta[""GPS""]) == 1126259462
    assert meta[""version""] == 3


@pytest.mark.remote
",False
894,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_api.py,,test_fetch_event_json_error,"def test_fetch_event_json_error():
    with pytest.raises(ValueError):
        api.fetch_event_json(""GW150914-v3"", version=1)
    with pytest.raises(ValueError):
        api.fetch_event_json(""GW150914-v3"", catalog=""test"")
    with pytest.raises(ValueError):
        api.fetch_event_json(""blah"")
",False
895,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_api.py,,test_fetch_event_json_version,"def test_fetch_event_json_version():
    out = api.fetch_event_json(""GW150914-v3"")[""events""][""GW150914-v3""]
    assert out[""version""] == 3
    assert out[""catalog.shortName""] == ""GWTC-1-confident""


@pytest.mark.remote
",False
896,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_api.py,,test_fetch_run_json,"def test_fetch_run_json():
    run = 'S6'
    detector = 'L1'
    start = 934000000
    end = 934100000
    out = api.fetch_run_json(run, detector, start, end)
    assert out['dataset'] == run
    assert out['GPSstart'] == start
    assert out['GPSend'] == end
    check_json_url_list(out['strain'])


@mock.patch('gwosc.api.fetch_json')
",False
897,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_catalog.py,,test_datasets,"def test_datasets():
    datasets = catalog.datasets(""GWTC-1-confident"")
    assert ""GW150914_R1"" in datasets


@pytest.mark.remote
",False
898,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_catalog.py,,test_datasets_detector,"def test_datasets_detector():
    datasets = catalog.datasets(""GWTC-1-confident"", detector=""V1"")
    assert ""GW150914_R1"" not in datasets
    assert ""GW170817_R1"" in datasets


@pytest.mark.remote
",False
899,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_catalog.py,,test_download,"def test_download():
    data = catalog.download(""GWTC-1-confident"")
    assert ""GW150914"" in data[""data""]

    # check that the cache works properly
    data2 = catalog.download(""GWTC-1-confident"")
    assert data2 is data


@pytest.mark.remote
",False
900,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_catalog.py,,test_events,"def test_events():
    assert ""GW150914"" in catalog.events(""GWTC-1-confident"")
",False
901,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_dataset_type,"def test_dataset_type():
    assert datasets.dataset_type(""O1"") == ""run""
    assert datasets.dataset_type(""GW150914-v1"") == ""event""
    assert datasets.dataset_type(""GWTC-1-confident"") == ""catalog""
    with pytest.raises(ValueError):
        datasets.dataset_type(""invalid"")


@mock.patch(
    'gwosc.datasets.find_datasets',
    mock.MagicMock(side_effect=[[""testrun""], [], [""testevent""], [], [], []]),
)
",False
902,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_event_detectors,"def test_event_detectors():
    assert datasets.event_detectors(""GW150914"") == {""H1"", ""L1""}
    assert datasets.event_detectors(""GW170814"") == {""H1"", ""L1"", ""V1""}


@mock.patch(
    ""gwosc.api._fetch_allevents_event_json"",
    mock.MagicMock(return_value={
        ""events"": {""test"": {""strain"": [
            {""detector"": ""A1""},
            {""detector"": ""B1""},
        ]}},
    }),
)
",False
903,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_event_gps,"def test_event_gps():
    assert datasets.event_gps('GW170817') == 1187008882.4
    with pytest.raises(ValueError) as exc:
        datasets.event_gps('GW123456')
    assert str(exc.value) == 'no event dataset found for \'GW123456\''


@mock.patch(
    'gwosc.api._fetch_allevents_event_json',
    return_value={""events"": {""GW150914"": {
        'GPS': 12345,
        'something else': None,
    }}},
)
",False
904,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_find_datasets,"def test_find_datasets():
    sets = datasets.find_datasets()
    for dset in ('S6', 'O1', 'GW150914-v1', 'GW170817-v3'):
        assert dset in sets
    assert 'tenyear' not in sets
    assert 'history' not in sets


@pytest.mark.remote
",False
905,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_find_datasets_detector,"def test_find_datasets_detector():
    v1sets = datasets.find_datasets('V1')
    assert 'GW170817-v3' in v1sets
    assert 'GW150914-v1' not in v1sets

    assert datasets.find_datasets('X1', type=""run"") == []


@pytest.mark.remote
",False
906,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_find_datasets_match,"def test_find_datasets_match():
    assert ""O1"" not in datasets.find_datasets(match=""GW"")


@pytest.mark.remote
",False
907,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_find_datasets_segment,"def test_find_datasets_segment():
    sets = datasets.find_datasets(segment=(1126051217, 1137254417))
    assert ""GW150914-v1"" in sets
    assert ""GW170817"" not in sets


@pytest.mark.remote
",False
908,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_find_datasets_type,"def test_find_datasets_type():
    runsets = datasets.find_datasets(type='run')
    assert 'O1' in runsets
    run_regex = re.compile(r'\A([OS]\d+|BKGW\d{6})(_\d+KHZ)?(_[RV]\d+)?\Z')
    for dset in runsets:
        assert run_regex.match(dset)

    assert datasets.find_datasets(type='badtype') == []


@pytest.mark.remote
",False
909,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_locate.py,,test_get_event_urls,"def test_get_event_urls():
    urls = locate.get_event_urls(""GW150914-v3"", sample_rate=4096)
    assert len(urls) == 4
    for url in urls:
        assert ""_4KHZ"" in url


@pytest.mark.remote
",False
910,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_locate.py,,test_get_event_urls_segment,"def test_get_event_urls_segment():
    urls = locate.get_event_urls(
        ""GW150914-v1"",
        start=1126257415,
        end=1126257425,
    )
    assert len(urls) == 2
    for url in urls:  # check that these are the 4096-second files
        assert ""-4096."" in url


@pytest.mark.remote
",False
911,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_locate.py,,test_get_urls,"def test_get_urls():
    # test simple fetch for S6 data returns only files within segment
    detector = 'L1'
    start = 934000000
    end = 934100000
    span = (start, end)
    urls = locate.get_urls(detector, start, end)
    for url in urls:
        assert os.path.basename(url).startswith(
            '{}-{}'.format(detector[0], detector))
        assert utils.segments_overlap(
            utils.url_segment(url), span)

    # test fetch for GW170817 data
    assert len(locate.get_urls(
        'L1', 1187007040, 1187009088,
        dataset=""GW170817-v3"",
    )) == 2

    # test for O1 data
    assert len(locate.get_urls(""L1"", 1135136228, 1135140324)) == 2

    # assert no hits raises exception
    with pytest.raises(ValueError):  # no data in 1980
        locate.get_urls(detector, 0, 1)
    with pytest.raises(ValueError):  # no Virgo data for S6
        locate.get_urls('V1', start, end)


@pytest.mark.remote
",False
912,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_locate.py,,test_get_urls_deprecated_tag,"def test_get_urls_deprecated_tag():
    # test `tag` prints a warning
    pytest.deprecated_call(
        locate.get_urls,
        ""L1"",
        1187007040,
        1187009088,
        tag=""TEST"",
    )


@pytest.mark.remote
",False
913,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_locate.py,,test_get_urls_gw170104,"def test_get_urls_gw170104():
    # check that we can find the right URL from an event dataset for
    # a GPS time that doesn't overlap with the event, and ends before
    # the start of the 32-second files (this used to not work)
    urls = locate.get_urls('L1', 1167558912.6, 1167559012.6)
    assert list(map(os.path.basename, urls)) == [
        ""L-L1_GWOSC_4KHZ_R1-1167557889-4096.hdf5"",
    ]
",False
914,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_locate.py,,test_get_urls_version,"def test_get_urls_version():
    """"""Regression test against version not being respected in get_urls
    """"""
    urls = locate.get_urls('L1', 1187008877, 1187008887, version=2)
    assert Path(urls[0]).name == ""L-L1_LOSC_CLN_4_V1-1187007040-2048.hdf5""


@pytest.mark.remote
",False
915,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_timeline.py,,test_get_segments,"def test_get_segments(flag, start, end, result):
    assert timeline.get_segments(flag, start, end) == result


@pytest.mark.remote
",False
916,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_timeline.py,,test_get_segments,"def test_get_segments(flag, start, end, result):
    assert timeline.get_segments(flag, start, end) == result


@pytest.mark.remote
",False
917,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_timeline.py,,test_get_segments_long,"def test_get_segments_long():
    assert len(timeline.get_segments('H1_DATA', 1126051217, 1137196817)) == 654


@pytest.mark.remote
",False
918,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_timeline.py,,test_timeline_url,"def test_timeline_url():
    # check that unknown IFO results in no matches
    with pytest.raises(ValueError):
        timeline.timeline_url('X1', 1126259446, 1126259478)


@mock.patch('gwosc.timeline._find_dataset', return_value='S6')
",False
919,https://github.com/duncanmmacleod/gwopensci/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_urls.py,,test_sieve,"def test_sieve(gw150914_strain):
    nfiles = len(gw150914_strain)
    sieved = list(gwosc_urls.sieve(
        gw150914_strain,
        detector='L1',
    ))
    assert len(sieved) == nfiles // 2
    sieved = list(gwosc_urls.sieve(
        gw150914_strain,
        detector='L1',
        sampling_rate=4096,
    ))
    assert len(sieved) == nfiles // 4


# -- local tests

",False
920,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_api.py,,test_fetch_event_json_error,"def test_fetch_event_json_error():
    with pytest.raises(ValueError):
        api.fetch_event_json(""GW150914-v3"", version=1)
    with pytest.raises(ValueError):
        api.fetch_event_json(""GW150914-v3"", catalog=""test"")
    with pytest.raises(ValueError):
        api.fetch_event_json(""blah"")
",False
921,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_catalog.py,,test_events,"def test_events():
    assert ""GW150914"" in catalog.events(""GWTC-1-confident"")
",False
922,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_dataset_type,"def test_dataset_type():
    assert datasets.dataset_type(""O1"") == ""run""
    assert datasets.dataset_type(""GW150914-v1"") == ""event""
    assert datasets.dataset_type(""GWTC-1-confident"") == ""catalog""
    with pytest.raises(ValueError):
        datasets.dataset_type(""invalid"")


@mock.patch(
    'gwosc.datasets.find_datasets',
    mock.MagicMock(side_effect=[[""testrun""], [], [""testevent""], [], [], []]),
)
",False
923,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_event_detectors,"def test_event_detectors():
    assert datasets.event_detectors(""GW150914"") == {""H1"", ""L1""}
    assert datasets.event_detectors(""GW170814"") == {""H1"", ""L1"", ""V1""}


@mock.patch(
    ""gwosc.api._fetch_allevents_event_json"",
    mock.MagicMock(return_value={
        ""events"": {""test"": {""strain"": [
            {""detector"": ""A1""},
            {""detector"": ""B1""},
        ]}},
    }),
)
",False
924,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_event_gps,"def test_event_gps():
    assert datasets.event_gps('GW170817') == 1187008882.4
    with pytest.raises(ValueError) as exc:
        datasets.event_gps('GW123456')
    assert str(exc.value) == 'no event dataset found for \'GW123456\''


@mock.patch(
    'gwosc.api._fetch_allevents_event_json',
    return_value={""events"": {""GW150914"": {
        'GPS': 12345,
        'something else': None,
    }}},
)
",False
925,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_find_datasets,"def test_find_datasets():
    sets = datasets.find_datasets()
    for dset in ('S6', 'O1', 'GW150914-v1', 'GW170817-v3'):
        assert dset in sets
    assert 'tenyear' not in sets
    assert 'history' not in sets


@pytest.mark.remote
",False
926,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_find_datasets_match,"def test_find_datasets_match():
    assert ""O1"" not in datasets.find_datasets(match=""GW"")


@pytest.mark.remote
",False
927,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_datasets.py,,test_run_segment,"def test_run_segment():
    assert datasets.run_segment('O1') == (1126051217, 1137254417)
    with pytest.raises(ValueError) as exc:
        datasets.run_segment('S7')
    assert str(exc.value) == 'no run dataset found for \'S7\''


@mock.patch(
    'gwosc.api.fetch_dataset_json',
    mock.MagicMock(return_value=DATASET_JSON),
)
",False
928,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_locate.py,,test_get_event_urls_segment,"def test_get_event_urls_segment():
    urls = locate.get_event_urls(
        ""GW150914-v1"",
        start=1126257415,
        end=1126257425,
    )
    assert len(urls) == 2
    for url in urls:  # check that these are the 4096-second files
        assert ""-4096."" in url


@pytest.mark.remote
",False
929,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_locate.py,,test_get_urls,"def test_get_urls():
    # test simple fetch for S6 data returns only files within segment
    detector = 'L1'
    start = 934000000
    end = 934100000
    span = (start, end)
    urls = locate.get_urls(detector, start, end)
    for url in urls:
        assert os.path.basename(url).startswith(
            '{}-{}'.format(detector[0], detector))
        assert utils.segments_overlap(
            utils.url_segment(url), span)

    # test fetch for GW170817 data
    assert len(locate.get_urls(
        'L1', 1187007040, 1187009088,
        dataset=""GW170817-v3"",
    )) == 2

    # test for O1 data
    assert len(locate.get_urls(""L1"", 1135136228, 1135140324)) == 2

    # assert no hits raises exception
    with pytest.raises(ValueError):  # no data in 1980
        locate.get_urls(detector, 0, 1)
    with pytest.raises(ValueError):  # no Virgo data for S6
        locate.get_urls('V1', start, end)


@pytest.mark.remote
",False
930,https://github.com/gwpy/gwosc/blob/06b56ce506fda3af4857c8a1aae7bb60fb1925e9/gwosc/tests/test_locate.py,,test_get_urls_deprecated_tag,"def test_get_urls_deprecated_tag():
    # test `tag` prints a warning
    pytest.deprecated_call(
        locate.get_urls,
        ""L1"",
        1187007040,
        1187009088,
        tag=""TEST"",
    )


@pytest.mark.remote
",False
931,https://github.com/clapeyre/h5nav/blob/595040c2f9b65196ceaf18d1c2c58d848466a22c/tests/test_cli.py,,test_cat_star,"def test_cat_star(capsys, interp):
    interp.do_cd(""Group1"")
    interp.do_cd(""Subgroup1"")
    interp.do_cat(""*"")
    out, err = capsys.readouterr()
    assert out == """"""\
 field2 :
     [  0   2   4   6   8  10  12  14  16  18  20  22  24  26  28  30  32  34
  36  38  40  42  44  46  48  50  52  54  56  58  60  62  64  66  68  70
  72  74  76  78  80  82  84  86  88  90  92  94  96  98 100 102 104 106
 108 110 112 114 116 118 120 122 124 126 128 130 132 134 136 138 140 142
 144 146 148 150 152 154 156 158 160 162 164 166 168 170 172 174 176 178
 180 182 184 186 188 190 192 194 196 198]
field1 :
     [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47
 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71
 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95
 96 97 98 99]
""""""


# `stats` command
",True
932,https://github.com/clapeyre/h5nav/blob/595040c2f9b65196ceaf18d1c2c58d848466a22c/tests/test_cli.py,,test_cd_group,"def test_cd_group(interp):
    assert interp.position == '/'
    interp.do_cd(' Group2')
    assert interp.position == '/ Group2/'


",True
933,https://github.com/clapeyre/h5nav/blob/595040c2f9b65196ceaf18d1c2c58d848466a22c/tests/test_cli.py,,test_dump,"def test_dump(interp):
    fname = ""field1.npy""
    interp.do_cd("" Group2"")
    interp.do_dump(""field1"")
    data = np.load(fname)
    assert np.allclose(data, np.zeros(10))
    os.remove(fname)


# `txt_dump` command
",True
934,https://github.com/clapeyre/h5nav/blob/595040c2f9b65196ceaf18d1c2c58d848466a22c/tests/test_cli.py,,test_get_whitespace_name,"def test_get_whitespace_name(interp):
    name = interp.get_whitespace_name(""Group1"")
    assert name == ""Group1""
    name = interp.get_whitespace_name("" Group2"")
    assert name == "" Group2""


",True
935,https://github.com/clapeyre/h5nav/blob/595040c2f9b65196ceaf18d1c2c58d848466a22c/tests/test_cli.py,,test_ls_simple,"def test_ls_simple(capsys, interp):
    interp.do_ls('')
    out, err = capsys.readouterr()
    assert out == "" Group2/ Group1/\n""


",True
936,https://github.com/clapeyre/h5nav/blob/595040c2f9b65196ceaf18d1c2c58d848466a22c/tests/test_cli.py,,test_ls_star,"def test_ls_star(capsys, interp):
    interp.do_ls('*')
    out, err = capsys.readouterr()
    assert out == """"""\
 Group2/
    field1
Group1/
    Subgroup1/ field1
./
    \n""""""


",True
937,https://github.com/clapeyre/h5nav/blob/595040c2f9b65196ceaf18d1c2c58d848466a22c/tests/test_cli.py,,test_pdf,"def test_pdf(capsys, interp):
    interp.do_cd(""Group1"")
    interp.do_cd(""Subgroup1"")
    interp.do_pdf(""field1"")
    out, err = capsys.readouterr()
    assert out == """"""\
Min         Max         | Pdf (10 buckets)
----------------------------------------------
 0.0000e+00  9.9000e+01 | [10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
""""""


# `dump` command
",True
938,https://github.com/clapeyre/h5nav/blob/595040c2f9b65196ceaf18d1c2c58d848466a22c/tests/test_cli.py,,test_stats,"def test_stats(capsys, interp):
    interp.do_cd(""Group1"")
    interp.do_cd(""Subgroup1"")
    interp.do_stats(""field1"")
    out, err = capsys.readouterr()
    assert out == """"""\
Type           mean +/- std*2       [        min, max        ] (Shape)
--------------------------------------------------------------------------
int64  4.9500e+01 +/-  5.7732e+01 [ 0.0000e+00,  9.9000e+01] (100,)
""""""


# `pdf` command
",True
939,https://github.com/clapeyre/h5nav/blob/595040c2f9b65196ceaf18d1c2c58d848466a22c/tests/test_cli.py,,test_txt_dump,"def test_txt_dump(interp):
    fname = ""field1.txt""
    interp.do_cd("" Group2"")
    interp.do_txt_dump(""field1"")
    data = np.loadtxt(fname)
    assert np.allclose(data, np.zeros(10))
    os.remove(fname)

# `rm` command
",True
940,https://github.com/boy-hack/hack-requests/blob/f78ebc36edb08308222b00239850cefe87c77fb6/tests/test_http.py,TestCase,test_localhost,"def test_localhost(self):
        headers = {
            ""Referer"": ""xx"",
            ""referer"": ""xx""
        }
        r = self.hack.http(""https://x.hacking8.com"", headers=headers)
        print(r.text())
",False
941,https://github.com/ryanhiebert/hirefire/blob/cf8686d127cc914cea350350b5bfe8acfa4163ce/tests/contrib/django/test_middleware.py,TestHireFireMiddleware,test_token,"def test_token(self, client, settings):
        response = client.get('/hirefire/%s/info' % settings.HIREFIRE_TOKEN)
        assert response.status_code == 200

        response = client.get('/hirefire/not-the-token-%s/info' % settings.HIREFIRE_TOKEN)
        assert response.status_code == 404
",False
942,https://github.com/jasonhamilton/hotwing-core/blob/f4d864b1618e928bd981540b2a446bdb74023ca6/tests/test_profile.py,TestProfile,test_scale,"def test_scale(self):
        filepath = self.random_profile_file()
        scale = 2.25
        p1 = Profile(filepath)
        p2 = Profile(filepath)
        p2 = Profile.scale(p2, scale)
        for i in range(len(p1.top.coordinates)):
            assert p2.top.coordinates[i] == p1.top.coordinates[i] * scale
        for i in range(len(p1.bottom.coordinates)):
            assert p2.bottom.coordinates[i] == p1.bottom.coordinates[i] * scale
        p3 = p1*scale
        assert p2 == p3

    ",False
943,https://github.com/laboo/hpdr/blob/6760ceb1f4a6078f70e86e54bb2ee4e269915f9c/tests/test_large.py,,test_years,"def test_years():
    do_100('years')

",False
944,https://github.com/cbornet/python-httpproblem/blob/0b08139277e9cba02339eeb0996c0910d047274a/tests/test_problem.py,,test_exception_to_http_response,"def test_exception_to_http_response():
    deactivate_traceback()
    try:
        raise Problem(1000, 'test_title', 'test_detail', 'test_type', 'test_instance', custom='test_custom')
    except Problem as e:
        response = e.to_http_response()
        assert response['statusCode'] == 1000
        assert response['headers'] == {'Content-Type': 'application/problem+json'}
        assert json.loads(response['body']) == {
            'status': 1000, 'title': 'test_title', 'detail': 'test_detail',
            'type': 'test_type', 'instance': 'test_instance', 'custom': 'test_custom'
        }


",True
945,https://github.com/cbornet/python-httpproblem/blob/0b08139277e9cba02339eeb0996c0910d047274a/tests/test_problem.py,,test_exception_to_http_response_with_global_traceback,"def test_exception_to_http_response_with_global_traceback():
    activate_traceback()
    try:
        raise Problem()
    except Problem as e:
        response = e.to_http_response()
        body = json.loads(response['body'])
        assert ""Traceback (most recent call last):"" in body['traceback']
        del body['traceback']
        assert body == {}


",True
946,https://github.com/cbornet/python-httpproblem/blob/0b08139277e9cba02339eeb0996c0910d047274a/tests/test_problem.py,,test_exception_to_http_response_with_traceback_param,"def test_exception_to_http_response_with_traceback_param():
    deactivate_traceback()
    try:
        raise Problem()
    except Problem as e:
        response = e.to_http_response(with_traceback=True)
        body = json.loads(response['body'])
        assert ""Traceback (most recent call last):"" in body['traceback']
        del body['traceback']
        assert body == {}


",True
947,https://github.com/cbornet/python-httpproblem/blob/0b08139277e9cba02339eeb0996c0910d047274a/tests/test_problem.py,,test_problem_http_response,"def test_problem_http_response(status, title, detail, type, instance, headers, kwargs, expected_body, expected_headers):
    response = problem_http_response(status, title, detail, type, instance, headers, **kwargs)
    assert response['statusCode'] == status
    assert response['headers'] == expected_headers
    assert json.loads(response['body']) == expected_body


",True
948,https://github.com/cbornet/python-httpproblem/blob/0b08139277e9cba02339eeb0996c0910d047274a/tests/test_problem.py,,test_problem_http_response,"def test_problem_http_response(status, title, detail, type, instance, headers, kwargs, expected_body, expected_headers):
    response = problem_http_response(status, title, detail, type, instance, headers, **kwargs)
    assert response['statusCode'] == status
    assert response['headers'] == expected_headers
    assert json.loads(response['body']) == expected_body


",True
949,https://github.com/cbornet/python-httpproblem/blob/0b08139277e9cba02339eeb0996c0910d047274a/tests/test_problem.py,,test_problem_http_response,"def test_problem_http_response(status, title, detail, type, instance, headers, kwargs, expected_body, expected_headers):
    response = problem_http_response(status, title, detail, type, instance, headers, **kwargs)
    assert response['statusCode'] == status
    assert response['headers'] == expected_headers
    assert json.loads(response['body']) == expected_body


",True
950,https://github.com/cbornet/python-httpproblem/blob/0b08139277e9cba02339eeb0996c0910d047274a/tests/test_problem.py,,test_problem_http_response,"def test_problem_http_response(status, title, detail, type, instance, headers, kwargs, expected_body, expected_headers):
    response = problem_http_response(status, title, detail, type, instance, headers, **kwargs)
    assert response['statusCode'] == status
    assert response['headers'] == expected_headers
    assert json.loads(response['body']) == expected_body


",True
951,https://github.com/ndbroadbent/icloud_photos_downloader/blob/e5f304941e2a74b1fbda06c4270ec2fc100e6a49/tests/test_cli.py,CliTestCase,test_tqdm,"def test_tqdm(self):
        if not os.path.exists(""tests/fixtures/Photos""):
            os.makedirs(""tests/fixtures/Photos"")
        with vcr.use_cassette(""tests/vcr_cassettes/listing_photos.yml""):
            # Force tqdm progress bar via ENV var
            os.environ[""FORCE_TQDM""] = ""yes""
            runner = CliRunner()
            result = runner.invoke(
                main,
                [
                    ""--username"",
                    ""jdoe@gmail.com"",
                    ""--password"",
                    ""password1"",
                    ""--recent"",
                    ""0"",
                    ""-d"",
                    ""tests/fixtures/Photos"",
                ],
            )
            del os.environ[""FORCE_TQDM""]
            assert result.exit_code == 0

    ",True
952,https://github.com/ndbroadbent/icloud_photos_downloader/blob/e5f304941e2a74b1fbda06c4270ec2fc100e6a49/tests/test_email_notifications.py,EmailNotificationsTestCase,test_2sa_notification_without_smtp_login_and_tls,"def test_2sa_notification_without_smtp_login_and_tls(self):
        with vcr.use_cassette(""tests/vcr_cassettes/auth_requires_2sa.yml""):
            with patch(""smtplib.SMTP"") as smtp:
                # Pass fixed client ID via environment variable
                os.environ[""CLIENT_ID""] = ""EC5646DE-9423-11E8-BF21-14109FE0B321""
                runner = CliRunner()
                result = runner.invoke(
                    main,
                    [
                        ""--username"",
                        ""jdoe@gmail.com"",
                        ""--password"",
                        ""password1"",
                        ""--smtp-no-tls"",
                        ""--notification-email"",
                        ""jdoe+notifications@gmail.com"",
                        ""-d"",
                        ""tests/fixtures/Photos"",
                    ],
                )
                print(result.output)
                assert result.exit_code == 1
            smtp_instance = smtp()
            smtp_instance.connect.assert_called_once()
            smtp_instance.starttls.assert_not_called()
            smtp_instance.login.assert_not_called()
            smtp_instance.sendmail.assert_called_once_with(
                ""jdoe+notifications@gmail.com"",
                ""jdoe+notifications@gmail.com"",
                ""From: iCloud Photos Downloader <jdoe+notifications@gmail.com>\n""
                ""To: jdoe+notifications@gmail.com\n""
                ""Subject: icloud_photos_downloader: Two step authentication has expired\n""
                ""Date: 01/01/2018 00:00\n\nHello,\n\n""
                ""Two-step authentication has expired for the icloud_photos_downloader script.\n""
                ""Please log in to your server and run the script manually to update two-step ""
                ""authentication."",
            )

    @freeze_time(""2018-01-01"")
    ",False
953,https://github.com/ndbroadbent/icloud_photos_downloader/blob/e5f304941e2a74b1fbda06c4270ec2fc100e6a49/tests/test_email_notifications.py,EmailNotificationsTestCase,test_2sa_required_email_notification,"def test_2sa_required_email_notification(self):
        with vcr.use_cassette(""tests/vcr_cassettes/auth_requires_2sa.yml""):
            with patch(""smtplib.SMTP"") as smtp:
                # Pass fixed client ID via environment variable
                os.environ[""CLIENT_ID""] = ""EC5646DE-9423-11E8-BF21-14109FE0B321""
                runner = CliRunner()
                result = runner.invoke(
                    main,
                    [
                        ""--username"",
                        ""jdoe@gmail.com"",
                        ""--password"",
                        ""password1"",
                        ""--smtp-username"",
                        ""jdoe+smtp@gmail.com"",
                        ""--smtp-password"",
                        ""password1"",
                        ""--notification-email"",
                        ""jdoe+notifications@gmail.com"",
                        ""-d"",
                        ""tests/fixtures/Photos"",
                    ],
                )
                print(result.output)
                assert result.exit_code == 1
            smtp_instance = smtp()
            smtp_instance.connect.assert_called_once()
            smtp_instance.starttls.assert_called_once()
            smtp_instance.login.assert_called_once_with(
                ""jdoe+smtp@gmail.com"", ""password1""
            )
            smtp_instance.sendmail.assert_called_once_with(
                ""jdoe+smtp@gmail.com"",
                ""jdoe+notifications@gmail.com"",
                ""From: iCloud Photos Downloader <jdoe+smtp@gmail.com>\n""
                ""To: jdoe+notifications@gmail.com\n""
                ""Subject: icloud_photos_downloader: Two step authentication has expired\n""
                ""Date: 01/01/2018 00:00\n\nHello,\n\n""
                ""Two-step authentication has expired for the icloud_photos_downloader script.\n""
                ""Please log in to your server and run the script manually to update two-step ""
                ""authentication."",
            )

    @freeze_time(""2018-01-01"")
    ",False
954,https://github.com/ndbroadbent/icloud_photos_downloader/blob/e5f304941e2a74b1fbda06c4270ec2fc100e6a49/tests/test_email_notifications.py,EmailNotificationsTestCase,test_2sa_required_notification_script,"def test_2sa_required_notification_script(self):
        with vcr.use_cassette(""tests/vcr_cassettes/auth_requires_2sa.yml""):
            with patch(""subprocess.call"") as subprocess_patched:
                # Pass fixed client ID via environment variable
                os.environ[""CLIENT_ID""] = ""EC5646DE-9423-11E8-BF21-14109FE0B321""
                runner = CliRunner()
                result = runner.invoke(
                    main,
                    [
                        ""--username"",
                        ""jdoe@gmail.com"",
                        ""--password"",
                        ""password1"",
                        ""--notification-script"",
                        ""./test_script.sh"",
                        ""-d"",
                        ""tests/fixtures/Photos"",
                    ],
                )
                print(result.output)
                assert result.exit_code == 1
            subprocess_patched.assert_called_once_with([""./test_script.sh""])
",False
955,https://github.com/identixone/identixone-python/blob/232e5dfcf98ebe91a3ed433a265be161ee965a5e/tests/api/test_api_client.py,TestAPIClient,test_no_token_raises_exception,"def test_no_token_raises_exception(self):
        with self.assertRaises(IdentixOneException):
            Client(token=None, version=1)

    ",True
956,https://github.com/identixone/identixone-python/blob/232e5dfcf98ebe91a3ed433a265be161ee965a5e/tests/api/test_api_client.py,TestAPIClient,test_unsupported_version_raises_exception,"def test_unsupported_version_raises_exception(self):
        with self.assertRaises(IdentixOneException):
            Client(token=self.token, version=None)

    ",True
957,https://github.com/identixone/identixone-python/blob/232e5dfcf98ebe91a3ed433a265be161ee965a5e/tests/utils/test_environment.py,TestEnvironmentVar,test_dict_environ_invalid_without_prefix,"def test_dict_environ_invalid_without_prefix(self):
        environ = {}
        key = 'KEY'
        value = 'VALUE'
        environ[key] = value
        self.assertIsNone(env_var(os.environ, key))

    ",True
958,https://github.com/identixone/identixone-python/blob/232e5dfcf98ebe91a3ed433a265be161ee965a5e/tests/utils/test_environment.py,TestEnvironmentVar,test_os_environ_invalid_without_prefix,"def test_os_environ_invalid_without_prefix(self):
        key = 'KEY'
        value = 'VALUE'
        os.environ[key] = value
        self.assertIsNone(env_var(os.environ, key))

    ",True
959,https://github.com/ECSHackWeek/impedance.py/blob/d1019c161be9e967ae227117b72acae4351e198f/impedance/tests/test_circuit_elements.py,,test_each_element,"def test_each_element():
    freqs = [0.001, 1.0, 1000]
    correct_vals = {'R': [0.1, 0.1, 0.1],
                    'C': [-1591.5494309189532j,
                          -1.5915494309189535j,
                          -0.0015915494309189533j],
                    'L': [0.000628319j, 0.628319j, 628.319j],
                    'W': [(1.26156626-1.26156626j),
                          (0.03989423-0.03989423j),
                          (0.00126157-0.00126157j)],
                    'Wo': [(0.033333332999112786-79.57747433847442j),
                           (0.03300437046673635-0.08232866785870396j),
                           (0.0019947114020071634-0.0019947114020071634j)],
                    'Ws': [(0.09999998-4.18878913e-05j),
                           (0.08327519-3.33838167e-02j),
                           (0.00199471-1.99471140e-03j)],
                    'CPE': [(26.216236841407248-8.51817171087997j),
                            (6.585220960717244-2.139667994182814j),
                            (1.6541327179718126-0.537460300252313j)],
                    'La': [(0.21769191+0.07073239j),
                           (0.86664712+0.28159072j),
                           (3.45018434+1.12103285j)],
                    'G': [(0.09999994078244179-0.00006283179105931961j),
                          (0.07107755021941357-0.03427465211788068j),
                          (0.00199550459845528-0.0019939172581851707j)],
                    'Gs': [(0.3432733166533134-0.00041895248193532704j),
                           (0.1391819314527732-0.16248466787637972j),
                           (0.0019955029598887875-0.0019939170758457437j)],
                    'T': [(1.00041-0.00837309j),
                          (0.0156037-0.114062j),
                          (0.00141056-0.00141039j)],
                    'K': [(0.099999842086579 - 0.000125663507704j),
                          (0.038772663673915 - 0.048723166143232j),
                          (6.332569967499333e-08 - 7.957742115295703e-05j)]}
    input_vals = [0.1, 0.2, 0.3, 0.4]
    for key, f in circuit_elements.items():
        # don't test the outputs of series and parallel functions
        if key not in ['s', 'p']:
            num_inputs = f.num_params
            val = f(input_vals[:num_inputs], freqs)
            assert np.isclose(val, correct_vals[key]).all()

        # check for typing:
        with pytest.raises(AssertionError):
            f = circuit_elements['R']
            f(1, 2)

        # test for handling more wrong inputs
        with pytest.raises(AssertionError):
            f(['hi'], ['yes', 'hello'])

    # Test no overflow in T at high frequencies
    with pytest.warns(None) as record:
        circuit_elements['T']([1, 2, 50, 100], [10000])
    assert not record


",True
960,https://github.com/ECSHackWeek/impedance.py/blob/d1019c161be9e967ae227117b72acae4351e198f/impedance/tests/test_circuit_elements.py,,test_element_function_names,"def test_element_function_names():
    # run a simple check to ensure there are no integers
    # in the function names
    letters = string.ascii_uppercase + string.ascii_lowercase

    for elem in circuit_elements.keys():
        for char in elem:
            assert char in letters, \
                f'{char} in {elem} is not in the allowed set of {letters}'
",True
961,https://github.com/levi-rs/instabrade/blob/73d027ce2e3b0141c7f1c83567151b5638905355/tests/test_instagram.py,,test_app_store_center_popup_displayed,"def test_app_store_center_popup_displayed(instagram):
    """""" Verify the center app store popup display check works """"""
    instagram.driver.find_elements_by_xpath.side_effect = [[], [1, 2]]

    assert instagram.app_store_center_popup_displayed is False
    assert instagram.app_store_center_popup_displayed is True

    exp_call = call.find_elements_by_xpath(CENTER_POPUP_DISPLAYED_XPATH)
    assert exp_call in instagram.driver.method_calls


",True
962,https://github.com/levi-rs/instabrade/blob/73d027ce2e3b0141c7f1c83567151b5638905355/tests/test_instagram.py,,test_app_store_footer_popup_displayed,"def test_app_store_footer_popup_displayed(instagram, element):
    """""" Verify footer popup detection works """"""
    instagram.driver.execute_script.return_value = 100

    side_effects = [[], [element, ], [element, ], [element, ]]
    instagram.driver.find_elements_by_css_selector.side_effect = side_effects

    element.is_displayed.side_effect = [False, True, True, True]

    loc_side_effect = [SERE, {'y': 110}, {'y': 90}]
    type(element).location = PropertyMock(side_effect=loc_side_effect)

    instagram.app_store_footer_popup_displayed is False
    instagram.app_store_footer_popup_displayed is False
    instagram.app_store_footer_popup_displayed is False
    instagram.app_store_footer_popup_displayed is True


",True
963,https://github.com/NCAR/intake-cesm/blob/00fe97676b165bf41fb985a5e03b07a4a9772b71/tests/test_source.py,,test_esm_group_repr,"def test_esm_group_repr(group_args, capsys):
    source = ESMGroupDataSource(**group_args)
    print(repr(source))
    captured = capsys.readouterr()
    assert 'assets:' in captured.out


",False
964,https://github.com/NCAR/intake-esm/blob/00fe97676b165bf41fb985a5e03b07a4a9772b71/tests/test_source.py,,test_esm_group_repr,"def test_esm_group_repr(group_args, capsys):
    source = ESMGroupDataSource(**group_args)
    print(repr(source))
    captured = capsys.readouterr()
    assert 'assets:' in captured.out


",False
965,https://github.com/timb07/irritable/blob/6d250dd716890b7b78b2b42e2f04be3058b09856/tests/test_irritable.py,,test_irrit_resume,"def test_irrit_resume():
    """"""Probabilistic test: may fail very occasionally""""""
    count_empty = 0
    l = list(range(10))
    for _ in range(100):
        i = irrit(range(10), resume=True)
        l1 = [n for n in i]
        if len(l1) == 0:
            count_empty += 1
        elif len(l1) < 10:
            l2 = [n for n in i]
            assert l1 + l2 == l
        else:
            assert l1 == l
    assert 0 < count_empty < 100
",False
966,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_cast_attr,"def test_cast_attr(person: Person):
    assert isinstance(person.cast, list)
    item, credit = person.cast[0]
    assert isinstance(item, (Show, Movie))
    assert isinstance(credit, Credit)


",False
967,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_gender_attr,"def test_gender_attr(person: Person):
    assert isinstance(person.gender, int)


",False
968,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_get_combined_credits,"def test_get_combined_credits(empty_person: Person):
    credits = empty_person.get_combined_credits()
    assert credits == empty_person.data[""combined_credits""]


",False
969,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_get_details,"def test_get_details(empty_person: Person):
    details = empty_person.get_details()
    assert isinstance(details, dict)
    assert empty_person.data == details


",False
970,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_get_external_ids,"def test_get_external_ids(empty_person: Person):
    external_ids = empty_person.get_external_ids()
    assert external_ids == empty_person.data[""external_ids""]


",False
971,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_get_images,"def test_get_images(empty_person: Person):
    images = empty_person.get_images()
    assert images == empty_person.data[""images""]


",False
972,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_get_movie_credits,"def test_get_movie_credits(empty_person: Person):
    credits = empty_person.get_movie_credits()
    assert credits == empty_person.data[""movie_credits""]


",False
973,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_get_show_credits,"def test_get_show_credits(empty_person: Person):
    credits = empty_person.get_show_credits()
    assert credits == empty_person.data[""tv_credits""]


",False
974,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_get_translations,"def test_get_translations(empty_person: Person):
    translations = empty_person.get_translations()
    assert translations == empty_person.data[""translations""]


",False
975,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_objects/test_person.py,,test_is_adult_attr,"def test_is_adult_attr(person: Person):
    assert isinstance(person.is_adult, bool)


",False
976,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_person.py,,test_get_popular,"def test_get_popular():
    shows = isle.people.get_popular()
    assert inspect.isgenerator(shows)
    person = next(shows)
    assert isinstance(person, Person)
",False
977,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_show.py,,test_get_airing_today,"def test_get_airing_today():
    shows = isle.show.get_airing_today()
    assert inspect.isgenerator(shows)
    show = next(shows)
    assert isinstance(show, Show)


",False
978,https://github.com/dmkskn/isle/blob/81397e6e8c75543f9fd2efd2c34928077542da2a/tests/test_show.py,,test_get_top_rated,"def test_get_top_rated():
    shows = isle.show.get_top_rated()
    assert inspect.isgenerator(shows)
    show = next(shows)
    assert isinstance(show, Show)


",False
979,https://github.com/zzzzlzzzz/jackfruit/blob/350a41aa28e2bdc9367f9dd5e686b21125828589/tests/test_jackfruit.py,,test_single_view,"def test_single_view(dispatcher, view):
    j = Jackfruit(dispatcher, view)

    assert len(j.STATE) == 1
    assert j.STATE[view.get_name()] == view

    assert len(dispatcher.HANDLERS) == 2
    for h in dispatcher.HANDLERS:
        if isinstance(h, CallbackQueryHandler):
            assert h.callback == j._dispatch
        elif isinstance(h, MessageHandler):
            assert h.callback == j._dispatch
        else:
            assert False


",True
980,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_audit.py,TestAudit,test_call_audit_results_prints_output,"def test_call_audit_results_prints_output(self):
    """""" test_call_audit_results_prints_output ensures that when called with
    a valid result, audit_results returns the number of vulnerabilities found """"""
    filename = Path(__file__).parent / ""ossindexresponse.txt""
    with open(filename, ""r"") as stdin:
      response = json.loads(
          stdin.read(),
          cls=ResultsDecoder)
    self.assertEqual(self.func.audit_results(response),
                     self.expected_results())

  @staticmethod
  ",False
981,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_config.py,TestConfig,test_config_object_saves_config_file,"def test_config_object_saves_config_file(self):
    """"""test_config_object_saves_config_file ensures config objs are being written to file""""""
    result = self.func.save_config_to_file(
        {""Username"": ""test@me.com"", ""Token"": ""password""},
        "".oss-index-config"")
    self.assertEqual(result, True)

  ",False
982,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_iq_config.py,TestIQConfig,test_get_config_from_std_in,"def test_get_config_from_std_in(self):
    """"""test_get_config_from_std_in verifies the IQConfig class""""""
    testinput = """"""test@me.com
password
http://localhost:8070/""""""
    sys.stdin = io.StringIO(testinput)
    result = self.func.get_config_from_std_in()
    self.assertEqual(result, True)
    # reread stored config
    results = self.func.get_config_from_file("".iq-server-config"")
    self.assertEqual(results[""Username""], ""test@me.com"")
    self.assertEqual(results[""Token""], ""password"")
    self.assertEqual(results[""Server""], ""http://localhost:8070"")
",False
983,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_ossindex.py,TestOssIndex,test_chunk,"def test_chunk(self):
    """"""test_chunk ensures the chunk method is splitting responses with more
    than 128 purl results into 128-purl chunks""""""
    file = Path(__file__).parent / ""condalistoutput.txt""
    with open(file, ""r"") as stdin:
      purls = self.parse.get_deps_stdin(stdin)
      actual_result = self.func.chunk(purls)
    self.assertEqual(len(actual_result), 3)
    self.assertEqual(len(actual_result[0]), 128)
    self.assertEqual(actual_result[0][0],
                     ""pkg:conda/_ipyw_jlab_nb_ext_conf@0.1.0"")
    self.assertEqual(actual_result[1][0], ""pkg:conda/mistune@0.8.4"")
    self.assertEqual(actual_result[2][0], ""pkg:conda/yaml@0.1.7"")

  ",False
984,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_ossindex.py,TestOssIndex,test_clean_cache_wipes_database,"def test_clean_cache_wipes_database(self):
    """"""test_clean_cache_wipes_database ensures calls to clean_cache will
    clear out documents from the database""""""
    self.func.maybe_insert_into_cache(self.string_to_coordinatesresult(
        """"""[{""coordinates"":""pkg:conda/pycrypto@2.6.1"",
        ""reference"":""https://ossindex.sonatype.org/component/pkg:conda/pycrypto@2.6.1"",
        ""vulnerabilities"":[]}]""""""))
    self.assertEqual(self.func.clean_cache(), True)

  @staticmethod
  ",False
985,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_ossindex.py,TestOssIndex,test_get_headers,"def test_get_headers(self):
    """"""test_get_headers ensures headers are being retrieved correctly""""""
    self.assertEqual(self.func.get_headers(), {
        ""Content-type"":
        ""application/vnd.ossindex.component-report-request.v1+json"",
        ""User-Agent"":
        ""jake""})

  ",False
986,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_ossindex.py,TestOssIndex,test_get_purls_from_cache_with_cache_miss,"def test_get_purls_from_cache_with_cache_miss(self):
    """""" This test ensures that a) results can be added to the cache
    and b) if a purl is not in the cache, that purl is still in the new purls
    that are returned """"""
    self.func.maybe_insert_into_cache(self.string_to_coordinatesresult(
        """"""[{""coordinates"":""pkg:conda/pycrypto@2.6.1"",
        ""reference"":""https://ossindex.sonatype.org/component/pkg:conda/pycrypto@2.6.1"",
        ""vulnerabilities"":[{""id"":""156d71e4-6ed5-4d5f-ae47-7d57be01d387"",
        ""title"":""[CVE-2019-16056] jake the snake"",
        ""cvssScore"":0.0,""cve"":""CVE-2019-16056"",
        ""reference"":""http://www.wrestling.com""}]}]""""""))
    fake_purls = self.get_fake_actual_purls()
    fake_purls.add_coordinate('alabaster', '0.7.12', 'conda')
    (new_purls, results) = self.func.get_purls_and_results_from_cache(
        fake_purls)
    self.assertEqual(len(new_purls.get_coordinates()), 1)
    self.assertEqual(isinstance(new_purls, Coordinates), True)
    self.assertEqual(isinstance(results, list), True)
    self.assertEqual(isinstance(results[0], CoordinateResults), True)
    self.assertEqual(isinstance(
        results[0].get_vulnerabilities()[0],
        Vulnerabilities), True)
    self.assertEqual(results[0].get_vulnerabilities()[
        0].get_id(), ""156d71e4-6ed5-4d5f-ae47-7d57be01d387"")
    self.assertEqual(results[0].get_vulnerabilities()[
        0].get_cve(), ""CVE-2019-16056"")
    self.assertEqual(results[0].get_coordinates(),
                     ""pkg:conda/pycrypto@2.6.1"")
    self.assertEqual(results[0].get_reference(
    ), ""https://ossindex.sonatype.org/component/pkg:conda/pycrypto@2.6.1"")
    self.assertEqual(new_purls.get_coordinates()
                     [('alabaster', '0.7.12', 'conda')], ""pkg:conda/alabaster@0.7.12"")

  ",False
987,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_ossindex.py,TestOssIndex,test_get_purls_from_cache_with_non_valid_object,"def test_get_purls_from_cache_with_non_valid_object(self):
    """"""test_get_purls_from_cache_with_non_valid_object ensures calls to
    get_purls_and_results_from_cache with improper objects returns None for
    new_purls and results""""""
    (new_purls, results) = self.func.get_purls_and_results_from_cache(
        ""bad data"")
    self.assertEqual(new_purls, None)
    self.assertEqual(results, None)

  ",False
988,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_ossindex.py,TestOssIndex,test_insert_into_cache,"def test_insert_into_cache(self):
    """"""test_insert_into_cache ensures the results from an OSSIndex call
    are inserted into cache if they do not yet exist in cache""""""
    file = Path(__file__).parent / ""ossindexresponse.txt""
    with open(file, ""r"") as stdin:
      response = json.loads(stdin.read(), cls=ResultsDecoder)
      (cached, num_cached) = self.func.maybe_insert_into_cache(response)
    self.assertEqual(num_cached, 32)
    self.assertEqual(cached, True)

  ",False
989,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_ossindex.py,TestOssIndex,test_insert_into_cache_does_not_duplicate,"def test_insert_into_cache_does_not_duplicate(self):
    """"""test_insert_into_cache_does_not_duplicate ensures that maybe_insert_into_cache
    does not insert results into cache if they exist in cache""""""
    file = Path(__file__).parent / ""ossindexresponse.txt""
    with open(file, ""r"") as stdin:
      response = json.loads(stdin.read(), cls=ResultsDecoder)
      self.func.maybe_insert_into_cache(response)
      (cached, num_cached) = self.func.maybe_insert_into_cache(response)
    self.assertEqual(num_cached, 0)
    self.assertEqual(cached, False)

  ",False
990,https://github.com/sonatype-nexus-community/jake/blob/a1dd3401c8f3faac41dad8a836c2b3d9e7f4098d/jake/test/test_ossindex.py,TestOssIndex,test_insert_into_cache_expired_ttl,"def test_insert_into_cache_expired_ttl(self):
    """"""test_insert_into_cache_expired_ttl ensures that maybe_insert_into_cache
    inserts results into cache if the time to live is expired""""""
    database = TinyDB('/tmp/.ossindex/jake.json')
    coordinate_query = Query()
    response = self.string_to_coordinatesresult(
        """"""[{""coordinates"":""pkg:conda/pycrypto@2.6.1"",
        ""reference"":""https://ossindex.sonatype.org/component/pkg:conda/pycrypto@2.6.1"",
        ""vulnerabilities"":[]}]"""""")
    self.func.maybe_insert_into_cache(response)
    result_expired = database.search(
        coordinate_query.purl == ""pkg:conda/pycrypto@2.6.1"")
    time_unwind = parse(result_expired[0]['ttl']) - timedelta(hours=13)
    database.update({'ttl': time_unwind.isoformat()},
                    coordinate_query.purl == ""pkg:conda/pycrypto@2.6.1"")

    next_response = self.string_to_coordinatesresult(
        """"""[{""coordinates"":""pkg:conda/pycrypto@2.6.1"",
        ""reference"":""https://ossindex.sonatype.org/component/pkg:conda/pycrypto@2.6.1"",
        ""vulnerabilities"":[]}]"""""")
    (cached, num_cached) = self.func.maybe_insert_into_cache(next_response)
    self.assertEqual(cached, True)
    self.assertEqual(num_cached, 1)
    database.close()

  ",False
992,https://github.com/hefnawi/json-storage-manager/blob/c7521fc4a576cf23a8c2454106bed6fb8c951b8d/tests/test_main.py,,test_get_item,"def test_get_item(json_file):
    results = atomic.get_item(
        str(json_file), ""2299d69e-deba-11e8-bded-680715cce955"")
    assert results
    assert results[0][""name""] == 'Test Product'


",True
993,https://github.com/hefnawi/json-storage-manager/blob/c7521fc4a576cf23a8c2454106bed6fb8c951b8d/tests/test_main.py,,test_get_no_item,"def test_get_no_item(json_file):
    results = atomic.get_item(
        str(json_file), ""xxxxxxxx-deba-11e8-bded-680715cce955"")
    assert not results


",True
994,https://github.com/hefnawi/json-storage-manager/blob/c7521fc4a576cf23a8c2454106bed6fb8c951b8d/tests/test_main.py,,test_read_json,"def test_read_json(json_file):
    with open(str(json_file)) as f:
        products_data = json.load(f)
    for item in products_data:
        assert item[""uuid""]
        assert item[""name""]
        assert item[""price""]


# add to contents of json file
",True
995,https://github.com/hefnawi/json-storage-manager/blob/c7521fc4a576cf23a8c2454106bed6fb8c951b8d/tests/test_main.py,,test_set_item,"def test_set_item(json_file):
    new_item = {'uuid': ""1144d69e-joya-33e8-bdfd-680688cce955"",
                'price': 333.0,
                'name': ""Test Product via set_item""
                }
    results = atomic.set_item(str(json_file), new_item)
    results_get = atomic.get_item(
        str(json_file), ""1144d69e-joya-33e8-bdfd-680688cce955"")
    assert results
    assert results_get[0][""name""] == 'Test Product via set_item'


",True
996,https://github.com/hefnawi/json-storage-manager/blob/c7521fc4a576cf23a8c2454106bed6fb8c951b8d/tests/test_main.py,,test_set_item_fail,"def test_set_item_fail(json_file):
    new_item = {'uuid': ""1144d69e-joya-33e8-bdfd-680688cce955"",
                'price': 333.0,
                'name': ""Test Product via set_item""
                }
    results = atomic.set_item(str(json_file), new_item)
    assert not results
",True
997,https://github.com/hefnawi/json-storage-manager/blob/c7521fc4a576cf23a8c2454106bed6fb8c951b8d/tests/test_main.py,,test_update_item,"def test_update_item(json_file):
    mod_item = {'price': 777.0,
                'name': ""Test Product via update_item""
                }
    results = atomic.update_item(str(json_file), mod_item, ""1144d69e-joya-33e8-bdfd-680688cce955"")
    results_get = atomic.get_item(
        str(json_file), ""1144d69e-joya-33e8-bdfd-680688cce955"")
    assert results
    assert results_get[0][""name""] == 'Test Product via update_item'
    assert results_get[0][""price""] == 777.0


",True
998,https://github.com/hefnawi/json-storage-manager/blob/c7521fc4a576cf23a8c2454106bed6fb8c951b8d/tests/test_main.py,,test_write_json,"def test_write_json(json_file):
    with atomic.atomic_write(str(json_file)) as temp_file:
        with open(str(json_file)) as products_file:
            # get the JSON data into memory
            products_data = json.load(products_file)
        # now process the JSON data
        products_data.append(
            {'uuid': ""2299d69e-deba-11e8-bded-680715cce955"",
             'price': 111.0,
             'name': ""Test Product""
             })
        json.dump(products_data, temp_file)

    with open(str(json_file)) as f:
        products_data = json.load(f)
    test = [i for i in products_data if i[""uuid""] == ""2299d69e-deba-11e8-bded-680715cce955""]
    assert test[0][""name""] == 'Test Product'


",True
999,https://github.com/LGSInnovations/jupyter-sigplot/blob/498cda8f3648282cba84745d97e8973d2a02ed89/test/test_jupyter_sigplot.py,,test_empty_object,"def test_empty_object():
    plot = Plot()
    # instance variables
    assert plot.data_dir == ''
    assert plot.path_resolvers == []
    # traitlets
    assert plot.command_and_arguments == {}
    assert plot.plot_options == {}
    assert plot.progress == 0.0
    assert not plot.done


",True
1000,https://github.com/LGSInnovations/jupyter-sigplot/blob/498cda8f3648282cba84745d97e8973d2a02ed89/test/test_jupyter_sigplot.py,,test_overlay_href,"def test_overlay_href(traitlet_set_mock):
    plot = Plot()
    plot.overlay_href('bar|baz')
    assert traitlet_set_mock.call_count == 2
    for call_args in traitlet_set_mock.call_args_list:
        assert call_args[0][0]['command'] == 'overlay_href'
        assert len(call_args[0][0]['arguments']) == 1
        assert call_args[0][0]['arguments'][0] in ('bar', 'baz')


###########################################################################
# Other tests
###########################################################################


",True
1001,https://github.com/saabeilin/kafkian/blob/79eb88b874876632590fea48afcab09592c717dd/tests/unit/test_producer_avro.py,,test_avro_producer_produce,"def test_avro_producer_produce(avro_producer):
    key = 'a'
    value = message
    topic = 'z'
    avro_producer.produce(key=key, value=value, topic=topic)

    producer_produce_mock.assert_called_once_with(
        topic,
        key,
        avro_producer.value_serializer.serialize(value, topic)
    )

#
# ",True
1002,https://github.com/saabeilin/kafkian/blob/79eb88b874876632590fea48afcab09592c717dd/tests/unit/test_producer_avro_key.py,,test_avro_producer_produce,"def test_avro_producer_produce(avro_producer):
    key = 'a'
    value = 'a'
    topic = 'c'
    avro_producer.produce(topic, key=key, value=value)

    producer_produce_mock.assert_called_once_with(
        topic,
        b'\x00\x00\x00\x00\x01\x02a',
        value
    )
",True
1003,https://github.com/pythological/kanren/blob/bacc7eb5895c348e348c1b5291ddf188f88c5c88/tests/test_assoccomm.py,,test_eq_assoccomm,"def test_eq_assoccomm():
    x, y = var(), var()

    ac = ""commassoc_op""

    commutative.index.clear()
    commutative.facts.clear()

    fact(commutative, ac)
    fact(associative, ac)

    assert run(0, True, eq_assoccomm(1, 1)) == (True,)
    assert run(0, True, eq_assoccomm((1,), (1,))) == (True,)
    assert run(0, True, eq_assoccomm(x, (1,))) == (True,)
    assert run(0, True, eq_assoccomm((1,), x)) == (True,)

    # Assoc only
    assert run(0, True, eq_assoccomm((ac, 1, (ac, 2, 3)), (ac, (ac, 1, 2), 3))) == (
        True,
    )
    # Commute only
    assert run(0, True, eq_assoccomm((ac, 1, (ac, 2, 3)), (ac, (ac, 3, 2), 1))) == (
        True,
    )
    # Both
    assert run(0, True, eq_assoccomm((ac, 1, (ac, 3, 2)), (ac, (ac, 1, 2), 3))) == (
        True,
    )

    exp_res = set(
        (
            (ac, 1, 3, 2),
            (ac, 1, 2, 3),
            (ac, 2, 1, 3),
            (ac, 2, 3, 1),
            (ac, 3, 1, 2),
            (ac, 3, 2, 1),
            (ac, 1, (ac, 2, 3)),
            (ac, 1, (ac, 3, 2)),
            (ac, 2, (ac, 1, 3)),
            (ac, 2, (ac, 3, 1)),
            (ac, 3, (ac, 1, 2)),
            (ac, 3, (ac, 2, 1)),
            (ac, (ac, 2, 3), 1),
            (ac, (ac, 3, 2), 1),
            (ac, (ac, 1, 3), 2),
            (ac, (ac, 3, 1), 2),
            (ac, (ac, 1, 2), 3),
            (ac, (ac, 2, 1), 3),
        )
    )
    assert set(run(0, x, eq_assoccomm((ac, 1, (ac, 2, 3)), x))) == exp_res
    assert set(run(0, x, eq_assoccomm((ac, 1, 3, 2), x))) == exp_res
    assert set(run(0, x, eq_assoccomm((ac, 2, (ac, 3, 1)), x))) == exp_res
    # LHS variations
    assert set(run(0, x, eq_assoccomm(x, (ac, 1, (ac, 2, 3))))) == exp_res

    assert run(0, (x, y), eq_assoccomm((ac, (ac, 1, x), y), (ac, 2, (ac, 3, 1)))) == (
        (2, 3),
        (3, 2),
    )

    assert run(0, True, eq_assoccomm((ac, (ac, 1, 2), 3), (ac, 1, 2, 3))) == (True,)
    assert run(0, True, eq_assoccomm((ac, 3, (ac, 1, 2)), (ac, 1, 2, 3))) == (True,)
    assert run(0, True, eq_assoccomm((ac, 1, 1), (""other_op"", 1, 1))) == ()

    assert run(0, x, eq_assoccomm((ac, 3, (ac, 1, 2)), (ac, 1, x, 3))) == (2,)

    # Both arguments unground
    op_lv = var()
    z = var()
    res = run(4, (x, y), eq_assoccomm(x, y))
    exp_res_form = (
        (etuple(op_lv, x, y), etuple(op_lv, y, x)),
        (y, y),
        (etuple(etuple(op_lv, x, y)), etuple(etuple(op_lv, y, x)),),
        (etuple(op_lv, x, y, z), etuple(op_lv, etuple(op_lv, x, y), z),),
    )

    for a, b in zip(res, exp_res_form):
        s = unify(a, b)
        assert (
            op_lv not in s
            or (s[op_lv],) in associative.facts
            or (s[op_lv],) in commutative.facts
        )
        assert s is not False, (a, b)
        assert all(isvar(i) for i in reify((x, y, z), s))


",True
1004,https://github.com/kevinarpe/kevinarpe-rambutan3/blob/5d7469912b559338dc15f5c7fb2abc91103ea0c5/tests/check_args/base/test_RNotNoneTypeMatcher.py,,test_eq_ne_hash,"def test_eq_ne_hash():
    RTestUtil.test_eq_ne_hash(RNotNoneTypeMatcher(), RNotNoneTypeMatcher(), is_equal=True)
    RTestUtil.test_eq_ne_hash(RNotNoneTypeMatcher(), INT | RNotNoneTypeMatcher(), is_equal=False)


",True
1005,https://github.com/microsoft/knack/blob/dc7b7d857ce3c11b2a3155b81f2470b3b579e7c9/tests/test_cli_scenarios.py,TestCLIScenarios,test_case_insensitive_command_path,"def test_case_insensitive_command_path(self):
        ",True
1006,https://github.com/microsoft/knack/blob/dc7b7d857ce3c11b2a3155b81f2470b3b579e7c9/tests/test_help.py,TestHelp,test_help_extra_params,"def test_help_extra_params(self):
        """""" Ensure appropriate error is thrown when an extra argument is used. """"""

        # work around an argparse behavior where output is not printed and SystemExit
        # is not raised on Python 2.7.9
        if sys.version_info < (2, 7, 10):
            try:
                self.cli_ctx.invoke('n1 -a 1 -b c -c extra'.split())
            except SystemExit:
                pass
        else:
            with self.assertRaises(SystemExit):
                self.cli_ctx.invoke('n1 -a 1 -b c -c extra'.split())

        actual = io.getvalue()
        expected = 'unrecognized arguments: -c extra'
        self.assertIn(expected, actual)

    @redirect_io
    ",True
1007,https://github.com/microsoft/knack/blob/dc7b7d857ce3c11b2a3155b81f2470b3b579e7c9/tests/test_help.py,TestHelp,test_help_missing_params,"def test_help_missing_params(self):
        """""" Ensure the appropriate error is thrown when a required argument is missing. """"""

        # work around an argparse behavior where output is not printed and SystemExit
        # is not raised on Python 2.7.9
        if sys.version_info < (2, 7, 10):
            try:
                self.cli_ctx.invoke('n1 -a 1 --arg 2'.split())
            except SystemExit:
                pass
        else:
            with self.assertRaises(SystemExit):
                self.cli_ctx.invoke('n1 -a 1 --arg 2'.split())

            actual = io.getvalue()
            self.assertTrue('required' in actual and '-b' in actual)

    @redirect_io
    ",True
1008,https://github.com/microsoft/knack/blob/dc7b7d857ce3c11b2a3155b81f2470b3b579e7c9/tests/test_command_with_configured_defaults.py,TestCommandWithConfiguredDefaults,test_no_configured_default_on_required_arg,"def test_no_configured_default_on_required_arg(self):
        self._set_up_command_table(required=True)
        with self.assertRaises(SystemExit):
            self.cli_ctx.invoke('foo list'.split())
        actual = self.io.getvalue()
        expected = 'required: --my-param'
        if sys.version_info[0] == 2:
            expected = 'argument --my-param is required'
        self.assertEqual(expected in actual, True)

    @mock.patch.dict(os.environ, {'CLI_DEFAULTS_PARAM': 'myVal'})
    @redirect_io
    ",True
1009,https://github.com/microsoft/knack/blob/dc7b7d857ce3c11b2a3155b81f2470b3b579e7c9/tests/test_deprecation.py,TestArgumentDeprecation,test_deprecate_arguments_execute_expired,"def test_deprecate_arguments_execute_expired(self):
        """""" Ensure expired deprecated arguments can't be used. """"""
        with self.assertRaises(SystemExit):
            self.cli_ctx.invoke('arg-test --arg1 foo --opt1 bar --arg5 foo'.split())
        actual = self.io.getvalue()
        expected = 'unrecognized arguments: --arg5 foo'
        self.assertIn(expected, actual)

    @redirect_io
    ",True
1010,https://github.com/microsoft/knack/blob/dc7b7d857ce3c11b2a3155b81f2470b3b579e7c9/tests/test_deprecation.py,TestArgumentDeprecation,test_deprecate_options_execute_expired,"def test_deprecate_options_execute_expired(self):
        """""" Ensure expired deprecated options can't be used. """"""
        with self.assertRaises(SystemExit):
            self.cli_ctx.invoke('arg-test --arg1 foo --opt1 bar --alt5 foo'.split())
        actual = self.io.getvalue()
        expected = 'unrecognized arguments: --alt5 foo'
        self.assertIn(expected, actual)

    @redirect_io
    ",True
1011,https://github.com/microsoft/knack/blob/dc7b7d857ce3c11b2a3155b81f2470b3b579e7c9/tests/test_deprecation.py,TestCommandDeprecation,test_deprecate_command_expired_execute,"def test_deprecate_command_expired_execute(self):
        """""" Ensure expired command cannot be reached. """"""
        with self.assertRaises(SystemExit):
            self.cli_ctx.invoke('cmd5 -h'.split())
        actual = self.io.getvalue()
        expected = """"""cli: 'cmd5' is not in the 'cli' command group.""""""
        self.assertIn(expected, actual)

    @redirect_io
    @disable_color
    ",True
1012,https://github.com/microsoft/knack/blob/dc7b7d857ce3c11b2a3155b81f2470b3b579e7c9/tests/test_deprecation.py,TestCommandDeprecation,test_deprecate_command_expired_execute_no_color,"def test_deprecate_command_expired_execute_no_color(self):
        """""" Ensure error is displayed without color. """"""
        with self.assertRaises(SystemExit):
            self.cli_ctx.invoke('cmd5 -h'.split())
        actual = self.io.getvalue()
        expected = """"""ERROR: cli: 'cmd5' is not in the 'cli' command group.""""""
        self.assertIn(expected, actual)


class TestCommandGroupDeprecation(unittest.TestCase):

    ",True
1013,https://github.com/dask/knit/blob/934aee7012967453b7343f6e01f16b26aece2aaf/knit/tests/test_env.py,,test_miniconda_install,"def test_miniconda_install(tmp):
    c = CondaCreator(conda_root=tmp)
    assert tmp in c.conda_bin
    assert os.path.exists(c.conda_bin)


",False
1014,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_extraneous_whitespace.py,ExtraneousWhiteSpaceTestCase,test_rule_with_fix,"def test_rule_with_fix(self):
        cli_args = _create_arg_parser().parse_args([""--fix"", ""test_rule_with_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, _ = linter.lint_lines(""test_rule_with_fix"", self.TEST_INPUT)

        self.assertEqual(lines, self.FIXED_INPUT)
",True
1015,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_extraneous_whitespace.py,ExtraneousWhiteSpaceTestCase,test_rule_without_fix,"def test_rule_without_fix(self):
        cli_args = _create_arg_parser().parse_args([""test_rule_without_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, reporter = linter.lint_lines(""test_rule_without_fix"", self.TEST_INPUT)

        self.assertEqual(reporter.found_issues[Category.CONVENTION], 1)
        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)
        self.assertEqual(reporter.found_issues[Category.WARNING], 0)
        self.assertEqual(reporter.found_issues[Category.ERROR], 0)
        self.assertEqual(reporter.found_issues[Category.FATAL], 0)

        self.assertEqual(lines, self.TEST_INPUT)

        self.assertEqual(reporter.messages[0].line_number, 0)
        self.assertEqual(reporter.messages[0].column, 3)
        self.assertEqual(reporter.messages[0].message, ""superfluous whitespace"")
        self.assertEqual(reporter.messages[0].code, ""superfluous-whitespace"")

    ",True
1016,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_indentation_checker.py,IndentationCheckerTestCase,test_rule_with_fix,"def test_rule_with_fix(self):
        cli_args = _create_arg_parser().parse_args([""--fix"", ""test_rule_with_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, _ = linter.lint_lines(""test_rule_with_fix"", self.TEST_INPUT)

        self.assertEqual(lines, self.FIXED_INPUT)
",True
1017,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_indentation_checker.py,IndentationCheckerTestCase,test_rule_without_fix,"def test_rule_without_fix(self):
        cli_args = _create_arg_parser().parse_args([""test_rule_without_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, reporter = linter.lint_lines(""test_rule_without_fix"", self.TEST_INPUT)

        self.assertEqual(reporter.found_issues[Category.CONVENTION], 0)
        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)
        self.assertEqual(reporter.found_issues[Category.WARNING], 3)
        self.assertEqual(reporter.found_issues[Category.ERROR], 0)
        self.assertEqual(reporter.found_issues[Category.FATAL], 0)

        self.assertEqual(lines, self.TEST_INPUT)

        self.assertEqual(reporter.messages[0].line_number, 1)
        self.assertEqual(reporter.messages[0].column, 6)
        self.assertEqual(reporter.messages[0].message, ""wrong indentation (found 6 spaces, exptected 3)"")
        self.assertEqual(reporter.messages[0].code, ""bad-indentation"")

        self.assertEqual(reporter.messages[1].line_number, 4)
        self.assertEqual(reporter.messages[1].column, 3)
        self.assertEqual(reporter.messages[1].message, ""wrong indentation (found 3 spaces, exptected 0)"")
        self.assertEqual(reporter.messages[1].code, ""bad-indented-inline-form"")

        self.assertEqual(reporter.messages[2].line_number, 5)
        self.assertEqual(reporter.messages[2].column, 3)
        self.assertEqual(reporter.messages[2].message, ""wrong indentation (found 3 spaces, exptected 0)"")
        self.assertEqual(reporter.messages[2].code, ""bad-indented-inline-form"")

    ",False
1018,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_lower_or_mixed_case_built_in_type.py,LowerOrMixedCaseBuiltInTestCase,test_rule_with_fix,"def test_rule_with_fix(self):
        cli_args = _create_arg_parser().parse_args([""--fix"", ""test_rule_with_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, _ = linter.lint_lines(""test_rule_with_fix"", self.TEST_INPUT)

        self.assertEqual(lines, self.FIXED_INPUT)
",True
1019,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_lower_or_mixed_case_built_in_type.py,LowerOrMixedCaseBuiltInTestCase,test_rule_without_fix,"def test_rule_without_fix(self):
        cli_args = _create_arg_parser().parse_args([""test_rule_without_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, reporter = linter.lint_lines(""test_rule_without_fix"", self.TEST_INPUT)

        self.assertEqual(reporter.found_issues[Category.CONVENTION], 0)
        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)
        self.assertEqual(reporter.found_issues[Category.WARNING], 1)
        self.assertEqual(reporter.found_issues[Category.ERROR], 0)
        self.assertEqual(reporter.found_issues[Category.FATAL], 0)

        self.assertEqual(lines, self.TEST_INPUT)

        self.assertEqual(reporter.messages[0].line_number, 0)
        self.assertEqual(reporter.messages[0].column, 0)
        self.assertEqual(reporter.messages[0].message, ""lower or mixed case built-in type"")
        self.assertEqual(reporter.messages[0].code, ""wrong-case-type"")

    ",True
1020,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_open_task.py,OpenTaskTestCase,test_rule_with_fix,"def test_rule_with_fix(self):
        cli_args = _create_arg_parser().parse_args([""--fix"", ""test_rule_with_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, _ = linter.lint_lines(""test_rule_with_fix"", self.TEST_INPUT)

        self.assertEqual(lines, self.TEST_INPUT)",True
1021,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_open_task.py,OpenTaskTestCase,test_rule_without_fix,"def test_rule_without_fix(self):
        cli_args = _create_arg_parser().parse_args([""test_rule_without_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, reporter = linter.lint_lines(""test_rule_without_fix"", self.TEST_INPUT)

        self.assertEqual(reporter.found_issues[Category.CONVENTION], 0)
        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)
        self.assertEqual(reporter.found_issues[Category.WARNING], 1)
        self.assertEqual(reporter.found_issues[Category.ERROR], 0)
        self.assertEqual(reporter.found_issues[Category.FATAL], 0)

        self.assertEqual(lines, self.TEST_INPUT)

        self.assertEqual(reporter.messages[0].line_number, 0)
        self.assertEqual(reporter.messages[0].column, 0)
        self.assertEqual(reporter.messages[0].message, ""complete open task (This is a open task)"")
        self.assertEqual(reporter.messages[0].code, ""open-task"")

    ",True
1022,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_trailing_white_space_rule.py,TrailingWhiteSpaceTestCase,test_rule_with_fix,"def test_rule_with_fix(self):
        cli_args = _create_arg_parser().parse_args([""--fix"", ""test_rule_with_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, _ = linter.lint_lines(""test_rule_with_fix"", self.TEST_INPUT)

        self.assertEqual(lines, self.FIXED_INPUT)
",True
1023,https://github.com/d4nuu8/krllint/blob/2f9376cdae14c201364d9c31b4c19a8ff2f708d2/tests/test_trailing_white_space_rule.py,TrailingWhiteSpaceTestCase,test_rule_without_fix,"def test_rule_without_fix(self):
        cli_args = _create_arg_parser().parse_args([""test_rule_without_fix""])
        reload(config)
        config.REPORTER = MemoryReporter
        linter = Linter(cli_args, config)
        lines, reporter = linter.lint_lines(""test_rule_without_fix"", self.TEST_INPUT)

        self.assertEqual(reporter.found_issues[Category.CONVENTION], 1)
        self.assertEqual(reporter.found_issues[Category.REFACTOR], 0)
        self.assertEqual(reporter.found_issues[Category.WARNING], 0)
        self.assertEqual(reporter.found_issues[Category.ERROR], 0)
        self.assertEqual(reporter.found_issues[Category.FATAL], 0)

        self.assertEqual(lines, self.TEST_INPUT)

        self.assertEqual(reporter.messages[0].line_number, 0)
        self.assertEqual(reporter.messages[0].column, 16)
        self.assertEqual(reporter.messages[0].message, ""trailing whitespace"")
        self.assertEqual(reporter.messages[0].code, ""trailing-whitespace"")

    ",True
1024,https://github.com/jamesevickery/l293d/blob/c026a9b58769f23d3e999234ba9df30fb021f949/tests/test_l293d.py,L293DTestCase,test_create_motor_with_force_selection,"def test_create_motor_with_force_selection(self):
        """"""
        Test DC class instance creation with explicity
        force_selection parameter
        """"""
        import l293d as d
        cases = (([33, 36, 37], False), ([19, 21, 23], True))
        for pins, force_selection in cases:
            motor = d.DC(*pins, force_selection=force_selection)
            self.assertEqual(d.pins_in_use, pins)
            motor.remove()
        reload(d.driver)

    ",True
1025,https://github.com/jamesevickery/l293d/blob/c026a9b58769f23d3e999234ba9df30fb021f949/tests/test_l293d.py,L293DTestCase,test_motor_can_be_removed,"def test_motor_can_be_removed(self):
        """"""
        Test that a motor can be created and removed
        """"""
        import l293d as d
        original_pins = d.pins_in_use
        motor = d.DC(29, 7, 13)
        motor.remove()
        self.assertEqual(d.pins_in_use, original_pins)
        reload(d.driver)

    ",True
1026,https://github.com/jamesevickery/l293d/blob/c026a9b58769f23d3e999234ba9df30fb021f949/tests/test_l293d.py,L293DTestCase,test_pin_numbering_lock,"def test_pin_numbering_lock(self):
        """"""
        Test that pin_numbering can't be changed after a motor's definition
        """"""
        import l293d as d
        d.Config.pin_numbering = 'BcM'
        m1 = d.DC(4, 5, 6)
        error = 'No error'
        try:
            d.Config.pin_numbering = 'BoaRD'
        except ValueError as e:
            error = str(e)
        self.assertEqual(
            error, 'Pin numbering format cannot be changed '
                   'if motors already exist. Set this at '
                   'the start of your script.')
        m1.remove()
        d.Config.pin_numbering = 'BOARD'
        reload(d.driver)

    ",True
1027,https://github.com/dgellerup/laminar/blob/74258f6e6cc8b3b4e9eaf7cc522192a353a3b45e/test/test_laminar.py,,test_init_my_lam,"def test_init_my_lam(my_lam):
    assert my_lam.cores == 2
    assert my_lam.results == {}


",True
1028,https://github.com/staffanm/layeredconfig/blob/c0eae96da7848ea52b43ac947f284eb2324d9ce1/tests/test_layeredconfig.py,TestLayeredWithSingleSource,test_commandline,"def test_commandline(self):
        cfg = LayeredConfig(self.yamlsource, Commandline())
        self.assertEqual(""value"", cfg.section.subsection.key)

        cmdline = [""./foo.py"", ""--foo=bar""]
        cfg = LayeredConfig(self.yamlsource, Commandline(cmdline))
        self.assertEqual(""value"", cfg.section.subsection.key)

        cmdline = [""./foo.py"", ""--foo=bar"", ""--section-subsection-key=other""]
        cfg = LayeredConfig(self.yamlsource, Commandline(cmdline))
        self.assertEqual(""other"", cfg.section.subsection.key)

    ",True
1029,https://github.com/sanjaz/lazypr/blob/226895868769f613d9e905f265a4fd7c421d2fd4/tests/test_config.py,TestConfig,test_get_default_config_file_path,"def test_get_default_config_file_path(self):
        """"""Test getting default config file path.""""""
        real_home = os.environ.get(""HOME"")

        os.environ[""HOME""] = ""/some/test/value""
        expected_path = ""/some/test/value/.config/lazy_pr.ini""
        assert get_default_config_file_path() == expected_path

        if real_home is not None:
            os.environ[""HOME""] = real_home

    ",True
1030,https://github.com/OpenDataServices/lib-cove/blob/74ba874ec6882969894797ee0dbc5c70a16019e5/tests/lib/test_converters.py,,test_convert_activity_xml_1,"def test_convert_activity_xml_1():

    cove_temp_folder = tempfile.mkdtemp(
        prefix=""lib-cove-iati-tests-"", dir=tempfile.gettempdir()
    )

    activity_xml_filename = os.path.join(
        os.path.dirname(os.path.realpath(__file__)),
        ""fixtures"",
        ""converters"",
        ""convert_activity_1.xml"",
    )

    lib_cove_config = LibCoveConfig()
    output = convert_json(
        cove_temp_folder,
        """",
        activity_xml_filename,
        lib_cove_config,
        flatten=True,
        xml=True,
        root_list_path=""iati-activity"",
    )

    assert output[""converted_url""] == ""/flattened""
    assert len(output[""conversion_warning_messages""]) == 0
    assert output[""conversion""] == ""flatten""

    conversion_warning_messages_name = os.path.join(
        cove_temp_folder, ""conversion_warning_messages.json""
    )
    assert os.path.isfile(conversion_warning_messages_name)
    with open(conversion_warning_messages_name) as fp:
        conversion_warning_messages_data = json.load(fp)
    assert conversion_warning_messages_data == []

    assert os.path.isfile(os.path.join(cove_temp_folder, ""flattened.xlsx""))
    assert os.path.isfile(
        os.path.join(cove_temp_folder, ""flattened"", ""iati-activity.csv"")
    )

    with open(
        os.path.join(cove_temp_folder, ""flattened"", ""iati-activity.csv""), ""r""
    ) as csvfile:
        csvreader = csv.reader(csvfile)

        header = next(csvreader)
        assert header[0] == ""@default-currency""
        assert header[1] == ""iati-identifier""

        row1 = next(csvreader)
        assert row1[0] == ""GBP""
        assert row1[1] == ""GB-TEST-13-example_ODSC_2019""


",True
1031,https://github.com/OpenDataServices/lib-cove/blob/74ba874ec6882969894797ee0dbc5c70a16019e5/tests/lib/test_converters.py,,test_convert_json_1,"def test_convert_json_1():

    cove_temp_folder = tempfile.mkdtemp(
        prefix=""lib-cove-ocds-tests-"", dir=tempfile.gettempdir()
    )
    json_filename = os.path.join(
        os.path.dirname(os.path.realpath(__file__)),
        ""fixtures"",
        ""converters"",
        ""convert_json_1.json"",
    )

    lib_cove_config = LibCoveConfig()
    output = convert_json(
        cove_temp_folder, """", json_filename, lib_cove_config, flatten=True
    )

    assert output[""converted_url""] == ""/flattened""
    assert len(output[""conversion_warning_messages""]) == 0
    assert output[""conversion""] == ""flatten""

    conversion_warning_messages_name = os.path.join(
        cove_temp_folder, ""conversion_warning_messages.json""
    )
    assert os.path.isfile(conversion_warning_messages_name)
    with open(conversion_warning_messages_name) as fp:
        conversion_warning_messages_data = json.load(fp)
    assert conversion_warning_messages_data == []

    assert os.path.isfile(os.path.join(cove_temp_folder, ""flattened"", ""main.csv""))

    with open(os.path.join(cove_temp_folder, ""flattened"", ""main.csv""), ""r"") as csvfile:
        csvreader = csv.reader(csvfile)

        header = next(csvreader)
        assert header[0] == ""id""
        assert header[1] == ""title""

        row1 = next(csvreader)
        assert row1[0] == ""1""
        assert row1[1] == ""Cat""

        row2 = next(csvreader)
        assert row2[0] == ""2""
        assert row2[1] == ""Hat""


",True
1032,https://github.com/OpenDataServices/lib-cove/blob/74ba874ec6882969894797ee0dbc5c70a16019e5/tests/lib/test_converters.py,,test_convert_org_xml_1,"def test_convert_org_xml_1():

    cove_temp_folder = tempfile.mkdtemp(
        prefix=""lib-cove-iati-tests-"", dir=tempfile.gettempdir()
    )

    organisation_xml_filename = os.path.join(
        os.path.dirname(os.path.realpath(__file__)),
        ""fixtures"",
        ""converters"",
        ""convert_org_1.xml"",
    )

    lib_cove_config = LibCoveConfig()
    output = convert_json(
        cove_temp_folder,
        """",
        organisation_xml_filename,
        lib_cove_config,
        flatten=True,
        xml=True,
        root_list_path=""iati-organisation"",
        root_id=""organisation-identifier"",
    )

    assert output[""converted_url""] == ""/flattened""
    assert len(output[""conversion_warning_messages""]) == 0
    assert output[""conversion""] == ""flatten""

    conversion_warning_messages_name = os.path.join(
        cove_temp_folder, ""conversion_warning_messages.json""
    )
    assert os.path.isfile(conversion_warning_messages_name)
    with open(conversion_warning_messages_name) as fp:
        conversion_warning_messages_data = json.load(fp)
    assert conversion_warning_messages_data == []

    assert os.path.isfile(os.path.join(cove_temp_folder, ""flattened.xlsx""))
    assert os.path.isfile(
        os.path.join(cove_temp_folder, ""flattened"", ""iati-organisation.csv"")
    )

    with open(
        os.path.join(cove_temp_folder, ""flattened"", ""iati-organisation.csv""), ""r""
    ) as csvfile:
        csvreader = csv.reader(csvfile)

        header = next(csvreader)
        assert header[0] == ""organisation-identifier""
        assert header[4] == ""name/narrative""

        row1 = next(csvreader)
        assert row1[0] == ""GB-GOV-1""
        assert row1[4] == ""UK Department for International Development""


",True
1033,https://github.com/earthreader/libearth/blob/71d2f3246eb0b6a3668a64e2242616d20b1d7dcd/tests/parser_test.py,,test_rss_parser,"def test_rss_parser():
    my_opener = urllib2.build_opener(TestHTTPHandler)
    urllib2.install_opener(my_opener)
    crawled_feed, data_for_crawl = parse_rss2(
        rss_xml,
        'http://sourcetest.com/rss.xml'
    )
    feed = read(Feed, write(crawled_feed, as_bytes=True))
    assert crawled_feed.id == feed.id
    title = crawled_feed.title
    assert title.type == feed.title.type
    assert title.value == feed.title.value
    links = crawled_feed.links
    assert links[1].mimetype == feed.links[1].mimetype
    assert links[1].relation == feed.links[1].relation
    assert links[1].uri == feed.links[1].uri
    rights = crawled_feed.rights
    assert rights.type == feed.rights.type
    assert rights.value == feed.rights.value
    contributors = crawled_feed.contributors
    assert contributors[0].name == feed.contributors[0].name
    assert contributors[0].email == feed.contributors[0].email
    assert contributors[1].name == feed.contributors[1].name
    assert contributors[1].email == feed.contributors[1].email
    updated_at = crawled_feed.updated_at
    assert updated_at == feed.updated_at
    categories = crawled_feed.categories
    assert categories[0].term == feed.categories[0].term
    entries = crawled_feed.entries
    assert entries[0].title.type == feed.entries[0].title.type
    assert entries[0].title.value == feed.entries[0].title.value
    assert entries[0].links[0].mimetype == feed.entries[0].links[0].mimetype
    assert entries[0].links[0].relation == feed.entries[0].links[0].relation
    assert entries[0].links[0].uri == feed.entries[0].links[0].uri
    assert entries[0].content.value == feed.entries[0].content.value
    assert entries[0].authors[0].name == feed.entries[0].authors[0].name
    assert entries[0].authors[0].email == feed.entries[0].authors[0].email
    assert entries[0].links[1].mimetype == feed.entries[0].links[1].mimetype
    assert entries[0].links[1].uri == feed.entries[0].links[1].uri
    assert entries[0].id == feed.entries[0].id
    assert (entries[0].published_at ==
            entries[0].updated_at ==
            feed.entries[0].published_at ==
            feed.entries[0].updated_at)
    source = entries[0].source
    assert source.title.type == feed.entries[0].source.title.type
    assert source.title.value == feed.entries[0].source.title.value
    assert source.links[1].mimetype == feed.entries[0].source.links[1].mimetype
    assert source.links[1].uri == feed.entries[0].source.links[1].uri
    assert source.links[1].relation == feed.entries[0].source.links[1].relation
    assert source.subtitle.type == feed.entries[0].source.subtitle.type
    assert source.subtitle.value == feed.entries[0].source.subtitle.value
    assert not source.entries


category_with_no_term = '''
<feed>
    <id>categorywithnoterm.com</id>
    <title>Category has no term attribute</title>
    <updated>2013-08-10T15:27:04Z</updated>
    <category>this will not be parsed</category>
</feed>
'''


",False
1034,https://github.com/earthreader/libearth/blob/71d2f3246eb0b6a3668a64e2242616d20b1d7dcd/tests/parsing_test.py,,test_parse,"def test_parse(input_, expected):
    with open(os.path.join(test_suite_dir, input_), 'rb') as f:
        xml = f.read()
        if IRON_PYTHON:
            xml = bytes(xml)
    parse = get_format(xml)
    assert callable(parse)
    uri_filename = input_.rstrip('.xml') + '.uri.txt'
    try:
        with open(os.path.join(test_suite_dir, uri_filename)) as f:
            base_uri = f.read().strip()
    except (IOError, OSError):
        base_uri = 'http://example.com/'
    parsed_feed, _ = parse(xml, feed_url=base_uri)
    parsed_tree = fromstringlist(
        write(parsed_feed, canonical_order=True, hints=False)
    )
    if IRON_PYTHON:
        open_ = functools.partial(io.open, encoding='utf-8')
    elif PY3:
        open_ = functools.partial(open, encoding='utf-8')
    else:
        open_ = open
    with open_(os.path.join(test_suite_dir, expected)) as f:
        expected_tree = fromstringlist(f.read() if IRON_PYTHON else f)
    compare_tree(expected_tree, parsed_tree)


",False
1035,https://github.com/earthreader/libearth/blob/71d2f3246eb0b6a3668a64e2242616d20b1d7dcd/tests/parsing_test.py,,test_parse,"def test_parse(input_, expected):
    with open(os.path.join(test_suite_dir, input_), 'rb') as f:
        xml = f.read()
        if IRON_PYTHON:
            xml = bytes(xml)
    parse = get_format(xml)
    assert callable(parse)
    uri_filename = input_.rstrip('.xml') + '.uri.txt'
    try:
        with open(os.path.join(test_suite_dir, uri_filename)) as f:
            base_uri = f.read().strip()
    except (IOError, OSError):
        base_uri = 'http://example.com/'
    parsed_feed, _ = parse(xml, feed_url=base_uri)
    parsed_tree = fromstringlist(
        write(parsed_feed, canonical_order=True, hints=False)
    )
    if IRON_PYTHON:
        open_ = functools.partial(io.open, encoding='utf-8')
    elif PY3:
        open_ = functools.partial(open, encoding='utf-8')
    else:
        open_ = open
    with open_(os.path.join(test_suite_dir, expected)) as f:
        expected_tree = fromstringlist(f.read() if IRON_PYTHON else f)
    compare_tree(expected_tree, parsed_tree)


",False
1036,https://github.com/earthreader/libearth/blob/71d2f3246eb0b6a3668a64e2242616d20b1d7dcd/tests/parsing_test.py,,test_parse,"def test_parse(input_, expected):
    with open(os.path.join(test_suite_dir, input_), 'rb') as f:
        xml = f.read()
        if IRON_PYTHON:
            xml = bytes(xml)
    parse = get_format(xml)
    assert callable(parse)
    uri_filename = input_.rstrip('.xml') + '.uri.txt'
    try:
        with open(os.path.join(test_suite_dir, uri_filename)) as f:
            base_uri = f.read().strip()
    except (IOError, OSError):
        base_uri = 'http://example.com/'
    parsed_feed, _ = parse(xml, feed_url=base_uri)
    parsed_tree = fromstringlist(
        write(parsed_feed, canonical_order=True, hints=False)
    )
    if IRON_PYTHON:
        open_ = functools.partial(io.open, encoding='utf-8')
    elif PY3:
        open_ = functools.partial(open, encoding='utf-8')
    else:
        open_ = open
    with open_(os.path.join(test_suite_dir, expected)) as f:
        expected_tree = fromstringlist(f.read() if IRON_PYTHON else f)
    compare_tree(expected_tree, parsed_tree)


",False
1037,https://github.com/earthreader/libearth/blob/71d2f3246eb0b6a3668a64e2242616d20b1d7dcd/tests/parsing_test.py,,test_parse,"def test_parse(input_, expected):
    with open(os.path.join(test_suite_dir, input_), 'rb') as f:
        xml = f.read()
        if IRON_PYTHON:
            xml = bytes(xml)
    parse = get_format(xml)
    assert callable(parse)
    uri_filename = input_.rstrip('.xml') + '.uri.txt'
    try:
        with open(os.path.join(test_suite_dir, uri_filename)) as f:
            base_uri = f.read().strip()
    except (IOError, OSError):
        base_uri = 'http://example.com/'
    parsed_feed, _ = parse(xml, feed_url=base_uri)
    parsed_tree = fromstringlist(
        write(parsed_feed, canonical_order=True, hints=False)
    )
    if IRON_PYTHON:
        open_ = functools.partial(io.open, encoding='utf-8')
    elif PY3:
        open_ = functools.partial(open, encoding='utf-8')
    else:
        open_ = open
    with open_(os.path.join(test_suite_dir, expected)) as f:
        expected_tree = fromstringlist(f.read() if IRON_PYTHON else f)
    compare_tree(expected_tree, parsed_tree)


",False
1038,https://github.com/earthreader/libearth/blob/71d2f3246eb0b6a3668a64e2242616d20b1d7dcd/tests/parsing_test.py,,test_parse,"def test_parse(input_, expected):
    with open(os.path.join(test_suite_dir, input_), 'rb') as f:
        xml = f.read()
        if IRON_PYTHON:
            xml = bytes(xml)
    parse = get_format(xml)
    assert callable(parse)
    uri_filename = input_.rstrip('.xml') + '.uri.txt'
    try:
        with open(os.path.join(test_suite_dir, uri_filename)) as f:
            base_uri = f.read().strip()
    except (IOError, OSError):
        base_uri = 'http://example.com/'
    parsed_feed, _ = parse(xml, feed_url=base_uri)
    parsed_tree = fromstringlist(
        write(parsed_feed, canonical_order=True, hints=False)
    )
    if IRON_PYTHON:
        open_ = functools.partial(io.open, encoding='utf-8')
    elif PY3:
        open_ = functools.partial(open, encoding='utf-8')
    else:
        open_ = open
    with open_(os.path.join(test_suite_dir, expected)) as f:
        expected_tree = fromstringlist(f.read() if IRON_PYTHON else f)
    compare_tree(expected_tree, parsed_tree)


",False
1039,https://github.com/earthreader/libearth/blob/71d2f3246eb0b6a3668a64e2242616d20b1d7dcd/tests/parsing_test.py,,test_parse,"def test_parse(input_, expected):
    with open(os.path.join(test_suite_dir, input_), 'rb') as f:
        xml = f.read()
        if IRON_PYTHON:
            xml = bytes(xml)
    parse = get_format(xml)
    assert callable(parse)
    uri_filename = input_.rstrip('.xml') + '.uri.txt'
    try:
        with open(os.path.join(test_suite_dir, uri_filename)) as f:
            base_uri = f.read().strip()
    except (IOError, OSError):
        base_uri = 'http://example.com/'
    parsed_feed, _ = parse(xml, feed_url=base_uri)
    parsed_tree = fromstringlist(
        write(parsed_feed, canonical_order=True, hints=False)
    )
    if IRON_PYTHON:
        open_ = functools.partial(io.open, encoding='utf-8')
    elif PY3:
        open_ = functools.partial(open, encoding='utf-8')
    else:
        open_ = open
    with open_(os.path.join(test_suite_dir, expected)) as f:
        expected_tree = fromstringlist(f.read() if IRON_PYTHON else f)
    compare_tree(expected_tree, parsed_tree)


",False
1040,https://github.com/earthreader/libearth/blob/71d2f3246eb0b6a3668a64e2242616d20b1d7dcd/tests/stage_test.py,,test_get_dir_route,"def test_get_dir_route(fx_session, fx_stage):
    with fx_stage:
        dir = fx_stage.dir_docs
        assert isinstance(dir, Directory)
        assert len(dir) == 2
        assert frozenset(dir) == frozenset(['abc', 'def'])
        with raises(KeyError):
            dir['not-exist']
        doc = dir['abc']
        assert isinstance(doc, TestDoc)
        assert doc.__revision__.session is fx_session
        assert dir['abc'].__revision__ == doc.__revision__


",True
1041,https://github.com/starofrainnight/licenraptor/blob/ed543a2b43b75d733579509a78161928ac29234c/tests/test_db.py,TestRegisterFind,test_exisitng,"def test_exisitng(self, id):
        '''
        Test that an exisitng license can be found
        '''
        assert licenraptor.find(id).id == id


class TestFindByFunction(object):
    '''
    Tests for find_by_function()
    '''

    @pytest.mark.parametrize('multiple', (True, False))
    ",True
1042,https://github.com/starofrainnight/licenraptor/blob/ed543a2b43b75d733579509a78161928ac29234c/tests/test_db.py,TestRegisterFind,test_nonexisting,"def test_nonexisting(self):
        '''
        Test that non-existing license cannot be found
        '''
        with pytest.raises(KeyError):
            licenraptor.find('This is not an existing SPDX identifier')

    @pytest.mark.parametrize('id', ('MIT',))
    ",True
1043,https://github.com/starofrainnight/licenraptor/blob/ed543a2b43b75d733579509a78161928ac29234c/tests/test_db.py,TestRegisterFind,test_register_no_id,"def test_register_no_id(self):
        '''
        Test that License classes cannot be registered without id
        '''
        class FooLicense(base.License):
            pass

        with pytest.raises(AttributeError):
            licenraptor.register(FooLicense)

    ",True
1044,https://github.com/Poogles/limitediterables/blob/3ce3bc28d5c4092db3d5499ad60339c007f4c0e0/tests/test_iterables.py,,test_actual_rate_slower_than_rate_limit,"def test_actual_rate_slower_than_rate_limit():
    """"""Test to check we don't limit a iterator if it's slower already.""""""

    # Create dummy range of numbers.
    target = range(10)

    # Limit is set to be 100 second, with a range of 10
    # that would result in the list being consumed in 0.1s
    slow_iter = iterables.LimitedIterable(target, limit=100)

    start_time = time.perf_counter()
    # For each iteration sleep 0.3, for 10 iterations thats
    # 3 seconds total sleep time.
    consumed_target = []
    for i in slow_iter:
        time.sleep(0.3)
        consumed_target.append(i)
    end_time = time.perf_counter()

    expected = [i for i in target]
    time_taken = end_time - start_time
    assert consumed_target == expected, ""Check to see results are correct.""
    assert time_taken > 2.9, ""Check to see rate limit works low.""
    assert time_taken < 3.1, ""Check to see rate limit works high.""


",True
1045,https://github.com/Poogles/limitediterables/blob/3ce3bc28d5c4092db3d5499ad60339c007f4c0e0/tests/test_iterables.py,,test_rate_limit,"def test_rate_limit():
    """"""Test the rate limiting returns the same values as the parent.""""""

    # Create dummy range of numbers.
    target = range(100)

    slow_iter = iterables.LimitedIterable(target, limit=50)

    start_time = time.perf_counter()
    consumed_target = [i for i in slow_iter]
    end_time = time.perf_counter()

    expected = [i for i in target]

    assert consumed_target == expected, ""Check to see results are correct.""
    time_taken = end_time - start_time
    assert time_taken > 1.9, ""Check to see rate limit works low.""
    assert time_taken < 2.1, ""Check to see rate limit works high.""


",True
1046,https://github.com/Poogles/limitediterables/blob/3ce3bc28d5c4092db3d5499ad60339c007f4c0e0/tests/test_iterables.py,,test_rate_limit_negative,"def test_rate_limit_negative():
    """"""Test the rate limiting returns the same values as the parent.""""""

    # Create dummy range of numbers.
    target = range(100)

    slow_iter = iterables.LimitedIterable(target, limit=-50)

    start_time = time.perf_counter()
    consumed_target = [i for i in slow_iter]
    end_time = time.perf_counter()

    expected = [i for i in target]

    assert consumed_target == expected, ""Check to see results are correct.""
    time_taken = end_time - start_time
    assert time_taken > 1.9, ""Check to see rate limit works low.""
    assert time_taken < 2.1, ""Check to see rate limit works high.""


",True
1047,https://github.com/isac322/linux_aio/blob/007d033b42703e9bb4d7cd99ca50e54108215d46/test/test_non_rw.py,TestNonRW,test_poll,"def test_poll(self):
        with AIOContext(2) as ctx, \
                socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            host_ip = socket.gethostbyname('www.google.com')
            sock.connect((host_ip, 80))
            sock.sendall('GET / HTTP/1.1\r\nHost: www.google.com\r\n\r\n'.encode())

            block = PollBlock(sock, select.EPOLLIN)

            try:
                submit_ret = ctx.submit(block)
                self.assertEqual(1, submit_ret)

                events_ret = ctx.get_events(1, 1)
                self.assertEqual(1, len(events_ret))
                self.assertIsNone(events_ret[0].buffer)
                self.assertIsNone(events_ret[0].stripped_buffer())
                # TODO
                # self.assertTupleEqual(tuple(), events_ret)
            except OSError as err:
                if _linux_ver >= (4, 19):
                    raise
                else:
                    self.assertEqual(errno.EINVAL, err.errno)

        self.assertTrue(ctx.closed)

    ",False
1048,https://github.com/isac322/linux_aio/blob/007d033b42703e9bb4d7cd99ca50e54108215d46/test/test_non_rw.py,TestNonRW,test_poll_modify_masks,"def test_poll_modify_masks(self):
        with AIOContext(2) as ctx, \
                socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            host_ip = socket.gethostbyname('www.google.com')
            sock.connect((host_ip, 80))
            sock.sendall('GET / HTTP/1.1\r\nHost: www.google.com\r\n\r\n'.encode())

            block = PollBlock(sock, select.EPOLLIN)
            block.event_masks |= select.EPOLLOUT
            self.assertEqual(select.EPOLLOUT | select.EPOLLIN, block.event_masks)

            try:
                submit_ret = ctx.submit(block)
                self.assertEqual(1, submit_ret)

                events_ret = ctx.get_events(1, 1)
                self.assertEqual(1, len(events_ret))
                self.assertIsNone(events_ret[0].buffer)
                self.assertIsNone(events_ret[0].stripped_buffer())
                # TODO
                # self.assertTupleEqual(tuple(), events_ret)
            except OSError as err:
                if _linux_ver >= (4, 18):
                    raise
                else:
                    self.assertEqual(errno.EINVAL, err.errno)

        self.assertTrue(ctx.closed)

    ",False
1049,https://github.com/isac322/linux_aio/blob/007d033b42703e9bb4d7cd99ca50e54108215d46/test/test_non_rw.py,TestNonRW,test_poll_wo_initial_masks,"def test_poll_wo_initial_masks(self):
        with AIOContext(2) as ctx, \
                socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            host_ip = socket.gethostbyname('www.google.com')
            sock.connect((host_ip, 80))
            sock.sendall('GET / HTTP/1.1\r\nHost: www.google.com\r\n\r\n'.encode())

            block = PollBlock(sock)

            try:
                submit_ret = ctx.submit(block)
                self.assertEqual(1, submit_ret)

                events_ret = ctx.get_events(1, 1)
                self.assertEqual(1, len(events_ret))
                self.assertIsNone(events_ret[0].buffer)
                self.assertIsNone(events_ret[0].stripped_buffer())
                # TODO
                # self.assertTupleEqual(tuple(), events_ret)
            except OSError as err:
                if _linux_ver >= (4, 19):
                    raise
                else:
                    self.assertEqual(errno.EINVAL, err.errno)

        self.assertTrue(ctx.closed)

    ",False
1050,https://github.com/isac322/linux_aio/blob/007d033b42703e9bb4d7cd99ca50e54108215d46/test/test_non_vector_rw.py,TestRW,test_02_read,"def test_02_read(self):
        with AIOContext(1) as ctx, open(self._TEST_FILE_NAME) as fp:
            block = ReadBlock(fp, bytearray(64))

            submit_ret = ctx.submit(block)
            self.assertEqual(1, submit_ret)

            events = ctx.get_events(1, 1)
            self.assertEqual(1, len(events))

            event = events[0]
            self.assertEqual(self._content.encode(), event.buffer.rstrip(b'\0'))
            self.assertEqual(self._content.encode(), event.stripped_buffer())
            self.assertEqual(block, event.aio_block)
            self.assertEqual(len(self._content), event.response)
            self.assertEqual(0, event.response2)

    ",True
1051,https://github.com/isac322/linux_aio/blob/007d033b42703e9bb4d7cd99ca50e54108215d46/test/test_non_vector_rw.py,TestRW,test_02_read_2_str,"def test_02_read_2_str(self):
        with AIOContext(1) as ctx, open(self._TEST_FILE_NAME) as fp:
            buffer = 'buffer__'
            block = ReadBlock(fp, buffer)
            block.length = len(buffer)
            self.assertEqual(len(buffer), block.length)

            submit_ret = ctx.submit(block)
            self.assertEqual(1, submit_ret)

            events = ctx.get_events(1, 1)
            self.assertEqual(1, len(events))

            event = events[0]
            self.assertEqual(self._content.encode(), event.buffer.rstrip(b'\0'))
            self.assertEqual(self._content.encode(), event.stripped_buffer())
            self.assertEqual(block, event.aio_block)
            self.assertEqual(len(self._content), event.response)
            self.assertEqual(0, event.response2)

    ",True
1052,https://github.com/isac322/linux_aio/blob/007d033b42703e9bb4d7cd99ca50e54108215d46/test/test_non_vector_rw.py,TestRW,test_02_read_replace_file,"def test_02_read_replace_file(self):
        with AIOContext(1) as ctx, open(self._TEST_FILE_NAME) as fp:
            block = ReadBlock(fp, bytearray(64))
            block.file = fp.fileno()

            submit_ret = ctx.submit(block)
            self.assertEqual(1, submit_ret)

            events = ctx.get_events(1, 1)
            self.assertEqual(1, len(events))

            event = events[0]
            self.assertEqual(self._content.encode(), event.buffer.rstrip(b'\0'))
            self.assertEqual(self._content.encode(), event.stripped_buffer())
            self.assertEqual(block, event.aio_block)
            self.assertEqual(len(self._content), event.response)
            self.assertEqual(0, event.response2)

    ",True
1053,https://github.com/isac322/linux_aio/blob/007d033b42703e9bb4d7cd99ca50e54108215d46/test/test_non_vector_rw.py,TestRW,test_02_read_w_io_priority,"def test_02_read_w_io_priority(self):
        with AIOContext(1) as ctx, open(self._TEST_FILE_NAME) as fp:
            block = ReadBlock(fp, bytearray(64), priority_class=IOCBPriorityClass.RT, priority_value=1)
            self.assertEqual(IOCBPriorityClass.RT, block.priority_class)
            self.assertEqual(1, block.priority_value)
            block.set_priority(IOCBPriorityClass.IDLE, 2)
            self.assertEqual(IOCBPriorityClass.IDLE, block.priority_class)
            self.assertEqual(2, block.priority_value)
            block.priority_value = 3
            block.priority_class = IOCBPriorityClass.BE
            self.assertEqual(IOCBPriorityClass.BE, block.priority_class)
            self.assertEqual(3, block.priority_value)

            submit_ret = ctx.submit(block)
            self.assertEqual(1, submit_ret)

            events = ctx.get_events(1, 1)
            self.assertEqual(1, len(events))

            event = events[0]
            self.assertEqual(self._content.encode(), event.buffer.rstrip(b'\0'))
            self.assertEqual(self._content.encode(), event.stripped_buffer())
            self.assertEqual(block, event.aio_block)
            self.assertEqual(len(self._content), event.response)
            self.assertEqual(0, event.response2)

    ",True
1054,https://github.com/isac322/linux_aio/blob/007d033b42703e9bb4d7cd99ca50e54108215d46/test/test_non_vector_rw.py,TestRW,test_02_read_w_non_zero_offset,"def test_02_read_w_non_zero_offset(self):
        with AIOContext(1) as ctx, open(self._TEST_FILE_NAME) as fp:
            block = ReadBlock(fp, bytearray(64))
            block.offset = 1
            self.assertEqual(1, block.offset)

            submit_ret = ctx.submit(block)
            self.assertEqual(1, submit_ret)

            events = ctx.get_events(1, 1)
            self.assertEqual(1, len(events))

            event = events[0]
            self.assertEqual(self._content.encode()[1:], event.buffer.rstrip(b'\0'))
            self.assertEqual(self._content.encode()[1:], event.stripped_buffer())
            self.assertEqual(block, event.aio_block)
            self.assertEqual(len(self._content) - 1, event.response)
            self.assertEqual(0, event.response2)

    ",True
1055,https://github.com/isac322/linux_aio/blob/007d033b42703e9bb4d7cd99ca50e54108215d46/test/test_non_vector_rw.py,TestRW,test_02_read_w_rw_flags,"def test_02_read_w_rw_flags(self):
        with AIOContext(1) as ctx, open(self._TEST_FILE_NAME) as fp:
            block = ReadBlock(fp, bytearray(64))
            block.rw_flag |= IOCBRWFlag.HIPRI

            submit_ret = ctx.submit(block)
            self.assertEqual(1, submit_ret)

            events = ctx.get_events(1, 1)
            self.assertEqual(1, len(events))

            event = events[0]
            self.assertEqual(self._content.encode(), event.buffer.rstrip(b'\0'))
            self.assertEqual(self._content.encode(), event.stripped_buffer())
            self.assertEqual(block, event.aio_block)
            self.assertEqual(len(self._content), event.response)
            self.assertEqual(0, event.response2)

    ",True
1056,https://github.com/JonathanVusich/litedb/blob/2694bc39676d8398f669c0aed96aef89623dbc9a/tests/test_database/test_memory_database_hypothesis.py,TestMemoryDatabase,test_database_retrieve,"def test_database_retrieve(self, value):
        class_choice = self.class_choices[value % 3]
        with pytest.raises(IndexError):
            self.database.select(class_choice).retrieve(bad_index=value)
        if class_choice == BadObject:
            with pytest.raises(IndexError):
                self.database.select(class_choice).retrieve(good_index=value)
        elif class_choice == GoodObject:
            results = self.database.select(class_choice).retrieve(good_index=GoodIndex(value))
            if results:
                for result in results:
                    assert isinstance(result, GoodObject)
                    assert result.good_index == GoodIndex(value)
        elif class_choice == BadAndGoodObject:
            results = self.database.select(class_choice).retrieve(good_index=value)
            if results:
                for result in results:
                    assert isinstance(result, BadAndGoodObject)
                    assert result.good_index == value

    @given(
        value=integers()
    )
    ",True
1057,https://github.com/mahmoud/lithoxyl/blob/9961553a065a1ad8bb7a2407fe74f2cfd6c79a20/lithoxyl/tests/test_rate_sink.py,,test_rate_sink,"def test_rate_sink():
    sink = RateSink()
    logger = Logger('testlog', sinks=[sink])

    for i in range(10):
        with logger.info('sleeping', reraise=False):
            time.sleep(0.02)
            if i % 2:
                raise ValueError()
    test_rates = sink.get_rates()['testlog']['sleeping']
    # TODO: these are a little flaky, esp when moving between
    # environments, runtimes, and with/without coverage, hence the
    # range
    all_lower_limit = 40 if IS_PYPY else 48
    assert all_lower_limit <= round(test_rates['__all__']) <= 51
    assert 22 <= round(test_rates['exception']) <= 26

    counts = sink.get_total_counts()
    assert counts['__all__'] == 10

    assert repr(sink)


",False
1058,https://github.com/mahmoud/lithoxyl/blob/9961553a065a1ad8bb7a2407fe74f2cfd6c79a20/lithoxyl/tests/test_stats.py,,test_acc_random,"def test_acc_random():
    data = test_sets['random.random 0.0-1.0']

    qa = ReservoirAccumulator(data)
    capqa = ReservoirAccumulator(data, cap=True)
    p2qa = P2Accumulator(data)
    for acc in (qa, capqa, p2qa):
        for qp, v in acc.get_quantiles():
            if qp > 0:
                assert 0.95 < (v / qp) < 1.05
",True
1059,https://github.com/mahmoud/lithoxyl/blob/9961553a065a1ad8bb7a2407fe74f2cfd6c79a20/lithoxyl/tests/test_stats.py,,test_momentacc_norm,"def test_momentacc_norm():
    ma = MomentAccumulator()
    for v in [random.gauss(10, 4) for i in range(5000)]:
        ma.add(v)
    _assert_round_cmp(10, abs(ma.mean), mag=1)
    _assert_round_cmp(4, ma.std_dev, mag=1)
    _assert_round_cmp(0, ma.skewness, mag=1)
    _assert_round_cmp(3, ma.kurtosis, mag=1)


",True
1060,https://github.com/daknuett/ljson/blob/1d3dc13001d9d2f61bcfbf9d5c5b16d44fb8076e/test/test_ljson_disk.py,,test_contains,"def test_contains():
	header = ljson.base.generic.Header(header_descriptor)
	table = ljson.base.mem.Table(header, data)
	
	from io import StringIO
	fio = StringIO()
	table.save(fio)
	fio.seek(0)
	table = ljson.base.disk.Table.from_file(fio)

	assert {""lname"": ""griffin""} in table
	assert not {""lname"": ""griffindor""} in table

",True
1061,https://github.com/daknuett/ljson/blob/1d3dc13001d9d2f61bcfbf9d5c5b16d44fb8076e/test/test_ljson_disk.py,,test_delete,"def test_delete(tmpdir):
	import copy
	header = ljson.base.generic.Header(header_descriptor)
	table = ljson.base.mem.Table(header, copy.copy(data))
	import os

	filename = os.path.join(str(tmpdir), ""table.ljson"")

	fio = open(filename, ""w+"")
	table.save(fio)
	fio.seek(0)
	table = ljson.base.disk.Table.from_file(fio)

	data_ = copy.copy(data)

	del(data_[0])

	del(table[{""name"": ""peter""}])

	assert list(table) == data_


	table.additem(item_meg)
	del(table[{""name"": ""meg""}])
	assert list(table) == data_


@pytest.mark.slow
",True
1062,https://github.com/daknuett/ljson/blob/1d3dc13001d9d2f61bcfbf9d5c5b16d44fb8076e/test/test_ljson_disk.py,,test_edit,"def test_edit(tmpdir):
	import copy
	data_ = copy.deepcopy(data)

	filename = os.path.join(str(tmpdir), ""table.ljson"")

	header = ljson.base.generic.Header(header_descriptor)
	table = ljson.base.mem.Table(header, data_)

	fio = open(filename, ""w+"")

	table.save(fio)
	fio.seek(0)

	table = ljson.base.disk.Table.from_file(fio)
	table[{""lname"": ""griffin""}][""lname""] = ""Griffin""
	
	data_ = []

	for row in data:
		row_ = copy.copy(row)
		row_[""lname""] = ""Griffin""
		data_.append(row_)

	assert list(table) == data_

	table.additem(item_meg)

	assert list(table) == data_ + [item_meg]
	
	fio = table.file

	fio.seek(0)

	table_in = ljson.base.mem.Table.from_file(fio)
	table._first_next_call = True

	assert list(table) == list(table_in)

	assert table[{""lname"": ""griffin""}].getone(""name"") == ""meg""
	assert table[{""lname"": ""griffin""}].getone() == item_meg

	fio.seek(0)
	print(fio.readline()) # get rid of the header
	content = fio.read()
	print(content)
	fio.seek(0)
	fio.truncate(0)
	fio.write(content)
	fio.seek(0)
	table = ljson.base.disk.Table.from_file(fio)
	assert list(table) == list(table_in)

	import pytest

	with pytest.raises(RuntimeError):
		for item in table:
			table[{""name"": item[""name""]}][""name""] = item[""name""].upper()

		for d in data_:
			d[""name""] = d[""name""].upper()
		assert list(table) == data_
	table.close()




",True
1063,https://github.com/daknuett/ljson/blob/1d3dc13001d9d2f61bcfbf9d5c5b16d44fb8076e/test/test_ljson_disk.py,,test_read,"def test_read():
	from io import StringIO, BytesIO


	header = ljson.base.generic.Header(header_descriptor)
	table = ljson.base.mem.Table(header, data)

	fio = StringIO()

	table.save(fio)
	fio.seek(0)

	table_in = ljson.base.disk.Table.from_file(fio)

	assert list(table_in) == data

	import pytest

	with pytest.raises(KeyError):
		assert table_in[{""foo"": ""bar""}]

	assert table_in[{""lname"": ""griffin""}][""name""] == [d[""name""] for d in data]

	fio.seek(0)
	fio2 = BytesIO(fio.read().encode(""utf-8""))
	table_in = ljson.base.disk.Table.from_file(fio2)

	assert list(table_in) == data


",True
1064,https://github.com/daknuett/ljson/blob/1d3dc13001d9d2f61bcfbf9d5c5b16d44fb8076e/test/test_ljson_disk.py,,test_unique_check,"def test_unique_check():
	import copy
	from io import StringIO
	header_descriptor_ = copy.copy(header_descriptor)
	header_descriptor_[""name""][""modifiers""] = [""unique""]
	header = ljson.base.generic.Header(header_descriptor_)
	table = ljson.base.mem.Table(header, data)

	fio = StringIO()

	table.save(fio)
	fio.seek(0)

	table = ljson.base.disk.Table.from_file(fio)


	table.additem(item_meg)

	import pytest

	with pytest.raises(ValueError):
		table.additem({""age"": 12, ""name"": ""chris"",
				""lname"": ""griffin""})

",True
1065,https://github.com/daknuett/ljson/blob/1d3dc13001d9d2f61bcfbf9d5c5b16d44fb8076e/test/test_ljson_mem.py,,test_contains,"def test_contains():
	header = ljson.base.generic.Header(header_descriptor)
	table = ljson.base.mem.Table(header, data)


	assert {""lname"": ""griffin""} in table
	assert not {""lname"": ""griffindor""} in table


",True
1066,https://github.com/daknuett/ljson/blob/1d3dc13001d9d2f61bcfbf9d5c5b16d44fb8076e/test/test_ljson_mem.py,,test_edit,"def test_edit():
	import copy
	data_ = copy.copy(data)
	header = ljson.base.generic.Header(header_descriptor)
	table = ljson.base.mem.Table(header, data_)

	table[{""lname"": ""griffin""}][""lname""] = ""Griffin""

	data_ = []

	for row in data:
		row_ = copy.copy(row)
		row_[""lname""] = ""Griffin""
		data_.append(row_)

	assert list(table) == data_

	table.additem(item_meg)
	assert list(table) == data_ + [item_meg]


",True
1067,https://github.com/my8100/logparser/blob/ed7948b271884af68eb3bb13fa9ee51a4892552c/tests/test_telnet.py,,test_disable_telnet,"def test_disable_telnet(psr):
    last_update_timestamp = 0
    runtime = 0
    cwd = os.getcwd()
    os.chdir(cst.DEMO_PROJECT_PATH)
    try:
        version = '1.5.1' if (cst.ON_WINDOWS or on_fedora) else '1.6.0'
        cmd = 'pip install scrapy==%s' % version
        cst.sub_process(cmd, block=True)
        for name in ['enable_telnet', 'disable_telnet']:
            enable_telnet = name == 'enable_telnet'
            parser = psr(execute_main=False, enable_telnet=enable_telnet)
            # Test MyTelnet.verify_log_file_path()
            if enable_telnet:
                for _name in ['6023', '6024']:
                    _log_file = os.path.join(cst.DEMO_PROJECT_LOG_FOLDER_PATH, '%s.log' % _name)
                    cst.write_text(_log_file, TELNET_151_PORT_16023.replace(':16023', ':%s' % _name))

            log_file = os.path.join(cst.DEMO_PROJECT_LOG_FOLDER_PATH, '%s.log' % name)
            cmd = 'scrapy crawl example -s CLOSESPIDER_TIMEOUT=40 -s LOG_FILE=%s' % log_file
            cst.sub_process(cmd)
            time.sleep(10)
            parser.main()
            if enable_telnet:
                log_data = cst.read_data(re.sub(r'.log$', '.json', log_file))
                last_update_timestamp = log_data['crawler_stats']['last_update_timestamp']
                assert last_update_timestamp
                runtime = log_data['crawler_engine']['time()-engine.start_time']
                assert runtime
            time.sleep(10)
            parser.main()
            # Issue #4: Stats collected via telnet are not being updated periodically
            if enable_telnet:
                log_data = cst.read_data(re.sub(r'.log$', '.json', log_file))
                assert log_data['crawler_stats']['last_update_timestamp'] > last_update_timestamp
                assert log_data['crawler_engine']['time()-engine.start_time'] > runtime
            time.sleep(30)
            parser.main()
            log_data = cst.read_data(re.sub(r'.log$', '.json', log_file))
            assert log_data['latest_matches']['scrapy_version'] == version
            assert log_data['latest_matches']['telnet_console']
            assert log_data['crawler_stats']['source'] == 'log'
            if enable_telnet:
                assert log_data['crawler_engine']
            else:
                assert not log_data['crawler_engine']
    except:
        os.chdir(cwd)
        raise
    finally:
        os.chdir(cwd)


",False
1068,https://github.com/djrobstep/logx/blob/c53fabbc160fb8d70fa878684ea36f0c22fd5caa/tests/test_logx.py,,test_formatted_output,"def test_formatted_output(caplog, capsys):
    log.set_default_format()
    log.debug(""debug"")
    assert m(caplog) == ""debug""
    out, err = capsys.readouterr()
    assert out.endswith(""debug\n"")
    assert ""DEBUG [tests.test_logx.test_formatted_output:"" in out
    assert not err


",True
1069,https://github.com/djrobstep/logx/blob/c53fabbc160fb8d70fa878684ea36f0c22fd5caa/tests/test_logx.py,,test_plain_output,"def test_plain_output(caplog, capsys):
    logger_name = log.current_logger_name()
    assert logger_name == ""tests.test_logx""
    FIRST_MESSAGE = ""first message""
    log.info(FIRST_MESSAGE)
    assert m(caplog) == FIRST_MESSAGE
    out, err = capsys.readouterr()
    assert out == FIRST_MESSAGE + ""\n""
    assert not err


",True
1070,https://github.com/djrobstep/logx/blob/c53fabbc160fb8d70fa878684ea36f0c22fd5caa/tests/test_logx.py,,test_set_format,"def test_set_format(caplog, capsys):
    formatstring = '{ ""timestamp"": ""%(asctime)s"", ""severity"": ""%(levelname)s"", ""name"": ""%(name)s"", ""funcName"": ""%(funcName)s"", ""lineNo"": ""%(lineno)d"", ""message"": ""%(message)s""}'
    datefmt = ""%Y-%m-%dT%I:%M:%SZ""
    log.set_format(formatstring, datefmt=datefmt)
    log.debug(""log stuff"")
    output = json.loads(capsys.readouterr().out)
    assert datetime.strptime(output[""timestamp""], datefmt) is not None
    assert output.keys() == json.loads(formatstring).keys()


",True
1071,https://github.com/metachris/logzero/blob/b5d49fc2b118c370994c4ae5360d7c246d43ddc8/tests/test_logzero.py,,test_default_logger_stderr_output,"def test_default_logger_stderr_output(capsys):
    """"""
    Run the ``test_default_logger`` and confirm that the proper data is written to stderr
    """"""
    test_default_logger()
    out, err = capsys.readouterr()
    test_default_logger_output(err)


",True
1072,https://github.com/metachris/logzero/blob/b5d49fc2b118c370994c4ae5360d7c246d43ddc8/tests/test_logzero.py,,test_write_to_logfile_and_stderr,"def test_write_to_logfile_and_stderr(capsys):
    """"""
    Should log to a file.
    """"""
    logzero.reset_default_logger()
    temp = tempfile.NamedTemporaryFile()
    try:
        logger = logzero.setup_logger(logfile=temp.name)
        logger.info(""test log output"")

        _out, err = capsys.readouterr()
        assert "" test_logzero:"" in err
        assert err.endswith(""test log output\n"")

        with open(temp.name) as f:
            content = f.read()
            assert "" test_logzero:"" in content
            assert content.endswith(""test log output\n"")

    finally:
        temp.close()


",True
1073,https://github.com/gradam/lol_api/blob/33ea96f5eeac581737949b733d8af1c4436e94b9/tests/test_daemon.py,TestDaemon,test_short,"def test_short_request_unavailable(self):
        with pytest.raises(RateLimitExceededError):
            for _ in range(11):
                self.api_func(region='euw')

    ",False
1074,https://github.com/stateya/m3u-dump/blob/1ec3eeedb4c650af76c6c66859375ca2d2a6e1bc/tests/test_m3u_dump.py,,test_copy_music_dryrun,"def test_copy_music_dryrun(playlist_current, music_files, dump_music_path):
    playlist_path = str(playlist_current)
    files = list(M3uDump.parse_playlist(playlist_path))

    search_path_files = M3uDump.get_search_path_files(str(music_files))

    playlist = M3uDump.fix_playlist(search_path_files, files)

    M3uDump.copy_music(playlist, dump_music_path, True)

    assert os.path.exists(
        os.path.join(dump_music_path, 'dummy001.mp3')) is False
    assert os.path.exists(
        os.path.join(dump_music_path, 'dummy002.mp3')) is False
    assert os.path.exists(os.path.join(dump_music_path, 'あいう えお.mp3')) is False
    assert os.path.exists(os.path.join(dump_music_path, 'あいう　えお.mp3')) is False


# noinspection PyShadowingNames
",True
1075,https://github.com/mmundy42/mackinac/blob/eccd95394e48f508576af76e6863c9f51f75a5c9/mackinac/test/test_genome.py,TestGenomeBacteroidesThetaiotaomicron,test_get_features_bad_id,"def test_get_features_bad_id(self):
        with pytest.raises(ValueError):
            mackinac.get_genome_features('900.900')

    ",False
1076,https://github.com/wilfredinni/marlin/blob/85f4ae0080ee9a25c1b8d2e481725ac9c42ca99f/tests/test_marlin.py,,test_add_bookmark,"def test_add_bookmark():
    mock_object.add_bookmark()
    bookmark = Path((marlin_path) / 'mock')
    exists = Path(bookmark).exists()
    assert exists is True


",False
1077,https://github.com/wilfredinni/marlin/blob/85f4ae0080ee9a25c1b8d2e481725ac9c42ca99f/tests/test_marlin.py,,test_list_bookmark,"def test_list_bookmark():
    list_bookmark = mock_object.list_bookmark()
    assert isinstance(list_bookmark, list)


",False
1078,https://github.com/wilfredinni/marlin/blob/85f4ae0080ee9a25c1b8d2e481725ac9c42ca99f/tests/test_marlin.py,,test_read_bookmark,"def test_read_bookmark():
    mock_path = mock_object.read_bookmark('mock')
    assert mock_path == 'mock_path'


",True
1079,https://github.com/wilfredinni/marlin/blob/85f4ae0080ee9a25c1b8d2e481725ac9c42ca99f/tests/test_marlin.py,,test_remove_bookmark,"def test_remove_bookmark():
    mock_object.remove_bookmark()
    bookmark = Path((marlin_path) / 'mock')
    exists = Path(bookmark).exists()
    # assert exists is False
    if exists is not False:
        raise AssertionError()
",True
1080,https://github.com/pycqa/mccabe/blob/e92e9e79799c5796f76f3da821dbb5aa56e41028/test_mccabe.py,RegressionTests,test_max_complexity_is_always_an_int,"def test_max_complexity_is_always_an_int(self):
        """"""Ensure bug #32 does not regress.""""""
        class _options(object):
            max_complexity = None

        options = _options()
        options.max_complexity = '16'

        self.assertEqual(0, mccabe.McCabeChecker.max_complexity)
        mccabe.McCabeChecker.parse_options(options)
        self.assertEqual(16, mccabe.McCabeChecker.max_complexity)


if __name__ == ""__main__"":
    unittest.main()
",True
1081,https://github.com/didix21/mdutils/blob/2ef859ecc1e4f1a3e24f4150c96f61180bc57ceb/tests/test_mdutils.py,TestMdUtils,test_create_md_file,"def test_create_md_file(self):
        md_file = MdUtils(""Test_file"")
        md_file.create_md_file()
        md_file_expect = Path('Test_file.md')
        if md_file_expect.is_file():
            os.remove('Test_file.md')
            pass
        else:
            self.fail()

    ",True
1082,https://github.com/didix21/mdutils/blob/2ef859ecc1e4f1a3e24f4150c96f61180bc57ceb/tests/test_mdutils.py,TestMdUtils,test_new_checkbox_checked_list,"def test_new_checkbox_checked_list(self):
        md_file = MdUtils(file_name=""Test_file"", title="""")
        md_file.new_checkbox_list(self.complex_items, checked=True)
        md_file.create_md_file()

        self.assertEqual(self.expected_list.replace('-', '- [x]'), MarkDownFile.read_file('Test_file.md'))
",True
1083,https://github.com/didix21/mdutils/blob/2ef859ecc1e4f1a3e24f4150c96f61180bc57ceb/tests/test_mdutils.py,TestMdUtils,test_new_checkbox_list,"def test_new_checkbox_list(self):
        md_file = MdUtils(file_name=""Test_file"", title="""")
        md_file.new_checkbox_list(self.complex_items)
        md_file.create_md_file()

        self.assertEqual(self.expected_list.replace('-', '- [ ]'), MarkDownFile.read_file('Test_file.md'))

    ",True
1084,https://github.com/didix21/mdutils/blob/2ef859ecc1e4f1a3e24f4150c96f61180bc57ceb/tests/test_mdutils.py,TestMdUtils,test_new_header,"def test_new_header(self):
        file_name = 'Test_file'
        md_file = MdUtils(file_name)
        string_headers_expected = ""\n# Header 0\n\n## Header 1\n\n### Header 2\n\n#### Header 3\n\n"" \
                                  ""##### Header 4\n\n###### Header 5\n""
        string_headers = """"
        for x in range(6):
            string_headers += md_file.new_header(level=(x + 1), title='Header ' + str(x), style='atx')

        self.assertEqual(string_headers, string_headers_expected)
        md_file.create_md_file()
        file_result = md_file.read_md_file(file_name)
        self.assertEqual(file_result, '\n\n\n' + string_headers_expected)

    ",True
1085,https://github.com/didix21/mdutils/blob/2ef859ecc1e4f1a3e24f4150c96f61180bc57ceb/tests/test_mdutils.py,TestMdUtils,test_new_list,"def test_new_list(self):
        md_file = MdUtils(file_name=""Test_file"", title="""")
        md_file.new_list(self.complex_items)
        md_file.create_md_file()

        self.assertEqual(self.expected_list, MarkDownFile.read_file('Test_file.md'))

    ",True
1086,https://github.com/didix21/mdutils/blob/2ef859ecc1e4f1a3e24f4150c96f61180bc57ceb/tests/test_mdutils.py,TestMdUtils,test_new_reference_image_markdown_data,"def test_new_reference_image_markdown_data(self):
        md_file = MdUtils(file_name=""Test_file"", title="""")
        expected_image_1 = '![image_1][reference]'
        expected_image_2 = '![image_2]'
        image_1 = md_file.new_reference_image(text='image_1', path='../image.png', reference_tag=""reference"")
        image_2 = md_file.new_reference_image(text='image_2', path='../image_2.png')

        expected_created_data = ""\n\n\n"" \
                                ""  \n{}"".format(expected_image_1) + \
                                ""  \n{}"".format(expected_image_2) + \
                                ""\n\n\n"" \
                                ""[image_2]: ../image_2.png\n"" \
                                ""[reference]: ../image.png\n""

        md_file.new_line(image_1)
        md_file.new_line(image_2)
        md_file.create_md_file()

        actual_created_data = MarkDownFile.read_file(""Test_file"")

        self.assertEqual(expected_created_data, actual_created_data)

    ",True
1087,https://github.com/didix21/mdutils/blob/2ef859ecc1e4f1a3e24f4150c96f61180bc57ceb/tests/test_mdutils.py,TestMdUtils,test_new_table_of_contents,"def test_new_table_of_contents(self):
        # Create headers level 1 and 2.
        md_file = MdUtils(file_name=""Test_file"", title=""Testing table of contents"")
        list_headers = [""Header 1"", ""Header 1.1"", ""Header 2"", ""Header 2.2"", ""Header 2.3""]
        table_of_content_title = MdUtils(file_name='').new_header(level=1, title='Index', style='setext')
        md_file.new_header(level=1, title=list_headers[0])
        md_file.new_header(level=2, title=list_headers[1])
        md_file.new_header(level=1, title=list_headers[2])
        md_file.new_header(level=2, title=list_headers[3])
        md_file.new_header(level=2, title=list_headers[4])

        # Testing Depth 1
        table_of_contents_result = md_file.new_table_of_contents(table_title=""Index"", depth=1)
        table_of_content_expected = table_of_content_title \
                                    + '\n* [' + list_headers[0] + '](#' \
                                    + re.sub('[^a-z0-9_\-]', '', list_headers[0].lower().replace(' ', '-')) + ')' \
                                    + '\n* [' + list_headers[2] + '](#' \
                                    + re.sub('[^a-z0-9_\-]', '', list_headers[2].lower().replace(' ', '-')) + ')\n'
        self.assertEqual(table_of_contents_result, table_of_content_expected)
        # Testing created file
        md_file.create_md_file()
        data_file_result = MdUtils('').read_md_file('Test_file')
        data_file_expected = MdUtils('').new_header(1, ""Testing table of contents"", 'setext') \
                             + md_file.table_of_contents \
                             + md_file.file_data_text
        self.assertEqual(data_file_result, data_file_expected)
        os.remove('Test_file.md')

        # Testing Depth 2
        md_file = MdUtils(file_name=""Test_file"", title=""Testing table of contents"")
        list_headers = [""Header 1"", ""Header 1.1"", ""Header 2"", ""Header 2.2"", ""Header 2.3""]
        table_of_content_title = MdUtils(file_name='').new_header(level=1, title='Index', style='setext')
        md_file.new_header(level=1, title=list_headers[0])
        md_file.new_header(level=2, title=list_headers[1])
        md_file.new_header(level=1, title=list_headers[2])
        md_file.new_header(level=2, title=list_headers[3])
        md_file.new_header(level=2, title=list_headers[4])

        table_of_contents_result = md_file.new_table_of_contents(table_title=""Index"", depth=2)
        table_of_content_expected = table_of_content_title
        for x in range(len(list_headers)):
            if x in (0, 2):
                table_of_content_expected += '\n* [' + list_headers[x] + '](#' \
                                             + re.sub('[^a-z0-9_\-]', '', list_headers[x].lower().replace(' ', '-')) \
                                             + ')'
            else:
                table_of_content_expected += '\n\t* [' + list_headers[x] + '](#' \
                                             + re.sub('[^a-z0-9_\-]', '', list_headers[x].lower().replace(' ', '-')) \
                                             + ')'
        table_of_content_expected += '\n'
        self.assertEqual(table_of_contents_result, table_of_content_expected)

        md_file.create_md_file()
        data_file_result = MdUtils('').read_md_file('Test_file')
        data_file_expected = MdUtils('').new_header(1, ""Testing table of contents"", 'setext') \
                             + md_file.table_of_contents \
                             + md_file.file_data_text
        self.assertEqual(data_file_result, data_file_expected)
        os.remove('Test_file.md')

    ",True
1088,https://github.com/didix21/mdutils/blob/2ef859ecc1e4f1a3e24f4150c96f61180bc57ceb/tests/test_mdutils.py,TestMdUtils,test_references_placed_in_markdown_file,"def test_references_placed_in_markdown_file(self):
        md_file = MdUtils(file_name=""Test_file"", title="""")

        text = ""mdutils library""
        reference_tag = ""mdutils library""
        link = ""https://github.com/didix21/mdutils""

        expected_value = ""\n\n\n[mdutils library0][mdutils library0]\n"" \
                         ""[mdutils library1][mdutils library1]\n"" \
                         ""[mdutils library2][mdutils library2]\n"" \
                         ""[mdutils library3][mdutils library3]\n"" \
                         ""\n\n\n"" \
                         ""[mdutils library0]: https://github.com/didix21/mdutils0\n"" \
                         ""[mdutils library1]: https://github.com/didix21/mdutils1\n"" \
                         ""[mdutils library2]: https://github.com/didix21/mdutils2\n"" \
                         ""[mdutils library3]: https://github.com/didix21/mdutils3\n""

        for i in range(4):
            md_file.write(md_file.new_reference_link(
                link=link + str(i),
                text=text + str(i),
                reference_tag=reference_tag + str(i)))
            md_file.write('\n')

        md_file.create_md_file()

        created_data = MarkDownFile.read_file('Test_file.md')

        self.assertEqual(expected_value, created_data)

    ",True
1089,https://github.com/ozzywalsh/metcli/blob/4658176034cea68955849bf488494c8ce3ffcbcd/metcli/test_metcli.py,,test_met_request_should_handle_connection_problem,"def test_met_request_should_handle_connection_problem(capsys):
    with requests_mock.Mocker() as m:
        m.get('https://www.met.ie/api/weather/national',
              exc=requests.exceptions.ConnectionError)

        with pytest.raises(SystemExit) as excinfo:
            metcli.met_request('weather/national')

        assert str(excinfo.value.code) == 'There was a problem connecting to Met Éireann.'


",True
1090,https://github.com/ozzywalsh/metcli/blob/4658176034cea68955849bf488494c8ce3ffcbcd/metcli/test_metcli.py,,test_met_request_should_return_dict,"def test_met_request_should_return_dict():
    session = requests.Session()
    adapter = requests_mock.Adapter()
    session.mount('mock', adapter)

    json_data = '{""name"": ""Bob""}'

    with requests_mock.mock() as m:
        m.get('https://www.met.ie/api/weather/national', text=json_data)
        result = metcli.met_request('weather/national')

        assert isinstance(result, dict)


",True
1091,https://github.com/maximdanilchenko/mgun/blob/11540dd661afd2e8a18dd74ca0a5b416f671a4a1/tests/test_mgun.py,TestHttpRequests,test_post,"def test_post(self, client):
        data = {'data': [1, 2, 3]}
        response = client.post_.post(data)
        assert response.status == 200
        assert json.loads(response.data['data']) == data
        print(response)

    ",False
1092,https://github.com/Craven-Biostat-Lab/mihifepe/blob/7f03e4413d1e42e9265d790cb64c41f34dbea5ab/tests/test_mihifepe.py,,test_simulation_gaussian_noise,"def test_simulation_gaussian_noise(file_regression, tmpdir):
    """"""Test simulation with clustering hierarchy""""""
    func_name = sys._getframe().f_code.co_name
    output_dir = ""%s/output_dir_%s"" % (tmpdir, func_name)
    pvalues_filename = ""%s/%s"" % (output_dir, constants.PVALUES_FILENAME)
    cmd = (""python -m mihifepe.simulation -seed 4 -num_instances 100 -num_features 10 -fraction_relevant_features 0.5""
           "" -contiguous_node_names -hierarchy_type random -perturbation zeroing -noise_multiplier 0.1 -noise_type additive_gaussian""
           "" -output_dir %s"" % output_dir)
    pass_args = cmd.split()[2:]
    with patch.object(sys, 'argv', pass_args):
        simulation.main()
    with open(pvalues_filename, ""r"") as pvalues_file:
        pvalues = sorted(pvalues_file.readlines())
    file_regression.check(""\n"".join(pvalues), extension=""_pvalues.csv"")
    fdr_filename = ""%s/%s/%s.csv"" % (output_dir, constants.HIERARCHICAL_FDR_DIR, constants.HIERARCHICAL_FDR_OUTPUTS)
    with open(fdr_filename, ""r"") as fdr_file:
        fdr = sorted(fdr_file.readlines())
    file_regression.check(""\n"".join(fdr), extension=""_fdr.json"")


",False
1093,https://github.com/Craven-Biostat-Lab/mihifepe/blob/7f03e4413d1e42e9265d790cb64c41f34dbea5ab/tests/test_mihifepe.py,,test_simulation_noisy_interactions,"def test_simulation_noisy_interactions(file_regression, tmpdir):
    """"""Test simulation with interactions and noisy model""""""
    func_name = sys._getframe().f_code.co_name
    output_dir = ""%s/output_dir_%s"" % (tmpdir, func_name)
    pvalues_filename = ""%s/%s"" % (output_dir, constants.INTERACTIONS_PVALUES_FILENAME)
    cmd = (""python -m mihifepe.simulation -seed 5 -num_instances 100 -num_features 10 -fraction_relevant_features 0.5""
           "" -analyze_interactions -hierarchy_type random -perturbation zeroing -noise_multiplier 0.1 -noise_type additive_gaussian""
           "" -num_interactions 3 -output_dir %s"" % output_dir)
    pass_args = cmd.split()[2:]
    with patch.object(sys, 'argv', pass_args):
        simulation.main()
    with open(pvalues_filename, ""r"") as pvalues_file:
        pvalues = sorted(pvalues_file.readlines())
    file_regression.check(""\n"".join(pvalues), extension=""_pvalues.csv"")
    fdr_filename = ""%s/%s/%s.csv"" % (output_dir, constants.INTERACTIONS_FDR_DIR, constants.HIERARCHICAL_FDR_OUTPUTS)
    with open(fdr_filename, ""r"") as fdr_file:
        fdr = sorted(fdr_file.readlines())
    file_regression.check(""\n"".join(fdr), extension=""_fdr.json"")


",False
1094,https://github.com/Craven-Biostat-Lab/mihifepe/blob/7f03e4413d1e42e9265d790cb64c41f34dbea5ab/tests/test_mihifepe.py,,test_simulation_random_hierarchy,"def test_simulation_random_hierarchy(file_regression, tmpdir):
    """"""Test simulation with random hierarchy""""""
    func_name = sys._getframe().f_code.co_name
    output_dir = ""%s/output_dir_%s"" % (tmpdir, func_name)
    pvalues_filename = ""%s/%s"" % (output_dir, constants.PVALUES_FILENAME)
    cmd = (""python -m mihifepe.simulation -seed 1 -num_instances 100 -num_features 10 -fraction_relevant_features 0.5""
           "" -contiguous_node_names -hierarchy_type random -perturbation zeroing -no-condor-cleanup -output_dir %s"" % output_dir)
    pass_args = cmd.split()[2:]
    with patch.object(sys, 'argv', pass_args):
        simulation.main()
    with open(pvalues_filename, ""r"") as pvalues_file:
        pvalues = sorted(pvalues_file.readlines())
    file_regression.check(""\n"".join(pvalues), extension=""_pvalues.csv"")
    fdr_filename = ""%s/%s/%s.csv"" % (output_dir, constants.HIERARCHICAL_FDR_DIR, constants.HIERARCHICAL_FDR_OUTPUTS)
    with open(fdr_filename, ""r"") as fdr_file:
        fdr = sorted(fdr_file.readlines())
    file_regression.check(""\n"".join(fdr), extension=""_fdr.json"")


",False
1095,https://github.com/Craven-Biostat-Lab/mihifepe/blob/7f03e4413d1e42e9265d790cb64c41f34dbea5ab/tests/test_mihifepe.py,,test_simulation_shuffling_interactions,"def test_simulation_shuffling_interactions(file_regression, tmpdir):
    """"""Test simulation with interactions and shuffling perturbations""""""
    func_name = sys._getframe().f_code.co_name
    output_dir = ""%s/output_dir_%s"" % (tmpdir, func_name)
    pvalues_filename = ""%s/%s"" % (output_dir, constants.INTERACTIONS_PVALUES_FILENAME)
    cmd = (""python -m mihifepe.simulation -seed 5 -num_instances 1000 -num_features 10 -fraction_relevant_features 0.5""
           "" -analyze_interactions -hierarchy_type random -perturbation shuffling -num_shuffling_trials 200""
           "" -noise_multiplier 0.0 -noise_type additive_gaussian -num_interactions 3 -output_dir %s"" % output_dir)
    pass_args = cmd.split()[2:]
    with patch.object(sys, 'argv', pass_args):
        simulation.main()
    with open(pvalues_filename, ""r"") as pvalues_file:
        pvalues = sorted(pvalues_file.readlines())
    file_regression.check(""\n"".join(pvalues), extension=""_pvalues.csv"")
    fdr_filename = ""%s/%s/%s.csv"" % (output_dir, constants.INTERACTIONS_FDR_DIR, constants.HIERARCHICAL_FDR_OUTPUTS)
    with open(fdr_filename, ""r"") as fdr_file:
        fdr = sorted(fdr_file.readlines())
    file_regression.check(""\n"".join(fdr), extension=""_fdr.json"")
",False
1096,https://github.com/attzonko/mmpy_bot/blob/4faa19a9e04c75af94c45c24dbd0c9d9ecb867d4/tests/unit_tests/test_scheduler.py,,test_add_onetime_job_with_trigger_time,"def test_add_onetime_job_with_trigger_time(my_schedule):
    run_time = datetime.now() + timedelta(seconds=2)
    my_schedule.once(run_time).do(foo, msg='hello')
    if len(my_schedule.jobs) != 1:
        raise AssertionError(""Job is not added to schedule."")
    time.sleep(3)  # wait for worker threads to start
    my_schedule.run_pending()
    if len(my_schedule.jobs) != 0:
        raise AssertionError(""Job is not executed by schedule."")


",True
1097,https://github.com/attzonko/mmpy_bot/blob/4faa19a9e04c75af94c45c24dbd0c9d9ecb867d4/tests/unit_tests/test_scheduler.py,,test_add_onetime_job_without_trigger_time,"def test_add_onetime_job_without_trigger_time(my_schedule):
    my_schedule.once().do(foo, msg='hello')
    if len(my_schedule.jobs) != 1:
        raise AssertionError(""Job is not added to schedule."")
    time.sleep(1)  # wait for worker threads to start
    my_schedule.run_pending()
    if len(my_schedule.jobs) != 0:
        raise AssertionError(""Job is not executed by schedule."")


",True
1098,https://github.com/runwayml/model-sdk/blob/3132b2ab424f1020e8d30e4897057103ab3e6623/tests/test_model.py,,test_inference_async_provide_id,"def test_inference_async_provide_id():
    rw = RunwayModel()

    @rw.command('test_command', inputs={ 'input': number }, outputs = { 'output': text })
    ",False
1099,https://github.com/runwayml/model-sdk/blob/3132b2ab424f1020e8d30e4897057103ab3e6623/tests/test_model.py,,test_model_setup_and_command,"def test_model_setup_and_command():

    # use a dict to share state across function scopes. This makes up for the
    # fact that Python 2.x doesn't have support for the 'nonlocal' keyword.
    closure = dict(setup_ran = False, command_ran = False)

    expected_manifest = {
        'modelSDKVersion': model_sdk_version,
        'millisRunning': None,
        'millisSinceLastCommand': None,
        'GPU': os.environ.get('GPU', False),
        'options': [{
            'type': 'category',
            'name': 'size',
            'oneOf': ['big', 'small'],
            'default': 'big',
            'description': 'The size of the model. Bigger is better but also slower.',
        }],
        'commands': [{
            'name': 'test_command',
            'description': None,
            'inputs': [{
                'type': 'text',
                'name': 'input',
                'description': 'Some input text.',
                'default': '',
                'minLength': 0
            }],
            'outputs': [{
                'type': 'number',
                'name': 'output',
                'description': 'An output number.',
                'default': 0
            }]
        }]
    }

    rw = RunwayModel()

    description = 'The size of the model. Bigger is better but also slower.'
    @rw.setup(options={ 'size': category(choices=['big', 'small'], description=description) })
    ",True
1100,https://github.com/butla/mountepy/blob/796595f0011cc4a62cd7796dd71c3681008a4731/tests/test_http_service.py,,test_service_start_timeout_and_cleanup,"def test_service_start_timeout_and_cleanup():
    never_starting_service = os.path.join(os.path.dirname(__file__), 'never_starting_service.py')
    test_service = HttpService([sys.executable, never_starting_service, '{port}'])

    with pytest.raises(TimeoutError):
        # If this timeout is lower, then the test can sometimes fail.
        # It looks like Python can ignore SIGINT in the early process startup,
        # but this needs to be verified.
        # This wouldn't be a problem with SIGTERM.
        test_service.start(timeout=0.1)
    test_service._service_proc.wait(timeout=1.0)


",False
1101,https://github.com/butla/mountepy/blob/796595f0011cc4a62cd7796dd71c3681008a4731/tests/test_mb_mgmt.py,,test_check_mb_install_false,"def test_check_mb_install_false(monkeypatch):
    monkeypatch.setattr(
        'mountepy.mb_mgmt.MB_INSTALL_CHECK_CMD',
        ['asdasdqwerfbvc'])
    assert not mb_mgmt._check_mb_install()


",False
1102,https://github.com/butla/mountepy/blob/796595f0011cc4a62cd7796dd71c3681008a4731/tests/test_mountebank.py,,test_existing_mountebank_simple_imposter,"def test_existing_mountebank_simple_imposter():
    mb_port = port_for.select_random()
    test_port = port_for.select_random()
    test_response = 'Just some reponse body (that I used to know)'
    test_body = 'Some test message body'

    mb_process = subprocess.Popen(get_mb_command() + ['--mock', '--port', str(mb_port)])
    with ExistingMountebank('localhost', mb_port) as mb:
        imposter = mb.add_imposter_simple(
            port=test_port,
            method='POST',
            path='/some-path',
            status_code=201,
            response=test_response
        )

        response = requests.post('http://localhost:{}/some-path'.format(test_port), data=test_body)
        assert response.status_code == 201
        assert response.text == test_response
        assert imposter.wait_for_requests()[0].body == test_body

    mb_process.terminate()
",False
1103,https://github.com/butla/mountepy/blob/796595f0011cc4a62cd7796dd71c3681008a4731/tests/test_mountebank.py,,test_impostor_destroy,"def test_impostor_destroy():
    with Mountebank() as mb:
        imposter = mb.add_imposter_simple()
        imposter.destroy()
        with pytest.raises(requests.exceptions.ConnectionError):
            requests.get('http://localhost:{}'.format(imposter.port))


",False
1104,https://github.com/butla/mountepy/blob/796595f0011cc4a62cd7796dd71c3681008a4731/tests/test_mountebank.py,,test_impostor_get_matches_timeout,"def test_impostor_get_matches_timeout():
    with Mountebank() as mb:
        imposter = mb.add_imposter_simple()
        with pytest.raises(TimeoutError):
            imposter.wait_for_requests(timeout=0.001)


",False
1105,https://github.com/butla/mountepy/blob/796595f0011cc4a62cd7796dd71c3681008a4731/tests/test_mountebank.py,,test_mountebank_multiple_simple_impostors,"def test_mountebank_multiple_simple_impostors():
    test_port = port_for.select_random()
    test_response_1 = 'Just some response body (that I used to know)'
    test_response_2 = '{""Hey"": ""a JSON!""}'
    stub_1 = HttpStub(method='PUT', path='/path-1', status_code=201, response=test_response_1)
    stub_2 = HttpStub(method='POST', path='/path-2', status_code=202, response=test_response_2)

    with Mountebank() as mb:
        mb.add_multi_stub_imposter_simple(
            port=test_port,
            stubs=[stub_1, stub_2]
        )

        # TODO get rid of the code duplication
        response_1 = requests.put('http://localhost:{}/path-1'.format(test_port))
        assert response_1.status_code == 201
        assert response_1.text == test_response_1
        response_2 = requests.post('http://localhost:{}/path-2'.format(test_port))
        assert response_2.status_code == 202
        assert response_2.text == test_response_2


",False
1106,https://github.com/butla/mountepy/blob/796595f0011cc4a62cd7796dd71c3681008a4731/tests/test_mountebank.py,,test_mountebank_reset,"def test_mountebank_reset():
    test_port = port_for.select_random()
    with Mountebank() as mb:
        imposters_url = 'http://localhost:{}/imposters'.format(mb.port)
        mb.add_imposter_simple(
            port=test_port,
            method='GET',
            path='/',
            status_code=200,
            response=''
        )
        assert requests.get(imposters_url).json()['imposters'] != []
        mb.reset()
        assert requests.get(imposters_url).json()['imposters'] == []


",False
1107,https://github.com/butla/mountepy/blob/796595f0011cc4a62cd7796dd71c3681008a4731/tests/test_mountebank.py,,test_mountebank_set_impostor_and_cleanup,"def test_mountebank_set_impostor_and_cleanup():
    test_response = 333
    stub_port = 4545
    imposter_config = {
        ""port"": stub_port,
        ""protocol"": ""http"",
        ""stubs"": [
            {
                ""responses"": [
                    {
                        ""is"": {
                            ""statusCode"": 200,
                            ""headers"": {
                                ""Content-Type"": ""application/json""
                            },
                            ""body"": test_response
                        }
                    }
                ],
                ""predicates"": [
                    {
                        ""and"": [
                            {
                                ""equals"": {
                                    ""path"": ""/"",
                                    ""method"": ""GET"",
                                }
                            },
                        ]
                    }
                ]
            }
        ]
    }

    with Mountebank() as mb:
        mb.add_imposter(imposter_config)
        stub_address = 'http://localhost:{}'.format(stub_port)
        assert requests.get(stub_address).json() == test_response

    # process should be closed now
    with pytest.raises(requests.exceptions.ConnectionError):
        mb.add_imposter(imposter_config)


",False
1108,https://github.com/butla/mountepy/blob/796595f0011cc4a62cd7796dd71c3681008a4731/tests/test_mountebank.py,,test_mountebank_simple_impostor,"def test_mountebank_simple_impostor():
    test_port = port_for.select_random()
    test_response = 'Just some reponse body (that I used to know)'
    test_body = 'Some test message body'

    with Mountebank() as mb:
        imposter = mb.add_imposter_simple(
            port=test_port,
            method='POST',
            path='/some-path',
            status_code=201,
            response=test_response
        )

        response = requests.post('http://localhost:{}/some-path'.format(test_port), data=test_body)
        assert response.status_code == 201
        assert response.text == test_response
        assert imposter.wait_for_requests()[0].body == test_body


",False
1109,https://github.com/moyasar/moyasar-python/blob/aa8716ae3f98f8782141abe6869dfbb90af98b62/tests/moyasar_test.py,,test_request_should_return_json_object,"def test_request_should_return_json_object():
    ss.stub_server_request(method='GET', url=moyasar.api_url + '/payments',
                           resource=f.payments, status=200)
    response = moyasar.request('GET', moyasar.api_url + '/payments', None)
    assert isinstance(response.json(), dict)
",True
1110,https://github.com/sushobhit27/multiindex/blob/b631e60bd47558eca9067a0dc87f0e713cddc6f2/multiindex/tests/test_multiindex.py,,test_insert,"def test_insert(mi, emp_seq):
    assert emp_seq[3] == mi.get('first_name', 'Shawn')
    assert emp_seq[0] == mi.get('emp_id', 786)
    assert mi.get('emp_id', 321) is None
    assert emp_seq[0] == mi.get('first_name', 'Steve')
    assert emp_seq[1] == mi.get('last_name', 'Hart')
    assert emp_seq[2] == mi.get('last_name', 'Ramon')


",True
1111,https://github.com/sushobhit27/multiindex/blob/b631e60bd47558eca9067a0dc87f0e713cddc6f2/multiindex/tests/test_multiindex.py,,test_insert_overwrite,"def test_insert_overwrite(mi, emp_seq):
    assert emp_seq[3] == mi.get('first_name', 'Shawn')
    assert emp_seq[0] == mi.get('emp_id', 786)
    assert mi.get('emp_id', 321) is None
    assert emp_seq[0] == mi.get('first_name', 'Steve')
    assert emp_seq[1] == mi.get('last_name', 'Hart')
    assert emp_seq[2] == mi.get('last_name', 'Ramon')
    mi.insert(Employee('Steve', 'Austin', 123), overwrite=True)
    assert mi.get('first_name', 'Steve').emp_id == 123
    mi.insert(Employee('Razor', 'Topaz', 8732), overwrite=True)
    assert mi.get('emp_id', 8732).last_name == 'Topaz'
    assert mi.get('first_name', 'Razor').emp_id == 8732


",True
1112,https://github.com/sushobhit27/multiindex/blob/b631e60bd47558eca9067a0dc87f0e713cddc6f2/multiindex/tests/test_multiindex.py,,test_remove,"def test_remove(mi):
    mi.remove('emp_id', 666)
    assert mi.get('emp_id', 666) is None


",True
1113,https://github.com/sushobhit27/multiindex/blob/b631e60bd47558eca9067a0dc87f0e713cddc6f2/multiindex/tests/test_multiindex_hashed_non_unique.py,,test_insert,"def test_insert(mi, potus_seq):
    assert [potus_seq[4]] == mi.get('first_name', 'Barack')
    assert [potus_seq[2]] == mi.get('assumed_ofc_at', 43)
    assert None is mi.get('assumed_ofc_at', 0)
    assert None is mi.get('assumed_ofc_at', 786)
    assert [potus_seq[3]] == mi.get('last_name', 'Bush')
    assert [potus_seq[5]] == mi.get('first_name', 'Franklin')
    assert [potus_seq[1]] == mi.get('first_name', 'Thomas')

    for potus in mi.get('first_name', 'George'):
        assert potus in [potus_seq[3], potus_seq[0]]



",True
1114,https://github.com/0xHJK/music-dl/blob/883b643d62c63496572f5b883f76359324a5c853/tests/test_addon_kugou.py,,test_kugou,"def test_kugou():
    songs_list = kugou.search(""周杰伦"")
    assert songs_list is not None
",False
1115,https://github.com/Vnet-as/myr-base/blob/56e347b4f4d70f53a6afe55e96c1f9e35f5454eb/tests/test_base.py,TestApp,test_announcing_no_tasks,"def test_announcing_no_tasks(self, mocker):
        class Task:
            app = MyrApp()

        mocker.patch.object(Task.app, 'send_task')

        announce(Task)
        Task.app.send_task.assert_called_with(
            ENV.get('MYR_ANNOUNCE_TASK'),
            args=[{}],
            queue=ENV.get('MYR_ANNOUNCE_QUEUE'))

    ",True
1116,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_json,"def test_report_json():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""json"",
                ""analysis"",
                ""report"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert json.loads(result.output)[0] == json.loads(ISSUES_RESPONSE.to_json())
        assert result.exit_code == 0


",True
1117,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_json_blacklist,"def test_report_json_blacklist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""json"",
                ""analysis"",
                ""report"",
                ""--swc-blacklist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert all(
            x[""swcID""] != ""SWC-110"" for x in json.loads(result.output)[0][0][""issues""]
        )
        assert result.exit_code == 0


",True
1118,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_json_pretty,"def test_report_json_pretty():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""json-pretty"",
                ""analysis"",
                ""report"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert json.loads(result.output)[0] == json.loads(ISSUES_RESPONSE.to_json())
        assert result.exit_code == 0


",True
1119,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_json_pretty_blacklist,"def test_report_json_pretty_blacklist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""json-pretty"",
                ""analysis"",
                ""report"",
                ""--swc-blacklist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert all(
            x[""swcID""] != ""SWC-110"" for x in json.loads(result.output)[0][0][""issues""]
        )
        assert result.exit_code == 0


",True
1120,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_json_pretty_whitelist,"def test_report_json_pretty_whitelist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""json-pretty"",
                ""analysis"",
                ""report"",
                ""--swc-whitelist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert all(
            x[""swcID""] == ""SWC-110"" for x in json.loads(result.output)[0][0][""issues""]
        )
        assert result.exit_code == 0


",True
1121,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_json_whitelist,"def test_report_json_whitelist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""json"",
                ""analysis"",
                ""report"",
                ""--swc-whitelist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert all(
            x[""swcID""] == ""SWC-110"" for x in json.loads(result.output)[0][0][""issues""]
        )
        assert result.exit_code == 0


",True
1122,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_simple,"def test_report_simple():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""simple"",
                ""analysis"",
                ""report"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert result.output == ISSUES_SIMPLE
        assert result.exit_code == 0


",True
1123,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_simple_blacklist,"def test_report_simple_blacklist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""simple"",
                ""analysis"",
                ""report"",
                ""--swc-blacklist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert ""Assert Violation"" not in result.output
        assert result.exit_code == 0


",True
1124,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_simple_whitelist,"def test_report_simple_whitelist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""simple"",
                ""analysis"",
                ""report"",
                ""--swc-whitelist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )
        assert ""Assert Violation"" in result.output
        assert result.exit_code == 0


",True
1125,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_sonar_blacklist,"def test_report_sonar_blacklist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""sonar"",
                ""analysis"",
                ""report"",
                ""--swc-blacklist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert all(x[""forRule""] != ""SWC-110"" for x in json.loads(result.output))
        assert result.exit_code == 0


",True
1126,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_sonar_whitelist,"def test_report_sonar_whitelist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""--format"",
                ""sonar"",
                ""analysis"",
                ""report"",
                ""--swc-whitelist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert all(x[""forRule""] == ""SWC-110"" for x in json.loads(result.output))
        assert result.exit_code == 0


",True
1127,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_tabular,"def test_report_tabular():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli, [""analysis"", ""report"", ""ab9092f7-54d0-480f-9b63-1bb1508280e2""]
        )

        assert result.output == ISSUES_TABLE
        assert result.exit_code == 0


",True
1128,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_tabular_blacklist,"def test_report_tabular_blacklist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""analysis"",
                ""report"",
                ""--swc-blacklist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert ""Assert Violation"" not in result.output
        assert (
            ""/home/spoons/diligence/mythx-qa/land/contracts/estate/EstateStorage.sol""
            not in result.output
        )
        assert result.exit_code == 0


",True
1129,https://github.com/dmuhs/mythx-cli/blob/f6b3d20d51ca1cfaed3cd45226bd1074388d42b9/tests/test_report.py,,test_report_tabular_whitelist,"def test_report_tabular_whitelist():
    runner = CliRunner()
    with mock_context():
        result = runner.invoke(
            cli,
            [
                ""analysis"",
                ""report"",
                ""--swc-whitelist"",
                ""SWC-110"",
                ""ab9092f7-54d0-480f-9b63-1bb1508280e2"",
            ],
        )

        assert ""Assert Violation"" in result.output
        assert (
            ""/home/spoons/diligence/mythx-qa/land/contracts/estate/EstateStorage.sol""
            in result.output
        )
        assert result.exit_code == 0


",True
1130,https://github.com/napalm-automation/napalm/blob/0e23a55f52221e528be66c1f06a141f937e842f7/test/pyiosxr/test_iosxr.py,TestIOSXRDevice,test_lock_raises_LockError,"def test_lock_raises_LockError(self):

        """"""Tests if DB already locked raises LockError""""""

        if self.MOCK:
            self.assertRaises(LockError, self.device.lock)
            self.assertFalse(self.device.locked)
        else:
            self.device.unlock()  # make sure the config is not locked
            same_device = IOSXR(
                self.HOSTNAME,
                self.USERNAME,
                self.PASSWORD,
                port=self.PORT,
                lock=self.LOCK,
                logfile=self.LOG,
                timeout=self.TIMEOUT,
            )
            same_device.open()
            same_device.lock()
            # the other instance locks the config DB

            try:
                # trying to acquire the config DB
                self.device.lock()
            except LockError:
                self.assertFalse(self.device.locked)
            else:
                self.assertTrue(self.device.locked)

            same_device.close()

    ",True
1131,https://github.com/napalm-automation/napalm/blob/0e23a55f52221e528be66c1f06a141f937e842f7/test/pyiosxr/test_iosxr.py,TestIOSXRDevice,test_mock_lock_connection_open,"def test_mock_lock_connection_open(self):

        if self.MOCK:
            self.device.lock_on_connect = True
            # because there's one single mock file
            # and it is already used for the lock test
            # will tesst if raises LockError on connect
            self.assertRaises(LockError, self.device.lock)
            self.device.lock_on_connect = False
            # enough to see that will try to lock during connect

    ",True
1132,https://github.com/mrmechko/neon/blob/42ad78e3d79583a93abce6d06b81dafc29017514/tests/basic_tests.py,,test_dont_memoize,"def test_dont_memoize():
    assert foo({}) == {}
    assert foo not in MEMO
    assert any([m.__name__ == ""fib"" for m in MEMO])
",True
1133,https://github.com/strizhechenko/netutils-linux/blob/dfcb0900ffffa3020656338bbab123f6da00a168/netutils_linux_tuning/test_rx_buffers.py,RxBuffersTuneTest,test_all,"def test_all(self):
        for max_buffer in self.dataset:
            for current, expected in self.dataset[max_buffer]:
                self.assertEqual(self.tune.eval_prefered_size(current, max_buffer, self.default_upper_bound), expected)


",True
1134,https://github.com/neurodsp-tools/neurodsp/blob/19aa50c71deaa19e4ed85efa192afa8ab63d0bf1/neurodsp/tests/utils/test_download.py,,test_check_data_file,"def test_check_data_file():

    filename = 'sample_data_1.npy'

    check_data_file(filename, TEST_FOLDER)
    assert os.path.isfile(os.path.join(TEST_FOLDER, filename))

",True
1135,https://github.com/thimic/nodal/blob/261eeefd50298765c5722c5f7da72e6f2927bd3e/tests/nodal/nodes/test_noop.py,TestNoOp,test_name,"def test_name(self):
        noop = nodal.nodes.NoOp()
        self.assertEqual('NoOp1', noop.name)
        noop.name = 'FooOp'
        self.assertEqual('FooOp', noop.name)

    ",True
1136,https://github.com/thimic/nodal/blob/261eeefd50298765c5722c5f7da72e6f2927bd3e/tests/nodal/test_graph.py,TestGraph,test__on_node_create,"def test__on_node_create(self):
        with self.graph:
            noop1 = self.graph.create_node('NoOp')
            self.assertEqual(noop1.name, 'NoOp1')

            noop2 = nodal.nodes.NoOp()
            self.assertEqual(noop2.name, 'NoOp2')

            noop3 = self.graph.create_node('NoOp')
            self.assertEqual(noop3.name, 'NoOp3')

            noop4 = self.graph.create_node('NoOp', name='FooOp')
            self.assertEqual(noop4.name, 'FooOp1')

            output = nodal.nodes.Output()
            self.assertEqual(output.name, 'Output1')

    ",True
1137,https://github.com/thimic/nodal/blob/261eeefd50298765c5722c5f7da72e6f2927bd3e/tests/nodal/test_graph.py,TestGraph,test__on_node_destroy,"def test__on_node_destroy(self):

        with self.graph:

            # Create 3 NoOps
            noop1 = self.graph.create_node('NoOp')
            noop2 = nodal.nodes.NoOp()
            noop3 = self.graph.create_node('NoOp')

            # Delete two NoOps and check that we are left with one
            self.graph.delete_node(noop3)
            noop2.delete()
            self.assertEqual(self.graph.nodes, [noop1])

            # Create new NoOp and check that it gets named as expected
            noop2 = nodal.nodes.NoOp()
            self.assertEqual(noop2.name, 'NoOp2')

    ",True
1138,https://github.com/pv8/noipy/blob/c35add5386b57547c5a72650145a267dc88fa77e/test/test_noipy.py,PluginsTest,test_dyndns_plugin,"def test_dyndns_plugin(self):
        cmd_args = [""-u"", ""test"", ""-p"", ""test"",
                    ""--provider"", ""dyn"",
                    ""-n"", ""test.dyndns.org"", self.test_ip]

        args = self.parser.parse_args(cmd_args)
        result = main.execute_update(args)

        self.assertEqual(result.get('exec_result'), main.EXECUTION_RESULT_OK,
                         ""Update with 'DynDNS' provider failed."")

        self.assertEqual(result.get('response_code'), 200,
                         ""Invalid response code: %s. Should be 200.""
                         % result.get('response_code'))

    ",False
1139,https://github.com/ericmjl/nxviz/blob/d2a2a622e834148a9f4337dbe1021a05c5f18548/tests/test_geometry.py,,test_correct_negative_angle,"def test_correct_negative_angle(angle):
    """"""Test for correct calculation of negative angle.""""""
    assume(angle < 0)
    assume(angle >= -2 * np.pi)
    exp = 2 * np.pi + angle
    obs = correct_negative_angle(angle)

    assert np.allclose(obs, exp)
    assert obs <= 2 * np.pi
    assert obs >= 0
",True
1140,https://github.com/ericmjl/nxviz/blob/d2a2a622e834148a9f4337dbe1021a05c5f18548/tests/test_plots.py,,test_matrix_plot,"def test_matrix_plot():
    m = MatrixPlot(G)  # noqa: F841
    diff = diff_plots(m, ""matrix.png"", baseline_dir, result_dir)
    assert diff is None


",True
1141,https://github.com/DanielSank/observed/blob/d99fb99ff2a470a86efb2763685e8e2c021e799f/observed_test.py,TestBasics,test_callbacks,"def test_callbacks(self):
        """"""
        Test all combinations of types acting as observed and observer.

        For each combination of observed and observer we check that all
        observers are called. We also check that after discarding the
        observers subsequent invocations of the observed object do not call
        any observers.
        """"""

        a = Foo('a', self.buf)
        b = Foo('b', self.buf)
        c = Goo('c', self.buf)
        d = Goo('d', self.buf)

        @observable_function
        ",True
1142,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__encode_error_with_debug_enabled,"def test_dispatch__encode_error_with_debug_enabled(self):
        ",True
1143,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__error_handled_by_middleware,"def test_dispatch__error_handled_by_middleware(self):
        class ErrorMiddleware(object):
            ",True
1144,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__error_handled_by_middleware_raises_exception,"def test_dispatch__error_handled_by_middleware_raises_exception(self):
        class ErrorMiddleware(object):
            ",True
1145,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__error_with_debug_enabled,"def test_dispatch__error_with_debug_enabled(self):
        ",True
1146,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__exceptions,"def test_dispatch__exceptions(self, error, status):
        ",True
1147,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__exceptions,"def test_dispatch__exceptions(self, error, status):
        ",True
1148,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__exceptions,"def test_dispatch__exceptions(self, error, status):
        ",True
1149,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__exceptions,"def test_dispatch__exceptions(self, error, status):
        ",True
1150,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__exceptions,"def test_dispatch__exceptions(self, error, status):
        ",True
1151,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__exceptions,"def test_dispatch__exceptions(self, error, status):
        ",True
1152,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__http_response,"def test_dispatch__http_response(self):
        ",True
1153,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__invalid_headers,"def test_dispatch__invalid_headers(self, r, status, message):
        target = containers.ApiInterfaceBase()
        operation = Operation(mock_callback)
        actual = target.dispatch(operation, r)

        assert actual.status == status
        assert actual.body == message

    @pytest.mark.parametrize('error,status', (
        (api.ImmediateHttpResponse(None, HTTPStatus.NOT_MODIFIED, {}), HTTPStatus.NOT_MODIFIED),
        (ValidationError(""Error""), 400),
        (ValidationError({}), 400),
        (NotImplementedError, 501),
        (ValueError, 500),
        (api.ImmediateHttpResponse(ValueError, HTTPStatus.NOT_MODIFIED, {}), 500),
    ))
    ",True
1154,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__invalid_headers,"def test_dispatch__invalid_headers(self, r, status, message):
        target = containers.ApiInterfaceBase()
        operation = Operation(mock_callback)
        actual = target.dispatch(operation, r)

        assert actual.status == status
        assert actual.body == message

    @pytest.mark.parametrize('error,status', (
        (api.ImmediateHttpResponse(None, HTTPStatus.NOT_MODIFIED, {}), HTTPStatus.NOT_MODIFIED),
        (ValidationError(""Error""), 400),
        (ValidationError({}), 400),
        (NotImplementedError, 501),
        (ValueError, 500),
        (api.ImmediateHttpResponse(ValueError, HTTPStatus.NOT_MODIFIED, {}), 500),
    ))
    ",True
1155,https://github.com/python-odin/odinweb/blob/198424133584acc18cb41c8d18d91f803abc810f/tests/test_containers.py,TestApiInterfaceBase,test_dispatch__with_middleware,"def test_dispatch__with_middleware(self):
        calls = []

        class Middleware(object):
            ",True
1157,https://github.com/crazyscientist/osc-tiny/blob/88c33c2c7f73ea26067e1bb4190bab5dc298dd85/osctiny/tests/test_issues.py,TestIssue,test_get,"def test_get_trackers(self):
        response = self.osc.issues.get_trackers()
        self.assertTrue(isinstance(response, ObjectifiedElement))
        self.assertEqual(response.countchildren(), 3)
        self.assertEqual(
            {x.text for x in response.xpath(""issue-tracker/name"")},
            {'boost', 'bco', 'bnc'}
        )

    @responses.activate
    ",True
1158,https://github.com/lukas-linhart/pageobject/blob/6ae83680ae62a94f93cefc394e4f3cc6999aeead/tests/unit/commands/test_wait_until_vanished.py,,test_wait_until_vanished_passes_correct_function_to_wait_until,"def test_wait_until_vanished_passes_correct_function_to_wait_until(monkeypatch, mock_po):
    monkeypatch.setattr(mock_po.__class__, '_locator_value', 'locator')
    mock_po.is_existing_called = False
    ",False
1159,https://github.com/casamagalhaes/panamah-sdk-python/blob/746f3fb7ebcf01810917bf9afa8e7ff5a4efad21/tests/test_processor.py,TestStream,test_expiration_by_max_age,"def test_expiration_by_max_age(self):
        test_expiration(self, by_max_age=True)

    ",True
1160,https://github.com/casamagalhaes/panamah-sdk-python/blob/746f3fb7ebcf01810917bf9afa8e7ff5a4efad21/tests/test_processor.py,TestStream,test_expiration_by_max_length,"def test_expiration_by_max_length(self):
        test_expiration(self, by_max_length=True)

    ",True
1161,https://github.com/casamagalhaes/panamah-sdk-python/blob/746f3fb7ebcf01810917bf9afa8e7ff5a4efad21/tests/test_processor.py,TestStream,test_expiration_by_max_size,"def test_expiration_by_max_size(self):
        test_expiration(self, by_max_size=True)

    ",True
1162,https://github.com/casamagalhaes/panamah-sdk-python/blob/746f3fb7ebcf01810917bf9afa8e7ff5a4efad21/tests/test_processor.py,TestStream,test_get_pending_resources,"def test_get_pending_resources(self):
        processor = BatchProcessor('auth', 'secret', '12345')

        ",True
1163,https://github.com/casamagalhaes/panamah-sdk-python/blob/746f3fb7ebcf01810917bf9afa8e7ff5a4efad21/tests/test_processor.py,TestStream,test_initialization_and_accumulation,"def test_initialization_and_accumulation(self):
        holding = PanamahHolding(id='1234', descricao='teste')
        acesso = PanamahAcesso(id='4321', funcionario_ids=['1', '2'])
        secao = PanamahSecao(id='5555', codigo='6666', descricao='teste')

        b = BatchProcessor('auth', 'secret', '12345')

        self.assertTrue(os.path.exists(ROOT_PATH))
        self.assertTrue(os.path.exists(ACCUMULATED_PATH))
        self.assertTrue(os.path.exists(SENT_PATH))

        b.save(holding)

        self.assertEqual(b.current_batch.length, 1)
        self.assertEqual(b.current_batch.size, 107)
        sleep(.5)
        self.assertAlmostEqual(b.current_batch.age, 0.5, delta=0.2)

        b.save(acesso)

        self.assertEqual(b.current_batch.length, 2)
        self.assertEqual(b.current_batch.size, 221)
        sleep(.5)
        self.assertAlmostEqual(b.current_batch.age, 1, delta=0.2)

        b.save(secao)

        self.assertEqual(b.current_batch.length, 3)
        self.assertEqual(b.current_batch.size, 344)
        sleep(.5)
        self.assertAlmostEqual(b.current_batch.age, 1.5, delta=0.2)

        b.delete(holding)

        self.assertEqual(b.current_batch.length, 4)
        self.assertEqual(b.current_batch.size, 429)
        sleep(.5)
        self.assertAlmostEqual(b.current_batch.age, 2, delta=0.2)

        b.delete(secao)

        self.assertEqual(b.current_batch.length, 5)
        self.assertEqual(b.current_batch.size, 512)
        sleep(.5)
        self.assertAlmostEqual(b.current_batch.age, 2.5, delta=0.2)

        b.delete(acesso)

        self.assertEqual(b.current_batch.length, 6)
        self.assertEqual(b.current_batch.size, 596)
        sleep(.5)
        self.assertAlmostEqual(b.current_batch.age, 3, delta=0.2)

        self.assertEqual(
            b.current_batch.json(),
            '[{""data"": {""id"": ""1234"", ""descricao"": ""teste""}, ""tipo"": ""HOLDING"", ""op"": ""update"", ""assinanteId"": ""12345""}, {""data"": {""id"": ""4321"", ""funcionarioIds"": [""1"", ""2""]}, ""tipo"": ""ACESSO"", ""op"": ""update"", ""assinanteId"": ""12345""}, {""data"": {""id"": ""5555"", ""codigo"": ""6666"", ""descricao"": ""teste""}, ""tipo"": ""SECAO"", ""op"": ""update"", ""assinanteId"": ""12345""}, {""tipo"": ""HOLDING"", ""op"": ""delete"", ""data"": {""id"": ""1234""}, ""assinanteId"": ""12345""}, {""tipo"": ""SECAO"", ""op"": ""delete"", ""data"": {""id"": ""5555""}, ""assinanteId"": ""12345""}, {""tipo"": ""ACESSO"", ""op"": ""delete"", ""data"": {""id"": ""4321""}, ""assinanteId"": ""12345""}]'
        )

        b.save(holding)

        self.assertEqual(b.current_batch.length, 6)

        self.assertEqual(
            b.current_batch.json(),
            '[{""data"": {""id"": ""4321"", ""funcionarioIds"": [""1"", ""2""]}, ""tipo"": ""ACESSO"", ""op"": ""update"", ""assinanteId"": ""12345""}, {""data"": {""id"": ""5555"", ""codigo"": ""6666"", ""descricao"": ""teste""}, ""tipo"": ""SECAO"", ""op"": ""update"", ""assinanteId"": ""12345""}, {""tipo"": ""HOLDING"", ""op"": ""delete"", ""data"": {""id"": ""1234""}, ""assinanteId"": ""12345""}, {""tipo"": ""SECAO"", ""op"": ""delete"", ""data"": {""id"": ""5555""}, ""assinanteId"": ""12345""}, {""tipo"": ""ACESSO"", ""op"": ""delete"", ""data"": {""id"": ""4321""}, ""assinanteId"": ""12345""}, {""data"": {""id"": ""1234"", ""descricao"": ""teste""}, ""tipo"": ""HOLDING"", ""op"": ""update"", ""assinanteId"": ""12345""}]'
        )

    ",True
1164,https://github.com/casamagalhaes/panamah-sdk-python/blob/746f3fb7ebcf01810917bf9afa8e7ff5a4efad21/tests/test_processor.py,TestStream,test_recover_failures,"def test_recover_failures(self):
        processor = BatchProcessor(
            'auth', 'secret', '12345', batch_max_length=1
        )

        holding = PanamahHolding(id='1234', descricao='teste')
        batch = Batch()
        batch_filename = batch.filename
        batch.append(Update.from_model(holding))
        batch.save(directory=ACCUMULATED_PATH)

        loaded_batch = Batch(filename='%s/%s' %
                             (ACCUMULATED_PATH, batch_filename))
        mock_response = {
            'falhas': {
                'total': 1,
                'itens': loaded_batch.operations
            }
        }
        processor.recover_from_failures(loaded_batch, mock_response)
        self.assertTrue(bool(next((file for file in os.listdir(
            ACCUMULATED_PATH) if file.startswith('0_')), False)))


",True
1165,https://github.com/casamagalhaes/panamah-sdk-python/blob/746f3fb7ebcf01810917bf9afa8e7ff5a4efad21/tests/test_processor.py,TestStream,test_requesting_pending_resources,"def test_requesting_pending_resources(self):
        b = BatchProcessor('auth', 'secret', '12345')

        with mock.patch.object(b.client, 'get') as get_method:
            get_method.return_value = Response(200, {
                ""00934509022"": {
                    ""HOLDING"": [
                        ""07128945000132""
                    ],
                    ""LOJA"": [
                        ""111""
                    ],
                    ""PRODUTO"": [
                        ""1""
                    ],
                    ""SECAO"": [
                        ""xxxx""
                    ]
                },
                ""02541926375"": {
                    ""LOJA"": [
                        ""111"",
                        ""2345""
                    ],
                    ""PRODUTO"": [
                        ""1""
                    ],
                    ""SECAO"": [
                        ""xxxx""
                    ]
                }
            })

            (page, count) = b.request_pending_resources()

            self.assertEqual(count, 2)
            self.assertDictEqual(page, {'00934509022': {'HOLDING': ['07128945000132'], 'LOJA': ['111'], 'PRODUTO': [
                                 '1'], 'SECAO': ['xxxx']}, '02541926375': {'LOJA': ['111', '2345'], 'PRODUTO': ['1'], 'SECAO': ['xxxx']}})

            get_method.return_value = Response(200, {
                ""00934509022"": {
                    ""SECAO"": [
                        ""zzzz""
                    ]
                },
                ""02541926375"": {
                    ""LOJA"": [
                        ""3333""
                    ],
                    ""PRODUTO"": [
                        ""2""
                    ]
                }
            })

            (page2, count) = b.request_pending_resources(concat=page)

            self.assertEqual(count, 2)
            self.assertDictEqual(page2, {'00934509022': {'HOLDING': ['07128945000132'], 'LOJA': ['111'], 'PRODUTO': ['1'], 'SECAO': [
                                 'xxxx', 'zzzz']}, '02541926375': {'LOJA': ['111', '2345', '3333'], 'PRODUTO': ['1', '2'], 'SECAO': ['xxxx']}})

            get_method.return_value = Response(200, {})

            (page3, count) = b.request_pending_resources(concat=page)

            self.assertEqual(count, 0)
            self.assertDictEqual(page3, {'00934509022': {'HOLDING': ['07128945000132'], 'LOJA': ['111'], 'PRODUTO': ['1'], 'SECAO': [
                                 'xxxx', 'zzzz']}, '02541926375': {'LOJA': ['111', '2345', '3333'], 'PRODUTO': ['1', '2'], 'SECAO': ['xxxx']}})

    ",True
1166,https://github.com/casamagalhaes/panamah-sdk-python/blob/746f3fb7ebcf01810917bf9afa8e7ff5a4efad21/tests/test_stream.py,TestStream,test_events,"def test_events(self):
        global before_save_called
        global before_delete_called

        class ChildModel(Model):
            name = 'PRODUTO'
            schema = {
                'id': StringField(required=True)
            }

        stream = PanamahStream('auth', 'secret', '123')
        before_save_called = False
        before_delete_called = False

        class TestEvents:
            ",True
1167,https://github.com/naorlivne/parse_it/blob/886d7de0e74e67edc136411a5220e35c1149e743/test/test_prase_it.py,BaseTests,test_envvar_defined_false,"def test_envvar_defined_false(self):
        reply = envvar_defined(""TEST_ENV"")
        self.assertFalse(reply)

    ",True
1168,https://github.com/naorlivne/parse_it/blob/886d7de0e74e67edc136411a5220e35c1149e743/test/test_prase_it.py,BaseTests,test_parser_read_all_configuration_variables_raise_allowed_types_error,"def test_parser_read_all_configuration_variables_raise_allowed_types_error(self):
        parser = ParseIt(config_location=test_files_location)
        with self.assertRaises(TypeError):
            parser.read_all_configuration_variables(allowed_types={""file_type"": [bool, dict]})

    ",True
1169,https://github.com/davidhalter/parso/blob/6ae0efa415c9790000dba70f87e6ece20d6a4101/test/test_diff_parser.py,,test_simple,"def test_simple():
    """"""
    The diff parser reuses modules. So check for that.
    """"""
    grammar = load_grammar()
    module_a = grammar.parse('a', diff_cache=True)
    assert grammar.parse('b', diff_cache=True) == module_a


",False
1170,https://github.com/slarse/pdfebc/blob/ddc7b88f2b7df0063345c3e8c940ac76832a4af8/tests/test_core.py,CoreTest,test_compress_too_small_pdf,"def test_compress_too_small_pdf(self):
        with tempfile.TemporaryDirectory(dir=self.trash_can.name) as tmpoutdir:
            mock_status_callback = Mock(return_value=None)
            pdf_file = create_temporary_files_with_suffixes(self.trash_can.name, files_per_suffix=1)[0]
            pdf_file.close()
            output_path = os.path.join(tmpoutdir, os.path.basename(pdf_file.name))
            pdfebc.core.compress_pdf(pdf_file.name, output_path,
                                     pdfebc.cli.GHOSTSCRIPT_BINARY_DEFAULT, mock_status_callback)
            expected_not_compressing_message = pdfebc.core.NOT_COMPRESSING.format(
                pdf_file.name, 0,
                pdfebc.core.FILE_SIZE_LOWER_LIMIT)
            expected_done_message = pdfebc.core.FILE_DONE.format(output_path)
            mock_status_callback.assert_any_call(expected_not_compressing_message)
            mock_status_callback.assert_any_call(expected_done_message)

    @patch('subprocess.Popen', autospec=True)
    ",False
1171,https://github.com/slarse/pdfebc-core/blob/fc40857bc42365b7434714333e37d7a3487603a0/tests/test_compress.py,CoreTest,test_compress_too_small_pdf,"def test_compress_too_small_pdf(self, mock_logger):
        with tempfile.TemporaryDirectory(dir=self.trash_can.name) as tmpoutdir:
            pdf_file = create_temporary_files_with_suffixes(self.trash_can.name,
                                                            files_per_suffix=1)[0]
            pdf_file.close()
            output_path = os.path.join(tmpoutdir, os.path.basename(pdf_file.name))
            pdfebc_core.compress.compress_pdf(pdf_file.name, output_path, self.gs_binary)
            expected_not_compressing_message = pdfebc_core.compress.NOT_COMPRESSING.format(
                pdf_file.name, 0,
                pdfebc_core.compress.FILE_SIZE_LOWER_LIMIT)
            expected_done_message = pdfebc_core.compress.FILE_DONE.format(output_path)
            mock_logger.info.assert_any_call(expected_not_compressing_message)
            mock_logger.info.assert_any_call(expected_done_message)

    @patch('pdfebc_core.compress.LOGGER')
    @patch('subprocess.Popen', autospec=True)
    ",False
1172,https://github.com/laike9m/pdir2/blob/ef5e2200074d68e2ca3df4ee441a1b9ea6ca5abc/tests/test_user_config.py,,test_invalid_config_1,"def test_invalid_config_1(clean):
    shutil.copyfile('tests/data/error_config_1.ini', clean)
    with pytest.raises(ValueError, match='Invalid key: doc-color1'):
        import pdir

        pdir()


",True
1173,https://github.com/laike9m/pdir2/blob/ef5e2200074d68e2ca3df4ee441a1b9ea6ca5abc/tests/test_user_config.py,,test_invalid_config_2,"def test_invalid_config_2(clean):
    shutil.copyfile('tests/data/error_config_2.ini', clean)
    with pytest.raises(ValueError, match='Invalid color value: 42'):
        import pdir

        pdir()
",True
1174,https://github.com/laike9m/pdir2/blob/ef5e2200074d68e2ca3df4ee441a1b9ea6ca5abc/tests/test_user_config.py,,test_read_config,"def test_read_config(clean):
    # 'clean' is the DEFAULT_CONFIG_FILE yielded from fixture.
    shutil.copyfile('tests/data/config_1.ini', clean)
    from pdir.format import doc_color, category_color, attribute_color, comma

    assert doc_color == COLORS['white']
    assert category_color == COLORS['bright yellow']
    assert comma == '\033[1;32m, \033[0m'
    assert attribute_color == COLORS['cyan']


",True
1175,https://github.com/laike9m/pdir2/blob/ef5e2200074d68e2ca3df4ee441a1b9ea6ca5abc/tests/test_user_config.py,,test_read_config_from_custom_location,"def test_read_config_from_custom_location(clean):
    os.environ['PDIR2_CONFIG_FILE'] = os.path.join(os.path.expanduser('~'), '.myconfig')
    shutil.copyfile('tests/data/config_1.ini', os.environ['PDIR2_CONFIG_FILE'])
    from pdir.format import doc_color, category_color, attribute_color, comma

    assert doc_color == COLORS['white']
    assert category_color == COLORS['bright yellow']
    assert comma == '\033[1;32m, \033[0m'
    assert attribute_color == COLORS['cyan']


",True
1176,https://github.com/laike9m/pdir2/blob/ef5e2200074d68e2ca3df4ee441a1b9ea6ca5abc/tests/test_user_config.py,,test_set_env_without_config,"def test_set_env_without_config(clean):
    os.environ['PDIR2_CONFIG_FILE'] = 'aaa'
    with pytest.raises(OSError, match='Config file not exist: aaa'):
        import pdir

        pdir()


",True
1177,https://github.com/laike9m/pdir2/blob/ef5e2200074d68e2ca3df4ee441a1b9ea6ca5abc/tests/test_user_config.py,,test_uniform_color,"def test_uniform_color(clean):
    shutil.copyfile('tests/data/config_2.ini', clean)
    from pdir.format import doc_color, category_color, attribute_color, comma

    assert doc_color == COLORS['white']
    assert category_color == COLORS['white']
    assert comma == '\033[0;37m, \033[0m'
    assert attribute_color == COLORS['white']


",True
1178,https://github.com/zerotosingularity/pdl/blob/fd39c391101b3fe315631565a0f4eb7c99890789/tests/test_pdl.py,,test_no_archive_url,"def test_no_archive_url():
    """""" Test a non-archive url """"""
    pdl_test_helper(NON_ARCHIVE_URL, False)


@pytest.mark.skip(reason=""only used for attribute error fixing"")
",True
1179,https://github.com/Oprax/pidom/blob/b92741ee3c3e16cbaa2a2fa69ca1a103cfa52463/test_pidom.py,,test_group,"def test_group():
    pidom = PiDom()
    device_name1 = 'foo'
    device_name2 = 'bar'
    group_name = 'foobar'
    pidom.synchronize(device_name1)
    pidom.synchronize(device_name2)
    pidom.switch_on(device_name1)
    assert pidom.state(device_name1) is True
    pidom.new_group(group_name, [device_name1, device_name2])
    assert pidom.state(device_name1) is False
    assert pidom.state(device_name2) is False
    assert device_name1 in pidom._groups[group_name]
    assert device_name2 in pidom._groups[group_name]

    pidom.switch_on(group_name)
    assert pidom.state(device_name1) is True
    assert pidom.state(device_name2) is True

    pidom.switch_off(group_name)
    assert pidom.state(device_name1) is False
    assert pidom.state(device_name2) is False

    pidom.toggle(group_name)
    assert pidom.state(device_name1) is True
    assert pidom.state(device_name2) is True

    pidom.toggle(group_name)
    assert pidom.state(device_name1) is False
    assert pidom.state(device_name2) is False

    pidom.switch_on(group_name)

    pidom.rm_group(group_name)
    assert pidom.state(device_name1) is False
    assert pidom.state(device_name2) is False
    assert group_name not in pidom._groups.keys()


",False
1180,https://github.com/Oprax/pidom/blob/b92741ee3c3e16cbaa2a2fa69ca1a103cfa52463/test_pidom.py,,test_reset,"def test_reset():
    pidom = PiDom()
    device_name = 'test'
    pidom.synchronize(device_name)
    assert pidom.state(device_name) is False
    pidom.toggle(device_name)
    assert pidom.state(device_name) is True
    pidom.reset()
    assert pidom.state(device_name) is False


",False
1181,https://github.com/Oprax/pidom/blob/b92741ee3c3e16cbaa2a2fa69ca1a103cfa52463/test_pidom.py,,test_switch,"def test_switch():
    pidom = PiDom()
    device_name = 'test'
    pidom.synchronize(device_name)
    assert pidom.state(device_name) is False
    pidom.switch_on(device_name)
    assert pidom.state(device_name) is True
    pidom.switch_off(device_name)
    assert pidom.state(device_name) is False


",False
1182,https://github.com/Oprax/pidom/blob/b92741ee3c3e16cbaa2a2fa69ca1a103cfa52463/test_pidom.py,,test_synchronize,"def test_synchronize():
    pidom = PiDom()
    assert len(pidom.devices) == 0
    pidom.synchronize('test')
    assert len(pidom.devices) == 1
    device_name = pidom.devices[0]
    assert device_name == 'test'
    device_id = pidom._register[device_name]['device_id']
    assert device_id not in pidom._id_available
    pidom.unsynchronize('test')
    assert len(pidom.devices) == 0
    assert device_id in pidom._id_available


",False
1183,https://github.com/Oprax/pidom/blob/b92741ee3c3e16cbaa2a2fa69ca1a103cfa52463/test_pidom.py,,test_toggle,"def test_toggle():
    pidom = PiDom()
    device_name = 'test'
    pidom.synchronize(device_name)
    assert pidom.state(device_name) is False
    pidom.toggle(device_name)
    assert pidom.state(device_name) is True
    pidom.toggle(device_name)
    assert pidom.state(device_name) is False


",False
1184,https://github.com/raphaelvallat/pingouin/blob/08560bb978949e97653b203f7374e90b022b88fb/pingouin/tests/test_regression.py,TestRegression,test_linear_regression,"def test_linear_regression(self):
        """"""Test function linear_regression.

        Compare against JASP and R lm() function.
        """"""
        # Simple regression (compare to R lm())
        lm = linear_regression(df['X'], df['Y'])  # Pingouin
        sc = linregress(df['X'], df['Y'])  # SciPy
        # When using assert_equal, we need to use .to_numpy()
        assert_equal(lm['names'].to_numpy(), ['Intercept', 'X'])
        assert_almost_equal(lm['coef'][1], sc.slope)
        assert_almost_equal(lm['coef'][0], sc.intercept)
        assert_almost_equal(lm['se'][1], sc.stderr)
        assert_almost_equal(lm['pval'][1], sc.pvalue)
        assert_almost_equal(np.sqrt(lm['r2'][0]), sc.rvalue)
        assert lm.residuals_.size == df['Y'].size
        assert_equal(lm['CI[2.5%]'].round(5).to_numpy(), [1.48155, 0.17553])
        assert_equal(lm['CI[97.5%]'].round(5).to_numpy(), [4.23286, 0.61672])
        assert round(lm['r2'].iloc[0], 4) == 0.1147
        assert round(lm['adj_r2'].iloc[0], 4) == 0.1057
        assert lm.df_model_ == 1
        assert lm.df_resid_ == 98

        # Multiple regression with intercept (compare to JASP)
        X = df[['X', 'M']].to_numpy()
        y = df['Y'].to_numpy()
        lm = linear_regression(X, y, as_dataframe=False)  # Pingouin
        sk = LinearRegression(fit_intercept=True).fit(X, y)  # SkLearn
        assert_equal(lm['names'], ['Intercept', 'x1', 'x2'])
        assert_almost_equal(lm['coef'][1:], sk.coef_)
        assert_almost_equal(lm['coef'][0], sk.intercept_)
        assert_almost_equal(sk.score(X, y), lm['r2'])
        assert lm['residuals'].size == y.size
        # No need for .to_numpy here because we're using a dict and not pandas
        assert_equal([.605, .110, .101], np.round(lm['se'], 3))
        assert_equal([3.145, 0.361, 6.321], np.round(lm['T'], 3))
        assert_equal([0.002, 0.719, 0.000], np.round(lm['pval'], 3))
        assert_equal([.703, -.178, .436], np.round(lm['CI[2.5%]'], 3))
        assert_equal([3.106, .257, .835], np.round(lm['CI[97.5%]'], 3))

        # No intercept
        lm = linear_regression(X, y, add_intercept=False, as_dataframe=False)
        sk = LinearRegression(fit_intercept=False).fit(X, y)
        assert_almost_equal(lm['coef'], sk.coef_)
        # Scikit-learn gives wrong R^2 score when no intercept present because
        # sklearn.metrics.r2_score always assumes that an intercept is present
        # https://stackoverflow.com/questions/54614157/scikit-learn-statsmodels-which-r-squared-is-correct
        # assert_almost_equal(sk.score(X, y), lm['r2'])
        # Instead, we compare to R lm() function:
        assert round(lm['r2'], 4) == 0.9096
        assert round(lm['adj_r2'], 4) == 0.9078
        assert lm['df_model'] == 2
        assert lm['df_resid'] == 98

        # Test other arguments
        linear_regression(df[['X', 'M']], df['Y'], coef_only=True)
        linear_regression(df[['X', 'M']], df['Y'], alpha=0.01)
        linear_regression(df[['X', 'M']], df['Y'], alpha=0.10)

        # With missing values
        linear_regression(df_nan[['X', 'M']], df_nan['Y'], remove_na=True)

        # With columns with only one unique value
        lm1 = linear_regression(df[['X', 'M', 'One']], df['Y'])
        lm2 = linear_regression(df[['X', 'M', 'One']], df['Y'],
                                add_intercept=False)
        assert lm1.shape[0] == 3
        assert lm2.shape[0] == 3
        assert np.isclose(lm1.at[0, 'r2'], lm2.at[0, 'r2'])

        # With zero-only column
        lm1 = linear_regression(df[['X', 'M', 'Zero', 'One']], df['Y'])
        lm2 = linear_regression(df[['X', 'M', 'Zero', 'One']],
                                df['Y'].to_numpy(), add_intercept=False)
        lm3 = linear_regression(df[['X', 'Zero', 'M', 'Zero']].to_numpy(),
                                df['Y'], add_intercept=False)
        assert_equal(lm1.loc[:, 'names'].to_numpy(), ['Intercept', 'X', 'M'])
        assert_equal(lm2.loc[:, 'names'].to_numpy(), ['X', 'M', 'One'])
        assert_equal(lm3.loc[:, 'names'].to_numpy(), ['x1', 'x3'])

        # With duplicate columns
        lm1 = linear_regression(df[['X', 'One', 'Zero', 'M', 'M', 'X']],
                                df['Y'])
        lm2 = linear_regression(
            df[['X', 'One', 'Zero', 'M', 'M', 'X']].to_numpy(),
            df['Y'], add_intercept=False
        )
        assert_equal(lm1.loc[:, 'names'].to_numpy(), ['Intercept', 'X', 'M'])
        assert_equal(lm2.loc[:, 'names'].to_numpy(), ['x1', 'x2', 'x4'])

        # Relative importance
        # Compare to R package relaimpo
        # >>> data <- read.csv('mediation.csv')
        # >>> lm1 <- lm(Y ~ X + M, data = data)
        # >>> calc.relimp(lm1, type=c(""lmg""))
        lm = linear_regression(df[['X', 'M']], df['Y'], relimp=True)
        assert_almost_equal(lm.loc[[1, 2], 'relimp'], [0.05778011, 0.31521913])
        assert_almost_equal(lm.loc[[1, 2], 'relimp_perc'],
                            [15.49068, 84.50932], decimal=4)
        # Now we make sure that relimp_perc sums to 100% and relimp sums to r2
        assert np.isclose(lm['relimp_perc'].sum(), 100.)
        assert np.isclose(lm['relimp'].sum(), lm.at[0, 'r2'])
        # 2 predictors, no intercept
        # Careful here, the sum of relimp is always the R^2 of the model
        # INCLUDING the intercept. Therefore, if the data are not normalized
        # and we set add_intercept to false, the sum of relimp will be
        # higher than the linear regression model.
        # A workaround is to standardize our data before:
        df_z = df[['X', 'M', 'Y']].apply(zscore)
        lm = linear_regression(df_z[['X', 'M']], df_z['Y'],
                               add_intercept=False,
                               as_dataframe=False, relimp=True)
        assert_almost_equal(lm['relimp'], [0.05778011, 0.31521913], decimal=4)
        assert_almost_equal(lm['relimp_perc'], [15.49068, 84.50932], decimal=4)
        assert np.isclose(np.sum(lm['relimp']), lm['r2'])
        # 3 predictors + intercept
        lm = linear_regression(df[['X', 'M', 'Ybin']], df['Y'], relimp=True)
        assert_almost_equal(lm.loc[[1, 2, 3], 'relimp'],
                            [0.06010737, 0.31724368, 0.01217479])
        assert_almost_equal(lm.loc[[1, 2, 3], 'relimp_perc'],
                            [15.43091, 81.44355, 3.12554], decimal=4)
        assert np.isclose(lm['relimp'].sum(), lm.at[0, 'r2'])

        ######################################################################
        # WEIGHTED REGRESSION - compare against R lm() function
        # Note that the summary function of R sometimes round to 4 decimals,
        # sometimes to 5, etc..
        lm = linear_regression(df[['X', 'M']], df['Y'], weights=df['W2'])
        assert_equal(lm['coef'].round(5).to_numpy(),
                     [1.89530, 0.03905, 0.63912])
        assert_equal(lm['se'].round(5).to_numpy(),
                     [0.60498, 0.10984, 0.10096])
        assert_equal(lm['T'].round(3).to_numpy(),
                     [3.133, 0.356, 6.331])  # R round to 3
        assert_equal(lm['pval'].round(5).to_numpy(),
                     [0.00229, 0.72296, 0.00000])
        assert_equal(lm['CI[2.5%]'].round(5).to_numpy(),
                     [0.69459, -0.17896, 0.43874])
        assert_equal(lm['CI[97.5%]'].round(5).to_numpy(),
                     [3.09602, 0.25706, 0.83949])
        assert round(lm['r2'].iloc[0], 4) == 0.3742
        assert round(lm['adj_r2'].iloc[0], 4) == 0.3613
        assert lm.df_model_ == 2
        assert lm.df_resid_ == 97

        # No intercept
        lm = linear_regression(df[['X', 'M']], df['Y'], add_intercept=False,
                               weights=df['W2'])
        assert_equal(lm['coef'].round(5).to_numpy(), [0.26924, 0.71733])
        assert_equal(lm['se'].round(5).to_numpy(), [0.08525, 0.10213])
        assert_equal(lm['T'].round(3).to_numpy(), [3.158, 7.024])
        assert_equal(lm['pval'].round(5).to_numpy(), [0.00211, 0.00000])
        assert_equal(lm['CI[2.5%]'].round(5).to_numpy(), [0.10007, 0.51466])
        assert_equal(lm['CI[97.5%]'].round(4).to_numpy(), [0.4384, 0.9200])
        assert round(lm['r2'].iloc[0], 4) == 0.9090
        assert round(lm['adj_r2'].iloc[0], 4) == 0.9072
        assert lm.df_model_ == 2
        assert lm.df_resid_ == 98

        # With some weights set to zero
        # Here, R gives slightl different results than statsmodels because
        # zero weights are not taken into account when calculating the degrees
        # of freedom. Pingouin is similar to R.
        lm = linear_regression(df[['X']], df['Y'], weights=df['W1'])
        assert_equal(lm['coef'].round(4).to_numpy(), [3.5597, 0.2820])
        assert_equal(lm['se'].round(4).to_numpy(), [0.7355, 0.1222])
        assert_equal(lm['pval'].round(4).to_numpy(), [0.0000, 0.0232])
        assert_equal(lm['CI[2.5%]'].round(5).to_numpy(), [2.09935, 0.03943])
        assert_equal(lm['CI[97.5%]'].round(5).to_numpy(), [5.02015, 0.52453])
        assert round(lm['r2'].iloc[0], 5) == 0.05364
        assert round(lm['adj_r2'].iloc[0], 5) == 0.04358
        assert lm.df_model_ == 1
        assert lm.df_resid_ == 94

        # No intercept
        lm = linear_regression(df[['X']], df['Y'], add_intercept=False,
                               weights=df['W1'])
        assert_equal(lm['coef'].round(5).to_numpy(), [0.85060])
        assert_equal(lm['se'].round(5).to_numpy(), [0.03719])
        assert_equal(lm['pval'].round(5).to_numpy(), [0.0000])
        assert_equal(lm['CI[2.5%]'].round(5).to_numpy(), [0.77678])
        assert_equal(lm['CI[97.5%]'].round(5).to_numpy(), [0.92443])
        assert round(lm['r2'].iloc[0], 4) == 0.8463
        assert round(lm['adj_r2'].iloc[0], 4) == 0.8447
        assert lm.df_model_ == 1
        assert lm.df_resid_ == 95

        # With all weights to one, should be equal to OLS
        assert_frame_equal(linear_regression(df[['X', 'M']], df['Y']),
                           linear_regression(df[['X', 'M']], df['Y'],
                                             weights=df['One']))

        with pytest.raises(ValueError):
            linear_regression(df[['X']], df['Y'], weights=df['W1'],
                              relimp=True)

    ",False
1185,https://github.com/raphaelvallat/pingouin/blob/08560bb978949e97653b203f7374e90b022b88fb/pingouin/tests/test_regression.py,TestRegression,test_logistic_regression,"def test_logistic_regression(self):
        """"""Test function logistic_regression.""""""
        # Simple regression
        lom = logistic_regression(df['X'], df['Ybin'], as_dataframe=False)
        # Compare to R
        # Reproduce in jupyter notebook with rpy2 using
        # %load_ext rpy2.ipython (in a separate cell)
        # Together in one cell below
        # %%R -i df
        # summary(glm(Ybin ~ X, data=df, family=binomial))
        assert_equal(np.round(lom['coef'], 4), [1.3191, -0.1995])
        assert_equal(np.round(lom['se'], 4), [0.7582, 0.1211])
        assert_equal(np.round(lom['z'], 4), [1.7399, -1.6476])
        assert_equal(np.round(lom['pval'], 4), [0.0819, 0.0994])
        assert_equal(np.round(lom['CI[2.5%]'], 4), [-.1669, -.4367])
        assert_equal(np.round(lom['CI[97.5%]'], 4), [2.8050, 0.0378])

        # Multiple predictors
        X = df[['X', 'M']].to_numpy()
        y = df['Ybin'].to_numpy()
        lom = logistic_regression(X, y).round(4)  # Pingouin
        # Compare against R
        # summary(glm(Ybin ~ X+M, data=df, family=binomial))
        assert_equal(lom['coef'].to_numpy(), [1.3275, -0.1960, -0.0060])
        assert_equal(lom['se'].to_numpy(), [0.7784, 0.1408, 0.1253])
        assert_equal(lom['z'].to_numpy(), [1.7055, -1.3926, -0.0475])
        assert_equal(lom['pval'].to_numpy(), [0.0881, 0.1637, 0.9621])
        assert_equal(lom['CI[2.5%]'].to_numpy(), [-.1981, -.4719, -.2516])
        assert_equal(lom['CI[97.5%]'].to_numpy(), [2.8531, 0.0799, 0.2397])

        # Test other arguments
        c = logistic_regression(df[['X', 'M']], df['Ybin'], coef_only=True)
        assert_equal(np.round(c, 4), [1.3275, -0.1960, -0.0060])

        # With missing values
        logistic_regression(df_nan[['X', 'M']], df_nan['Ybin'], remove_na=True)

        # Test **kwargs
        logistic_regression(X, y, solver='sag', C=10, max_iter=10000,
                            penalty=""l2"")
        logistic_regression(X, y, solver='sag', multi_class='auto')

        # Test regularization coefficients are strictly closer to 0 than
        # unregularized
        c = logistic_regression(df['X'], df['Ybin'], coef_only=True)
        c_reg = logistic_regression(df['X'], df['Ybin'], coef_only=True,
                                    penalty='l2')
        assert all(np.abs(c - 0) > np.abs(c_reg - 0))

        # With one column that has only one unique value
        c = logistic_regression(df[['One', 'X']], df['Ybin'])
        assert_equal(c.loc[:, 'names'].to_numpy(), ['Intercept', 'X'])
        c = logistic_regression(df[['X', 'One', 'M', 'Zero']], df['Ybin'])
        assert_equal(c.loc[:, 'names'].to_numpy(), ['Intercept', 'X', 'M'])

        # With duplicate columns
        c = logistic_regression(df[['X', 'M', 'X']], df['Ybin'])
        assert_equal(c.loc[:, 'names'].to_numpy(), ['Intercept', 'X', 'M'])
        c = logistic_regression(df[['X', 'X', 'X']], df['Ybin'])
        assert_equal(c.loc[:, 'names'].to_numpy(), ['Intercept', 'X'])

        # Error: dependent variable is not binary
        with pytest.raises(ValueError):
            y[3] = 2
            logistic_regression(X, y)

        # --------------------------------------------------------------------
        # 2ND dataset (Penguin)-- compare to R
        lom = logistic_regression(data['body_mass_g'], data['male'],
                                  as_dataframe=False)
        assert np.allclose(lom['coef'], [-5.162541644, 0.001239819])
        assert_equal(np.round(lom['se'], 5), [0.72439, 0.00017])
        assert_equal(np.round(lom['z'], 3), [-7.127, 7.177])
        assert np.allclose(lom['pval'], [1.03e-12, 7.10e-13])
        assert_equal(np.round(lom['CI[2.5%]'], 3), [-6.582, 0.001])
        assert_equal(np.round(lom['CI[97.5%]'], 3), [-3.743, 0.002])

        # With a different scaling: z / p-values should be similar
        lom = logistic_regression(data['body_mass_kg'], data['male'],
                                  as_dataframe=False)
        assert np.allclose(lom['coef'], [-5.162542, 1.239819])
        assert_equal(np.round(lom['se'], 4), [0.7244, 0.1727])
        assert_equal(np.round(lom['z'], 3), [-7.127, 7.177])
        assert np.allclose(lom['pval'], [1.03e-12, 7.10e-13])
        assert_equal(np.round(lom['CI[2.5%]'], 3), [-6.582, 0.901])
        assert_equal(np.round(lom['CI[97.5%]'], 3), [-3.743, 1.578])

        # With no intercept
        lom = logistic_regression(data['body_mass_kg'], data['male'],
                                  as_dataframe=False, fit_intercept=False)
        assert np.isclose(lom['coef'], 0.04150582)
        assert np.round(lom['se'], 5) == 0.02570
        assert np.round(lom['z'], 3) == 1.615
        assert np.round(lom['pval'], 3) == 0.106
        assert np.round(lom['CI[2.5%]'], 3) == -0.009
        assert np.round(lom['CI[97.5%]'], 3) == 0.092

        # With categorical predictors
        # R: >>> glm(""male ~ body_mass_kg + species"", family=binomial, ...)
        #    >>> confint.default(model)  # Wald CI
        # See https://stats.stackexchange.com/a/275421/253579
        data_dum = pd.get_dummies(data, columns=['species'], drop_first=True)
        X = data_dum[['body_mass_kg', 'species_Chinstrap', 'species_Gentoo']]
        y = data_dum['male']
        lom = logistic_regression(X, y, as_dataframe=False)
        assert_equal(np.round(lom['coef'], 7),
                     [-27.1318593, 7.3728436, -0.2559251, -10.1778083])
        assert_equal(np.round(lom['se'], 4),
                     [2.9984, 0.8141, 0.4293, 1.1946])
        assert_equal(np.round(lom['z'], 3),
                     [-9.049, 9.056, -0.596, -8.520])
        assert_equal(np.round(lom['CI[2.5%]'], 3),
                     [-33.009, 5.777, -1.097, -12.519])
        assert_equal(np.round(lom['CI[97.5%]'], 3),
                     [-21.255, 8.969, 0.586, -7.836])

    ",True
1186,https://github.com/ohjeah/pip-validate/blob/9651b4dd6a252650c3a707218054b1baadc8b944/test_pip_validate.py,,test_match_to_alias,"def test_match_to_alias():
    imports = [""dateutil""]
    requirements = [""python-dateutil""]
    aliases, unsed_req = match_to_alias(imports, requirements)
    print(requirements)
    print(aliases)
    for i, r in zip(imports, requirements):
        assert aliases[i] == r
    assert unsed_req == []


@pytest.mark.skipif(not is_connected(), reason=""Need an internet connection"")
",False
1187,https://github.com/ohjeah/pip-validate/blob/9651b4dd6a252650c3a707218054b1baadc8b944/test_pip_validate.py,,test_validate_imports_alias,"def test_validate_imports_alias():
    assert validate_imports([""dateutil""], [""python-dateutil""])
    assert not validate_imports([""dateutil""], [""___""])


",False
1188,https://github.com/quantenschaum/piripherals/blob/74e4807a64363e3c95a03222fa250a1073387eaf/tests/test_led.py,,test_neopixels_rainbow,"def test_neopixels_rainbow(np):
    strip = np._strip
    np.rainbow(period=T, timeout=T, delay=T / 6, wait=1)
    assert strip.color_data == [0] * 3
    assert strip.setPixelColorRGB.call_count == 7 * 3
    assert strip.show.call_count == 8
    strip.setBrightness.assert_called_once_with(128)
    assert_colors(strip.setPixelColorRGB.call_args_list,
                  [(0, 254, 0, 0), (1, 0, 254, 0), (2, 0, 0, 254),
                   (0, 126, 0, 128), (1, 128, 126, 0), (2, 0, 128, 126),
                   (0, 0, 1, 253), (1, 253, 0, 1), (2, 1, 253, 0),
                   (0, 0, 128, 126), (1, 126, 0, 128), (2, 128, 126, 0),
                   (0, 2, 252, 0), (1, 0, 2, 252), (2, 252, 0, 2),
                   (0, 130, 124, 0), (1, 0, 130, 124), (2, 124, 0, 130),
                   (0, 0, 0, 0), (1, 0, 0, 0), (2, 0, 0, 0)],
                  tol=10)


",False
1189,https://github.com/matheusbsilva/plai/blob/1d3bfb0438bb6bd2f8d8e42f17207f9449319763/tests/test_evaluation.py,TestPipeline,test_pipeline_raise_error_on_undeclared_dataframe,"def test_pipeline_raise_error_on_undeclared_dataframe(self):
        with pytest.raises(NameError):
            run('pipeline(df): {drop(.name)}')

    ",True
1190,https://github.com/Cognexa/plcx/blob/2756c0ba78c4c9e572d95ba002708957bc55d4fa/plcx/tests/comm/test_client.py,,test_clientx,"def test_clientx(tcp_server, msg):
    """"""
    Test tcp clientx coroutine.

    :param tcp_server: tuple with host and port of testing server
    :param msg: message to send
    """"""
    host, port = tcp_server
    loop = asyncio.get_event_loop()

    assert loop.run_until_complete(clientx(host, port, msg.encode(), 32, time_out=5)).decode() == f""received:'{msg}'""
    assert (
        loop.run_until_complete(clientx(host, port, b""control message"", 32, time_out=5))
        == b""received:'control message'""
    )


@pytest.mark.parametrize(""msg"", [""111"", ""321"", ""hi""])
",True
1191,https://github.com/Cognexa/plcx/blob/2756c0ba78c4c9e572d95ba002708957bc55d4fa/plcx/tests/comm/test_client.py,,test_clientx,"def test_clientx(tcp_server, msg):
    """"""
    Test tcp clientx coroutine.

    :param tcp_server: tuple with host and port of testing server
    :param msg: message to send
    """"""
    host, port = tcp_server
    loop = asyncio.get_event_loop()

    assert loop.run_until_complete(clientx(host, port, msg.encode(), 32, time_out=5)).decode() == f""received:'{msg}'""
    assert (
        loop.run_until_complete(clientx(host, port, b""control message"", 32, time_out=5))
        == b""received:'control message'""
    )


@pytest.mark.parametrize(""msg"", [""111"", ""321"", ""hi""])
",True
1192,https://github.com/Cognexa/plcx/blob/2756c0ba78c4c9e572d95ba002708957bc55d4fa/plcx/tests/comm/test_client.py,,test_clientx,"def test_clientx(tcp_server, msg):
    """"""
    Test tcp clientx coroutine.

    :param tcp_server: tuple with host and port of testing server
    :param msg: message to send
    """"""
    host, port = tcp_server
    loop = asyncio.get_event_loop()

    assert loop.run_until_complete(clientx(host, port, msg.encode(), 32, time_out=5)).decode() == f""received:'{msg}'""
    assert (
        loop.run_until_complete(clientx(host, port, b""control message"", 32, time_out=5))
        == b""received:'control message'""
    )


@pytest.mark.parametrize(""msg"", [""111"", ""321"", ""hi""])
",True
1193,https://github.com/Cognexa/plcx/blob/2756c0ba78c4c9e572d95ba002708957bc55d4fa/plcx/tests/comm/test_client.py,,test_clientx_context,"def test_clientx_context(tcp_server, msg):
    """"""
    Test tcp clientx as context for connection to server.

    :param tcp_server: tuple with host and port of testing server
    :param msg: message to send
    """"""
    host, port = tcp_server
    client = ClientX(host=host, port=port)
    assert client.send(msg.encode(), 32, time_out=5).decode() == f""received:'{msg}'""
    assert client.send(b""control message"", 32, time_out=5) == b""received:'control message'""


",True
1194,https://github.com/Cognexa/plcx/blob/2756c0ba78c4c9e572d95ba002708957bc55d4fa/plcx/tests/comm/test_client.py,,test_clientx_context,"def test_clientx_context(tcp_server, msg):
    """"""
    Test tcp clientx as context for connection to server.

    :param tcp_server: tuple with host and port of testing server
    :param msg: message to send
    """"""
    host, port = tcp_server
    client = ClientX(host=host, port=port)
    assert client.send(msg.encode(), 32, time_out=5).decode() == f""received:'{msg}'""
    assert client.send(b""control message"", 32, time_out=5) == b""received:'control message'""


",True
1195,https://github.com/Cognexa/plcx/blob/2756c0ba78c4c9e572d95ba002708957bc55d4fa/plcx/tests/comm/test_client.py,,test_clientx_context,"def test_clientx_context(tcp_server, msg):
    """"""
    Test tcp clientx as context for connection to server.

    :param tcp_server: tuple with host and port of testing server
    :param msg: message to send
    """"""
    host, port = tcp_server
    client = ClientX(host=host, port=port)
    assert client.send(msg.encode(), 32, time_out=5).decode() == f""received:'{msg}'""
    assert client.send(b""control message"", 32, time_out=5) == b""received:'control message'""


",True
1196,https://github.com/Cognexa/plcx/blob/2756c0ba78c4c9e572d95ba002708957bc55d4fa/plcx/tests/comm/test_client.py,,test_clientx_error,"def test_clientx_error(tcp_server):
    """"""
    Test raising error.

    :param tcp_server: tuple with host and port of testing server
    """"""
    host, port = tcp_server

    loop = asyncio.get_event_loop()

    # testing connection to port 0
    with pytest.raises((OSError, asyncio.TimeoutError)):
        loop.run_until_complete(clientx(host, 0, b"""", 1, max_try=1))

    # testing connection to not exist port
    with pytest.raises((OSError, asyncio.TimeoutError)):
        loop.run_until_complete(clientx(host, 65432, b"""", 1, max_try=1))

    # testing connection to not exist address
    with pytest.raises((OSError, asyncio.TimeoutError)):
        loop.run_until_complete(clientx(""hola"", port, b"""", 1, max_try=1))

    # testing time out
    with pytest.raises((OSError, asyncio.TimeoutError)):
        loop.run_until_complete(clientx(host, port, b""123"", 16, time_out=0.005, max_try=1))
",True
1197,https://github.com/Poio-NLP/poio-lib/blob/2af55c863593511dbcf4c611c9265072022d8cdb/tests/test_wikipedia.py,TestWikipedia,test_extract_to,"def test_extract_to_txt(self):
        output_file = os.path.join(self.tmp_dir, ""cre.txt"")
        poiolib.wikipedia.extract_to_txt(""cre"", output_file)
        self.assertTrue(os.path.isfile(output_file))
        self.assertNotEqual(os.path.getsize(output_file), 0)

    ",False
1198,https://github.com/Poio-NLP/poio-lib/blob/2af55c863593511dbcf4c611c9265072022d8cdb/tests/test_wikipedia.py,TestWikipedia,test_extract_to_txt,"def test_extract_to_txt(self):
        output_file = os.path.join(self.tmp_dir, ""cre.txt"")
        poiolib.wikipedia.extract_to_txt(""cre"", output_file)
        self.assertTrue(os.path.isfile(output_file))
        self.assertNotEqual(os.path.getsize(output_file), 0)

    ",False
1199,https://github.com/nitmir/policyd-rate-limit/blob/79eb4e1760fb9c0ea6e205cb6a0953be8105e0d4/policyd_rate_limit/tests/test_daemon.py,DaemonTestCase,test_main_afinet_socket,"def test_main_afinet_socket(self):
        self.base_config[""SOCKET""] = (""127.0.0.1"", 27184)
        with test_utils.lauch(self.base_config) as cfg:
            self.base_test(cfg)

    ",False
1200,https://github.com/Netflix-Skunkworks/policyuniverse/blob/b633e572ecdba45d70398ac034fb44e0e4e7dbf8/policyuniverse/tests/test_expander_minimizer.py,TestMethods,test_expand_1,"def test_expand_1(self):
        expanded_policy = expand_policy(policy=dc(WILDCARD_POLICY_1))
        self.assertEqual(expanded_policy, EXPANDED_POLICY_1)
        policy = {
            ""Statement"": {
                ""NotAction"": [""ec2:thispermissiondoesntexist""],
                ""Resource"": ""*"",
                ""Effect"": ""Deny"",
            }
        }
        expected_policy = {
            ""Statement"": [
                {
                    ""NotAction"": [""ec2:thispermissiondoesntexist""],
                    ""Resource"": ""*"",
                    ""Effect"": ""Deny"",
                }
            ]
        }
        expanded_policy = expand_policy(policy=dc(policy), expand_deny=False)
        self.assertEqual(expanded_policy, expected_policy)
        expanded_policy = expand_policy(policy=dc(policy), expand_deny=True)
        self.assertEqual(type(expanded_policy[""Statement""]), list)

    ",True
1201,https://github.com/Netflix-Skunkworks/policyuniverse/blob/b633e572ecdba45d70398ac034fb44e0e4e7dbf8/policyuniverse/tests/test_expander_minimizer.py,TestMethods,test_expand_minimize_over_policies,"def test_expand_minimize_over_policies(self):
        result = expand_minimize_over_policies(dc(POLICIES_1), expand_policy)
        self.assertEqual(result, EXPANDED_POLICIES_1)

    ",True
1202,https://github.com/wsilva32/poly_decomp.py/blob/cb1a47f218e076772b9df137c1928023882df5e5/tests/test_poly_decomp.py,TestPoly_Decomp,test_not_polygonCanSee,"def test_not_polygonCanSee(self):
        assert poly_decomp.polygonCanSee(poly, 3, 4) == False

    ",True
1203,https://github.com/wsilva32/poly_decomp.py/blob/cb1a47f218e076772b9df137c1928023882df5e5/tests/test_poly_decomp.py,TestPoly_Decomp,test_not_polygonIsReflex,"def test_not_polygonIsReflex(self):
        assert poly_decomp.polygonIsReflex(poly, 4) == False

    ",True
1204,https://github.com/wsilva32/poly_decomp.py/blob/cb1a47f218e076772b9df137c1928023882df5e5/tests/test_poly_decomp.py,TestPoly_Decomp,test_polygonAt,"def test_polygonAt(self):
        index = 2
        assert poly_decomp.polygonAt(poly, index) == [5, 5]

    ",True
1205,https://github.com/wsilva32/poly_decomp.py/blob/cb1a47f218e076772b9df137c1928023882df5e5/tests/test_poly_decomp.py,TestPoly_Decomp,test_polygonAt_negative_index,"def test_polygonAt_negative_index(self):
        index = -2
        assert poly_decomp.polygonAt(poly, index) == [2.5, 2.5]

    ",True
1206,https://github.com/wsilva32/poly_decomp.py/blob/cb1a47f218e076772b9df137c1928023882df5e5/tests/test_poly_decomp.py,TestPoly_Decomp,test_polygonIsReflex,"def test_polygonIsReflex(self):
        assert poly_decomp.polygonIsReflex(poly, 3) == True

    ",True
1207,https://github.com/h2non/pook/blob/2071da27701c82ce02b015e01e2aa6fd203e7bb5/tests/integration/pook_requests_test.py,,test_requests_get,"def test_requests_get(mock):
    body = {'error': 'not found'}
    mock.get('http://foo.com').reply(404).json(body)

    res = requests.get('http://foo.com')
    assert res.status_code == 404
    assert res.headers == {'Content-Type': 'application/json'}
    assert res.json() == body
    assert pook.isdone() is True


",False
1208,https://github.com/h2non/pook/blob/2071da27701c82ce02b015e01e2aa6fd203e7bb5/tests/integration/pook_requests_test.py,,test_requests_match_url,"def test_requests_match_url(mock):
    body = {'foo': 'bar'}
    mock.get('http://foo.com').reply(200).json(body)

    res = requests.get('http://foo.com')
    assert res.status_code == 200
    assert res.headers == {'Content-Type': 'application/json'}
    assert res.json() == body
    assert pook.isdone() is True
",False
1209,https://github.com/h2non/pook/blob/2071da27701c82ce02b015e01e2aa6fd203e7bb5/tests/unit/api_test.py,,test_mock_contructors,"def test_mock_contructors(engine):
    assert engine.active is False
    assert engine.isdone() is True

    api.mock('foo.com')
    assert engine.isdone() is False
    assert len(engine.mocks) == 1
    api.off()

    assert len(engine.mocks) == 0
    assert engine.active is False
",True
1210,https://github.com/steven-murray/powerbox/blob/315e30b40b22e050304ca3a6600b8a1f28301c0b/tests/test_power.py,,test_power3d,"def test_power3d():
    pb = PowerBox(50, dim=3, pk=lambda k: 1.0 * k ** -2., boxlength=1.0, b=1)
    p, k = get_power(pb.delta_x(), pb.boxlength, b=1)

    print(p / (1.0 * k ** -2.))
    assert np.allclose(p, 1.0 * k ** -2., rtol=2)


",False
1211,https://github.com/steven-murray/powerbox/blob/315e30b40b22e050304ca3a6600b8a1f28301c0b/tests/test_tools.py,,test_var_trivial_weights,"def test_var_trivial_weights():
    x = np.linspace(-3, 3, 400)
    X, Y = np.meshgrid(x, x)
    r2 = X ** 2 + Y ** 2
    P = np.ones_like(r2)
    P += np.random.normal(scale=1, size=(len(x), len(x)))
    ave, coord, var = angular_average(P, np.sqrt(r2), bins=np.linspace(0,x.max(), 20), get_variance=True, weights=np.ones_like(r2))
    print(np.diff(var))
    assert np.all(np.diff(var)<=1e-6)


",False
1212,https://github.com/steven-murray/powerbox/blob/315e30b40b22e050304ca3a6600b8a1f28301c0b/tests/test_tools.py,,test_variance_2d,"def test_variance_2d():
    x = np.linspace(-3, 3, 400)
    X, Y = np.meshgrid(x, x)
    r2 = X ** 2 + Y ** 2
    P = np.ones_like(r2)
    P += np.random.normal(scale=1, size=(len(x), len(x)))
    ave, coord, var = angular_average(P, np.sqrt(r2), bins=np.linspace(0,x.max(), 20), get_variance=True)
    print(np.diff(var))
    assert np.all(np.diff(var)<=0)


",False
1213,https://github.com/ww-tech/primrose/blob/bd9bb8d5d5aaf31d473d01645a862ac9d5fc6f8e/test/test_abstract_pipeline.py,,test_execute_pipeline,"def test_execute_pipeline():
    class TestTransformer(AbstractTransformer):
        ",False
1214,https://github.com/ww-tech/primrose/blob/bd9bb8d5d5aaf31d473d01645a862ac9d5fc6f8e/test/test_factory.py,,test_unregister,"def test_unregister():
    f1 = NodeFactory()
    class TestWriter(AbstractFileWriter):
        ",True
1215,https://github.com/ww-tech/primrose/blob/bd9bb8d5d5aaf31d473d01645a862ac9d5fc6f8e/test/test_s3_writer.py,,test_init_ok,"def test_init_ok():
    config = {
        ""implementation_config"": {
            ""postprocess_config"": {
                ""nodename"": {
                    ""class"": ""TestPostprocess"",
                    ""key1"":""val1"",
                    ""key2"":""val2"",
                    ""destinations"": [""recipe_s3_writer""]
                }
            },
            ""writer_config"": {
                ""recipe_s3_writer"": {
                    ""class"": ""S3Writer"",
                    ""dir"": ""cache"",
                    ""key"": DataObject.DATA_KEY,
                    ""bucket_name"": ""does_not_exist_bucket_name"",
                    ""bucket_filename"": ""does_not_exist.csv""
                }
            }
        }
    }
    class TestPostprocess(AbstractNode):
        @staticmethod
        ",False
1216,https://github.com/syrusakbary/promise/blob/4627315476f6b9fc82818327ae09b04f89f9bda7/tests/test_dataloader.py,,test_wrong_loader_return_type_does_not_block_async_instance,"def test_wrong_loader_return_type_does_not_block_async_instance():
    @Promise.safe
    ",True
1217,https://github.com/abhinavsingh/proxy.py/blob/9b4263777bea7b3e00a1a3546511f2117f210a2b/tests/common/test_utils.py,TestSocketConnectionUtils,test_new_socket_connection_ipv4,"def test_new_socket_connection_ipv4(self, mock_socket: mock.Mock) -> None:
        conn = new_socket_connection(self.addr_ipv4)
        mock_socket.assert_called_with(socket.AF_INET, socket.SOCK_STREAM, 0)
        self.assertEqual(conn, mock_socket.return_value)
        mock_socket.return_value.connect.assert_called_with(self.addr_ipv4)

    @mock.patch('socket.socket')
    ",True
1218,https://github.com/abhinavsingh/proxy.py/blob/9b4263777bea7b3e00a1a3546511f2117f210a2b/tests/common/test_utils.py,TestSocketConnectionUtils,test_new_socket_connection_ipv6,"def test_new_socket_connection_ipv6(self, mock_socket: mock.Mock) -> None:
        conn = new_socket_connection(self.addr_ipv6)
        mock_socket.assert_called_with(socket.AF_INET6, socket.SOCK_STREAM, 0)
        self.assertEqual(conn, mock_socket.return_value)
        mock_socket.return_value.connect.assert_called_with(
            (self.addr_ipv6[0], self.addr_ipv6[1], 0, 0))

    @mock.patch('socket.create_connection')
    ",False
1219,https://github.com/abhinavsingh/proxy.py/blob/9b4263777bea7b3e00a1a3546511f2117f210a2b/tests/http/test_web_server.py,TestWebServerPlugin,test_static_web_server_serves,"def test_static_web_server_serves(
            self, mock_fromfd: mock.Mock, mock_selector: mock.Mock) -> None:
        # Setup a static directory
        static_server_dir = os.path.join(tempfile.gettempdir(), 'static')
        index_file_path = os.path.join(static_server_dir, 'index.html')
        html_file_content = b'''<html><head></head><body><h1>Proxy.py Testing</h1></body></html>'''
        os.makedirs(static_server_dir, exist_ok=True)
        with open(index_file_path, 'wb') as f:
            f.write(html_file_content)

        self._conn = mock_fromfd.return_value
        self._conn.recv.return_value = build_http_request(
            b'GET', b'/index.html')

        mock_selector.return_value.select.side_effect = [
            [(selectors.SelectorKey(
                fileobj=self._conn,
                fd=self._conn.fileno,
                events=selectors.EVENT_READ,
                data=None), selectors.EVENT_READ)],
            [(selectors.SelectorKey(
                fileobj=self._conn,
                fd=self._conn.fileno,
                events=selectors.EVENT_WRITE,
                data=None), selectors.EVENT_WRITE)], ]

        flags = Flags(
            enable_static_server=True,
            static_server_dir=static_server_dir)
        flags.plugins = Flags.load_plugins(
            b'proxy.http.proxy.HttpProxyPlugin,proxy.http.server.HttpWebServerPlugin')

        self.protocol_handler = HttpProtocolHandler(
            TcpClientConnection(self._conn, self._addr),
            flags=flags)
        self.protocol_handler.initialize()

        self.protocol_handler.run_once()
        self.protocol_handler.run_once()

        self.assertEqual(mock_selector.return_value.select.call_count, 2)
        self.assertEqual(self._conn.send.call_count, 1)
        encoded_html_file_content = gzip.compress(html_file_content)
        self.assertEqual(self._conn.send.call_args[0][0], build_http_response(
            200, reason=b'OK', headers={
                b'Content-Type': b'text/html',
                b'Cache-Control': b'max-age=86400',
                b'Content-Encoding': b'gzip',
                b'Connection': b'close',
                b'Content-Length': bytes_(len(encoded_html_file_content)),
            },
            body=encoded_html_file_content
        ))

    @mock.patch('selectors.DefaultSelector')
    @mock.patch('socket.fromfd')
    ",False
1220,https://github.com/willvousden/ptemcee/blob/a411be2e29e39585212c92acea1893f955aa9be8/ptemcee/tests.py,Tests,test_inf_logprob,"def test_inf_logprob(self):
        """"""
        If a walker has any parameter negative, ``logprobfn`` returns
        ``-np.inf``.  Start the ensembles in the all-positive part of the
        parameter space, then run for long enough for sampler to migrate into
        negative parts.  (We can't start outside the posterior support, or the
        sampler will fail).  The sampler should be happy with this; otherwise,
        a FloatingPointError will be thrown by Numpy.  Don't bother checking
        the results because this posterior is difficult to sample.

        """"""
        sampler = Sampler(self.nwalkers, self.ndim,
                          LogLikeGaussian(self.icov_unit, test_inf=True),
                          LogPriorGaussian(self.icov_unit, cutoff=self.cutoff),
                          betas=make_ladder(self.ndim, self.ntemps, np.inf))

        self.check_sampler(sampler, p0=np.abs(self.p0_unit), weak=True)

    ",True
1221,https://github.com/sgaynetdinov/py-vkontakte/blob/b03246b8d4b6f5ee5ab7e5c67e09e1f14b85fd9c/tests/test_message.py,,test_message,"def test_message(factory):
    message = Message.from_json(None, message_json)

    assert isinstance(message, Message)
    assert message.date == 621734400 
    assert message.id == 18000
    assert message.out == 1
    assert message.body == ""Hello world""
    assert message.random_id == 597248445
    assert message.update_time == None

@pytest.mark.parametrize('update_time, expected', [
    (None, None),
    (100500, 100500),
])
",True
1222,https://github.com/ganehag/pyMeterBus/blob/bc853aa38ac6b10301bdf97f13ac25b36985316f/tests/test_globals.py,TestSequenceFunctions,test_debug_default_value,"def test_debug_default_value(self):
        self.assertEqual(meterbus.g.debug, False)

    ",True
1223,https://github.com/samuelduchesne/pyTrnsysType/blob/6cf552e4ccd66f7b728e84654e580befe2061114/tests/test_xml.py,TestTrnsysModel,test_get_attr_derivative,"def test_get_attr_derivative(self, tank_type):
        """"""Test setter for class Derivative""""""
        attr_name = ""Initial_temperature_of_node_1""
        assert tank_type.derivatives[attr_name].value.m == 50.0

    ",True
1224,https://github.com/JBielan/py_ev/blob/0a2d48235b8ff2268254c151a179a2ece40cbd37/tests/test_py_ev.py,,test_reset,"def test_reset():
    ev.reset()
    assert len(ev.deck) == 52
    assert ev.board == []


",True
1225,https://github.com/M0r13n/pyais/blob/d2ca5ff08c532fce5da1c9d268eb453924f12a33/tests/test_ais.py,TestAIS,test_msg_type_15,"def test_msg_type_15(self):
        msg = NMEAMessage(b""!AIVDM,1,1,,A,?5OP=l00052HD00,2*5B"").decode()
        assert msg['type'] == 15
        assert msg['repeat'] == 0
        assert msg['mmsi'] == 368578000
        assert msg['offset1_1'] == 0

        msg = NMEAMessage(b""!AIVDM,1,1,,B,?h3Ovn1GP<K0<P@59a0,2*04"").decode()
        assert msg['type'] == 15
        assert msg['repeat'] == 3
        assert msg['mmsi'] == 3669720
        assert msg['mmsi1'] == 367014320
        assert msg['type1_1'] == 3

        assert msg['mmsi2'] == 0
        assert msg['type1_2'] == 5
        assert msg['offset1_2'] == 617

    ",False
1226,https://github.com/verdan/pyatlasclient/blob/6c3ef3926eef059f00730b6bcc1a1787f6bbcd9c/tests/test_models.py,TestDiscoveryREST,test_search_attribute_get,"def test_search_attribute_get(self, mocker, atlas_client, search_attribute_response):
        mocker.patch.object(atlas_client.search_attribute.client, 'get')
        atlas_client.search_attribute.client.get.return_value =  search_attribute_response 
        params = {'attrName': 'attrName', 'attrValue': 'attrVal', 'offset': '1'}
        search_results = atlas_client.search_attribute(**params) 
        for s in search_results:
            assert s.queryType == 'GREMLIN'
            atlas_client.search_attribute.client.get.assert_called_with(s.url, params=params)
        for s in search_results:
            for e in s.entities:
                assert e.attributes['property1'] == {}

    ",True
1227,https://github.com/gijzelaerr/pybl3p/blob/98c102c02cb93803ee47941a48a8aa8d62fa4d6c/tests/test_public.py,PublicTest,test_tradehistory,"def test_tradehistory(self):
        result = tradehistory()

    ",False
1228,https://github.com/gijzelaerr/pybl3p/blob/98c102c02cb93803ee47941a48a8aa8d62fa4d6c/tests/test_public.py,PublicTest,test_trades,"def test_trades(self):
        result = trades()

    ",False
1229,https://github.com/airbrake/pybrake/blob/9bf82941d8bf521055b258cea91596a11e4eb81f/pybrake/test_notifier.py,,test_unauthorized,"def test_unauthorized():
    notifier = Notifier()

    notice = notifier.notify_sync(""hello"")

    assert notice[""error""] == ""Project API key is required""


",False
1230,https://github.com/Teamworksapp/pydbvolve/blob/e18bb8cf98997c52de0cf30a8e106c480ba0bb57/tests/unittests/test_00_initialization.py,,test_09_get_migration_table_schema,"def test_09_get_migration_table_schema():
    """"""Verify that we get a non-Falsey return from get_migration_table_schema.""""""
    schema = pydbvolve.get_migration_table_schema()
    assert(schema is not None)
    assert(isinstance(schema, str))
    assert(len(schema) > 0)
# End test_09_get_migration_table_name


",True
1231,https://github.com/Teamworksapp/pydbvolve/blob/e18bb8cf98997c52de0cf30a8e106c480ba0bb57/tests/unittests/test_00_initialization.py,,test_13_pre_config,"def test_13_pre_config():
    res = None
    
    try:
        res = pydbvolve.get_db_credentials(None)
    except Exception as e:
        assert(e.__class__.__name__ == 'NotImplementedError')
    
    assert(res is None)
    
    try:
        res = pydbvolve.get_db_connection(None, None)
    except Exception as f:
        assert(f.__class__.__name__ == 'NotImplementedError')
    
    assert(res is None)
# End test_13_pre_config


",True
1232,https://github.com/Teamworksapp/pydbvolve/blob/e18bb8cf98997c52de0cf30a8e106c480ba0bb57/tests/unittests/test_01_migration_table.py,,test_02_check_migration_table_bad_structure,"def test_02_check_migration_table_bad_structure():
    """"""Verify that an aberrant table structure can be detected""""""
    config = pydbvolve.initialize(TEST_CONFIG_FILE, 'info', 'r1.1.10', True, False)
    _create_bad_migration_table(config)
    exc = None
    try:
        res = pydbvolve.check_migration_table(config)
    except Exception as e:
        exc = e
    
    assert(isinstance(exc, pydbvolve.MigrationTableOutOfSync))
# End test_02_check_migration_table_bad_structure


",True
1233,https://github.com/yukinotenshi/pydeploy/blob/e3ddf907b293c9da28503b3d72414a303c5dfbed/pydeploy/tests/test_command_chain.py,TestCommandChain,test_all,"def test_all(self):
        data = {
            'post_script': [
                ""echo "" + self.first_out,
                ""echo "" + self.second_out,
            ],
            'pre_script': [
                ""echo "" + self.first_out,
                ""echo "" + self.second_out,
            ],
            'remote': 'origin',
            'branch': 'master'
        }

        with open(self.filename, 'w') as f:
            json.dump(data, f)

        chain = CommandChain.load_from_config(self.filename)
        chain.commands[0].execute()
        chain.commands[1].execute()
        chain.commands[3].execute()
        chain.commands[4].execute()
        self.assertEqual(len(chain.commands), 5)
        self.assertEqual(chain.commands[2].cmd, 'git pull origin master')
        self.assertIn(self.first_out, chain.commands[0].out)
        self.assertIn(self.second_out, chain.commands[1].out)
        self.assertIn(self.first_out, chain.commands[3].out)
        self.assertIn(self.second_out, chain.commands[4].out)

    ",True
1234,https://github.com/yukinotenshi/pydeploy/blob/e3ddf907b293c9da28503b3d72414a303c5dfbed/pydeploy/tests/test_command_chain.py,TestCommandChain,test_notifier_loaded,"def test_notifier_loaded(self):
        data = {
            'pre_script': [],
            'post_script': [],
            'remote': 'origin',
            'branch': 'master',
            'notifier': {
                'type': 'discord',
                'receiver': 'something'
            }
        }

        with open(self.filename, 'w') as f:
            json.dump(data, f)

        chain = CommandChain.load_from_config(self.filename)
        self.assertIsNotNone(chain.notifier)
",True
1235,https://github.com/yukinotenshi/pydeploy/blob/e3ddf907b293c9da28503b3d72414a303c5dfbed/pydeploy/tests/test_command_chain.py,TestCommandChain,test_postscript_only,"def test_postscript_only(self):
        data = {
            'post_script': [
                ""echo "" + self.first_out,
                ""echo "" + self.second_out,
            ],
            'pre_script': [],
            'remote': 'origin',
            'branch': 'master'
        }

        with open(self.filename, 'w') as f:
            json.dump(data, f)

        chain = CommandChain.load_from_config(self.filename)
        chain.commands[1].execute()
        chain.commands[2].execute()
        self.assertEqual(len(chain.commands), 3)
        self.assertEqual(chain.commands[0].cmd, 'git pull origin master')
        self.assertIn(self.first_out, chain.commands[1].out)
        self.assertIn(self.second_out, chain.commands[2].out)

    ",True
1236,https://github.com/yukinotenshi/pydeploy/blob/e3ddf907b293c9da28503b3d72414a303c5dfbed/pydeploy/tests/test_command_chain.py,TestCommandChain,test_prescript_only,"def test_prescript_only(self):
        data = {
            'pre_script': [
                ""echo "" + self.first_out,
                ""echo "" + self.second_out,
            ],
            'post_script': [],
            'remote': 'origin',
            'branch': 'master'
        }

        with open(self.filename, 'w') as f:
            json.dump(data, f)

        chain = CommandChain.load_from_config(self.filename)
        chain.commands[0].execute()
        chain.commands[1].execute()
        self.assertEqual(len(chain.commands), 3)
        self.assertEqual(chain.commands[2].cmd, 'git pull origin master')
        self.assertIn(self.first_out, chain.commands[0].out)
        self.assertIn(self.second_out, chain.commands[1].out)

    ",True
1237,https://github.com/sdrobert/pydrobert-gpyopt/blob/ce2699ca89687f848c2a86db44eed125d65886de/test_gpyopt.py,,test_strings_are_provided,"def test_strings_are_provided():

    ",True
1238,https://github.com/Prodesire/pydu/blob/4a1c2f15f7274d5079fb08b02ab1dbe08c0cefef/tests/test_misc.py,TestSuperLen,test_file,"def test_file(self, tmpdir, mode, warnings_num, recwarn):
        file_obj = tmpdir.join('test.txt')
        file_obj.write('Test')
        with file_obj.open(mode) as fd:
            assert super_len(fd) == 4
        assert len(recwarn) == warnings_num

    ",False
1239,https://github.com/Prodesire/pydu/blob/4a1c2f15f7274d5079fb08b02ab1dbe08c0cefef/tests/test_network.py,,test_get_free_port,"def test_get_free_port():
    port = get_free_port()
    assert isinstance(port, int)
    assert 65536 > port > 0


",True
1240,https://github.com/whisller/pyeventdispatcher/blob/5382e5e8578dea89a76481e15d410d516999055a/test/test_pyeventdispatcher.py,TestRegister,test_it_allows_to_register,"def test_it_allows_to_register(self, registered, capsys):
        py_event_dispatcher = EventDispatcher()
        py_event_dispatcher.register(""foo.bar"", registered)
        py_event_dispatcher.dispatch(Event(""foo.bar"", {""a"": ""b""}))

        captured = capsys.readouterr()

        assert captured.out == ""{'a': 'b'}\n""

    @pytest.mark.parametrize(
        ""to_register, output"",
        [
            # With default ""priority"" - in order they were added
            (
                (
                    {""lambda"": lambda event: print(""First""), ""priority"": 0},
                    {""lambda"": lambda event: print(""Second""), ""priority"": 0},
                ),
                ""First\nSecond\n"",
            ),
            # Based on priority
            (
                (
                    {""lambda"": lambda event: print(""First""), ""priority"": 0},
                    {""lambda"": lambda event: print(""Second""), ""priority"": -100},
                ),
                ""Second\nFirst\n"",
            ),
        ],
    )
    ",True
1241,https://github.com/whisller/pyeventdispatcher/blob/5382e5e8578dea89a76481e15d410d516999055a/test/test_pyeventdispatcher.py,TestRegister,test_it_allows_to_register,"def test_it_allows_to_register(self, registered, capsys):
        py_event_dispatcher = EventDispatcher()
        py_event_dispatcher.register(""foo.bar"", registered)
        py_event_dispatcher.dispatch(Event(""foo.bar"", {""a"": ""b""}))

        captured = capsys.readouterr()

        assert captured.out == ""{'a': 'b'}\n""

    @pytest.mark.parametrize(
        ""to_register, output"",
        [
            # With default ""priority"" - in order they were added
            (
                (
                    {""lambda"": lambda event: print(""First""), ""priority"": 0},
                    {""lambda"": lambda event: print(""Second""), ""priority"": 0},
                ),
                ""First\nSecond\n"",
            ),
            # Based on priority
            (
                (
                    {""lambda"": lambda event: print(""First""), ""priority"": 0},
                    {""lambda"": lambda event: print(""Second""), ""priority"": -100},
                ),
                ""Second\nFirst\n"",
            ),
        ],
    )
    ",True
1242,https://github.com/whisller/pyeventdispatcher/blob/5382e5e8578dea89a76481e15d410d516999055a/test/test_pyeventdispatcher.py,TestRegister,test_listeners_executed_in_order,"def test_listeners_executed_in_order(self, to_register, output, capsys):
        py_event_dispatcher = EventDispatcher()
        for register in to_register:
            py_event_dispatcher.register(
                ""foo.bar"", register[""lambda""], register[""priority""]
            )
        py_event_dispatcher.dispatch(Event(""foo.bar"", {""a"": ""b""}))

        captured = capsys.readouterr()

        assert captured.out == output

    ",True
1243,https://github.com/whisller/pyeventdispatcher/blob/5382e5e8578dea89a76481e15d410d516999055a/test/test_pyeventdispatcher.py,TestRegister,test_listeners_executed_in_order,"def test_listeners_executed_in_order(self, to_register, output, capsys):
        py_event_dispatcher = EventDispatcher()
        for register in to_register:
            py_event_dispatcher.register(
                ""foo.bar"", register[""lambda""], register[""priority""]
            )
        py_event_dispatcher.dispatch(Event(""foo.bar"", {""a"": ""b""}))

        captured = capsys.readouterr()

        assert captured.out == output

    ",True
1244,https://github.com/ferdinandvwyk/pyfilm/blob/20688f59536c713650516f09e1873fcb5b506a17/tests/test_pyfilm.py,TestClass,test_calculate_cbar_ticks,"def test_calculate_cbar_ticks(self):
        options = {}
        options = set_default_options(options)
        z = np.random.randint(low=0, high=2, size=[2,2,2])
        options = calculate_cbar_ticks(z, options)
        assert np.sum(options['cbar_ticks'] - np.linspace(0, 1, 5)) < 1e-5

        options = {}
        options = set_default_options(options)
        options['cbar_ticks'] = 7
        z = np.random.randint(low=0, high=2, size=[2,2,2])
        options = calculate_cbar_ticks(z, options)
        assert np.sum(options['cbar_ticks'] - np.linspace(0, 1, 7)) < 1e-5

    ",True
1245,https://github.com/supercoderz/pyflightdata/blob/ae59893f58f8bd1630c1c8f1ab9d388bbd72ee71/pyflightdata/test_pyflightdata.py,TestGetByTailNumber,test_aircraft_info,"def test_aircraft_info(self):
        result = f.get_info_by_tail_number('9V-MGA')
        assert result.__len__() > 0

    ",False
1246,https://github.com/nielstron/pyfronius/blob/5aee17d94330547b6ff2a72df3daff380f8f831c/pyfronius/tests/test_web.py,FroniusWebTest,test_fronius_get_inverter_realtime_data_system,"def test_fronius_get_inverter_realtime_data_system(self):
        res = asyncio.get_event_loop().run_until_complete(
            self.fronius.current_system_inverter_data())
        self.assertEqual(res, GET_INVERTER_REALTIME_DATA_SYSTEM)

    ",False
1247,https://github.com/chaosmail/python-fs/blob/2567922ced9387e327e65f3244caff3b7af35684/fs/tests/test_mkdir.py,,test_mkdir,"def test_mkdir():

    dir_name = ""foo""
    path = os.path.join(TEST_DIR, dir_name)

    if (os.path.exists(path)):
        raise ValueError(""Directory %s already exists!"" % path)

    fs.mkdir(path)

    assert os.path.exists(path) is True

",True
1248,https://github.com/RBGKew/pykew/blob/557c1852ad7a4366467e344e7a46b42549ce8694/pykew/test_powo.py,,test_basic_search,"def test_basic_search():
    res = powo.search('Poa Annua')
    assert res.size() >= 2
    assert next(res)['fqId'] == 'urn:lsid:ipni.org:names:320035-2'

",False
1249,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,CurveTests,test_curve,"def test_curve(self):
        curve = Curve.parse(
            '(fp_curve (pts (xy 0 0) (xy 1 1) (xy 2 2) (xy 3 3)))')
        assert curve.start == (0, 0)
        assert curve.bezier1 == (1, 1)
        assert curve.bezier2 == (2, 2)
        assert curve.end == (3, 3)


class ModelTests(unittest.TestCase):
    ",True
1250,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,DrillTests,test_drill,"def test_drill(self):
        drill = Drill.parse('(drill 0.8)')
        assert drill.size == 0.8
        assert Drill.parse(drill.to_string()) == drill

    ",True
1251,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,DrillTests,test_drill_offset,"def test_drill_offset(self):
        drill = Drill.parse('(drill 0.8 (offset 0.1 0.2))')
        assert drill.size == 0.8 and drill.offset == [0.1, 0.2]
        assert Drill.parse(drill.to_string()) == drill


class PadTests(unittest.TestCase):
    ",True
1252,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,DrillTests,test_drill_oval,"def test_drill_oval(self):
        drill = Drill.parse('(drill oval 0.6 0.8)')
        assert drill.size == [0.6, 0.8]
        assert Drill.parse(drill.to_string()) == drill

    ",True
1253,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,LineTests,test_line,"def test_line(self):
        line = Line.parse('(fp_line (start 0 0) (end 1 1) (layer layer))')
        assert line.start == [0.0, 0.0]
        assert line.end == [1.0, 1.0]
        assert line.layer == 'layer'
        assert Line.parse(line.to_string()) == line


class PolygonTests(unittest.TestCase):
    ",True
1254,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,ModelTests,test_model,"def test_model(self):
        model_string = (
            '(model path'
            '    (at (xyz 0 0 0))'
            '    (scale (xyz 0 0 0))'
            '    (rotate (xyz 0 0 0)))')
        model = Model.parse(model_string)
        assert model.at == (0, 0, 0)
        assert model.scale == (0, 0, 0)
        assert model.rotate == (0, 0, 0)
        assert Model.parse(model.to_string()) == model


class ModuleTests(unittest.TestCase):
    ",True
1255,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,ModuleTests,test_module,"def test_module(self):
        module_string = '(module name (layer F.Cu) %s)'
        module = Module.parse(module_string % '')
        assert module.name == 'name'
        assert module.layer == 'F.Cu'
        assert Module.parse(module.to_string()) == module

        pads = ''
        for i in range(2):
            pads += Pad(str(i + 1), drill=Drill(0.8)).to_string()

        module = Module.parse(module_string % pads)
        assert module.pads[0].name == '1'
        assert module.pads[0].drill.size == 0.8
        assert module.pads[1].name == '2'
        assert module.pads[1].drill.size == 0.8
        assert Module.parse(module.to_string()) == module


class NetTests(unittest.TestCase):
    ",True
1256,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,NetTests,test_net_auto_numbering,"def test_net_auto_numbering(self):
        n1, n2, n3 = Net(), Net(), Net()
        assert n1.code == 1
        assert n2.code == 2
        assert n3.code == 3
",True
1257,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,PadTests,test_pad,"def test_pad(self):
        pad = Pad.parse(
            '(pad 1 smd rect (at 0.1 0.1) (size 0.2 0.2) (layers F.Cu))')
        assert pad.name == '1'
        assert pad.type == 'smd'
        assert pad.shape == 'rect'
        assert pad.at == [0.1, 0.1]
        assert pad.size == [0.2, 0.2]
        assert pad.layers == ['F.Cu']
        assert Pad.parse(pad.to_string()) == pad

    ",True
1258,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,PadTests,test_pad_with_drill,"def test_pad_with_drill(self):
        pad = Pad.parse('(pad 1 smd rect (at 0.1 0.1) (size 0.2 0.2) '
                        '(layers F.Cu) (drill 0.8))')
        assert pad.drill.size == 0.8
        assert Pad.parse(pad.to_string()) == pad

    ",True
1259,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,PadTests,test_pad_with_multiple_layers,"def test_pad_with_multiple_layers(self):
        pad = Pad.parse('(pad 1 smd rect (at 0.1 0.1) (size 0.2 0.2) '
                        '(layers F.Cu B.Cu))')
        assert pad.layers == ['F.Cu', 'B.Cu']
        assert Pad.parse(pad.to_string()) == pad


class TextTests(unittest.TestCase):
    ",True
1260,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,PolygonTests,test_polygon,"def test_polygon(self):
        poly = Polygon.parse('(fp_poly (pts (xy 0 0) (xy 1 0)) (width 0.01))')
        assert poly.pts == [(0, 0), (1, 0)]
        assert poly.width == 0.01
        assert Polygon.parse(poly.to_string()) == poly


class CurveTests(unittest.TestCase):
    ",True
1261,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,TextTests,test_text,"def test_text(self):
        text = Text.parse('(fp_text user text (at 0.0 0.0) (layer F.SilkS))')
        assert text.type == 'user'
        assert text.text == 'text'
        assert text.at == [0.0, 0.0]
        assert text.layer == 'F.SilkS'
        assert Text.parse(text.to_string()) == text

    ",True
1262,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,TextTests,test_text_with_hide,"def test_text_with_hide(self):
        text = Text.parse(
            '(fp_text user text (at 0.0 0.0) (layer F.SilkS) hide)')
        assert text.hide == True
        assert Text.parse(text.to_string()) == text

    ",True
1263,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,TextTests,test_text_with_justify,"def test_text_with_justify(self):
        text = Text.parse('(fp_text user text (at 0.0 0.0) (layer layer) '
                          '(effects (justify mirror)))')
        assert text.justify == 'mirror'
        assert Text.parse(text.to_string()) == text


class LineTests(unittest.TestCase):
    ",True
1264,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,TextTests,test_text_with_rotation,"def test_text_with_rotation(self):
        text = Text.parse(
            '(fp_text user text (at 0.0 0.0 0.0) (layer F.SilkS))')
        assert text.at == [0.0, 0.0, 0.0]
        assert text.hide == False
        assert Text.parse(text.to_string()) == text

    ",True
1265,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_module.py,TextTests,test_text_with_thickness,"def test_text_with_thickness(self):
        text = Text.parse('(fp_text user text (at 0.0 0.0) (layer F.SilkS) '
                          '(effects (font (size 0.1 0.1) (thickness 0.2))))')
        assert text.size == [0.1, 0.1]
        assert text.thickness == 0.2
        assert Text.parse(text.to_string()) == text

    ",True
1266,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,NetClassTests,test_parse,"def test_parse(self):
        nc_string = ""(net_class name description (add_net GND))""
        nc = NetClass.parse(nc_string)
        assert nc.name == 'name'
        assert nc.description == 'description'
        assert nc.nets == ['GND']

    ",True
1267,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,NetClassTests,test_with_multiple_nets,"def test_with_multiple_nets(self):
        nc = NetClass('default')
        nc.nets += ['GND', 'VO']
        nc_str = nc.to_string()
        assert NetClass.parse(nc.to_string()) == nc


class ZoneTests(unittest.TestCase):
    ",True
1268,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,NetClassTests,test_with_net,"def test_with_net(self):
        nc = NetClass('default')
        nc.nets.append('GND')
        assert NetClass.parse(nc.to_string()) == nc

    ",True
1269,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,NetClassTests,test_without_net,"def test_without_net(self):
        nc = NetClass('default')
        assert NetClass.parse(nc.to_string()) == nc

    ",True
1270,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,PcbTests,test_comment,"def test_comment(self):
        pcb = Pcb(comment1='hello world', comment2='bye world')
        assert Pcb.parse(pcb.to_string()) == pcb

    ",True
1271,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,PcbTests,test_layers,"def test_layers(self):
        pcb = Pcb()
        pcb.layers.append(Layer('B.Cu'))
        assert Pcb.parse(pcb.to_string()) == pcb
        pcb.layers.append(Layer('F.Cu'))
        assert Pcb.parse(pcb.to_string()) == pcb
",True
1272,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,PcbTests,test_minimal_pcb,"def test_minimal_pcb(self):
        pcb_string = open('tests/minimal_pcb.kicad_pcb', 'r').read()
        pcb = Pcb.parse(pcb_string)
        assert pcb.version == 123
        assert pcb.host == ['pcbnew', 'version']
        assert len(pcb.nets) == 4
        assert len(pcb.modules) == 2
        assert Pcb.parse(pcb.to_string()) == pcb

    ",True
1273,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,PcbTests,test_num_nets,"def test_num_nets(self):
        pcb = Pcb(num_nets=5)
        assert Pcb.parse(pcb.to_string()) == pcb
        pcb.nets.append(Net())
        assert Pcb.parse(pcb.to_string()) == pcb

    ",True
1274,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,PcbTests,test_page,"def test_page(self):
        pcb = Pcb()
        assert Pcb.parse(pcb.to_string()) == pcb
        pcb.page_type = 'A4'
        assert Pcb.parse(pcb.to_string()) == pcb
        pcb.page_type = [200, 200]
        assert Pcb.parse(pcb.to_string()) == pcb

    ",True
1275,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,PcbTests,test_single_module,"def test_single_module(self):
        pcb = Pcb()
        pcb.modules.append(Module(name='R'))
        assert Pcb.parse(pcb.to_string()) == pcb

    ",True
1276,https://github.com/dvc94ch/pykicad/blob/cdebcaeb4ab6c8903ebecfd0748f826ea406923f/tests/test_pcb.py,ZoneTests,test_parse,"def test_parse(self):
        zone_string = '(zone (polygon (pts (xy 0 0) (xy 1 1))))'
        zone = Zone.parse(zone_string)
        assert zone.polygon[0] == (0, 0)
        assert zone.polygon[1] == (1, 1)
        assert Zone.parse(zone.to_string()) == zone


class PcbTests(unittest.TestCase):
    ",True
1277,https://github.com/konstantint/pyliftover/blob/c95c70ab74686a6b5ac56e7601ccdbeab3178e52/tests/liftover_test.py,,test_issue_2_3_4,"def test_issue_2_3_4():
    '''
    Check the correctness of coordinate conversion for issue 2/3/4.
    
    NB: We are using the ""live"" hg38ToHg19.over.chain.gz file, hence if it happens to change later on,
    the test may start failing. Just in case we have the original cached in the data directory as well.
    '''
    lo = LiftOver('hg38', 'hg19')
    test_input = os.path.join(DATA_DIR, 'hg38ToHg19.testinput.txt')
    test_output = os.path.join(DATA_DIR, 'hg38ToHg19.testoutput.txt')
    
    test_input = dict([(ln[3], (ln[0], int(ln[1]), ln[5].strip())) for ln in [line.split() for line in open(test_input)]])
    test_output = dict([(ln[3], (ln[0], int(ln[1]), ln[5].strip())) for ln in [line.split() for line in open(test_output)]])
    
    for k in test_input:
        res = lo.convert_coordinate(*test_input[k])
        if k not in test_output:
            assert len(res) == 0
        else:
            assert len(res) == 1 and res[0][0:3] == test_output[k]
",False
1278,https://github.com/zembrodt/pymdb/blob/bca5a414fdcdbbc1f86ed5b284945665c1edf43f/tests/test_scraper.py,TestGetCompany,test_get_company_multiple_pages,"def test_get_company_multiple_pages(self):
        company_id = 'co0076091'
        scraper = PyMDbScraper()
        valid_titles = {
            'tt1856101', 'tt1219827', 'tt0338526', 'tt1136608', 'tt1596576', 'tt0477407', 'tt0806017', 'tt4656248'
        }
        for company in scraper.get_company(company_id):
            self.assertEqual(company.company_id, company_id)
            if company.title_id in valid_titles:
                valid_titles.remove(company.title_id)
        self.assertEqual(len(valid_titles), 0)

    ",False
1279,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_simple.py,SimplePubSubTest,test_event_serialization,"def test_event_serialization(self):
        called = threading.Event()

        ",True
1280,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_simple.py,SimplePubSubTest,test_topic,"def test_topic(self):
        invocations = queue.Queue()

        ",True
1281,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcQueueTest,test_queue_collection_types,"def test_queue_collection_types(self):
        q = pymq.queue('test_queue')

        q.put(('a', 1))
        v = q.get()
        self.assertIsInstance(v, tuple)
        self.assertIsInstance(v[0], str)
        self.assertIsInstance(v[1], int)

        q.put([1, 'v'])
        v = q.get()
        self.assertIsInstance(v, list)
        self.assertIsInstance(v[0], int)
        self.assertIsInstance(v[1], str)

        q.put({'a': 1, 'b': 'c'})
        v = q.get()
        self.assertIsInstance(v, dict)
        self.assertIsInstance(v['a'], int)
        self.assertIsInstance(v['b'], str)

    ",True
1282,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcQueueTest,test_queue_complex_types,"def test_queue_complex_types(self):
        q = pymq.queue('test_queue')

        q.put(EventWithPayload(Payload('foo', 42)))
        v = q.get()
        self.assertIsInstance(v, EventWithPayload)
        self.assertIsInstance(v.payload, Payload)
        self.assertIsInstance(v.payload.name, str)
        self.assertIsInstance(v.payload.value, int)
",True
1283,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcQueueTest,test_queue_get_blocking,"def test_queue_get_blocking(self):
        q = pymq.queue('test_queue')
        event = threading.Event()

        ",True
1284,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcQueueTest,test_queue_get_nowait_timeout,"def test_queue_get_nowait_timeout(self):
        q = pymq.queue('test_queue')
        then = time.time()
        self.assertRaises(pymq.Empty, q.get_nowait)
        diff = time.time() - then
        self.assertAlmostEqual(0, diff, delta=0.3)

    @timeout_decorator.timeout(2)
    ",True
1285,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcQueueTest,test_queue_primitive_types,"def test_queue_primitive_types(self):
        q = pymq.queue('test_queue')

        q.put('abc')
        self.assertIsInstance(q.get(), str)

        q.put(1)
        self.assertIsInstance(q.get(), int)

        q.put(1.1)
        self.assertIsInstance(q.get(), float)

    ",True
1286,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcQueueTest,test_queue_put_get,"def test_queue_put_get(self):
        q = pymq.queue('test_queue')
        q.put('elem1')
        q.put('elem2')

        self.assertEqual('elem1', q.get())
        self.assertEqual('elem2', q.get())

    @timeout_decorator.timeout(2)
    ",True
1287,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_echo_command_response_function,"def test_echo_command_response_function(self):
        pymq.expose(echo_command_response_function, channel='echo_command_response_function')

        stub = pymq.stub('echo_command_response_function')
        result = stub(EchoCommand('unittest'))

        self.assertIsInstance(result, EchoResponse)
        self.assertEqual(result.result, 'Hello unittest!')

    @timeout_decorator.timeout(5)
    ",True
1288,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_error_function,"def test_error_function(self):
        pymq.expose(error_function, channel='error_function')

        stub = pymq.stub('error_function')
        try:
            result = stub()
            self.fail('Should have thrown exception, but received result %s' % result)
        except RemoteInvocationError as e:
            self.assertIn('ValueError', str(e))
",True
1289,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_remote_decorator,"def test_remote_decorator(self):
        @pymq.remote
        ",True
1290,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_simple_function,"def test_simple_function(self):
        pymq.expose(simple_remote_function, channel='simple_remote_function')

        stub = pymq.stub('simple_remote_function')
        result = stub('unittest')
        self.assertEqual('Hello unittest!', result)

    @timeout_decorator.timeout(2)
    ",True
1291,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_simple_list_param_function,"def test_simple_list_param_function(self):
        pymq.expose(simple_list_param_function, channel='simple_list_param_function')

        stub = pymq.stub('simple_list_param_function')
        result = stub([2, 3, 4])
        self.assertEqual(9, result)

    @timeout_decorator.timeout(2)
    ",True
1292,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_simple_multiple_param_default_function,"def test_simple_multiple_param_default_function(self):
        pymq.expose(simple_multiple_param_default_function, channel='simple_multiple_param_default_function')

        stub = pymq.stub('simple_multiple_param_default_function')
        result = stub(2)
        self.assertEqual(6, result)

    @timeout_decorator.timeout(2)
    ",True
1293,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_simple_multiple_param_function,"def test_simple_multiple_param_function(self):
        pymq.expose(simple_multiple_param_function, channel='simple_multiple_param_function')

        stub = pymq.stub('simple_multiple_param_function')
        result = stub(2, 3)
        self.assertEqual(6, result)

    @timeout_decorator.timeout(2)
    ",True
1294,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_stateful_rpc,"def test_stateful_rpc(self):
        obj = RpcHolder()
        pymq.expose(obj.echo)

        stub = pymq.stub(RpcHolder.echo)
        result = stub(EchoCommand('unittest'))
        self.assertIsInstance(result, EchoResponse)
        self.assertEqual('Hello unittest!', result.result)

    @timeout_decorator.timeout(2)
    ",True
1295,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_timeout,"def test_timeout(self):
        pymq.expose(delaying_function, channel='delaying_function')
        stub = pymq.stub('delaying_function', timeout=1)
        self.assertRaises(RemoteInvocationError, stub)

    @timeout_decorator.timeout(2)
    ",True
1296,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_ipc.py,IpcRpcTest,test_void_function_error,"def test_void_function_error(self):
        pymq.expose(void_function, channel='void_function')

        stub = pymq.stub('void_function')
        self.assertRaises(RemoteInvocationError, stub, 1, 2, 3)

    @timeout_decorator.timeout(2)
    ",True
1297,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_simple.py,SimpleRpcTest,test_stateful_rpc,"def test_stateful_rpc(self):
        obj = RpcHolder()
        pymq.expose(obj.echo)

        stub = pymq.stub(RpcHolder.echo)
        result = stub(EchoCommand('unittest'))
        self.assertIsInstance(result, EchoResponse)
        self.assertEqual('Hello unittest!', result.result)

    @timeout_decorator.timeout(2)
    ",True
1298,https://github.com/thrau/pymq/blob/101857bca2b705c328d3bda3b26797b51e8ffb70/tests/test_provider_redis.py,RedisRpcTest,test_channel_expire,"def test_channel_expire(self):
        self.bus.rpc_channel_expire = 1
        called = threading.Event()

        ",True
1299,https://github.com/ioos/pyoos/blob/908660385029ecd8eccda8ab3a6b20b47b915c77/tests/collectors/test_ndbc_sos.py,NdbcSosTest,test_raw_ndbc_get_observation,"def test_raw_ndbc_get_observation(self):
        self.c.start_time = datetime.strptime(""2012-10-01"", ""%Y-%m-%d"")
        self.c.end_time = datetime.strptime(""2012-10-02"", ""%Y-%m-%d"")
        self.c.features = [""41012""]
        self.c.variables = [""air_pressure_at_sea_level""]

        response = self.c.raw(responseFormat=""text/csv"").decode()
        assert isinstance(response, string_types)
        """"""
        station_id,sensor_id,""latitude (degree)"",""longitude (degree)"",date_time,""depth (m)"",""air_pressure_at_sea_level (hPa)""  # noqa
        urn:ioos:station:wmo:41012,urn:ioos:sensor:wmo:41012::baro1,30.04,-80.55,2012-10-01T00:50:00Z,0.00,1009.8
        """"""
        data = list(csv.DictReader(io.StringIO(response)))
        assert data[0][""station_id""] == ""urn:ioos:station:wmo:41012""
        assert data[0][""sensor_id""] == ""urn:ioos:sensor:wmo:41012::baro1""
        assert data[0][""date_time""] == ""2012-10-01T00:50:00Z""
        assert data[0][""depth (m)""] == ""0.00""
        assert data[0][""air_pressure_at_sea_level (hPa)""] == ""1009.8""

    ",False
1300,https://github.com/ioos/pyoos/blob/908660385029ecd8eccda8ab3a6b20b47b915c77/tests/collectors/test_usgs.py,USGSTest,test_by_bbox,"def test_by_bbox(self):
        self.c.filter(bbox=(-87, 46, -85, 48))
        collection = self.c.collect()
        collection.calculate_bounds()

        # Another flaky test.
        assert len(collection.elements) == 7
        assert sorted((x.uid for x in collection.elements)) == [
            ""04044724"",
            ""04044755"",
            ""04045500"",
            ""04046000"",
            ""04052500"",
            ""04052600"",
            ""04056500"",
        ]

        station = collection.elements[0]
        assert station.name == ""AU TRAIN RIVER AT FOREST LAKE, MI""
        # Measures 2 variables
        assert len(station.get_unique_members()) == 2
        assert station.location.x == -86.8501514
        assert station.location.y == 46.34077908
        assert station.location.z == 0

        # Apply time filter as well
        starting = datetime(2013, 12, 31, 0, 0, 0)
        ending = starting + timedelta(hours=6)
        self.c.filter(start=starting, end=ending)
        collection = self.c.collect()
        collection.calculate_bounds()

        # Returns 4 stations: 04044724, 04045500, 04046000, 04056500
        assert len(collection.elements) == 4
        assert sorted((x.uid for x in collection.elements)) == [
            ""04044724"",
            ""04045500"",
            ""04046000"",
            ""04056500"",
        ]

    ",False
1301,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_BaseDataset_common_behaviours.py,,test_save_load,"def test_save_load():

    ds.save(file_path=out_file)
    reloaded_ds = ds.__class__(dataset_path=out_file)

    if ds != reloaded_ds:
        raise IOError('Error in save/load implementation!')

    must_have_attr = ('_data', '_targets',
                      '_dtype', '_target_type', '_description',
                      '_num_features', '_feature_names',
                      '_attr', '_attr_dtype', '_dataset_attr')

    for attr in must_have_attr:
        if not hasattr(reloaded_ds, attr):
            raise AttributeError('Attribute {} missing after reload from disk'
                                 ''.format(attr))

        orig_val = getattr(ds, attr)
        reloaded = getattr(reloaded_ds, attr)

        not_equal = False
        try:
            if isinstance(orig_val, dict):
                for key, val in orig_val.items():
                    if _not_equal(val, reloaded[key]):
                        warn('Values differ for attr {} in samplet {}'
                                         ' when reloaded from disk'.format(attr, key))
                        not_equal = True
                        break
            elif is_iterable_but_not_str(orig_val):
                for aa, bb in zip(orig_val, reloaded):
                    if aa != bb:
                        not_equal= True
                        break
                # not_equal = any(np.not_equal(orig_val, reloaded))
            elif np.issubdtype(type(orig_val), np.generic):
                not_equal = reloaded != orig_val
            else:
                raise TypeError('Unrecognized type {} for attr {}'
                                ''.format(type(orig_val), attr))
        except:
            raise

        if not isinstance(not_equal, bool):
            not_equal = any(not_equal)

        if not_equal:
            raise AttributeError('Attribute {} differs between the reloaded'
                                 ' and the original datasets'.format(attr))


",True
1302,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_classify_dataset.py,,test_add,"def test_add():
    a = other_targets_ds + random_target_ds
    n = a.num_samplets
    n1 = other_targets_ds.num_samplets
    n2 = random_target_ds.num_samplets
    assert n1 + n2 == n

    assert set(a.samplet_ids) == set(
            other_targets_ds.samplet_ids + random_target_ds.samplet_ids)
    assert a.num_features == other_targets_ds.num_features == \
           random_target_ds.num_features
    assert all(a.feature_names == other_targets_ds.feature_names)

    comb_ds = test_dataset + same_ids_new_feat
    comb_names = np.concatenate([test_dataset.feature_names,
                                 same_ids_new_feat.feature_names])
    if not all(comb_ds.feature_names == comb_names):
        raise ValueError('feature names were not carried forward in combining two '
                         'datasets with same IDs and different feature names!')


",True
1303,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_classify_dataset.py,,test_cant_write_to_nonexisting_dir,"def test_cant_write_to_nonexisting_dir():
    with raises(IOError):
        test_dataset.save('/nonexistentrandomdir/jdknvoindvi93/arbitrary.noname.pkl')


",True
1304,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_classify_dataset.py,,test_init_with_dict,"def test_init_with_dict():
    new_ds = ClfDataset(data=test_dataset.data,
                        targets=test_dataset.targets)
    assert new_ds == test_dataset


# ",True
1305,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_classify_dataset.py,,test_num_targets,"def test_num_targets():
    assert test_dataset.num_targets == num_targets


",True
1306,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_classify_dataset.py,,test_return_data_labels,"def test_return_data_labels():
    matrix, vec_labels, sub_ids = test_dataset.data_and_labels()
    assert len(vec_labels) == len(sub_ids)
    assert len(vec_labels) == matrix.shape[0]


",True
1307,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_old_pyradigm.py,,test_add,"def test_add():
    a = other_classes_ds + random_class_ds
    n = a.num_samples
    n1 = other_classes_ds.num_samples
    n2 = random_class_ds.num_samples
    assert n1 + n2 == n

    assert set(a.sample_ids) == set(other_classes_ds.sample_ids+random_class_ds.sample_ids)
    assert a.num_features == other_classes_ds.num_features == random_class_ds.num_features
    assert all(a.feature_names == other_classes_ds.feature_names)

    comb_ds = test_dataset + same_ids_new_feat
    comb_names = np.concatenate([ test_dataset.feature_names,
                            same_ids_new_feat.feature_names])
    if not all(comb_ds.feature_names == comb_names):
        raise ValueError('feature names were not carried forward in combining two '
                         'datasets with same IDs and different feature names!')

",True
1308,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_old_pyradigm.py,,test_init_with_dict,"def test_init_with_dict():
    new_ds = MLDataset(data=test_dataset.data, labels=test_dataset.labels, classes=test_dataset.classes)
    assert new_ds == test_dataset

",True
1309,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_old_pyradigm.py,,test_num_classes,"def test_num_classes():
    assert test_dataset.num_classes == num_classes

",True
1310,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_old_pyradigm.py,,test_return_data_labels,"def test_return_data_labels():
    matrix, vec_labels, sub_ids = test_dataset.data_and_labels()
    assert len(vec_labels)==len(sub_ids)
    assert len(vec_labels)==matrix.shape[0]

",True
1311,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_regress_dataset.py,,test_add,"def test_add():
    a = other_targets_ds + random_target_ds
    n = a.num_samplets
    n1 = other_targets_ds.num_samplets
    n2 = random_target_ds.num_samplets
    assert n1 + n2 == n

    assert set(a.samplet_ids) == set(
            other_targets_ds.samplet_ids + random_target_ds.samplet_ids)
    assert a.num_features == other_targets_ds.num_features == \
           random_target_ds.num_features
    assert all(a.feature_names == other_targets_ds.feature_names)

    comb_ds = test_dataset + same_ids_new_feat
    comb_names = np.concatenate([test_dataset.feature_names,
                                 same_ids_new_feat.feature_names])
    if not all(comb_ds.feature_names == comb_names):
        raise ValueError('feature names were not carried forward in combining two '
                         'datasets with same IDs and different feature names!')


",True
1312,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_regress_dataset.py,,test_cant_write_to_nonexisting_dir,"def test_cant_write_to_nonexisting_dir():
    with raises(IOError):
        test_dataset.save('/nonexistentrandomdir/jdknvoindvi93/arbitrary.noname.pkl')


",True
1313,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_regress_dataset.py,,test_init_with_dict,"def test_init_with_dict():
    new_ds = RegrDataset(data=test_dataset.data,
                         targets=test_dataset.targets)
    assert new_ds == test_dataset


# ",True
1314,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_regress_dataset.py,,test_num_targets,"def test_num_targets():
    assert test_dataset.num_targets == num_targets


",True
1315,https://github.com/raamana/pyradigm/blob/01d47cf34a9af4bb104e2891559059a522221b4d/pyradigm/tests/test_regress_dataset.py,,test_return_data_labels,"def test_return_data_labels():
    matrix, vec_labels, sub_ids = test_dataset.data_and_targets()
    assert len(vec_labels) == len(sub_ids)
    assert len(vec_labels) == matrix.shape[0]


",True
1316,https://github.com/opper/pyserverpilot/blob/b6b896fea1155fa95febde84f74e0d2230523ab0/tests/test_app.py,TestApp,test_add_ssl,"def test_add_ssl(self, mock_sp, client: AppsModule, shared):
        app = shared['app']  # type: AppModel

        with pytest.raises(ValidationError):
            client.add_ssl(app.id)  # missing params

            client.add_ssl(app.id, key=123, cert='sslcert', cacerts='sslcacert')  # invalid parameter type

        mock_sp.return_value = AppMock('add_ssl')
        response = client.add_ssl(app.id, key='sslkey', cert='sslcert', cacerts=None)

        assert response.key == 'sslkey'
        assert response.cert == 'sslcert'

        app.ssl = response

    ",True
1317,https://github.com/opper/pyserverpilot/blob/b6b896fea1155fa95febde84f74e0d2230523ab0/tests/test_app.py,TestApp,test_enable_force_ssl,"def test_enable_force_ssl(self, mock_sp, client: AppsModule, shared):
        app = shared['app']  # type: AppModel

        with pytest.raises(ValidationError):
            client.set_force_ssl(app.id)

            client.set_force_ssl(app.id, force=""yes"")  # invalid parameter type

        mock_sp.return_value = AppMock('set_force_ssl')
        response = client.set_force_ssl(app.id, force=True)

        assert response.key == app.ssl.key
        assert response.force is True
",True
1318,https://github.com/opper/pyserverpilot/blob/b6b896fea1155fa95febde84f74e0d2230523ab0/tests/test_app.py,TestApp,test_get_app,"def test_get_app(self, mock_sp, client: AppsModule, shared):
        mock_sp.return_value = AppMock('get_app')
        app = shared['app']

        response = client.get_app(app.id)
        assert response.id == app.id

    ",True
1319,https://github.com/opper/pyserverpilot/blob/b6b896fea1155fa95febde84f74e0d2230523ab0/tests/test_app.py,TestApp,test_update_app_validation,"def test_update_app_validation(self, mock_sp, client: AppsModule, shared):
        app = shared['app']  # type: AppModel

        with pytest.raises(ValidationError):
            client.update_app(app.id, domains=""website.com"")  # invalid parameter type

        mock_sp.return_value = AppMock('update_app')
        response = client.update_app(app.id, domains=['www.myshop.com', 'myshop.com'], runtime='php7.1')

        assert response.id == app.id
        assert response.runtime == 'php7.2'

    ",True
1320,https://github.com/opper/pyserverpilot/blob/b6b896fea1155fa95febde84f74e0d2230523ab0/tests/test_db.py,TestDb,test_get_db,"def test_get_dbs(self, mock_sp, client: DbsModule):
        mock_sp.return_value = DbMock('get_dbs')

        response = client.get_dbs()

        assert len(response) == 2

    ",True
1321,https://github.com/opper/pyserverpilot/blob/b6b896fea1155fa95febde84f74e0d2230523ab0/tests/test_db.py,TestDb,test_update_db,"def test_update_db(self, mock_sp, client: DbsModule, shared):
        db = shared['db']

        with pytest.raises(ValidationError):
            client.update_db(db.id)  # no params error

            client.update_db(db.id, user={})  # invalid user schema

            client.update_db(db.id,
                             user={
                                 'name': 'superlongnameshouldbeinvalid',  # invalid username
                                 'password': 'BaOWYl3IjMc4raBe'
                             })

            client.update_db(db.id,
                             user={
                                 'name': 'username',
                                 'password': 'passw',  # invalid password
                             })

            client.update_db(db.id,
                             user={
                                 'name': 'username',
                                 'password': 'BaOWYl3IjMc4raBe',
                                 'hello': 'extraparam'  # extra invalid param
                             })

        new_user = {
            'name': 'jerry',
            'password': 'BaOWYl3IjMc4raBe'
        }

        mock_sp.return_value = DbMock('update_db')
        client.update_db(db.id, user=new_user)

        mock_sp.return_value = DbMock('update_db')

        response = client.get_db(shared['db'].id)

        assert response.user['name'] == new_user['name']
",True
1322,https://github.com/kivio/pysllo/blob/8bc4d17f9a668e9aff3c77f688f0c06ed2e7686b/tests/test_propagation_logger.py,,test_forcing_level_by_dict,"def test_forcing_level_by_dict(propagation_logger, handler):
    msg1 = ""TEST1""
    msg2 = ""TEST2""
    propagation_logger.setLevel(logging.INFO)
    levels = {
            'logger_1': logging.DEBUG
        }
    propagation_logger.force_level(levels)
    additional_logger = logging.getLogger('logger_1')
    additional_logger.setLevel(logging.INFO)
    additional_logger.addHandler(handler)
    propagation_logger.debug(msg1)
    additional_logger.debug(msg2)
    record = handler.pop()
    assert record.msg == msg2
    assert record.levelname == logging.getLevelName(logging.DEBUG)
    with pytest.raises(IndexError):
        handler.pop()


",True
1323,https://github.com/kivio/pysllo/blob/8bc4d17f9a668e9aff3c77f688f0c06ed2e7686b/tests/test_propagation_logger.py,,test_forcing_level_with_kwargs_by_level,"def test_forcing_level_with_kwargs_by_level(propagation_logger, handler):
    msg1 = ""TEST1""
    msg2 = ""TEST2""
    propagation_logger.setLevel(logging.INFO)
    propagation_logger.force_level(logger_1=logging.DEBUG)
    additional_logger = logging.getLogger('logger_1')
    additional_logger.setLevel(logging.INFO)
    additional_logger.addHandler(handler)
    propagation_logger.debug(msg1)
    additional_logger.debug(msg2)
    record = handler.pop()
    assert record.msg == msg2
    assert record.levelname == logging.getLevelName(logging.DEBUG)
    with pytest.raises(IndexError):
        handler.pop()


",True
1324,https://github.com/ljvmiranda921/pyswarms/blob/08756526f39699eef28e515cac2ead17cef55710/tests/optimizers/test_local_best.py,TestLocalBestOptimizer,test_obj_with_kwargs,"def test_obj_with_kwargs(self, obj_with_args, optimizer, options):
        """"""Test if kwargs are passed properly in objfunc""""""
        x_max = 10 * np.ones(2)
        x_min = -1 * x_max
        bounds = (x_min, x_max)
        opt = optimizer(100, 2, options=options, bounds=bounds)
        cost, pos = opt.optimize(obj_with_args, 1000, a=1, b=100)
        assert np.isclose(cost, 0, rtol=1e-03)
        assert np.isclose(pos[0], 1.0, rtol=1e-03)
        assert np.isclose(pos[1], 1.0, rtol=1e-03)

    ",True
1325,https://github.com/ljvmiranda921/pyswarms/blob/08756526f39699eef28e515cac2ead17cef55710/tests/optimizers/test_tolerance.py,TestToleranceOptions,test_ftol_effect,"def test_ftol_effect(self, optimizer):
        """"""Test early stopping with ftol""""""
        optm, params = optimizer
        params[""ftol""] = 0.01
        opt = optm(**params)
        opt.optimize(objective_function, iters=iterations, **kwargs)
        assert len(opt.cost_history) <= iterations

    ",True
1326,https://github.com/ljvmiranda921/pyswarms/blob/08756526f39699eef28e515cac2ead17cef55710/tests/optimizers/test_tolerance.py,TestToleranceOptions,test_ftol_effect,"def test_ftol_effect(self, optimizer):
        """"""Test early stopping with ftol""""""
        optm, params = optimizer
        params[""ftol""] = 0.01
        opt = optm(**params)
        opt.optimize(objective_function, iters=iterations, **kwargs)
        assert len(opt.cost_history) <= iterations

    ",True
1327,https://github.com/ljvmiranda921/pyswarms/blob/08756526f39699eef28e515cac2ead17cef55710/tests/optimizers/test_tolerance.py,TestToleranceOptions,test_ftol_effect,"def test_ftol_effect(self, optimizer):
        """"""Test early stopping with ftol""""""
        optm, params = optimizer
        params[""ftol""] = 0.01
        opt = optm(**params)
        opt.optimize(objective_function, iters=iterations, **kwargs)
        assert len(opt.cost_history) <= iterations

    ",True
1328,https://github.com/ljvmiranda921/pyswarms/blob/08756526f39699eef28e515cac2ead17cef55710/tests/optimizers/test_tolerance.py,TestToleranceOptions,test_no_ftol,"def test_no_ftol(self, optimizer):
        """"""Test complete run""""""
        optm, params = optimizer
        opt = optm(**params)
        opt.optimize(objective_function, iters=iterations, **kwargs)
        assert len(opt.cost_history) == iterations

    ",True
1329,https://github.com/ljvmiranda921/pyswarms/blob/08756526f39699eef28e515cac2ead17cef55710/tests/optimizers/test_tolerance.py,TestToleranceOptions,test_no_ftol,"def test_no_ftol(self, optimizer):
        """"""Test complete run""""""
        optm, params = optimizer
        opt = optm(**params)
        opt.optimize(objective_function, iters=iterations, **kwargs)
        assert len(opt.cost_history) == iterations

    ",True
1330,https://github.com/ljvmiranda921/pyswarms/blob/08756526f39699eef28e515cac2ead17cef55710/tests/optimizers/test_tolerance.py,TestToleranceOptions,test_no_ftol,"def test_no_ftol(self, optimizer):
        """"""Test complete run""""""
        optm, params = optimizer
        opt = optm(**params)
        opt.optimize(objective_function, iters=iterations, **kwargs)
        assert len(opt.cost_history) == iterations

    ",True
1331,https://github.com/encukou/pytest-level/blob/6a15132419429c95d67b77e9f8892e0a864a364f/test_pytest_level.py,,test_level_marker,"def test_level_marker(run_pytest):
    run_pytest(
        """"""
            import pytest

            @pytest.mark.level(1)
            ",False
1332,https://github.com/pytest-dev/pytest-subtests/blob/96fc692a151f0709bf8ee209f8ce5d37b035f076/tests/test_subtests.py,TestSubTest,test_simple_terminal_verbose,"def test_simple_terminal_verbose(self, simple_script, testdir, runner):

        if runner == ""unittest"":
            result = testdir.run(sys.executable, simple_script, ""-v"")
            result.stderr.fnmatch_lines(
                [
                    ""test_foo (__main__.T) ... "",
                    ""FAIL: test_foo (__main__.T) [custom] (i=1)"",
                    ""AssertionError: 1 != 0"",
                    ""FAIL: test_foo (__main__.T) [custom] (i=3)"",
                    ""AssertionError: 1 != 0"",
                    ""Ran 1 test in *"",
                    ""FAILED (failures=2)"",
                ]
            )
        else:
            if runner == ""pytest-normal"":
                result = testdir.runpytest(simple_script, ""-v"")
                expected_lines = [
                    ""*collected 1 item"",
                    ""test_simple_terminal_verbose.py::T::test_foo FAILED *100%*"",
                    ""test_simple_terminal_verbose.py::T::test_foo FAILED *100%*"",
                    ""test_simple_terminal_verbose.py::T::test_foo PASSED *100%*"",
                ]
            else:
                pytest.importorskip(""xdist"")
                result = testdir.runpytest(simple_script, ""-n1"", ""-v"")
                expected_lines = [
                    ""gw0 [1]"",
                    ""*gw0*100%* FAILED test_simple_terminal_verbose.py::T::test_foo*"",
                    ""*gw0*100%* FAILED test_simple_terminal_verbose.py::T::test_foo*"",
                    ""*gw0*100%* PASSED test_simple_terminal_verbose.py::T::test_foo*"",
                ]
            result.stdout.fnmatch_lines(
                expected_lines
                + [
                    ""* T.test_foo [[]custom[]] (i=1) *"",
                    ""E  * AssertionError: 1 != 0"",
                    ""* T.test_foo [[]custom[]] (i=3) *"",
                    ""E  * AssertionError: 1 != 0"",
                    ""* 2 failed, 1 passed in *"",
                ]
            )

    @pytest.mark.parametrize(""runner"", [""unittest"", ""pytest-normal"", ""pytest-xdist""])
    ",False
1333,https://github.com/lrowe/pytest_exact_fixtures/blob/b72bf9d7661c65e1535e5fbbddc343fd6120e15c/test_exact_fixtures.py,,test_alternative1,"def test_alternative1(alternative1):
    assert active == set(['alternative1'])


",True
1334,https://github.com/lrowe/pytest_exact_fixtures/blob/b72bf9d7661c65e1535e5fbbddc343fd6120e15c/test_exact_fixtures.py,,test_alternative2,"def test_alternative2(alternative2):
    assert active == set(['alternative2'])
",True
1335,https://github.com/haney/python-ansel/blob/afb2b28d8595beeb1f87e355b611f01e13b8e664/tests/test_incremental.py,,test_decode_invalid_raising_error_handler,"def test_decode_invalid_raising_error_handler(input):
    decoder = IncrementalDecoder(errors=""raises"")
    with pytest.raises(EncodingError):
        decoder.decode(input)
    assert (b"""", 0) == decoder.getstate()


@pytest.mark.parametrize(
    ""input, expected, expected_len"",
    [(b""+"", u""\uFFFD"", 1), (b""a+b"", u""1\uFFFD23"", 3), (b""an+"", u""1\uFFFD5"", 3)],
)
",True
1336,https://github.com/hypoport/python-aws-dataclasses/blob/30bfe90457a83957d10ec18fe7d61439b5b74280/tests/test_sns_event.py,,test_message_attributes,"def test_message_attributes(sns_event):
    msg_attr = sns_event.first_record.sns.message_attributes
    assert msg_attr.get(""Test"").value == ""TestString""
    assert msg_attr.get(""Test"").type == ""String""


",True
1337,https://github.com/python-dugong/python-dugong/blob/00dd4d5aab6eddb116cace2829a9f93bda153664/test/test_dugong.py,,test_smallbuffer,"def test_smallbuffer(conn, buffer_size):
    conn._rbuf = dugong._Buffer(buffer_size)
    conn.send_request('GET', '/send_512_bytes')
    resp = conn.read_response()
    assert resp.status == 200
    assert resp.path == '/send_512_bytes'
    assert resp.length == 512
    assert conn.readall() == DUMMY_DATA[:512]
    assert not conn.response_pending()

",False
1338,https://github.com/femueller/python-n26/blob/22cb609efbf5125e36879441ea20d5a1c2a51e98/tests/test_cards.py,CardsTests,test_block_card_cli_all,"def test_block_card_cli_all(self):
        from n26.cli import card_block
        card_id_1 = ""12345678-1234-abcd-abcd-1234567890ab""
        card_id_2 = ""22345678-1234-abcd-abcd-1234567890ab""

        result = self._run_cli_cmd(card_block)
        self.assertEqual(result.output, ""Blocked card: {}\nBlocked card: {}\n"".format(card_id_1, card_id_2))

    @mock_requests(method=GET, response_file=""cards.json"")
    @mock_requests(method=POST, response_file=""card_unblock_single.json"")
    ",True
1339,https://github.com/femueller/python-n26/blob/22cb609efbf5125e36879441ea20d5a1c2a51e98/tests/test_cards.py,CardsTests,test_block_card_cli_single,"def test_block_card_cli_single(self):
        from n26.cli import card_block
        card_id = ""12345678-1234-abcd-abcd-1234567890ab""
        result = self._run_cli_cmd(card_block, [""--card"", card_id])
        self.assertEqual(result.output, ""Blocked card: {}\n"".format(card_id))

    @mock_requests(method=GET, response_file=""cards.json"")
    @mock_requests(method=POST, response_file=""card_block_single.json"")
    ",True
1340,https://github.com/femueller/python-n26/blob/22cb609efbf5125e36879441ea20d5a1c2a51e98/tests/test_cards.py,CardsTests,test_unblock_card_cli_all,"def test_unblock_card_cli_all(self):
        from n26.cli import card_unblock
        card_id_1 = ""12345678-1234-abcd-abcd-1234567890ab""
        card_id_2 = ""22345678-1234-abcd-abcd-1234567890ab""

        result = self._run_cli_cmd(card_unblock)
        self.assertEqual(result.output, ""Unblocked card: {}\nUnblocked card: {}\n"".format(card_id_1, card_id_2))
",False
1341,https://github.com/femueller/python-n26/blob/22cb609efbf5125e36879441ea20d5a1c2a51e98/tests/test_cards.py,CardsTests,test_unblock_card_cli_single,"def test_unblock_card_cli_single(self):
        from n26.cli import card_unblock
        card_id = ""12345678-1234-abcd-abcd-1234567890ab""
        result = self._run_cli_cmd(card_unblock, [""--card"", card_id])
        self.assertEqual(result.output, ""Unblocked card: {}\n"".format(card_id))

    @mock_requests(method=GET, response_file=""cards.json"")
    @mock_requests(method=POST, response_file=""card_unblock_single.json"")
    ",True
1342,https://github.com/kytos/python-openflow/blob/a3387a7b28d529a3605aa1506a028e03394e4526/tests/unit/v0x04/test_controller2switch/test_flow_mod.py,TestFlowMod,test_minimum_size,"def test_minimum_size(self):
        """"""Test struct minimum size.""""""
        if self._min_size is None:
            raise self.skipTest('minimum size was not set.')
        obj = TestStruct._msg_cls()
        self.assertEqual(obj.get_size(), self._min_size)
",True
1343,https://github.com/jbfavre/python-protobix/blob/96b7095a9c2485c9e1bdba098b7d82b93f91acb1/tests/test_memory_leak.py,,test_long_run_for_memory_leak,"def test_long_run_for_memory_leak(data_type, debug_level):
    """"""
    Simulate long running process with and without debug
    and control memory usage
    """"""
    initial_memory, final_memory = long_run(data_type, debug_level)
    assert initial_memory == final_memory
",False
1344,https://github.com/unfoldingWord-dev/python-resource-container/blob/64d87f900af969f47b20b798cf00c2861435b0d8/tests/container_test.py,TestResourceContainer,test_should_fail_to_load_missing_rc,"def test_should_fail_to_load_missing_rc(self):
        directory = os.path.join(DATA_DIR, 'temp', 'missing')
        os.mkdir(directory)
        rc = None
        with pytest.raises(Exception) as my_error:
            rc = factory.load(directory)
        assert 'Not a resource container. Missing manifest.yaml' in str(my_error.value)
        assert rc is None

    ",True
1345,https://github.com/unfoldingWord-dev/python-resource-container/blob/64d87f900af969f47b20b798cf00c2861435b0d8/tests/container_test.py,TestResourceContainer,test_should_load_a_missing_rc_when_not_in_strict_mode,"def test_should_load_a_missing_rc_when_not_in_strict_mode(self):
        directory = os.path.join(DATA_DIR, 'temp', 'missing')
        if os.path.isdir(directory):
            os.rmdir(directory)
        os.mkdir(directory)
        rc = factory.load(directory, False)
        assert rc is not None

    ",True
1346,https://github.com/sashgorokhov/python-telegram-handler/blob/4ac0e5cbb6ac3c3f81a57be6b3cea49dfd8e8ec4/tests/test_handlers.py,,test_handler_init_without_chat,"def test_handler_init_without_chat():
    with mock.patch('requests.post') as patch:
        response = requests.Response()
        response.status_code = 200
        response._content = json.dumps({'ok': False}).encode()
        patch.return_value = response

        handler = telegram_handler.handlers.TelegramHandler('foo', level=logging.INFO)

        assert patch.called
        assert telegram_handler.handlers.logger.handlers[0].messages['error']

        assert handler.level == logging.NOTSET

",True
1347,https://github.com/andreycizov/python-xrpc/blob/ed403ae74d5e89e0ebac68bcc58591d6b32742ff/xrpc_tests/test_popen.py,TestPOpen,test_wait_all_2,"def test_wait_all_2(self):
        ",False
1348,https://github.com/andreycizov/python-xrpc/blob/ed403ae74d5e89e0ebac68bcc58591d6b32742ff/xrpc_tests/test_popen.py,TestPOpen,test_wait_all_3,"def test_wait_all_3(self):
        ",False
1349,https://github.com/mohankishore/python_dynamodb_lock/blob/be57d31492893ceb773e46892eaeb04858e287f3/tests/test_python_dynamodb_lock.py,TestDynamoDBLockClient,test_send_heartbeat_success,"def test_send_heartbeat_success(self):
        self.ddb_table.update_item = mock.MagicMock('update_item')
        self.lock_client.acquire_lock('key')
        time.sleep(200/1000) # 200 millis
        self.ddb_table.update_item.assert_called()


    ",False
1350,https://github.com/teamhide/pythondi/blob/913e6a60fc5d02c3db385ad322f970ecec36969b/tests/test_configure.py,,test_configure,"def test_configure():
    provider = Provider()
    provider.bind(int, str)
    configure(provider=provider)
    assert isinstance(Container.get(), Provider)
    assert Container.get().bindings[int] == str
    with raises(InjectException):
        configure(provider=provider)


",True
1351,https://github.com/taxpon/pytidy/blob/0a0a54b80b53dadd8ecc8ff2db42444741b75865/tests/test_dataclass.py,,test_class_is_inserted_to_dataclass,"def test_class_is_inserted_to_dataclass():
        obj = D()
        another = D()
        assert obj.get() == ""c""
        assert id(obj.c) == id(another.c)
",True
1352,https://github.com/taxpon/pytidy/blob/0a0a54b80b53dadd8ecc8ff2db42444741b75865/tests/test_function.py,,test_object_insertion,"def test_object_insertion():
    obj = B()
    another = B()
    assert obj.get() == ""a""
    assert id(obj.a) == id(another.a)


",True
1353,https://github.com/taxpon/pytidy/blob/0a0a54b80b53dadd8ecc8ff2db42444741b75865/tests/test_function.py,,test_return_type_none,"def test_return_type_none():
    obj = B2()
    another = B()
    assert obj.get() == ""a""
    assert id(obj.a) == id(another.a)
",True
1354,https://github.com/izar/pytm/blob/724df0c6346706e9c3678bee11e23d9609d8fa4c/tests/test_private_func.py,TestMethod,test_defaults,"def test_defaults(self):
        tm = TM(""my test tm"", description=""aa"", isOrdered=True)

        internet = Boundary(""Internet"")
        cloud = Boundary(""Cloud"")

        user = Actor(""User"", inBoundary=internet)
        server = Server(""Server"")
        db = Datastore(""DB"", inBoundary=cloud, isSQL=True)
        func = Datastore(""Lambda function"", inBoundary=cloud)

        request = Dataflow(user, server, ""request"")
        response = Dataflow(server, user, ""response"", isResponse=True)
        user_query = Dataflow(user, db, ""user query"")
        server_query = Dataflow(server, db, ""server query"")
        func_query = Dataflow(func, db, ""func query"")

        default_target = [""Actor"", ""Boundary"", ""Dataflow"", ""Datastore"", ""Server""]
        testCases = [
            {""target"": server, ""condition"": ""target.oneOf(Server, Datastore)""},
            {""target"": server, ""condition"": ""not target.oneOf(Actor, Dataflow)""},
            {""target"": request, ""condition"": ""target.crosses(Boundary)""},
            {""target"": user_query, ""condition"": ""target.crosses(Boundary)""},
            {""target"": server_query, ""condition"": ""target.crosses(Boundary)""},
            {""target"": func_query, ""condition"": ""not target.crosses(Boundary)""},
            {""target"": func_query, ""condition"": ""not target.enters(Boundary)""},
            {""target"": func_query, ""condition"": ""not target.exits(Boundary)""},
            {""target"": request, ""condition"": ""not target.enters(Boundary)""},
            {""target"": request, ""condition"": ""target.exits(Boundary)""},
            {""target"": response, ""condition"": ""target.enters(Boundary)""},
            {""target"": response, ""condition"": ""not target.exits(Boundary)""},
            {""target"": user, ""condition"": ""target.inside(Boundary)""},
            {""target"": func, ""condition"": ""not any(target.inputs)""},
            {
                ""target"": server,
                ""condition"": ""any(f.sink.oneOf(Datastore) and f.sink.isSQL ""
                ""for f in target.outputs)"",
            },
        ]

        self.assertTrue(tm.check())

        for case in testCases:
            t = Threat(SID="""", target=default_target, condition=case[""condition""])
            self.assertTrue(
                t.apply(case[""target""]),
                ""Failed to match {} against {}"".format(
                    case[""target""], case[""condition""],
                ),
            )
",True
1355,https://github.com/izar/pytm/blob/724df0c6346706e9c3678bee11e23d9609d8fa4c/tests/test_private_func.py,TestUniqueNames,test_duplicate_boundary_names_have_different_unique_names,"def test_duplicate_boundary_names_have_different_unique_names(self):
        random.seed(0)
        object_1 = Boundary(""foo"")
        object_2 = Boundary(""foo"")

        object_1_uniq_name = object_1._uniq_name()
        object_2_uniq_name = object_2._uniq_name()

        self.assertNotEqual(object_1_uniq_name, object_2_uniq_name)
        self.assertEqual(object_1_uniq_name, ""boundary_foo_acf3059e70"")
        self.assertEqual(object_2_uniq_name, ""boundary_foo_88f2d9c06f"")


class TestAttributes(unittest.TestCase):
    ",True
1356,https://github.com/markperdue/pyvesync/blob/4a43bad8a7b9d3b2e7f580f1f3739f27a00bdc2b/src/tests/test_vesync_15a.py,TestVesync15ASwitch,test_15a_monthly,"def test_15a_monthly(self, api_mock):
        """"""Test 15A get_monthly_energy""""""
        self.mock_api.return_value = ENERGY_HISTORY
        vswitch15a = VeSyncOutlet15A(DEV_LIST_DETAIL, self.vesync_obj)
        vswitch15a.get_monthly_energy()
        body = helpers.req_body(self.vesync_obj, 'energy_month')
        body['uuid'] = vswitch15a.uuid
        self.mock_api.assert_called_with(
            '/15a/v1/device/energymonth', 'post',
            headers=helpers.req_headers(self.vesync_obj), json=body)
        energy_dict = vswitch15a.energy['month']
        assert energy_dict['energy_consumption_of_today'] == 1
        assert energy_dict['cost_per_kwh'] == 1
        assert energy_dict['max_energy'] == 1
        assert energy_dict['total_energy'] == 1
        assert energy_dict['data'] == [1, 1]
        assert vswitch15a.monthly_energy_total == 1

    ",False
1357,https://github.com/webdjoe/pyvesync_v2/blob/a5677b0599912fbc6dcc6604b0342e1edec92de1/src/tests/test_vesync_login.py,,test_login,"def test_login(mock_api, email, password, testid):
    """"""Test multiple failed login calls.""""""
    return_tuple = {'code': 455, 'msg': 'sdasd'}
    mock_api.return_value.ok = True
    mock_api.return_value.json.return_value = return_tuple
    vesync_obj = VeSync(email, password)
    vesync_login = vesync_obj.login()
    assert vesync_login is False
    if testid == 'correct':
        jd = helpers.req_body(vesync_obj, 'login')
        mock_api.assert_called_with(
            'https://smartapi.vesync.com/cloud/v1/user/login',
            headers=None,
            json=jd,
            timeout=5)
    else:
        assert not mock_api.called
",False
1358,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_findlinks.py,,test_find_links,"def test_find_links(tmpdir):
    """"""Verify that a wheel for req-compile can be discovered properly""""""
    wheeldir = str(tmpdir.mkdir(""wheeldir""))

    source_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "".."", ""..""))
    subprocess.check_call(
        [sys.executable, ""setup.py"", ""bdist_wheel"", ""--dist-dir"", wheeldir],
        cwd=source_dir,
    )

    repo = FindLinksRepository(wheeldir)
    candidates = list(repo.get_candidates(None))
    assert len(candidates) == 1
    assert candidates[0].name == ""req_compile""
",False
1359,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_no_candidates,"def test_no_candidates(mocked_responses, tmpdir):
    wheeldir = str(tmpdir)
    mocked_responses.add(responses.GET, INDEX_URL + ""/garbage/"", status=404)
    repo = PyPIRepository(INDEX_URL, wheeldir)

    candidates = repo.get_candidates(pkg_resources.Requirement.parse(""garbage""))

    assert candidates == []
    assert len(mocked_responses.calls) == 1


",True
1360,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_pypi_500,"def test_pypi_500(mocked_responses, tmpdir):
    wheeldir = str(tmpdir)
    mocked_responses.add(responses.GET, INDEX_URL + ""/numpy/"", status=500)
    repo = PyPIRepository(INDEX_URL, wheeldir)

    with pytest.raises(requests.HTTPError):
        repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))


",True
1361,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_python_requires_wheel_tags,"def test_python_requires_wheel_tags(
    mocked_responses, tmpdir, mock_py_version, read_contents, url_to_check
):
    mock_py_version(""3.7.12"")

    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )

    repo = PyPIRepository(INDEX_URL, wheeldir)
    candidate = [
        candidate
        for candidate in repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))
        if candidate.link[1] == url_to_check
    ][0]
    if candidate.py_version:
        assert candidate.py_version.check_compatibility()


@pytest.mark.parametrize(
    ""sys_py_version, py_requires"",
    [
        (""2.7.15"", "">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*""),
        (""3.6.4"", "">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*""),
        (""3.5.0"", ""==3.5""),
        (""3.2.17"", "">=2.7, ==3.*""),
        (""3.5.4"", ""~=3.5""),
        (""3.7.4"", ""~=3""),
        (""2.7.12"", ""2.7""),
    ],
)
",True
1362,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_python_requires_wheel_tags,"def test_python_requires_wheel_tags(
    mocked_responses, tmpdir, mock_py_version, read_contents, url_to_check
):
    mock_py_version(""3.7.12"")

    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )

    repo = PyPIRepository(INDEX_URL, wheeldir)
    candidate = [
        candidate
        for candidate in repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))
        if candidate.link[1] == url_to_check
    ][0]
    if candidate.py_version:
        assert candidate.py_version.check_compatibility()


@pytest.mark.parametrize(
    ""sys_py_version, py_requires"",
    [
        (""2.7.15"", "">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*""),
        (""3.6.4"", "">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*""),
        (""3.5.0"", ""==3.5""),
        (""3.2.17"", "">=2.7, ==3.*""),
        (""3.5.4"", ""~=3.5""),
        (""3.7.4"", ""~=3""),
        (""2.7.12"", ""2.7""),
    ],
)
",True
1363,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_python_requires_wheel_tags,"def test_python_requires_wheel_tags(
    mocked_responses, tmpdir, mock_py_version, read_contents, url_to_check
):
    mock_py_version(""3.7.12"")

    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )

    repo = PyPIRepository(INDEX_URL, wheeldir)
    candidate = [
        candidate
        for candidate in repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))
        if candidate.link[1] == url_to_check
    ][0]
    if candidate.py_version:
        assert candidate.py_version.check_compatibility()


@pytest.mark.parametrize(
    ""sys_py_version, py_requires"",
    [
        (""2.7.15"", "">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*""),
        (""3.6.4"", "">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*""),
        (""3.5.0"", ""==3.5""),
        (""3.2.17"", "">=2.7, ==3.*""),
        (""3.5.4"", ""~=3.5""),
        (""3.7.4"", ""~=3""),
        (""2.7.12"", ""2.7""),
    ],
)
",True
1364,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_resolve_new_numpy,"def test_resolve_new_numpy(mocked_responses, tmpdir, read_contents, mocker):
    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )

    repo = PyPIRepository(INDEX_URL, wheeldir)
    candidates = repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))
    for candidate in candidates:
        if ""1.16.3"" in candidate.link[1]:
            mocked_responses.add(
                responses.GET,
                candidate.link[1],
                body=read_contents(""numpy.whl-contents""),
                status=200,
            )

    mock_extract = mocker.MagicMock()
    mock_extract.return_value.name = ""numpy""

    mocker.patch(""req_compile.repos.pypi.extract_metadata"", mock_extract)
    candidate, cached = repo.get_candidate(pkg_resources.Requirement.parse(""numpy""))
    assert candidate is not None
    assert not cached

    listing = tmpdir.listdir()
    assert len(listing) == 1
    assert ""1.16.3"" in str(listing[0])
    assert "".whl"" in str(listing[0])

    # Query the index, and download
    assert len(mocked_responses.calls) == 2


@pytest.mark.parametrize(
    ""url_to_check"",
    [
        ""https://pypi.org/numpy-1.16.3-cp37-cp37m-win_amd64.whl#sha256=HASH"",
        ""https://pypi.org/numpy-1.16.3-cp37-cp37m-manylinux1_x86_64.whl#sha256=HASH"",
        ""https://pypi.org/numpy-1.16.3.zip#sha256=HASH"",
    ],
)
",False
1365,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_successful_numpy,"def test_successful_numpy(mocked_responses, tmpdir, read_contents):
    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )
    repo = PyPIRepository(INDEX_URL, wheeldir)

    candidates = repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))

    # The total is the total number of links - exe links, which we do not support
    assert len(candidates) == 1127 - 34
    assert len(mocked_responses.calls) == 1


",True
1366,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/test_extractor.py,,test_extractor,"def test_extractor(archive_fixture, tmpdir, mock_targz, mock_zip):
    directory = ""comtypes-1.1.7""
    if archive_fixture == ""mock_targz"":
        archive = mock_targz(directory)
    elif archive_fixture == ""mock_zip"":
        archive = mock_zip(directory)
    else:
        archive = os.path.abspath(os.path.join(""source-packages"", directory))

    if archive_fixture == ""mock_targz"":
        extractor = req_compile.metadata.extractor.TarExtractor(""gz"", archive)
        prefix = directory + ""/""
    elif archive_fixture == ""mock_zip"":
        extractor = req_compile.metadata.extractor.ZipExtractor(archive)
        prefix = directory + ""/""
    else:
        extractor = req_compile.metadata.extractor.NonExtractor(archive)
        prefix = """"

    with contextlib.closing(extractor):
        all_names = set(extractor.names())
        assert all_names == {
            prefix + ""README"",
            prefix + ""setup.py"",
            prefix + ""comtypes/__init__.py"",
            prefix + ""test/setup.py"",
        }

        prefix = extractor.fake_root + os.sep + prefix

        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        with extractor.open(prefix + ""README"") as handle:
            assert handle.read(2) == ""RE""
        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        assert extractor.exists(prefix + ""test"")
        assert extractor.exists(prefix + ""test/setup.py"")
        assert not extractor.exists(prefix + ""test/setup2.py"")
",True
1367,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/test_extractor.py,,test_extractor,"def test_extractor(archive_fixture, tmpdir, mock_targz, mock_zip):
    directory = ""comtypes-1.1.7""
    if archive_fixture == ""mock_targz"":
        archive = mock_targz(directory)
    elif archive_fixture == ""mock_zip"":
        archive = mock_zip(directory)
    else:
        archive = os.path.abspath(os.path.join(""source-packages"", directory))

    if archive_fixture == ""mock_targz"":
        extractor = req_compile.metadata.extractor.TarExtractor(""gz"", archive)
        prefix = directory + ""/""
    elif archive_fixture == ""mock_zip"":
        extractor = req_compile.metadata.extractor.ZipExtractor(archive)
        prefix = directory + ""/""
    else:
        extractor = req_compile.metadata.extractor.NonExtractor(archive)
        prefix = """"

    with contextlib.closing(extractor):
        all_names = set(extractor.names())
        assert all_names == {
            prefix + ""README"",
            prefix + ""setup.py"",
            prefix + ""comtypes/__init__.py"",
            prefix + ""test/setup.py"",
        }

        prefix = extractor.fake_root + os.sep + prefix

        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        with extractor.open(prefix + ""README"") as handle:
            assert handle.read(2) == ""RE""
        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        assert extractor.exists(prefix + ""test"")
        assert extractor.exists(prefix + ""test/setup.py"")
        assert not extractor.exists(prefix + ""test/setup2.py"")
",True
1368,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/test_extractor.py,,test_extractor,"def test_extractor(archive_fixture, tmpdir, mock_targz, mock_zip):
    directory = ""comtypes-1.1.7""
    if archive_fixture == ""mock_targz"":
        archive = mock_targz(directory)
    elif archive_fixture == ""mock_zip"":
        archive = mock_zip(directory)
    else:
        archive = os.path.abspath(os.path.join(""source-packages"", directory))

    if archive_fixture == ""mock_targz"":
        extractor = req_compile.metadata.extractor.TarExtractor(""gz"", archive)
        prefix = directory + ""/""
    elif archive_fixture == ""mock_zip"":
        extractor = req_compile.metadata.extractor.ZipExtractor(archive)
        prefix = directory + ""/""
    else:
        extractor = req_compile.metadata.extractor.NonExtractor(archive)
        prefix = """"

    with contextlib.closing(extractor):
        all_names = set(extractor.names())
        assert all_names == {
            prefix + ""README"",
            prefix + ""setup.py"",
            prefix + ""comtypes/__init__.py"",
            prefix + ""test/setup.py"",
        }

        prefix = extractor.fake_root + os.sep + prefix

        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        with extractor.open(prefix + ""README"") as handle:
            assert handle.read(2) == ""RE""
        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        assert extractor.exists(prefix + ""test"")
        assert extractor.exists(prefix + ""test/setup.py"")
        assert not extractor.exists(prefix + ""test/setup2.py"")
",True
1369,https://github.com/sputt/qer/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/test_metadata.py,,test_source_dist,"def test_source_dist(
    archive_fixture, directory, name, version, reqs, mock_targz, mock_zip, mocker
):
    mock_build = mocker.patch(""req_compile.metadata.source._build_wheel"")

    if archive_fixture == ""mock_targz"":
        archive = mock_targz(directory)
    elif archive_fixture == ""mock_zip"":
        archive = mock_zip(directory)
    else:
        archive = os.path.join(os.path.dirname(__file__), ""source-packages"", directory)

    metadata = req_compile.metadata.extract_metadata(archive)
    assert not mock_build.called

    if archive_fixture != ""mock_fs"":
        assert metadata.name == name
        if version is not None:
            assert metadata.version == pkg_resources.parse_version(version)
    if reqs is not None:
        assert set(metadata.reqs) == set(pkg_resources.parse_requirements(reqs))


",False
1370,https://github.com/quantopian/qgrid/blob/877b420d3bd83297bbcc97202b914001a85afff2/qgrid/tests/test_grid.py,,test_edit_multi_index_df,"def test_edit_multi_index_df():
    df_multi = create_multi_index_df()
    df_multi.index.set_names(""first"", level=0, inplace=True)
    view = QgridWidget(df=df_multi)
    old_val = df_multi.loc[(""bar"", ""two""), 1]

    check_edit_success(
        view,
        1,
        1,
        old_val,
        round(old_val, pd.get_option(""display.precision"") - 1),
        3.45678,
        3.45678,
    )


",True
1371,https://github.com/QsonLabs/qlmetrics/blob/3a4cc70bb68ef9b476aaee562b82a4d54acfd826/tests/test_bench.py,TestBenchmarkMemory,test_bench_as_decorator_trackmem_does_print_timing_info_to_stdout_in_non_default,"def test_bench_as_decorator_trackmem_does_print_timing_info_to_stdout_in_non_default(self, capsys):
        """""" capsys variable is a pytest function to capture system error and output
        """"""
        @bench.trackmem(verbose=True)
        ",True
1372,https://github.com/markokr/rarfile/blob/65810aceeb872ed61ec14cb615ed12feefbbb89e/test/test_extract.py,,test_readonly,"def test_readonly(fn, tmp_path):
    with rarfile.RarFile(fn) as rf:
        assert get_props(rf, ""ro_dir"") == ""-D-""
        assert get_props(rf, ""ro_dir/ro_file.txt"") == ""F--""

        rf.extractall(tmp_path)

    assert os.access(tmp_path / ""ro_dir/ro_file.txt"", os.R_OK)
    assert not os.access(tmp_path / ""ro_dir/ro_file.txt"", os.W_OK)

    if sys.platform != ""win32"":
        assert os.access(tmp_path / ""ro_dir"", os.R_OK)
        assert not os.access(tmp_path / ""ro_dir"", os.W_OK)


@pytest.mark.parametrize(""fn"", [
    ""test/files/rar3-symlink-unix.rar"",
    ""test/files/rar5-symlink-unix.rar"",
])
",False
1373,https://github.com/markokr/rarfile/blob/65810aceeb872ed61ec14cb615ed12feefbbb89e/test/test_extract.py,,test_symlink,"def test_symlink(fn, tmp_path):
    with rarfile.RarFile(fn) as rf:
        assert get_props(rf, ""data.txt"") == ""F--""
        assert get_props(rf, ""data_link"") == ""--L""
        assert get_props(rf, ""random_link"") == ""--L""

        rf.extractall(tmp_path)

        assert sorted(os.listdir(tmp_path)) == [""data.txt"", ""data_link"", ""random_link""]

        data = rf.getinfo(""data.txt"")
        data_link = rf.getinfo(""data_link"")
        random_link = rf.getinfo(""random_link"")

        assert not data.is_symlink()
        assert data_link.is_symlink()
        assert random_link.is_symlink()

        assert rf.read(data) == b""data\n""
        assert rf.read(data_link) == b""data.txt""
        assert rf.read(random_link) == b""../random123""

        assert os.path.isfile(tmp_path / ""data.txt"")
        assert os.path.islink(tmp_path / ""data_link"")
        assert os.path.islink(tmp_path / ""random_link"")

        # str - work around pypy3 bug
        assert os.readlink(str(tmp_path / ""data_link"")) == ""data.txt""
        assert os.readlink(str(tmp_path / ""random_link"")) == ""../random123""


",False
1374,https://github.com/markokr/rarfile/blob/65810aceeb872ed61ec14cb615ed12feefbbb89e/test/test_extract.py,,test_symlink_win,"def test_symlink_win(tmp_path):
    fn = ""test/files/rar5-symlink-win.rar""
    with rarfile.RarFile(fn) as rf:
        assert get_props(rf, ""content/dir1"") == ""-D-""
        assert get_props(rf, ""content/dir2"") == ""-D-""
        assert get_props(rf, ""content/file.txt"") == ""F--""
        assert get_props(rf, ""links/bad_link"") == ""--L""
        assert get_props(rf, ""links/dir_junction"") == ""--L""
        assert get_props(rf, ""links/dir_link"") == ""--L""
        assert get_props(rf, ""links/file_link"") == ""--L""

        with pytest.warns(rarfile.UnsupportedWarning):
            rf.extractall(tmp_path)

        assert sorted(os.listdir(tmp_path)) == [""content"", ""links""]
        assert sorted(os.listdir(tmp_path / ""content"")) == [""dir1"", ""dir2"", ""file.txt""]
        assert sorted(os.listdir(tmp_path / ""links"")) == [""bad_link"", ""dir_link"", ""file_link""]

        assert os.path.islink(tmp_path / ""links/bad_link"")
        assert os.path.islink(tmp_path / ""links/dir_link"")
        assert os.path.islink(tmp_path / ""links/file_link"")

",False
1375,https://github.com/markokr/rarfile/blob/65810aceeb872ed61ec14cb615ed12feefbbb89e/test/test_korrupt.py,,test_corrupt_quick_rar5,"def test_corrupt_quick_rar5():
    process_rar(""test/files/rar5-times.rar"", True)


",False
1376,https://github.com/DevKeh/redisqueue/blob/feac4dfc30837e0ab1a55a8479443ea74b2793f2/tests/test_redisqueue.py,,test_mock_queue_get_put_same_task,"def test_mock_queue_get_put_same_task():
    mock_queue.clear()

    task = MockTask()
    task.test = 'my_test'
    mock_queue.put(task)

    assert mock_queue.qsize() == 1

    my_task = mock_queue.get()
    assert my_task.test == 'my_test'
    assert mock_queue.qsize() == 0

    mock_queue.put(my_task)
    assert mock_queue.qsize() == 1


@pytest.mark.skipif(do_live_testing is False,
                    reason='Live Redis testing not enabled.')
",True
1377,https://github.com/DevKeh/redisqueue/blob/feac4dfc30837e0ab1a55a8479443ea74b2793f2/tests/test_redisqueue.py,,test_mock_queue_put_get,"def test_mock_queue_put_get():
    assert mock_queue.qsize() == 0

    task = MockTask()
    task.uri = ""my_uri""
    mock_queue.put(task)
    assert mock_queue.qsize() == 1

    returned_task = mock_queue.get()
    assert isinstance(returned_task, MockTask) is True
    assert returned_task.uid == task.uid
    assert returned_task.unique_hash() == task.unique_hash()
    assert returned_task.uri == ""my_uri""
    assert mock_queue.qsize() == 0


",True
1378,https://github.com/DevKeh/redisqueue/blob/feac4dfc30837e0ab1a55a8479443ea74b2793f2/tests/test_redisqueue.py,,test_mock_queue_unique,"def test_mock_queue_unique():
    assert mock_queue.qsize() == 0

    task = MockTask()
    task.unique = True
    task.uri = 'unique1'
    task2 = MockTask()
    task2.unique = True
    task2.uri = 'unique1'

    assert task.unique_hash() == task2.unique_hash()

    mock_queue.put(task)
    with pytest.raises(TaskAlreadyInQueueException):
        mock_queue.put(task2)

    task3 = MockTask()
    task3.unique = True
    task3.uri = 'unique2'
    mock_queue.put(task3)
    assert mock_queue.qsize() == 2


",True
1379,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_check_filters.py,TestCheckFilters,test_have_cpu_only,"def test_have_cpu_only(self):
        assert 1 == self.count_checks(filters.have_cpu_only())

    ",True
1380,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_check_filters.py,TestCheckFilters,test_have_gpu_only,"def test_have_gpu_only(self):
        assert 2 == self.count_checks(filters.have_gpu_only())

    ",True
1381,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_check_filters.py,TestCheckFilters,test_have_name,"def test_have_name(self):
        assert 1 == self.count_checks(filters.have_name('check1'))
        assert 3 == self.count_checks(filters.have_name('check'))
        assert 2 == self.count_checks(filters.have_name(r'\S*1|\S*3'))
        assert 0 == self.count_checks(filters.have_name('Check'))
        assert 3 == self.count_checks(filters.have_name('(?i)Check'))
        assert 2 == self.count_checks(filters.have_name('(?i)check1|CHECK2'))

    ",True
1382,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_check_filters.py,TestCheckFilters,test_have_not_name,"def test_have_not_name(self):
        assert 2 == self.count_checks(filters.have_not_name('check1'))
        assert 1 == self.count_checks(filters.have_not_name('check1|check3'))
        assert 0 == self.count_checks(filters.have_not_name(
            'check1|check2|check3'))
        assert 3 == self.count_checks(filters.have_not_name('Check1'))
        assert 2 == self.count_checks(filters.have_not_name('(?i)Check1'))

    ",True
1383,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_check_filters.py,TestCheckFilters,test_have_prgenv,"def test_have_prgenv(self):
        assert 1 == self.count_checks(filters.have_prgenv('env1|env2'))
        assert 2 == self.count_checks(filters.have_prgenv('env3'))
        assert 1 == self.count_checks(filters.have_prgenv('env4'))
        assert 3 == self.count_checks(filters.have_prgenv('env1|env3'))

    @rt.switch_runtime(fixtures.TEST_CONFIG_FILE, 'testsys')
    ",True
1384,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_check_filters.py,TestCheckFilters,test_have_tags,"def test_have_tags(self):
        assert 2 == self.count_checks(filters.have_tag('a|c'))
        assert 0 == self.count_checks(filters.have_tag('p|q'))
        assert 2 == self.count_checks(filters.have_tag('z'))

    ",True
1385,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_check_filters.py,TestCheckFilters,test_invalid_regex,"def test_invalid_regex(self):
        # We need to explicitly call `evaluate` to make sure the exception
        # is triggered in all cases
        with pytest.raises(ReframeError):
            self.count_checks(filters.have_name('*foo')).evaluate()

        with pytest.raises(ReframeError):
            self.count_checks(filters.have_not_name('*foo')).evaluate()

        with pytest.raises(ReframeError):
            self.count_checks(filters.have_tag('*foo')).evaluate()

        with pytest.raises(ReframeError):
            self.count_checks(filters.have_prgenv('*foo')).evaluate()
",True
1386,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_check_filters.py,TestCheckFilters,test_partition,"def test_partition(self):
        p = fixtures.partition_by_name('gpu')
        assert 2 == self.count_checks(filters.have_partition([p]))
        p = fixtures.partition_by_name('login')
        assert 0 == self.count_checks(filters.have_partition([p]))

    ",True
1387,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_check_failure,"def test_check_failure(run_reframe):
    returncode, stdout, _ = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['-t', 'BadSetupCheck']
    )
    assert 'FAILED' in stdout
    assert returncode != 0


",False
1388,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_check_kbd_interrupt,"def test_check_kbd_interrupt(run_reframe):
    returncode, stdout, stderr = run_reframe(
        checkpath=[
            'unittests/resources/checks_unlisted/kbd_interrupt.py'
        ],
        more_options=['-t', 'KeyboardInterruptCheck'],
        local=False,
    )
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert 'FAILED' in stdout
    assert returncode != 0


",False
1389,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_check_sanity_failure,"def test_check_sanity_failure(run_reframe, tmp_path):
    returncode, stdout, stderr = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['-t', 'SanityFailureCheck']
    )
    assert 'FAILED' in stdout

    # This is a normal failure, it should not raise any exception
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert returncode != 0
    assert os.path.exists(
        tmp_path / 'stage' / 'generic' / 'default' /
        'builtin-gcc' / 'SanityFailureCheck'
    )


",False
1390,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_check_setup_failure,"def test_check_setup_failure(run_reframe):
    returncode, stdout, stderr = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['-t', 'BadSetupCheckEarly'],
        local=False,

    )
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert 'FAILED' in stdout
    assert returncode != 0


",False
1391,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_check_success,"def test_check_success(run_reframe, tmp_path, logfile):
    returncode, stdout, _ = run_reframe(more_options=['--save-log-files'])
    assert 'PASSED' in stdout
    assert 'FAILED' not in stdout
    assert returncode == 0
    assert os.path.exists(tmp_path / 'output' / logfile)
    assert os.path.exists(tmp_path / 'report.json')


",True
1392,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_checkpath_recursion,"def test_checkpath_recursion(run_reframe):
    _, stdout, _ = run_reframe(action='list', checkpath=[])
    num_checks_default = re.search(r'Found (\d+) check', stdout).group(1)

    _, stdout, _ = run_reframe(action='list',
                               checkpath=['checks/'],
                               more_options=['-R'])
    num_checks_in_checkdir = re.search(r'Found (\d+) check', stdout).group(1)
    assert num_checks_in_checkdir == num_checks_default

    _, stdout, _ = run_reframe(action='list',
                               checkpath=['checks/'],
                               more_options=[])
    num_checks_in_checkdir = re.search(r'Found (\d+) check', stdout).group(1)
    assert num_checks_in_checkdir == '0'


",False
1393,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_checkpath_symlink,"def test_checkpath_symlink(run_reframe, tmp_path):
    # FIXME: This should move to test_loader.py
    checks_symlink = tmp_path / 'checks_symlink'
    os.symlink(os.path.abspath('unittests/resources/checks'),
               checks_symlink)

    returncode, stdout, _ = run_reframe(
        action='list',
        more_options=['-R'],
        checkpath=['unittests/resources/checks', str(checks_symlink)]
    )
    num_checks_default = re.search(
        r'Found (\d+) check', stdout, re.MULTILINE).group(1)
    num_checks_in_checkdir = re.search(
        r'Found (\d+) check', stdout, re.MULTILINE).group(1)
    assert num_checks_in_checkdir == num_checks_default


",False
1394,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_dont_restage,"def test_dont_restage(run_reframe, tmp_path):
    run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['-t', 'SanityFailureCheck']
    )

    # Place a random file in the test's stage directory and rerun with
    # `--dont-restage` and `--max-retries`
    stagedir = (tmp_path / 'stage' / 'generic' / 'default' /
                'builtin-gcc' / 'SanityFailureCheck')
    (stagedir / 'foobar').touch()
    returncode, stdout, stderr = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['-t', 'SanityFailureCheck',
                      '--dont-restage', '--max-retries=1']
    )
    assert os.path.exists(stagedir / 'foobar')
    assert not os.path.exists(f'{stagedir}_retry1')

    # And some standard assertions
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert returncode != 0


",False
1395,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_execution_modes,"def test_execution_modes(run_reframe):
    returncode, stdout, stderr = run_reframe(
        checkpath=[],
        environs=[],
        local=False,
        mode='unittest'
    )
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert 'FAILED' not in stdout
    assert 'PASSED' in stdout
    assert 'Ran 1 test case' in stdout


",False
1396,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_failure_stats,"def test_failure_stats(run_reframe):
    returncode, stdout, stderr = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['-t', 'SanityFailureCheck', '--failure-stats']
    )
    assert r'FAILURE STATISTICS' in stdout
    assert r'sanity        1     [SanityFailureCheck' in stdout
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert returncode != 0
",False
1397,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_list_check_with_empty_prgenvs,"def test_list_check_with_empty_prgenvs(run_reframe):
    returncode, stdout, _ = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        action='list',
        environs=['foo'],
        more_options=['-n', 'NoPrgEnvCheck']
    )
    assert 'Found 0 check(s)' in stdout
    assert returncode == 0


",False
1398,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_list_empty_prgenvs_check_and_options,"def test_list_empty_prgenvs_check_and_options(run_reframe):
    returncode, stdout, _ = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        action='list',
        environs=[],
        more_options=['-n', 'NoPrgEnvCheck'],
    )
    assert 'Found 0 check(s)' in stdout
    assert returncode == 0


",False
1399,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_list_empty_prgenvs_in_check_and_options,"def test_list_empty_prgenvs_in_check_and_options(run_reframe):
    returncode, stdout, _ = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        action='list',
        environs=[],
        more_options=['-n', 'NoPrgEnvCheck']
    )
    assert 'Found 0 check(s)' in stdout
    assert returncode == 0


",False
1400,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_no_ignore_check_conflicts,"def test_no_ignore_check_conflicts(run_reframe):
    returncode, *_ = run_reframe(
        checkpath=['unittests/resources/checks'],
        more_options=['-R'],
        ignore_check_conflicts=False,
        action='list'
    )
    assert returncode != 0


",False
1401,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_performance_check_failure,"def test_performance_check_failure(run_reframe, tmp_path, perflogdir):
    returncode, stdout, stderr = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['-t', 'PerformanceFailureCheck']
    )
    assert 'FAILED' in stdout

    # This is a normal failure, it should not raise any exception
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert returncode != 0
    assert os.path.exists(
        tmp_path / 'stage' / 'generic' / 'default' /
        'builtin-gcc' / 'PerformanceFailureCheck'
    )
    assert os.path.exists(perflogdir / 'generic' /
                          'default' / 'PerformanceFailureCheck.log')


",True
1402,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_performance_report,"def test_performance_report(run_reframe):
    returncode, stdout, stderr = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['-t', 'PerformanceFailureCheck', '--performance-report']
    )
    assert r'PERFORMANCE REPORT' in stdout
    assert r'perf: 10 Gflop/s' in stdout


",False
1403,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_report_file_with_sessionid,"def test_report_file_with_sessionid(run_reframe, tmp_path):
    returncode, stdout, _ = run_reframe(
        more_options=[
            f'--save-log-files',
            f'--report-file={tmp_path / ""rfm-report-{sessionid}.json""}'
        ]
    )
    assert returncode == 0
    assert os.path.exists(tmp_path / 'rfm-report-0.json')


",False
1404,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_same_output_stage_dir,"def test_same_output_stage_dir(run_reframe, tmp_path):
    output_dir = str(tmp_path / 'foo')
    returncode, *_ = run_reframe(
        more_options=['-o', output_dir, '-s', output_dir]
    )
    assert returncode == 1

    # Retry with --keep-stage-files
    returncode, *_ = run_reframe(
        more_options=['-o', output_dir, '-s', output_dir, '--keep-stage-files']
    )
    assert returncode == 0
    assert os.path.exists(output_dir)


",False
1405,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_sanity_of_checks,"def test_sanity_of_checks(run_reframe, tmp_path, logfile):
    # This test will effectively load all the tests in the checks path and
    # will force a syntactic and runtime check at least for the constructor
    # of the checks
    returncode, *_ = run_reframe(
        action='list',
        more_options=['--save-log-files'],
        checkpath=[]
    )
    assert returncode == 0
    os.path.exists(tmp_path / 'output' / logfile)


",False
1406,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_show_config_all,"def test_show_config_all(run_reframe):
    # Just make sure that this option does not make the frontend crash
    returncode, stdout, stderr = run_reframe(
        more_options=['--show-config'],
        system='testsys'
    )
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert returncode == 0


",False
1407,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_show_config_param,"def test_show_config_param(run_reframe):
    # Just make sure that this option does not make the frontend crash
    returncode, stdout, stderr = run_reframe(
        more_options=['--show-config=systems'],
        system='testsys'
    )
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert returncode == 0


",False
1408,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_show_config_unknown_param,"def test_show_config_unknown_param(run_reframe):
    # Just make sure that this option does not make the frontend crash
    returncode, stdout, stderr = run_reframe(
        more_options=['--show-config=foo'],
        system='testsys'
    )
    assert 'no such configuration parameter found' in stdout
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert returncode == 0


",False
1409,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_skip_prgenv_check_option,"def test_skip_prgenv_check_option(run_reframe):
    returncode, stdout, _ = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['--skip-prgenv-check', '-t', 'NoPrgEnvCheck']
    )
    assert 'PASSED' in stdout
    assert returncode == 0


",False
1410,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_skip_system_check_option,"def test_skip_system_check_option(run_reframe):
    returncode, stdout, _ = run_reframe(
        checkpath=['unittests/resources/checks/frontend_checks.py'],
        more_options=['--skip-system-check', '-t', 'NoSystemCheck']
    )
    assert 'PASSED' in stdout
    assert returncode == 0


",True
1411,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_timestamp_option,"def test_timestamp_option(run_reframe):
    from datetime import datetime

    timefmt = datetime.now().strftime('xxx_%F')
    returncode, stdout, _ = run_reframe(
        checkpath=['unittests/resources/checks'],
        ignore_check_conflicts=False,
        action='list',
        more_options=['-R', '--timestamp=xxx_%F']
    )
    assert returncode != 0
    assert timefmt in stdout


",False
1412,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_verbosity,"def test_verbosity(run_reframe):
    returncode, stdout, stderr = run_reframe(
        more_options=['-vvvvv'],
        system='testsys',
        action='list'
    )
    assert stdout != ''
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert returncode == 0


",False
1413,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_cli.py,,test_verbosity_with_check,"def test_verbosity_with_check(run_reframe):
    returncode, stdout, stderr = run_reframe(
        more_options=['-vvvvv'],
        system='testsys',
        checkpath=['unittests/resources/checks/hellocheck.py']
    )
    assert '' != stdout
    assert '--- Logging error ---' not in stdout
    assert 'Traceback' not in stdout
    assert 'Traceback' not in stderr
    assert 0 == returncode


",False
1414,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_dependencies.py,,test_build_deps_unknown_source_env,"def test_build_deps_unknown_source_env(loader, exec_ctx):
    checks = loader.load_all()

    # Add some inexistent dependencies
    test0 = find_check('Test0', checks)
    test1 = find_check('Test1_default', checks)
    test1.depends_on('Test0', rfm.DEPEND_EXACT, {'eX': ['e0']})

    # Unknown source is ignored, because it might simply be that the test
    # is not executed for eX
    deps = dependency.build_deps(executors.generate_testcases(checks))
    assert num_deps(deps, 'Test1_default') == 4


",False
1415,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_dependencies.py,,test_build_deps_unknown_target_env,"def test_build_deps_unknown_target_env(loader, exec_ctx):
    checks = loader.load_all()

    # Add some inexistent dependencies
    test0 = find_check('Test0', checks)
    test1 = find_check('Test1_default', checks)
    test1.depends_on('Test0', rfm.DEPEND_EXACT, {'e0': ['eX']})
    with pytest.raises(DependencyError):
        dependency.build_deps(executors.generate_testcases(checks))


",False
1416,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_dependencies.py,,test_build_deps_unknown_test,"def test_build_deps_unknown_test(loader, exec_ctx):
    checks = loader.load_all()

    # Add some inexistent dependencies
    test0 = find_check('Test0', checks)
    for depkind in ('default', 'fully', 'by_env', 'exact'):
        test1 = find_check('Test1_' + depkind, checks)
        if depkind == 'default':
            test1.depends_on('TestX')
        elif depkind == 'exact':
            test1.depends_on('TestX', rfm.DEPEND_EXACT, {'e0': ['e0']})
        elif depkind == 'fully':
            test1.depends_on('TestX', rfm.DEPEND_FULLY)
        elif depkind == 'by_env':
            test1.depends_on('TestX', rfm.DEPEND_BY_ENV)

        with pytest.raises(DependencyError):
            dependency.build_deps(executors.generate_testcases(checks))


",True
1417,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_dependencies.py,,test_cyclic_deps,"def test_cyclic_deps(make_test, exec_ctx):
    #
    #       t0       +-->t5<--+
    #       ^        |        |
    #       |        |        |
    #   +-->t1<--+   t6       t7
    #   |   |    |            ^
    #   t2  |    t3           |
    #   ^   |    ^            |
    #   |   v    |            t8
    #   +---t4---+
    #
    t0 = make_test('t0')
    t1 = make_test('t1')
    t2 = make_test('t2')
    t3 = make_test('t3')
    t4 = make_test('t4')
    t5 = make_test('t5')
    t6 = make_test('t6')
    t7 = make_test('t7')
    t8 = make_test('t8')
    t1.depends_on('t0')
    t1.depends_on('t4')
    t2.depends_on('t1')
    t3.depends_on('t1')
    t4.depends_on('t2')
    t4.depends_on('t3')
    t6.depends_on('t5')
    t7.depends_on('t5')
    t8.depends_on('t7')
    deps = dependency.build_deps(
        executors.generate_testcases([t0, t1, t2, t3, t4,
                                      t5, t6, t7, t8])
    )

    with pytest.raises(DependencyError) as exc_info:
        dependency.validate_deps(deps)

    assert ('t4->t2->t1->t4' in str(exc_info.value) or
            't2->t1->t4->t2' in str(exc_info.value) or
            't1->t4->t2->t1' in str(exc_info.value) or
            't1->t4->t3->t1' in str(exc_info.value) or
            't4->t3->t1->t4' in str(exc_info.value) or
            't3->t1->t4->t3' in str(exc_info.value))


",False
1418,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_dependencies.py,,test_cyclic_deps_by_env,"def test_cyclic_deps_by_env(make_test, exec_ctx):
    t0 = make_test('t0')
    t1 = make_test('t1')
    t1.depends_on('t0', rfm.DEPEND_EXACT, {'e0': ['e0']})
    t0.depends_on('t1', rfm.DEPEND_EXACT, {'e1': ['e1']})
    deps = dependency.build_deps(
        executors.generate_testcases([t0, t1])
    )
    with pytest.raises(DependencyError) as exc_info:
        dependency.validate_deps(deps)

    assert ('t1->t0->t1' in str(exc_info.value) or
            't0->t1->t0' in str(exc_info.value))


",False
1419,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_dependencies.py,,test_eq_hash,"def test_eq_hash(loader, exec_ctx):
    cases = executors.generate_testcases(loader.load_all())
    case0 = find_case('Test0', 'e0', cases)
    case1 = find_case('Test0', 'e1', cases)
    case0_copy = case0.clone()

    assert case0 == case0_copy
    assert hash(case0) == hash(case0_copy)
    assert case1 != case0
    assert hash(case1) != hash(case0)


",False
1420,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_dependencies.py,,test_toposort,"def test_toposort(make_test, exec_ctx):
    #
    #       t0       +-->t5<--+
    #       ^        |        |
    #       |        |        |
    #   +-->t1<--+   t6       t7
    #   |        |            ^
    #   t2<------t3           |
    #   ^        ^            |
    #   |        |            t8
    #   +---t4---+
    #
    t0 = make_test('t0')
    t1 = make_test('t1')
    t2 = make_test('t2')
    t3 = make_test('t3')
    t4 = make_test('t4')
    t5 = make_test('t5')
    t6 = make_test('t6')
    t7 = make_test('t7')
    t8 = make_test('t8')
    t1.depends_on('t0')
    t2.depends_on('t1')
    t3.depends_on('t1')
    t3.depends_on('t2')
    t4.depends_on('t2')
    t4.depends_on('t3')
    t6.depends_on('t5')
    t7.depends_on('t5')
    t8.depends_on('t7')
    deps = dependency.build_deps(
        executors.generate_testcases([t0, t1, t2, t3, t4,
                                      t5, t6, t7, t8])
    )
    cases = dependency.toposort(deps)
    assert_topological_order(cases, deps)


",False
1421,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_dependencies.py,,test_toposort_subgraph,"def test_toposort_subgraph(make_test, exec_ctx):
    #
    #       t0
    #       ^
    #       |
    #   +-->t1<--+
    #   |        |
    #   t2<------t3
    #   ^        ^
    #   |        |
    #   +---t4---+
    #
    t0 = make_test('t0')
    t1 = make_test('t1')
    t2 = make_test('t2')
    t3 = make_test('t3')
    t4 = make_test('t4')
    t1.depends_on('t0')
    t2.depends_on('t1')
    t3.depends_on('t1')
    t3.depends_on('t2')
    t4.depends_on('t2')
    t4.depends_on('t3')
    full_deps = dependency.build_deps(
        executors.generate_testcases([t0, t1, t2, t3, t4])
    )
    partial_deps = dependency.build_deps(
        executors.generate_testcases([t3, t4]), full_deps
    )
    cases = dependency.toposort(partial_deps, is_subgraph=True)
    assert_topological_order(cases, partial_deps)
",True
1422,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_environments.py,TestEnvironment,test_environ_snapshot,"def test_environ_snapshot(self):
        rt.loadenv(self.environ, self.environ_other)
        self.environ_save.restore()
        assert self.environ_save == env.snapshot()
        assert not rt.is_env_loaded(self.environ)
        assert not rt.is_env_loaded(self.environ_other)

    ",True
1423,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_environments.py,TestEnvironment,test_immutability,"def test_immutability(self):
        # Check emit_load_commands()
        _, commands = rt.loadenv(self.environ)

        # Try to modify the returned list of commands
        commands.append('foo')
        assert 'foo' not in rt.loadenv(self.environ)[1]

        # Test ProgEnvironment
        prgenv = env.ProgEnvironment('foo_prgenv')
        assert isinstance(prgenv, env.Environment)
        with pytest.raises(AttributeError):
            prgenv.cc = 'gcc'

        with pytest.raises(AttributeError):
            prgenv.cxx = 'g++'

        with pytest.raises(AttributeError):
            prgenv.ftn = 'gfortran'

        with pytest.raises(AttributeError):
            prgenv.nvcc = 'clang'

        with pytest.raises(AttributeError):
            prgenv.cppflags = ['-DFOO']

        with pytest.raises(AttributeError):
            prgenv.cflags = ['-O1']

        with pytest.raises(AttributeError):
            prgenv.cxxflags = ['-O1']

        with pytest.raises(AttributeError):
            prgenv.fflags = ['-O1']

        with pytest.raises(AttributeError):
            prgenv.ldflags = ['-lm']

    @fixtures.switch_to_user_runtime
    ",True
1424,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_environments.py,TestEnvironment,test_load_non_overlapping,"def test_load_non_overlapping(self):
        e0 = env.Environment(name='e0', variables=[('a', '1'), ('b', '2')])
        e1 = env.Environment(name='e1', variables=[('c', '3'), ('d', '4')])
        rt.loadenv(e0, e1)
        assert rt.is_env_loaded(e0)
        assert rt.is_env_loaded(e1)

    ",True
1425,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_environments.py,TestEnvironment,test_load_overlapping,"def test_load_overlapping(self):
        e0 = env.Environment(name='e0', variables=[('a', '1'), ('b', '2')])
        e1 = env.Environment(name='e1', variables=[('b', '3'), ('c', '4')])
        rt.loadenv(e0, e1)
        assert not rt.is_env_loaded(e0)
        assert rt.is_env_loaded(e1)

    ",True
1426,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_environments.py,TestEnvironment,test_load_restore,"def test_load_restore(self):
        snapshot, _ = rt.loadenv(self.environ)
        os.environ['_var0'] == 'val1'
        os.environ['_var1'] == 'val1'
        os.environ['_var2'] == 'val1'
        os.environ['_var3'] == 'val1'
        if fixtures.has_sane_modules_system():
            self.assertModulesLoaded(self.environ.modules)

        assert rt.is_env_loaded(self.environ)
        snapshot.restore()
        self.environ_save == env.snapshot()
        os.environ['_var0'], 'val0'
        if fixtures.has_sane_modules_system():
            assert not self.modules_system.is_module_loaded('testmod_foo')

        assert not rt.is_env_loaded(self.environ)

    @fixtures.switch_to_user_runtime
    ",True
1427,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_environments.py,TestEnvironment,test_setup,"def test_setup(self):
        if fixtures.has_sane_modules_system():
            assert len(self.environ.modules) == 1
            assert 'testmod_foo' in self.environ.modules

        assert len(self.environ.variables.keys()) == 3
        assert self.environ.variables['_var0'] == 'val1'

        # No variable expansion, if environment is not loaded
        self.environ.variables['_var2'] == '$_var0'
        self.environ.variables['_var3'] == '${_var1}'

    ",True
1428,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_loader.py,TestRegressionCheckLoader,test_conflicted_checks,"def test_conflicted_checks(self):
        self.loader_with_path._ignore_conflicts = False
        with pytest.raises(NameConflictError):
            self.loader_with_path.load_all()

    ",True
1429,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_loader.py,TestRegressionCheckLoader,test_load_all,"def test_load_all(self):
        checks = self.loader_with_path.load_all()
        assert 11 == len(checks)

    ",True
1430,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_loader.py,TestRegressionCheckLoader,test_load_bad_init,"def test_load_bad_init(self):
        tests = self.loader.load_from_file(
            'unittests/resources/checks_unlisted/bad_init_check.py')
        assert 0 == len(tests)

    ",True
1431,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_loader.py,TestRegressionCheckLoader,test_load_file_absolute,"def test_load_file_absolute(self):
        checks = self.loader.load_from_file(
            os.path.abspath('unittests/resources/checks/emptycheck.py'))
        assert 1 == len(checks)
        assert checks[0].name == 'EmptyTest'

    ",True
1432,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_loader.py,TestRegressionCheckLoader,test_load_file_relative,"def test_load_file_relative(self):
        checks = self.loader.load_from_file(
            'unittests/resources/checks/emptycheck.py')
        assert 1 == len(checks)
        assert checks[0].name == 'EmptyTest'

    ",True
1433,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_loader.py,TestRegressionCheckLoader,test_load_new_syntax,"def test_load_new_syntax(self):
        checks = self.loader.load_from_file(
            'unittests/resources/checks_unlisted/good.py')
        assert 13 == len(checks)

    ",True
1434,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_loader.py,TestRegressionCheckLoader,test_load_recursive,"def test_load_recursive(self):
        checks = self.loader.load_from_dir('unittests/resources/checks',
                                           recurse=True)
        assert 12 == len(checks)

    ",True
1435,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_loader.py,TestRegressionCheckLoader,test_special_test,"def test_special_test(self):
        with pytest.warns(ReframeDeprecationWarning):
            @rfm.simple_test
            class TestDeprecated(rfm.RegressionTest):
                ",False
1436,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_logging.py,,test_handler_noappend,"def test_handler_noappend(temp_runtime, logfile):
    runtime = temp_runtime(
        {
            'level': 'info',
            'handlers': [
                {
                    'type': 'file',
                    'name': logfile,
                    'level': 'warning',
                    'format': '[%(asctime)s] %(levelname)s: %(message)s',
                    'datefmt': '%F',
                    'append': False,
                }
            ],
            'handlers_perflog': []
        }

    )
    next(runtime)

    rlog.configure_logging(rt.runtime().site_config)
    rlog.getlogger().warning('foo')
    _close_handlers()

    # Reload logger
    rlog.configure_logging(rt.runtime().site_config)
    rlog.getlogger().warning('bar')

    assert not _found_in_logfile('foo', logfile)
    assert _found_in_logfile('bar', logfile)


",False
1437,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_logging.py,TestLogger,test_check_logger,"def test_check_logger(self):
        self.logger_with_check.info('foo')
        self.logger_with_check.verbose('bar')

        assert os.path.exists(self.logfile)
        assert self.found_in_logfile('info')
        assert self.found_in_logfile('verbose')
        assert self.found_in_logfile('_FakeCheck')

    ",True
1438,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_logging.py,TestLogger,test_custom_handler_levels,"def test_custom_handler_levels(self):
        self.handler.setLevel('verbose')
        self.handler.setLevel(rlog.VERBOSE)

        self.logger_with_check.debug('foo')
        self.logger_with_check.verbose('bar')

        assert not self.found_in_logfile('foo')
        assert self.found_in_logfile('bar')

    ",True
1439,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_logging.py,TestLogger,test_custom_loglevels,"def test_custom_loglevels(self):
        self.logger_without_check.info('foo')
        self.logger_without_check.verbose('bar')

        assert os.path.exists(self.logfile)
        assert self.found_in_logfile('info')
        assert self.found_in_logfile('verbose')
        assert self.found_in_logfile('reframe')

    ",True
1440,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_logging.py,TestLogger,test_handler_types,"def test_handler_types(self):
        assert issubclass(logging.Handler, rlog.Handler)
        assert issubclass(logging.StreamHandler, rlog.Handler)
        assert issubclass(logging.FileHandler, rlog.Handler)
        assert issubclass(logging.handlers.RotatingFileHandler, rlog.Handler)

        # Try to instantiate rlog.Handler
        with pytest.raises(TypeError):
            rlog.Handler()

    ",True
1441,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_logging.py,TestLogger,test_invalid_loglevel,"def test_invalid_loglevel(self):
        with pytest.raises(ValueError):
            self.logger.setLevel('level')

        with pytest.raises(ValueError):
            rlog.Logger('logger', 'level')

    ",True
1442,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_logging.py,TestLogger,test_logger_levels,"def test_logger_levels(self):
        self.logger_with_check.setLevel('verbose')
        self.logger_with_check.setLevel(rlog.VERBOSE)

        self.logger_with_check.debug('bar')
        self.logger_with_check.verbose('foo')

        assert not self.found_in_logfile('bar')
        assert self.found_in_logfile('foo')

    ",True
1443,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_logging.py,TestLogger,test_rfc3339_timezone_extension,"def test_rfc3339_timezone_extension(self):
        self.formatter = rlog.RFC3339Formatter(
            fmt=('[%(asctime)s] %(levelname)s: %(check_name)s: '
                 'ct:%(check_job_completion_time)s: %(message)s'),
            datefmt='%FT%T%:z')
        self.handler.setFormatter(self.formatter)
        self.logger_with_check.info('foo')
        self.logger_without_check.info('foo')
        assert not self.found_in_logfile(r'%%:z')
        assert self.found_in_logfile(r'\[.+(\+|-)\d\d:\d\d\]')
        assert self.found_in_logfile(r'ct:.+(\+|-)\d\d:\d\d')

    ",True
1444,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_logging.py,TestLogger,test_rfc3339_timezone_wrong_directive,"def test_rfc3339_timezone_wrong_directive(self):
        self.formatter = rlog.RFC3339Formatter(
            fmt='[%(asctime)s] %(levelname)s: %(check_name)s: %(message)s',
            datefmt='%FT%T:z')
        self.handler.setFormatter(self.formatter)
        self.logger_without_check.info('foo')
        assert self.found_in_logfile(':z')


@pytest.fixture
",True
1445,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_compile_hooks,"def test_compile_hooks(local_exec_ctx):
    @fixtures.custom_prefix('unittests/resources/checks')
    class MyTest(HelloTest):
        ",False
1446,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_environ_setup,"def test_environ_setup(hellotest, local_exec_ctx):
    # Use test environment for the regression check
    hellotest.variables = {'_FOO_': '1', '_BAR_': '2'}
    hellotest.setup(*local_exec_ctx)
    for k in hellotest.variables.keys():
        assert k not in os.environ


",True
1447,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_extra_resources,"def test_extra_resources(testsys_system):
    @fixtures.custom_prefix('unittests/resources/checks')
    class MyTest(HelloTest):
        ",False
1448,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_hellocheck_local,"def test_hellocheck_local(hellotest, local_exec_ctx):
    # Test also the prebuild/postbuild functionality
    hellotest.prebuild_cmds = ['touch prebuild', 'mkdir prebuild_dir']
    hellotest.postbuild_cmds = ['touch postbuild', 'mkdir postbuild_dir']
    hellotest.keep_files = ['prebuild', 'postbuild',
                            'prebuild_dir', 'postbuild_dir']

    # Force local execution of the test; just for testing .local
    hellotest.local = True
    _run(hellotest, *local_exec_ctx)
    must_keep = [
        hellotest.stdout.evaluate(),
        hellotest.stderr.evaluate(),
        hellotest.build_stdout.evaluate(),
        hellotest.build_stderr.evaluate(),
        hellotest.job.script_filename,
        *hellotest.keep_files
    ]
    for f in must_keep:
        assert os.path.exists(os.path.join(hellotest.outputdir, f))


",True
1449,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_hellocheck_local_prepost_run,"def test_hellocheck_local_prepost_run(hellotest, local_exec_ctx):
    @sn.sanity_function
    ",True
1450,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_multiple_hooks,"def test_multiple_hooks(local_exec_ctx):
    @fixtures.custom_prefix('unittests/resources/checks')
    class MyTest(HelloTest):
        ",False
1451,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_name_compileonly_test,"def test_name_compileonly_test():
    class MyTest(rfm.CompileOnlyRegressionTest):
        ",True
1452,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_name_runonly_test,"def test_name_runonly_test():
    class MyTest(rfm.RunOnlyRegressionTest):
        ",True
1453,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_name_user_inheritance,"def test_name_user_inheritance():
    class MyBaseTest(rfm.RegressionTest):
        ",True
1454,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_performance_var_evaluation,"def test_performance_var_evaluation(dummytest, sanity_file,
                                    perf_file, dummy_gpu_exec_ctx):
    # All performance values must be evaluated, despite the first one
    # failing To test this, we need an extract function that will have a
    # side effect when evaluated, whose result we will check after calling
    # `check_performance()`.
    logfile = 'perf.log'

    @sn.sanity_function
    ",False
1455,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_reference_default,"def test_reference_default(dummytest, sanity_file,
                           perf_file, dummy_gpu_exec_ctx):
    sanity_file.write_text('result = success\n')
    perf_file.write_text('perf1 = 1.3\n'
                         'perf2 = 1.8\n'
                         'perf3 = 3.3\n')
    dummytest.reference = {
        '*': {
            'value1': (1.4, -0.1, 0.1, None),
            'value2': (1.7, -0.1, 0.1, None),
            'value3': (3.1, -0.1, 0.1, None),
        }
    }
    _run_sanity(dummytest, *dummy_gpu_exec_ctx)


",False
1456,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_reference_unknown_tag,"def test_reference_unknown_tag(dummytest, sanity_file,
                               perf_file, dummy_gpu_exec_ctx):
    sanity_file.write_text('result = success\n')
    perf_file.write_text('perf1 = 1.3\n'
                         'perf2 = 1.8\n'
                         'perf3 = 3.3\n')
    dummytest.reference = {
        'testsys': {
            'value1': (1.4, -0.1, 0.1, None),
            'value2': (1.7, -0.1, 0.1, None),
            'foo': (3.1, -0.1, 0.1, None),
        }
    }
    with pytest.raises(SanityError):
        _run_sanity(dummytest, *dummy_gpu_exec_ctx)


",False
1457,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_registration_of_tests,"def test_registration_of_tests():
    import sys
    import unittests.resources.checks_unlisted.good as mod

    checks = mod._rfm_gettests()
    assert 13 == len(checks)
    assert [mod.MyBaseTest(0, 0),
            mod.MyBaseTest(0, 1),
            mod.MyBaseTest(1, 0),
            mod.MyBaseTest(1, 1),
            mod.MyBaseTest(2, 0),
            mod.MyBaseTest(2, 1),
            mod.AnotherBaseTest(0, 0),
            mod.AnotherBaseTest(0, 1),
            mod.AnotherBaseTest(1, 0),
            mod.AnotherBaseTest(1, 1),
            mod.AnotherBaseTest(2, 0),
            mod.AnotherBaseTest(2, 1),
            mod.MyBaseTest(10, 20)] == checks


",True
1458,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_regression_test_name,"def test_regression_test_name():
    class MyTest(rfm.RegressionTest):
        ",True
1459,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_strange_test_names,"def test_strange_test_names():
    class C:
        ",True
1460,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_supports_environ,"def test_supports_environ(hellotest, generic_system):
    hellotest.valid_prog_environs = ['*']
    assert hellotest.supports_environ('foo1')
    assert hellotest.supports_environ('foo-env')
    assert hellotest.supports_environ('*')


",True
1461,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_pipeline.py,,test_supports_system,"def test_supports_system(hellotest, testsys_system):
    hellotest.valid_systems = ['*']
    assert hellotest.supports_system('gpu')
    assert hellotest.supports_system('login')
    assert hellotest.supports_system('testsys:gpu')
    assert hellotest.supports_system('testsys:login')

    hellotest.valid_systems = ['*:*']
    assert hellotest.supports_system('gpu')
    assert hellotest.supports_system('login')
    assert hellotest.supports_system('testsys:gpu')
    assert hellotest.supports_system('testsys:login')

    hellotest.valid_systems = ['testsys']
    assert hellotest.supports_system('gpu')
    assert hellotest.supports_system('login')
    assert hellotest.supports_system('testsys:gpu')
    assert hellotest.supports_system('testsys:login')

    hellotest.valid_systems = ['testsys:gpu']
    assert hellotest.supports_system('gpu')
    assert not hellotest.supports_system('login')
    assert hellotest.supports_system('testsys:gpu')
    assert not hellotest.supports_system('testsys:login')

    hellotest.valid_systems = ['testsys:login']
    assert not hellotest.supports_system('gpu')
    assert hellotest.supports_system('login')
    assert not hellotest.supports_system('testsys:gpu')
    assert hellotest.supports_system('testsys:login')

    hellotest.valid_systems = ['foo']
    assert not hellotest.supports_system('gpu')
    assert not hellotest.supports_system('login')
    assert not hellotest.supports_system('testsys:gpu')
    assert not hellotest.supports_system('testsys:login')

    hellotest.valid_systems = ['*:gpu']
    assert hellotest.supports_system('testsys:gpu')
    assert hellotest.supports_system('foo:gpu')
    assert not hellotest.supports_system('testsys:cpu')
    assert not hellotest.supports_system('testsys:login')

    hellotest.valid_systems = ['testsys:*']
    assert hellotest.supports_system('testsys:login')
    assert hellotest.supports_system('gpu')
    assert not hellotest.supports_system('foo:gpu')


",True
1462,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_concurrency_limited,"def test_concurrency_limited(async_runner, make_cases, make_async_exec_ctx):
    # The number of checks must be <= 2*max_jobs.
    num_checks, max_jobs = 5, 3
    ctx = make_async_exec_ctx(max_jobs)
    next(ctx)

    runner, monitor = async_runner
    runner.runall(make_cases([SleepCheck(.5) for i in range(num_checks)]))

    # Ensure that all tests were run and without failures.
    assert num_checks == runner.stats.num_cases()
    assert_runall(runner)
    assert 0 == len(runner.stats.failures())

    # Ensure that maximum concurrency was reached as fast as possible
    assert max_jobs == max(monitor.num_tasks)
    assert max_jobs == monitor.num_tasks[max_jobs]

    begin_stamps, end_stamps = _read_timestamps(monitor.tasks)

    # Ensure that the jobs after the first #max_jobs were each run after
    # one of the previous #max_jobs jobs had finished
    # (e.g. begin[max_jobs] > end[0]).
    # Note: we may ensure this strictly as we may ensure serial behaviour.
    begin_after_end = (b > e for b, e in zip(begin_stamps[max_jobs:],
                                             end_stamps[:-max_jobs]))
    assert all(begin_after_end)

    # NOTE: to ensure that these remaining jobs were also run
    # in parallel one could do the command hereafter; however, it would
    # require to substantially increase the sleep time (in SleepCheck),
    # because of the delays in rescheduling (1s, 2s, 3s, 1s, 2s,...).
    # We currently prefer not to do this last concurrency test to avoid an
    # important prolongation of the unit test execution time.
    # self.assertTrue(self.begin_stamps[-1] < self.end_stamps[max_jobs])

    # Warn if the first #max_jobs jobs were not run in parallel; the
    # corresponding strict check would be:
    # self.assertTrue(self.begin_stamps[max_jobs-1] <= self.end_stamps[0])
    if begin_stamps[max_jobs-1] > end_stamps[0]:
        pytest.skip('the system seems too loaded.')


",True
1463,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_concurrency_none,"def test_concurrency_none(async_runner, make_cases, make_async_exec_ctx):
    num_checks = 3
    ctx = make_async_exec_ctx(1)
    next(ctx)

    runner, monitor = async_runner
    runner.runall(make_cases([SleepCheck(.5) for i in range(num_checks)]))

    # Ensure that all tests were run and without failures.
    assert num_checks == runner.stats.num_cases()
    assert_runall(runner)
    assert 0 == len(runner.stats.failures())

    # Ensure that a single task was running all the time
    assert 1 == max(monitor.num_tasks)

    # Read the timestamps sorted to permit simple concurrency tests.
    begin_stamps, end_stamps = _read_timestamps(monitor.tasks)

    # Ensure that the jobs were run after the previous job had finished
    # (e.g. begin[1] > end[0]).
    begin_after_end = (b > e
                       for b, e in zip(begin_stamps[1:], end_stamps[:-1]))
    assert all(begin_after_end)


",False
1464,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_concurrency_unlimited,"def test_concurrency_unlimited(async_runner, make_cases, make_async_exec_ctx):
    num_checks = 3

    # Trigger evaluation of the execution context
    ctx = make_async_exec_ctx(num_checks)
    next(ctx)

    runner, monitor = async_runner
    runner.runall(make_cases([SleepCheck(.5) for i in range(num_checks)]))

    # Ensure that all tests were run and without failures.
    assert num_checks == runner.stats.num_cases()
    assert_runall(runner)
    assert 0 == len(runner.stats.failures())

    # Ensure that maximum concurrency was reached as fast as possible
    assert num_checks == max(monitor.num_tasks)
    assert num_checks == monitor.num_tasks[num_checks]
    begin_stamps, end_stamps = _read_timestamps(monitor.tasks)

    # Warn if not all tests were run in parallel; the corresponding strict
    # check would be:
    #
    #     assert begin_stamps[-1] <= end_stamps[0]
    #
    if begin_stamps[-1] > end_stamps[0]:
        pytest.skip('the system seems too much loaded.')


",True
1465,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_dependencies,"def test_dependencies(make_runner, dep_cases, common_exec_ctx):
    runner = make_runner()
    runner.runall(dep_cases)
    assert_dependency_run(runner)


",True
1466,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_dependencies,"def test_dependencies(make_runner, dep_cases, common_exec_ctx):
    runner = make_runner()
    runner.runall(dep_cases)
    assert_dependency_run(runner)


",True
1467,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_dependencies_with_retries,"def test_dependencies_with_retries(make_runner, dep_cases, common_exec_ctx):
    runner = make_runner(max_retries=2)
    runner.runall(dep_cases)
    assert_dependency_run(runner)


class _TaskEventMonitor(executors.TaskEventListener):
    '''Event listener for monitoring the execution of the asynchronous
    execution policy.

    We need to make sure two things for the async policy:

    1. The number of running tasks never exceed the max job size per partition.
    2. Given a set of regression tests with a reasonably long runtime, the
       execution policy must be able to reach the maximum concurrency. By
       reasonably long runtime, we mean that that the regression tests must run
       enough time, so as to allow the policy to execute all the tests until
       their ""run"" phase, before the first submitted test finishes.
    '''

    ",True
1468,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_dependencies_with_retries,"def test_dependencies_with_retries(make_runner, dep_cases, common_exec_ctx):
    runner = make_runner(max_retries=2)
    runner.runall(dep_cases)
    assert_dependency_run(runner)


class _TaskEventMonitor(executors.TaskEventListener):
    '''Event listener for monitoring the execution of the asynchronous
    execution policy.

    We need to make sure two things for the async policy:

    1. The number of running tasks never exceed the max job size per partition.
    2. Given a set of regression tests with a reasonably long runtime, the
       execution policy must be able to reach the maximum concurrency. By
       reasonably long runtime, we mean that that the regression tests must run
       enough time, so as to allow the policy to execute all the tests until
       their ""run"" phase, before the first submitted test finishes.
    '''

    ",True
1469,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_kbd_interrupt_in_wait_with_concurrency,"def test_kbd_interrupt_in_wait_with_concurrency(async_runner, make_cases,
                                                make_async_exec_ctx):
    ctx = make_async_exec_ctx(4)
    next(ctx)

    runner, _ = async_runner
    with pytest.raises(KeyboardInterrupt):
        runner.runall(make_cases([
            KeyboardInterruptCheck(), SleepCheck(10),
            SleepCheck(10), SleepCheck(10)
        ]))

    assert_interrupted_run(runner)


",True
1470,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_kbd_interrupt_within_test,"def test_kbd_interrupt_within_test(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    check = KeyboardInterruptCheck()
    with pytest.raises(KeyboardInterrupt):
        runner.runall(make_cases([KeyboardInterruptCheck()]))

    stats = runner.stats
    assert 1 == len(stats.failures())
    assert_all_dead(runner)


",False
1471,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_kbd_interrupt_within_test,"def test_kbd_interrupt_within_test(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    check = KeyboardInterruptCheck()
    with pytest.raises(KeyboardInterrupt):
        runner.runall(make_cases([KeyboardInterruptCheck()]))

    stats = runner.stats
    assert 1 == len(stats.failures())
    assert_all_dead(runner)


",False
1472,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_pass_in_retries,"def test_pass_in_retries(make_runner, make_cases, tmp_path, common_exec_ctx):
    tmpfile = tmp_path / 'out.txt'
    tmpfile.write_text('0\n')
    runner = make_runner(max_retries=3)
    pass_run_no = 2
    runner.runall(make_cases([RetriesCheck(pass_run_no, tmpfile)]))

    # Ensure that the test passed after retries in run `pass_run_no`
    assert 1 == runner.stats.num_cases()
    assert_runall(runner)
    assert 1 == len(runner.stats.failures(run=0))
    assert pass_run_no == rt.runtime().current_run
    assert 0 == len(runner.stats.failures())


",True
1473,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_pass_in_retries,"def test_pass_in_retries(make_runner, make_cases, tmp_path, common_exec_ctx):
    tmpfile = tmp_path / 'out.txt'
    tmpfile.write_text('0\n')
    runner = make_runner(max_retries=3)
    pass_run_no = 2
    runner.runall(make_cases([RetriesCheck(pass_run_no, tmpfile)]))

    # Ensure that the test passed after retries in run `pass_run_no`
    assert 1 == runner.stats.num_cases()
    assert_runall(runner)
    assert 1 == len(runner.stats.failures(run=0))
    assert pass_run_no == rt.runtime().current_run
    assert 0 == len(runner.stats.failures())


",True
1474,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_retries_bad_check,"def test_retries_bad_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner(max_retries=2)
    runner.runall(make_cases([BadSetupCheck(), BadSetupCheckEarly()]))

    # Ensure that the test was retried #max_retries times and failed
    assert 2 == runner.stats.num_cases()
    assert_runall(runner)
    assert runner.max_retries == rt.runtime().current_run
    assert 2 == len(runner.stats.failures())

    # Ensure that the report does not raise any exception
    runner.stats.retry_report()


",True
1475,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_retries_bad_check,"def test_retries_bad_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner(max_retries=2)
    runner.runall(make_cases([BadSetupCheck(), BadSetupCheckEarly()]))

    # Ensure that the test was retried #max_retries times and failed
    assert 2 == runner.stats.num_cases()
    assert_runall(runner)
    assert runner.max_retries == rt.runtime().current_run
    assert 2 == len(runner.stats.failures())

    # Ensure that the report does not raise any exception
    runner.stats.retry_report()


",True
1476,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_retries_good_check,"def test_retries_good_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner(max_retries=2)
    runner.runall(make_cases([HelloTest()]))

    # Ensure that the test passed without retries.
    assert 1 == runner.stats.num_cases()
    assert_runall(runner)
    assert 0 == rt.runtime().current_run
    assert 0 == len(runner.stats.failures())


",False
1477,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall,"def test_runall(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    time_start = time.time()
    runner.runall(make_cases())
    time_end = time.time()
    assert 8 == runner.stats.num_cases()
    assert_runall(runner)
    assert 5 == len(runner.stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 1 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')

    # Create a run report and validate it
    run_stats = runner.stats.json()
    report = {
        'session_info': {
            'cmdline': ' '.join(sys.argv),
            'config_file': rt.runtime().site_config.filename,
            'data_version': '1.0',
            'hostname': socket.gethostname(),
            'num_cases': run_stats[0]['num_cases'],
            'num_failures': run_stats[-1]['num_failures'],
            'prefix_output': rt.runtime().output_prefix,
            'prefix_stage': rt.runtime().stage_prefix,
            'time_elapsed': time_end - time_start,
            'time_end': time.strftime(
                '%FT%T%z', time.localtime(time_end),
            ),
            'time_start': time.strftime(
                '%FT%T%z', time.localtime(time_start),
            ),
            'user': os_ext.osuser(),
            'version': os_ext.reframe_version(),
            'workdir': os.getcwd()
        },
        'runs': run_stats
    }
    _validate_runreport(report)


",True
1478,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall,"def test_runall(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    time_start = time.time()
    runner.runall(make_cases())
    time_end = time.time()
    assert 8 == runner.stats.num_cases()
    assert_runall(runner)
    assert 5 == len(runner.stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 1 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')

    # Create a run report and validate it
    run_stats = runner.stats.json()
    report = {
        'session_info': {
            'cmdline': ' '.join(sys.argv),
            'config_file': rt.runtime().site_config.filename,
            'data_version': '1.0',
            'hostname': socket.gethostname(),
            'num_cases': run_stats[0]['num_cases'],
            'num_failures': run_stats[-1]['num_failures'],
            'prefix_output': rt.runtime().output_prefix,
            'prefix_stage': rt.runtime().stage_prefix,
            'time_elapsed': time_end - time_start,
            'time_end': time.strftime(
                '%FT%T%z', time.localtime(time_end),
            ),
            'time_start': time.strftime(
                '%FT%T%z', time.localtime(time_start),
            ),
            'user': os_ext.osuser(),
            'version': os_ext.reframe_version(),
            'workdir': os.getcwd()
        },
        'runs': run_stats
    }
    _validate_runreport(report)


",True
1479,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall_skip_performance_check,"def test_runall_skip_performance_check(make_runner, make_cases,
                                       common_exec_ctx):
    runner = make_runner()
    runner.policy.skip_performance_check = True
    runner.runall(make_cases())
    stats = runner.stats
    assert 8 == stats.num_cases()
    assert_runall(runner)
    assert 4 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 0 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1480,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall_skip_performance_check,"def test_runall_skip_performance_check(make_runner, make_cases,
                                       common_exec_ctx):
    runner = make_runner()
    runner.policy.skip_performance_check = True
    runner.runall(make_cases())
    stats = runner.stats
    assert 8 == stats.num_cases()
    assert_runall(runner)
    assert 4 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 0 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1481,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall_skip_prgenv_check,"def test_runall_skip_prgenv_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    runner.runall(make_cases(skip_environ_check=True))
    stats = runner.stats
    assert 9 == stats.num_cases()
    assert_runall(runner)
    assert 5 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 1 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1482,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall_skip_prgenv_check,"def test_runall_skip_prgenv_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    runner.runall(make_cases(skip_environ_check=True))
    stats = runner.stats
    assert 9 == stats.num_cases()
    assert_runall(runner)
    assert 5 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 1 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1483,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall_skip_sanity_check,"def test_runall_skip_sanity_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    runner.policy.skip_sanity_check = True
    runner.runall(make_cases())
    stats = runner.stats
    assert 8 == stats.num_cases()
    assert_runall(runner)
    assert 4 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 0 == num_failures_stage(runner, 'sanity')
    assert 1 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1484,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall_skip_sanity_check,"def test_runall_skip_sanity_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    runner.policy.skip_sanity_check = True
    runner.runall(make_cases())
    stats = runner.stats
    assert 8 == stats.num_cases()
    assert_runall(runner)
    assert 4 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 0 == num_failures_stage(runner, 'sanity')
    assert 1 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1485,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall_skip_system_check,"def test_runall_skip_system_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    runner.runall(make_cases(skip_system_check=True))
    stats = runner.stats
    assert 9 == stats.num_cases()
    assert_runall(runner)
    assert 5 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 1 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1486,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_runall_skip_system_check,"def test_runall_skip_system_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    runner.runall(make_cases(skip_system_check=True))
    stats = runner.stats
    assert 9 == stats.num_cases()
    assert_runall(runner)
    assert 5 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 1 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1487,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_sigterm_handling,"def test_sigterm_handling(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    with pytest.raises(ReframeForceExitError,
                       match='received TERM signal'):
        runner.runall(make_cases([SelfKillCheck()]))

    assert_all_dead(runner)
    assert runner.stats.num_cases() == 1
    assert len(runner.stats.failures()) == 1


@pytest.fixture
",True
1488,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_sigterm_handling,"def test_sigterm_handling(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    with pytest.raises(ReframeForceExitError,
                       match='received TERM signal'):
        runner.runall(make_cases([SelfKillCheck()]))

    assert_all_dead(runner)
    assert runner.stats.num_cases() == 1
    assert len(runner.stats.failures()) == 1


@pytest.fixture
",False
1489,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_strict_performance_check,"def test_strict_performance_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    runner.policy.strict_check = True
    runner.runall(make_cases())
    stats = runner.stats
    assert 8 == stats.num_cases()
    assert_runall(runner)
    assert 6 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 2 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1490,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_policies.py,,test_strict_performance_check,"def test_strict_performance_check(make_runner, make_cases, common_exec_ctx):
    runner = make_runner()
    runner.policy.strict_check = True
    runner.runall(make_cases())
    stats = runner.stats
    assert 8 == stats.num_cases()
    assert_runall(runner)
    assert 6 == len(stats.failures())
    assert 2 == num_failures_stage(runner, 'setup')
    assert 1 == num_failures_stage(runner, 'sanity')
    assert 2 == num_failures_stage(runner, 'performance')
    assert 1 == num_failures_stage(runner, 'cleanup')


",True
1491,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_cancel,"def test_cancel(make_job, exec_ctx):
    minimal_job = make_job(sched_access=exec_ctx.access)
    prepare_job(minimal_job, 'sleep 30')
    t_job = datetime.now()
    minimal_job.submit()
    minimal_job.cancel()
    minimal_job.wait()
    t_job = datetime.now() - t_job
    assert minimal_job.finished()
    assert t_job.total_seconds() < 30

    # Additional scheduler-specific checks
    sched_name = minimal_job.scheduler.registered_name
    if sched_name in ('slurm', 'squeue'):
        assert minimal_job.state == 'CANCELLED'


",True
1492,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_cancel_before_submit,"def test_cancel_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.cancel()


",True
1493,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_cancel_before_submit,"def test_cancel_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.cancel()


",True
1494,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_cancel_before_submit,"def test_cancel_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.cancel()


",True
1495,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_cancel_before_submit,"def test_cancel_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.cancel()


",True
1496,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_cancel_before_submit,"def test_cancel_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.cancel()


",True
1497,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_cancel_term_ignore,"def test_cancel_term_ignore(minimal_job, scheduler, local_only):
    # This test emulates a descendant process of the spawned job that
    # ignores the SIGTERM signal:
    #
    #   reframe --- local job script --- sleep_deeply.sh --- sleep
    #                                      (TERM IGN)
    #
    #  Since the ""local job script"" does not ignore SIGTERM, it will be
    #  terminated immediately after we cancel the job. However, the deeply
    #  spawned sleep will ignore it. We need to make sure that our
    #  implementation grants the sleep process a grace period and then
    #  kills it.
    minimal_job.time_limit = '1m'
    minimal_job.scheduler._cancel_grace_period = 2
    prepare_job(minimal_job,
                command=os.path.join(fixtures.TEST_RESOURCES_CHECKS,
                                     'src', 'sleep_deeply.sh'),
                pre_run=[''],
                post_run=[''])
    minimal_job.submit()

    # Stall a bit here to let the the spawned process start and install its
    # signal handler for SIGTERM
    time.sleep(1)

    t_grace = datetime.now()
    minimal_job.cancel()
    t_grace = datetime.now() - t_grace
    minimal_job.wait()

    # Read pid of spawned sleep
    with open(minimal_job.stdout) as fp:
        sleep_pid = int(fp.read())

    assert t_grace.total_seconds() >= 2
    assert minimal_job.state == 'TIMEOUT'

    # Verify that the spawned sleep is killed, too
    assert_process_died(sleep_pid)


# Flexible node allocation tests


@pytest.fixture
",True
1498,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_cancel_with_grace,"def test_cancel_with_grace(minimal_job, scheduler, local_only):
    # This test emulates a spawned process that ignores the SIGTERM signal
    # and also spawns another process:
    #
    #   reframe --- local job script --- sleep 10
    #                  (TERM IGN)
    #
    # We expect the job not to be cancelled immediately, since it ignores
    # the gracious signal we are sending it. However, we expect it to be
    # killed immediately after the grace period of 2 seconds expires.
    #
    # We also check that the additional spawned process is also killed.
    minimal_job.time_limit = '1m'
    minimal_job.scheduler._cancel_grace_period = 2
    prepare_job(minimal_job,
                command='sleep 5 &',
                pre_run=['trap -- """" TERM'],
                post_run=['echo $!', 'wait'])
    minimal_job.submit()

    # Stall a bit here to let the the spawned process start and install its
    # signal handler for SIGTERM
    time.sleep(1)

    t_grace = datetime.now()
    minimal_job.cancel()
    t_grace = datetime.now() - t_grace

    minimal_job.wait()
    # Read pid of spawned sleep
    with open(minimal_job.stdout) as fp:
        sleep_pid = int(fp.read())

    assert t_grace.total_seconds() >= 2
    assert t_grace.total_seconds() < 5
    assert minimal_job.state == 'TIMEOUT'

    # Verify that the spawned sleep is killed, too
    assert_process_died(sleep_pid)


",True
1499,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_combined_access_constraint,"def test_combined_access_constraint(make_job, slurm_only):
    job = make_job(sched_access=['--constraint=c1'])
    job.options = ['-C c2&c3']
    prepare_job(job)
    with open(job.script_filename) as fp:
        script_content = fp.read()

    assert re.search(r'(?m)--constraint=c1&c2&c3$', script_content)
    assert re.search(r'(?m)--constraint=(c1|c2&c3)$', script_content) is None


",True
1500,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_combined_access_constraint,"def test_combined_access_constraint(make_job, slurm_only):
    job = make_job(sched_access=['--constraint=c1'])
    job.options = ['-C c2&c3']
    prepare_job(job)
    with open(job.script_filename) as fp:
        script_content = fp.read()

    assert re.search(r'(?m)--constraint=c1&c2&c3$', script_content)
    assert re.search(r'(?m)--constraint=(c1|c2&c3)$', script_content) is None


",True
1501,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_combined_access_multiple_constraints,"def test_combined_access_multiple_constraints(make_job, slurm_only):
    job = make_job(sched_access=['--constraint=c1'])
    job.options = ['--constraint=c2', '-C c3']
    prepare_job(job)
    with open(job.script_filename) as fp:
        script_content = fp.read()

    assert re.search(r'(?m)--constraint=c1&c3$', script_content)
    assert re.search(r'(?m)--constraint=(c1|c2|c3)$', script_content) is None


",True
1502,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_combined_access_multiple_constraints,"def test_combined_access_multiple_constraints(make_job, slurm_only):
    job = make_job(sched_access=['--constraint=c1'])
    job.options = ['--constraint=c2', '-C c3']
    prepare_job(job)
    with open(job.script_filename) as fp:
        script_content = fp.read()

    assert re.search(r'(?m)--constraint=c1&c3$', script_content)
    assert re.search(r'(?m)--constraint=(c1|c2|c3)$', script_content) is None


",False
1503,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_combined_access_verbatim_constraint,"def test_combined_access_verbatim_constraint(make_job, slurm_only):
    job = make_job(sched_access=['--constraint=c1'])
    job.options = ['#SBATCH --constraint=c2', '#SBATCH -C c3']
    prepare_job(job)
    with open(job.script_filename) as fp:
        script_content = fp.read()

    assert re.search(r'(?m)--constraint=c1$', script_content)
    assert re.search(r'(?m)^#SBATCH --constraint=c2$', script_content)
    assert re.search(r'(?m)^#SBATCH -C c3$', script_content)


",True
1504,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_combined_access_verbatim_constraint,"def test_combined_access_verbatim_constraint(make_job, slurm_only):
    job = make_job(sched_access=['--constraint=c1'])
    job.options = ['#SBATCH --constraint=c2', '#SBATCH -C c3']
    prepare_job(job)
    with open(job.script_filename) as fp:
        script_content = fp.read()

    assert re.search(r'(?m)--constraint=c1$', script_content)
    assert re.search(r'(?m)^#SBATCH --constraint=c2$', script_content)
    assert re.search(r'(?m)^#SBATCH -C c3$', script_content)


",False
1505,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_constraint_idle,"def test_flex_alloc_constraint_idle(make_flexible_job):
    job = make_flexible_job('idle')
    job.options = ['--constraint=f1']
    prepare_job(job)
    assert job.num_tasks == 8


",True
1506,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_default_partition_all,"def test_flex_alloc_default_partition_all(make_flexible_job):
    job = make_flexible_job('all')
    prepare_job(job)
    assert job.num_tasks == 16


",True
1507,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_enough_nodes_constraint_partition,"def test_flex_alloc_enough_nodes_constraint_partition(make_flexible_job):
    job = make_flexible_job('all')
    job.options = ['-C f1&f2', '--partition=p1,p2']
    job.num_tasks = -4
    prepare_job(job)
    assert job.num_tasks == 4


@pytest.fixture
",True
1508,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_exclude_nodes_cmd,"def test_flex_alloc_exclude_nodes_cmd(make_flexible_job):
    job = make_flexible_job('all',
                            sched_access=['--constraint=f1'],
                            sched_exclude_nodelist='nid00001')
    prepare_job(job)
    assert job.num_tasks == 8


",True
1509,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_exclude_nodes_opt,"def test_flex_alloc_exclude_nodes_opt(make_flexible_job):
    job = make_flexible_job('all', sched_access=['--constraint=f1'])
    job.options = ['-x nid00001']
    prepare_job(job)
    assert job.num_tasks == 8


",True
1510,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_invalid_constraint,"def test_flex_alloc_invalid_constraint(make_flexible_job):
    job = make_flexible_job('all')
    job.options = ['--constraint=invalid']
    with pytest.raises(JobError):
        prepare_job(job)


",True
1511,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_invalid_partition_cmd,"def test_flex_alloc_invalid_partition_cmd(make_flexible_job):
    job = make_flexible_job('all', sched_partition='invalid')
    with pytest.raises(JobError):
        prepare_job(job)


",False
1512,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_invalid_partition_opt,"def test_flex_alloc_invalid_partition_opt(make_flexible_job):
    job = make_flexible_job('all')
    job.options = ['--partition=invalid']
    with pytest.raises(JobError):
        prepare_job(job)


",True
1513,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_maintenance_nodes,"def test_flex_alloc_maintenance_nodes(make_flexible_job):
    job = make_flexible_job('maint')
    job.options = ['--partition=p4']
    prepare_job(job)
    assert job.num_tasks == 4


",True
1514,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_no_num_tasks_per_node,"def test_flex_alloc_no_num_tasks_per_node(make_flexible_job):
    job = make_flexible_job('all')
    job.num_tasks_per_node = None
    job.options = ['-C f1&f2', '--partition=p1,p2']
    prepare_job(job)
    assert job.num_tasks == 1


",True
1515,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_nodes_negative,"def test_flex_alloc_nodes_negative(make_flexible_job):
    job = make_flexible_job(-1, sched_access=['--constraint=f1'])
    with pytest.raises(JobError):
        prepare_job(job)


",True
1516,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_nodes_positive,"def test_flex_alloc_nodes_positive(make_flexible_job):
    job = make_flexible_job(12, sched_access=['--constraint=f1'])
    prepare_job(job)
    assert job.num_tasks == 48


",True
1517,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_nodes_zero,"def test_flex_alloc_nodes_zero(make_flexible_job):
    job = make_flexible_job(0, sched_access=['--constraint=f1'])
    with pytest.raises(JobError):
        prepare_job(job)


",False
1518,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_not_enough_idle_nodes,"def test_flex_alloc_not_enough_idle_nodes(make_flexible_job):
    job = make_flexible_job('idle')
    job.num_tasks = -12
    with pytest.raises(JobError):
        prepare_job(job)


",True
1519,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_not_enough_nodes_constraint_partition,"def test_flex_alloc_not_enough_nodes_constraint_partition(make_flexible_job):
    job = make_flexible_job('all')
    job.options = ['-C f1&f2', '--partition=p1,p2']
    job.num_tasks = -8
    with pytest.raises(JobError):
        prepare_job(job)


",True
1520,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_partition_idle,"def test_flex_alloc_partition_idle(make_flexible_job):
    job = make_flexible_job('idle', sched_partition='p2')
    with pytest.raises(JobError):
        prepare_job(job)


",True
1521,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_sched_access_constraint_partition,"def test_flex_alloc_sched_access_constraint_partition(make_flexible_job):
    job = make_flexible_job(
        'all', sched_access=['--constraint=f1', '--partition=p2']
    )
    prepare_job(job)
    assert job.num_tasks == 4


",False
1522,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_sched_access_idle,"def test_flex_alloc_sched_access_idle(make_flexible_job):
    job = make_flexible_job('idle', sched_access=['--constraint=f1'])
    prepare_job(job)
    assert job.num_tasks == 8


",True
1523,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_sched_access_idle_sequence_view,"def test_flex_alloc_sched_access_idle_sequence_view(make_flexible_job):
    # Here we simulate passing a readonly 'sched_access' as returned
    # by a 'SystemPartition' instance.

    from reframe.utility import SequenceView

    job = make_flexible_job('idle',
                            sched_access=SequenceView(['--constraint=f3']),
                            sched_partition='p3')
    prepare_job(job)
    assert job.num_tasks == 4


",True
1524,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_sched_access_partition,"def test_flex_alloc_sched_access_partition(make_flexible_job):
    job = make_flexible_job('all', sched_access=['--partition=p1'])
    prepare_job(job)
    assert job.num_tasks == 16


",True
1525,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_valid_constraint_opt,"def test_flex_alloc_valid_constraint_opt(make_flexible_job):
    job = make_flexible_job('all')
    job.options = ['-C f1']
    prepare_job(job)
    assert job.num_tasks == 12


",True
1526,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_valid_constraint_partition,"def test_flex_alloc_valid_constraint_partition(make_flexible_job):
    job = make_flexible_job('all')
    job.options = ['-C f1&f2', '--partition=p1,p2']
    prepare_job(job)
    assert job.num_tasks == 4


",True
1527,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_valid_multiple_constraints,"def test_flex_alloc_valid_multiple_constraints(make_flexible_job):
    job = make_flexible_job('all')
    job.options = ['-C f1&f3']
    prepare_job(job)
    assert job.num_tasks == 4


",True
1528,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_valid_multiple_partitions,"def test_flex_alloc_valid_multiple_partitions(make_flexible_job):
    job = make_flexible_job('all')
    job.options = ['--partition=p1,p2']
    prepare_job(job)
    assert job.num_tasks == 4


",True
1529,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_valid_partition_cmd,"def test_flex_alloc_valid_partition_cmd(make_flexible_job):
    job = make_flexible_job('all', sched_partition='p2')
    prepare_job(job)
    assert job.num_tasks == 8


",True
1530,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_valid_partition_opt,"def test_flex_alloc_valid_partition_opt(make_flexible_job):
    job = make_flexible_job('all')
    job.options = ['-p p2']
    prepare_job(job)
    assert job.num_tasks == 8


",True
1531,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_valid_reservation_cmd,"def test_flex_alloc_valid_reservation_cmd(make_flexible_job):
    job = make_flexible_job('all',
                            sched_access=['--constraint=f2'],
                            sched_reservation='dummy')

    prepare_job(job)
    assert job.num_tasks == 4


",True
1532,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_flex_alloc_valid_reservation_option,"def test_flex_alloc_valid_reservation_option(make_flexible_job):
    job = make_flexible_job('all', sched_access=['--constraint=f2'])
    job.options = ['--reservation=dummy']
    prepare_job(job)
    assert job.num_tasks == 4


",True
1533,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_guess_num_tasks,"def test_guess_num_tasks(minimal_job, scheduler):
    minimal_job.num_tasks = 0
    if scheduler.registered_name == 'local':
        # We want to trigger bug #1087 (Github), that's why we set allocation
        # policy to idle.
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'idle'
        prepare_job(minimal_job)
        minimal_job.submit()
        minimal_job.wait()
        assert minimal_job.num_tasks == 1
    elif scheduler.registered_name in ('slurm', 'squeue'):
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'all'

        # Monkey patch `allnodes()` to simulate extraction of
        # slurm nodes through the use of `scontrol show`
        minimal_job.scheduler.allnodes = lambda: set()

        # monkey patch `_get_default_partition()` to simulate extraction
        # of the default partition through the use of `scontrol show`
        minimal_job.scheduler._get_default_partition = lambda: 'pdef'
        assert minimal_job.guess_num_tasks() == 0
    else:
        with pytest.raises(NotImplementedError):
            minimal_job.guess_num_tasks()


",False
1534,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_guess_num_tasks,"def test_guess_num_tasks(minimal_job, scheduler):
    minimal_job.num_tasks = 0
    if scheduler.registered_name == 'local':
        # We want to trigger bug #1087 (Github), that's why we set allocation
        # policy to idle.
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'idle'
        prepare_job(minimal_job)
        minimal_job.submit()
        minimal_job.wait()
        assert minimal_job.num_tasks == 1
    elif scheduler.registered_name in ('slurm', 'squeue'):
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'all'

        # Monkey patch `allnodes()` to simulate extraction of
        # slurm nodes through the use of `scontrol show`
        minimal_job.scheduler.allnodes = lambda: set()

        # monkey patch `_get_default_partition()` to simulate extraction
        # of the default partition through the use of `scontrol show`
        minimal_job.scheduler._get_default_partition = lambda: 'pdef'
        assert minimal_job.guess_num_tasks() == 0
    else:
        with pytest.raises(NotImplementedError):
            minimal_job.guess_num_tasks()


",False
1535,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_guess_num_tasks,"def test_guess_num_tasks(minimal_job, scheduler):
    minimal_job.num_tasks = 0
    if scheduler.registered_name == 'local':
        # We want to trigger bug #1087 (Github), that's why we set allocation
        # policy to idle.
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'idle'
        prepare_job(minimal_job)
        minimal_job.submit()
        minimal_job.wait()
        assert minimal_job.num_tasks == 1
    elif scheduler.registered_name in ('slurm', 'squeue'):
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'all'

        # Monkey patch `allnodes()` to simulate extraction of
        # slurm nodes through the use of `scontrol show`
        minimal_job.scheduler.allnodes = lambda: set()

        # monkey patch `_get_default_partition()` to simulate extraction
        # of the default partition through the use of `scontrol show`
        minimal_job.scheduler._get_default_partition = lambda: 'pdef'
        assert minimal_job.guess_num_tasks() == 0
    else:
        with pytest.raises(NotImplementedError):
            minimal_job.guess_num_tasks()


",True
1536,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_guess_num_tasks,"def test_guess_num_tasks(minimal_job, scheduler):
    minimal_job.num_tasks = 0
    if scheduler.registered_name == 'local':
        # We want to trigger bug #1087 (Github), that's why we set allocation
        # policy to idle.
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'idle'
        prepare_job(minimal_job)
        minimal_job.submit()
        minimal_job.wait()
        assert minimal_job.num_tasks == 1
    elif scheduler.registered_name in ('slurm', 'squeue'):
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'all'

        # Monkey patch `allnodes()` to simulate extraction of
        # slurm nodes through the use of `scontrol show`
        minimal_job.scheduler.allnodes = lambda: set()

        # monkey patch `_get_default_partition()` to simulate extraction
        # of the default partition through the use of `scontrol show`
        minimal_job.scheduler._get_default_partition = lambda: 'pdef'
        assert minimal_job.guess_num_tasks() == 0
    else:
        with pytest.raises(NotImplementedError):
            minimal_job.guess_num_tasks()


",True
1537,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_guess_num_tasks,"def test_guess_num_tasks(minimal_job, scheduler):
    minimal_job.num_tasks = 0
    if scheduler.registered_name == 'local':
        # We want to trigger bug #1087 (Github), that's why we set allocation
        # policy to idle.
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'idle'
        prepare_job(minimal_job)
        minimal_job.submit()
        minimal_job.wait()
        assert minimal_job.num_tasks == 1
    elif scheduler.registered_name in ('slurm', 'squeue'):
        minimal_job.num_tasks = 0
        minimal_job._sched_flex_alloc_nodes = 'all'

        # Monkey patch `allnodes()` to simulate extraction of
        # slurm nodes through the use of `scontrol show`
        minimal_job.scheduler.allnodes = lambda: set()

        # monkey patch `_get_default_partition()` to simulate extraction
        # of the default partition through the use of `scontrol show`
        minimal_job.scheduler._get_default_partition = lambda: 'pdef'
        assert minimal_job.guess_num_tasks() == 0
    else:
        with pytest.raises(NotImplementedError):
            minimal_job.guess_num_tasks()


",True
1538,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_no_empty_lines_in_preamble,"def test_no_empty_lines_in_preamble(minimal_job):
    for line in minimal_job.scheduler.emit_preamble(minimal_job):
        assert line != ''


",True
1539,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_no_empty_lines_in_preamble,"def test_no_empty_lines_in_preamble(minimal_job):
    for line in minimal_job.scheduler.emit_preamble(minimal_job):
        assert line != ''


",True
1540,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_no_empty_lines_in_preamble,"def test_no_empty_lines_in_preamble(minimal_job):
    for line in minimal_job.scheduler.emit_preamble(minimal_job):
        assert line != ''


",True
1541,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_no_empty_lines_in_preamble,"def test_no_empty_lines_in_preamble(minimal_job):
    for line in minimal_job.scheduler.emit_preamble(minimal_job):
        assert line != ''


",True
1542,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_poll,"def test_poll(make_job, exec_ctx):
    minimal_job = make_job(sched_access=exec_ctx.access)
    prepare_job(minimal_job, 'sleep 2')
    minimal_job.submit()
    assert not minimal_job.finished()
    minimal_job.wait()


",False
1543,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_poll_before_submit,"def test_poll_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.finished()


",True
1544,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_poll_before_submit,"def test_poll_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.finished()


",True
1545,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_poll_before_submit,"def test_poll_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.finished()


",True
1546,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_poll_before_submit,"def test_poll_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.finished()


",True
1547,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_poll_before_submit,"def test_poll_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.finished()


",True
1548,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare,"def test_prepare(fake_job):
    sched_name = fake_job.scheduler.registered_name
    if sched_name == 'pbs':
        fake_job.options += ['mem=100GB', 'cpu_type=haswell']
    elif sched_name == 'torque':
        fake_job.options += ['-l mem=100GB', 'haswell']

    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        found_directives = set(re.findall(r'^\#\w+ .*', fp.read(),
                                          re.MULTILINE))

    expected_directives = globals()[f'_expected_{sched_name}_directives']
    assert_job_script_sanity(fake_job)
    assert expected_directives(fake_job) == found_directives


",True
1549,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare,"def test_prepare(fake_job):
    sched_name = fake_job.scheduler.registered_name
    if sched_name == 'pbs':
        fake_job.options += ['mem=100GB', 'cpu_type=haswell']
    elif sched_name == 'torque':
        fake_job.options += ['-l mem=100GB', 'haswell']

    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        found_directives = set(re.findall(r'^\#\w+ .*', fp.read(),
                                          re.MULTILINE))

    expected_directives = globals()[f'_expected_{sched_name}_directives']
    assert_job_script_sanity(fake_job)
    assert expected_directives(fake_job) == found_directives


",True
1550,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare,"def test_prepare(fake_job):
    sched_name = fake_job.scheduler.registered_name
    if sched_name == 'pbs':
        fake_job.options += ['mem=100GB', 'cpu_type=haswell']
    elif sched_name == 'torque':
        fake_job.options += ['-l mem=100GB', 'haswell']

    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        found_directives = set(re.findall(r'^\#\w+ .*', fp.read(),
                                          re.MULTILINE))

    expected_directives = globals()[f'_expected_{sched_name}_directives']
    assert_job_script_sanity(fake_job)
    assert expected_directives(fake_job) == found_directives


",True
1551,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare,"def test_prepare(fake_job):
    sched_name = fake_job.scheduler.registered_name
    if sched_name == 'pbs':
        fake_job.options += ['mem=100GB', 'cpu_type=haswell']
    elif sched_name == 'torque':
        fake_job.options += ['-l mem=100GB', 'haswell']

    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        found_directives = set(re.findall(r'^\#\w+ .*', fp.read(),
                                          re.MULTILINE))

    expected_directives = globals()[f'_expected_{sched_name}_directives']
    assert_job_script_sanity(fake_job)
    assert expected_directives(fake_job) == found_directives


",True
1552,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare,"def test_prepare(fake_job):
    sched_name = fake_job.scheduler.registered_name
    if sched_name == 'pbs':
        fake_job.options += ['mem=100GB', 'cpu_type=haswell']
    elif sched_name == 'torque':
        fake_job.options += ['-l mem=100GB', 'haswell']

    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        found_directives = set(re.findall(r'^\#\w+ .*', fp.read(),
                                          re.MULTILINE))

    expected_directives = globals()[f'_expected_{sched_name}_directives']
    assert_job_script_sanity(fake_job)
    assert expected_directives(fake_job) == found_directives


",True
1553,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare_no_exclusive,"def test_prepare_no_exclusive(make_job, slurm_only):
    job = make_job(sched_exclusive_access=False)
    prepare_job(job)
    with open(job.script_filename) as fp:
        assert re.search(r'--exclusive', fp.read()) is None


",True
1554,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare_no_exclusive,"def test_prepare_no_exclusive(make_job, slurm_only):
    job = make_job(sched_exclusive_access=False)
    prepare_job(job)
    with open(job.script_filename) as fp:
        assert re.search(r'--exclusive', fp.read()) is None


",True
1555,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare_no_smt,"def test_prepare_no_smt(fake_job, slurm_only):
    fake_job.use_smt = None
    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        assert re.search(r'--hint', fp.read()) is None


",False
1556,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare_no_smt,"def test_prepare_no_smt(fake_job, slurm_only):
    fake_job.use_smt = None
    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        assert re.search(r'--hint', fp.read()) is None


",True
1557,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare_with_smt,"def test_prepare_with_smt(fake_job, slurm_only):
    fake_job.use_smt = True
    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        assert re.search(r'--hint=multithread', fp.read()) is not None


",True
1558,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare_with_smt,"def test_prepare_with_smt(fake_job, slurm_only):
    fake_job.use_smt = True
    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        assert re.search(r'--hint=multithread', fp.read()) is not None


",True
1559,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare_without_smt,"def test_prepare_without_smt(fake_job, slurm_only):
    fake_job.use_smt = False
    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        assert re.search(r'--hint=nomultithread', fp.read()) is not None


",False
1560,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_prepare_without_smt,"def test_prepare_without_smt(fake_job, slurm_only):
    fake_job.use_smt = False
    prepare_job(fake_job)
    with open(fake_job.script_filename) as fp:
        assert re.search(r'--hint=nomultithread', fp.read()) is not None


",True
1561,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_submit,"def test_submit(make_job, exec_ctx):
    minimal_job = make_job(sched_access=exec_ctx.access)
    prepare_job(minimal_job)
    assert minimal_job.nodelist is None
    minimal_job.submit()
    assert minimal_job.jobid is not None
    minimal_job.wait()

    # Additional scheduler-specific checks
    sched_name = minimal_job.scheduler.registered_name
    if sched_name == 'local':
        assert [socket.gethostname()] == minimal_job.nodelist
        assert 0 == minimal_job.exitcode
    elif sched_name == ('slurm', 'squeue', 'pbs', 'torque'):
        num_tasks_per_node = minimal_job.num_tasks_per_node or 1
        num_nodes = minimal_job.num_tasks // num_tasks_per_node
        assert num_nodes == len(minimal_job.nodelist)
        assert 0 == minimal_job.exitcode


",True
1562,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_submit_timelimit,"def test_submit_timelimit(minimal_job, local_only):
    minimal_job.time_limit = '2s'
    prepare_job(minimal_job, 'sleep 10')
    t_job = datetime.now()
    minimal_job.submit()
    assert minimal_job.jobid is not None
    minimal_job.wait()
    t_job = datetime.now() - t_job
    assert t_job.total_seconds() >= 2
    assert t_job.total_seconds() < 3
    with open(minimal_job.stdout) as fp:
        assert re.search('postrun', fp.read()) is None

    assert minimal_job.state == 'TIMEOUT'


",True
1563,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_wait_before_submit,"def test_wait_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.wait()


",True
1564,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_wait_before_submit,"def test_wait_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.wait()


",True
1565,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_wait_before_submit,"def test_wait_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.wait()


",True
1566,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_wait_before_submit,"def test_wait_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.wait()


",True
1567,https://github.com/eth-cscs/reframe/blob/576eb3f1dcc015d1e6d7a10602c748d4f810da68/unittests/test_schedulers.py,,test_wait_before_submit,"def test_wait_before_submit(minimal_job):
    prepare_job(minimal_job, 'sleep 3')
    with pytest.raises(JobNotStartedError):
        minimal_job.wait()


",True
1568,https://github.com/juntossomosmais/regex4ocr/blob/9f96e9c6fe6ffc3e1452b23103fdfa6a0f1dcede/tests/integration/test_type_casting.py,,test_validate_types_removal,"def test_validate_types_removal(
    extracted_data_dict_1,
    expected_extracted_data_dict_with_removal,
    drm_model_tax_coupon_with_inline_groups,
):
    """"""
    Unit: tests validate_types when there are type conflicts and
          some fields are removed.
    """"""
    # creates a deep copy of the fixture so mutations wont affect next tests
    extracted_data_dict = copy.deepcopy(extracted_data_dict_1)

    extracted_data_dict[""fields""][""some_int""] = ""abc123""  # messes int casting

    # function invocation
    validate_types(extracted_data_dict, drm_model_tax_coupon_with_inline_groups)

    assert extracted_data_dict == expected_extracted_data_dict_with_removal
",True
1569,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_cached,"def test_cached(region):
    called = [0]

    @region.cached
    ",False
1570,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_cached,"def test_cached(region):
    called = [0]

    @region.cached
    ",False
1571,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_cached,"def test_cached(region):
    called = [0]

    @region.cached
    ",False
1572,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_children,"def test_children(region):
    sb = region.region('sub')
    assert sb in list(region.children())


",False
1573,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_children,"def test_children(region):
    sb = region.region('sub')
    assert sb in list(region.children())


",False
1574,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_get_or_compute,"def test_get_or_compute(region):
    x = region.get_or_compute('computed_key', 0)
    assert 'computed_key' in region
    assert region['computed_key'] == 0
    assert x == 0

    y = region.get_or_compute('computed_key2', lambda: 200)
    assert y == 200
    assert 'computed_key2' in region
    assert region['computed_key2'] == 200


",False
1575,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_get_or_compute,"def test_get_or_compute(region):
    x = region.get_or_compute('computed_key', 0)
    assert 'computed_key' in region
    assert region['computed_key'] == 0
    assert x == 0

    y = region.get_or_compute('computed_key2', lambda: 200)
    assert y == 200
    assert 'computed_key2' in region
    assert region['computed_key2'] == 200


",False
1576,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_get_or_compute,"def test_get_or_compute(region):
    x = region.get_or_compute('computed_key', 0)
    assert 'computed_key' in region
    assert region['computed_key'] == 0
    assert x == 0

    y = region.get_or_compute('computed_key2', lambda: 200)
    assert y == 200
    assert 'computed_key2' in region
    assert region['computed_key2'] == 200


",False
1577,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_get_or_compute,"def test_get_or_compute(region):
    x = region.get_or_compute('computed_key', 0)
    assert 'computed_key' in region
    assert region['computed_key'] == 0
    assert x == 0

    y = region.get_or_compute('computed_key2', lambda: 200)
    assert y == 200
    assert 'computed_key2' in region
    assert region['computed_key2'] == 200


",False
1578,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_init_app,"def test_init_app(app):
    c = RegionCache()
    c.init_app(app)
    assert c.conn
    assert c.conn.ping()
    assert c._root
    assert c._root_name in c._regions
    assert c._regions[c._root_name] is c._root
    assert len(c._regions) == 1


",False
1579,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_init_app,"def test_init_app(app):
    c = RegionCache()
    c.init_app(app)
    assert c.conn
    assert c.conn.ping()
    assert c._root
    assert c._root_name in c._regions
    assert c._regions[c._root_name] is c._root
    assert len(c._regions) == 1


",False
1580,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate,"def test_invalidate(region):
    region['key'] = 'value'
    region.invalidate()
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None

    sb = region.region('sub')
    sb['key2'] = 'value'
    region.invalidate()

    assert region._region_cache.conn.hget(sb.name, 'key2') is None
    assert 'key2' not in sb


",False
1581,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate,"def test_invalidate(region):
    region['key'] = 'value'
    region.invalidate()
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None

    sb = region.region('sub')
    sb['key2'] = 'value'
    region.invalidate()

    assert region._region_cache.conn.hget(sb.name, 'key2') is None
    assert 'key2' not in sb


",False
1582,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate,"def test_invalidate(region):
    region['key'] = 'value'
    region.invalidate()
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None

    sb = region.region('sub')
    sb['key2'] = 'value'
    region.invalidate()

    assert region._region_cache.conn.hget(sb.name, 'key2') is None
    assert 'key2' not in sb


",False
1583,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate,"def test_invalidate(region):
    region['key'] = 'value'
    region.invalidate()
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None

    sb = region.region('sub')
    sb['key2'] = 'value'
    region.invalidate()

    assert region._region_cache.conn.hget(sb.name, 'key2') is None
    assert 'key2' not in sb


",False
1584,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate_connections,"def test_invalidate_connections(region_cache):
    region_cache.invalidate_connections()
    assert region_cache._w_conn is None
    assert region_cache._r_conn is None


",False
1585,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate_connections,"def test_invalidate_connections(region_cache):
    region_cache.invalidate_connections()
    assert region_cache._w_conn is None
    assert region_cache._r_conn is None


",False
1586,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate_on,"def test_invalidate_on(region):
    import blinker
    s = blinker.signal('named_signal')
    t = blinker.signal('other_signal')

    region['key'] = 'value'
    region.invalidate_on(s, t)

    s.send('nothing',in_='particular')
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None

    region['key'] = 'value'

    t.send('nothing', in_='particular')
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None


",False
1587,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate_on,"def test_invalidate_on(region):
    import blinker
    s = blinker.signal('named_signal')
    t = blinker.signal('other_signal')

    region['key'] = 'value'
    region.invalidate_on(s, t)

    s.send('nothing',in_='particular')
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None

    region['key'] = 'value'

    t.send('nothing', in_='particular')
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None


",False
1588,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate_on,"def test_invalidate_on(region):
    import blinker
    s = blinker.signal('named_signal')
    t = blinker.signal('other_signal')

    region['key'] = 'value'
    region.invalidate_on(s, t)

    s.send('nothing',in_='particular')
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None

    region['key'] = 'value'

    t.send('nothing', in_='particular')
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None


",False
1589,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_invalidate_region,"def test_invalidate_region(region_cache, region):
    region['key'] = 'value'
    region_cache.region('root').invalidate()
    assert 'key' not in region
    assert region._region_cache.conn.hget(region.name, 'key') is None

    sb = region.region('sub')
    sb['key2'] = 'value'
    region.invalidate()

    assert region._region_cache.conn.hget(sb.name, 'key2') is None
    assert 'key2' not in sb


",False
1590,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_items,"def test_items(region):
    region['foo'] = 'bar'
    assert region['foo'] == 'bar'
    assert region._region_cache.conn.hget(region.name, 'foo') is not None
    del region['foo']
    assert pytest.raises(KeyError, lambda: region['foo'])


",False
1591,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_items,"def test_items(region):
    region['foo'] = 'bar'
    assert region['foo'] == 'bar'
    assert region._region_cache.conn.hget(region.name, 'foo') is not None
    del region['foo']
    assert pytest.raises(KeyError, lambda: region['foo'])


",False
1592,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_iter,"def test_iter(region, region_cache):
    region['foo'] = 'bar'
    assert [x for x in region]
    region.invalidate()


",False
1593,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_iter,"def test_iter(region, region_cache):
    region['foo'] = 'bar'
    assert [x for x in region]
    region.invalidate()


",False
1594,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_iter,"def test_iter(region, region_cache):
    region['foo'] = 'bar'
    assert [x for x in region]
    region.invalidate()


",False
1595,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_reconnect_backoff,"def test_reconnect_backoff(region, region_cache):
    region['key1'] = 0
    region['key2'] = 1
    region_cache._reconnect_backoff = 5  # 5 second backoff before trying to reconnect
    region_cache.invalidate_connections()
    assert region_cache.is_disconnected()
    with pytest.raises(KeyError):
        region['key1']
    assert region_cache._w_conn is None
    assert region_cache._r_conn is None


",False
1596,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_reconnect_backoff,"def test_reconnect_backoff(region, region_cache):
    region['key1'] = 0
    region['key2'] = 1
    region_cache._reconnect_backoff = 5  # 5 second backoff before trying to reconnect
    region_cache.invalidate_connections()
    assert region_cache.is_disconnected()
    with pytest.raises(KeyError):
        region['key1']
    assert region_cache._w_conn is None
    assert region_cache._r_conn is None


",False
1597,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_reconnect_backoff,"def test_reconnect_backoff(region, region_cache):
    region['key1'] = 0
    region['key2'] = 1
    region_cache._reconnect_backoff = 5  # 5 second backoff before trying to reconnect
    region_cache.invalidate_connections()
    assert region_cache.is_disconnected()
    with pytest.raises(KeyError):
        region['key1']
    assert region_cache._w_conn is None
    assert region_cache._r_conn is None


",False
1598,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_region_context_manager,"def test_region_context_manager(region):
    with region as r:
        r['key1'] = 0
        r['key2'] = 1

    assert 'key1' in region
    assert 'key2' in region
    assert region._region_cache.conn.hget(region.name, 'key1') is not None
    assert region._region_cache.conn.hget(region.name, 'key2') is not None


",False
1599,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_region_context_manager,"def test_region_context_manager(region):
    with region as r:
        r['key1'] = 0
        r['key2'] = 1

    assert 'key1' in region
    assert 'key2' in region
    assert region._region_cache.conn.hget(region.name, 'key1') is not None
    assert region._region_cache.conn.hget(region.name, 'key2') is not None


",False
1600,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_subregions,"def test_subregions(region_cache):
    r = region_cache.region('abc.xyz')
    assert '{region_cache._root_name}.abc'.format(region_cache=region_cache) in region_cache._regions
    assert '{region_cache._root_name}.abc.xyz'.format(region_cache=region_cache)  in region_cache._regions
    assert 'abc.xyz' not in region_cache._regions
    assert 'xyz' not in region_cache._regions

    r1 = region_cache.region('xml', timeout=60)
    assert r1._timeout == 60
    r2 = r1.region('json')
    assert r2._timeout == 60


",False
1601,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_subregions,"def test_subregions(region_cache):
    r = region_cache.region('abc.xyz')
    assert '{region_cache._root_name}.abc'.format(region_cache=region_cache) in region_cache._regions
    assert '{region_cache._root_name}.abc.xyz'.format(region_cache=region_cache)  in region_cache._regions
    assert 'abc.xyz' not in region_cache._regions
    assert 'xyz' not in region_cache._regions

    r1 = region_cache.region('xml', timeout=60)
    assert r1._timeout == 60
    r2 = r1.region('json')
    assert r2._timeout == 60


",False
1602,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_subregions,"def test_subregions(region_cache):
    r = region_cache.region('abc.xyz')
    assert '{region_cache._root_name}.abc'.format(region_cache=region_cache) in region_cache._regions
    assert '{region_cache._root_name}.abc.xyz'.format(region_cache=region_cache)  in region_cache._regions
    assert 'abc.xyz' not in region_cache._regions
    assert 'xyz' not in region_cache._regions

    r1 = region_cache.region('xml', timeout=60)
    assert r1._timeout == 60
    r2 = r1.region('json')
    assert r2._timeout == 60


",False
1603,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_subregions,"def test_subregions(region_cache):
    r = region_cache.region('abc.xyz')
    assert '{region_cache._root_name}.abc'.format(region_cache=region_cache) in region_cache._regions
    assert '{region_cache._root_name}.abc.xyz'.format(region_cache=region_cache)  in region_cache._regions
    assert 'abc.xyz' not in region_cache._regions
    assert 'xyz' not in region_cache._regions

    r1 = region_cache.region('xml', timeout=60)
    assert r1._timeout == 60
    r2 = r1.region('json')
    assert r2._timeout == 60


",False
1604,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_timeout_with_context,"def test_timeout_with_context(region_with_timeout):
    with region_with_timeout as r:
        r['key1'] = 0
        r['key2'] = 1

    assert region_with_timeout._region_cache.conn.hget(region_with_timeout.name, 'key1') is not None
    assert region_with_timeout._region_cache.conn.hget(region_with_timeout.name, 'key2') is not None

    assert region_with_timeout._region_cache.conn.ttl(region_with_timeout.name) > 0

    assert 'key1' in region_with_timeout
    assert 'key2' in region_with_timeout

    import time
    time.sleep(1)

    assert region_with_timeout._region_cache.conn.ttl(region_with_timeout.name) > 0

    assert region_with_timeout._region_cache.conn.hget(region_with_timeout.name, 'key1') is not None
    assert region_with_timeout._region_cache.conn.hget(region_with_timeout.name, 'key2') is not None

    assert 'key1' in region_with_timeout
    assert 'key2' in region_with_timeout

    time.sleep(1.5)

    assert region_with_timeout._region_cache.conn.ttl(region_with_timeout.name) == -2

    assert 'key1' not in region_with_timeout
    assert 'key2' not in region_with_timeout



",False
1605,https://github.com/Teamworksapp/region_cache/blob/8b2ae3ce4bb348c23a84d5fec546609e80579b94/tests/test_region_cache.py,,test_timeout_with_context,"def test_timeout_with_context(region_with_timeout):
    with region_with_timeout as r:
        r['key1'] = 0
        r['key2'] = 1

    assert region_with_timeout._region_cache.conn.hget(region_with_timeout.name, 'key1') is not None
    assert region_with_timeout._region_cache.conn.hget(region_with_timeout.name, 'key2') is not None

    assert region_with_timeout._region_cache.conn.ttl(region_with_timeout.name) > 0

    assert 'key1' in region_with_timeout
    assert 'key2' in region_with_timeout

    import time
    time.sleep(1)

    assert region_with_timeout._region_cache.conn.ttl(region_with_timeout.name) > 0

    assert region_with_timeout._region_cache.conn.hget(region_with_timeout.name, 'key1') is not None
    assert region_with_timeout._region_cache.conn.hget(region_with_timeout.name, 'key2') is not None

    assert 'key1' in region_with_timeout
    assert 'key2' in region_with_timeout

    time.sleep(1.5)

    assert region_with_timeout._region_cache.conn.ttl(region_with_timeout.name) == -2

    assert 'key1' not in region_with_timeout
    assert 'key2' not in region_with_timeout



",False
1606,https://github.com/spacetelescope/relic/blob/d5fc7bf6dbe01eb89de3ff5c2f6cfec2b4a6047d/tests/test_relic.py,TestRelease,test_read_relic_info,"def test_read_relic_info(self):
        runner('git tag -a 1.0.0 -m ""test message""')
        # Generate RELIC-INFO
        relic.release.get_info()
        shutil.rmtree('.git', onerror=onerror)
        # Read it back without git
        v = relic.release.get_info()
        assert v.short == '1.0.0'

    ",False
1607,https://github.com/spacetelescope/relic/blob/d5fc7bf6dbe01eb89de3ff5c2f6cfec2b4a6047d/tests/test_relic.py,TestRelease,test_version_long_is_long,"def test_version_long_is_long(self):
        runner('git tag -a 1.0.0 -m ""test message""')
        touch('testfile3')
        runner('git add testfile3')
        runner('git commit -m ""add testfile""')
        v = relic.release.get_info()
        assert isinstance(v.long, str)
        assert '.' in v.long
        assert '-' in v.long

    ",False
1608,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_findlinks.py,,test_find_links,"def test_find_links(tmpdir):
    """"""Verify that a wheel for req-compile can be discovered properly""""""
    wheeldir = str(tmpdir.mkdir(""wheeldir""))

    source_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), "".."", ""..""))
    subprocess.check_call(
        [sys.executable, ""setup.py"", ""bdist_wheel"", ""--dist-dir"", wheeldir],
        cwd=source_dir,
    )

    repo = FindLinksRepository(wheeldir)
    candidates = list(repo.get_candidates(None))
    assert len(candidates) == 1
    assert candidates[0].name == ""req_compile""
",False
1609,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_no_candidates,"def test_no_candidates(mocked_responses, tmpdir):
    wheeldir = str(tmpdir)
    mocked_responses.add(responses.GET, INDEX_URL + ""/garbage/"", status=404)
    repo = PyPIRepository(INDEX_URL, wheeldir)

    candidates = repo.get_candidates(pkg_resources.Requirement.parse(""garbage""))

    assert candidates == []
    assert len(mocked_responses.calls) == 1


",True
1610,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_pypi_500,"def test_pypi_500(mocked_responses, tmpdir):
    wheeldir = str(tmpdir)
    mocked_responses.add(responses.GET, INDEX_URL + ""/numpy/"", status=500)
    repo = PyPIRepository(INDEX_URL, wheeldir)

    with pytest.raises(requests.HTTPError):
        repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))


",True
1611,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_python_requires_wheel_tags,"def test_python_requires_wheel_tags(
    mocked_responses, tmpdir, mock_py_version, read_contents, url_to_check
):
    mock_py_version(""3.7.12"")

    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )

    repo = PyPIRepository(INDEX_URL, wheeldir)
    candidate = [
        candidate
        for candidate in repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))
        if candidate.link[1] == url_to_check
    ][0]
    if candidate.py_version:
        assert candidate.py_version.check_compatibility()


@pytest.mark.parametrize(
    ""sys_py_version, py_requires"",
    [
        (""2.7.15"", "">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*""),
        (""3.6.4"", "">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*""),
        (""3.5.0"", ""==3.5""),
        (""3.2.17"", "">=2.7, ==3.*""),
        (""3.5.4"", ""~=3.5""),
        (""3.7.4"", ""~=3""),
        (""2.7.12"", ""2.7""),
    ],
)
",True
1612,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_python_requires_wheel_tags,"def test_python_requires_wheel_tags(
    mocked_responses, tmpdir, mock_py_version, read_contents, url_to_check
):
    mock_py_version(""3.7.12"")

    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )

    repo = PyPIRepository(INDEX_URL, wheeldir)
    candidate = [
        candidate
        for candidate in repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))
        if candidate.link[1] == url_to_check
    ][0]
    if candidate.py_version:
        assert candidate.py_version.check_compatibility()


@pytest.mark.parametrize(
    ""sys_py_version, py_requires"",
    [
        (""2.7.15"", "">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*""),
        (""3.6.4"", "">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*""),
        (""3.5.0"", ""==3.5""),
        (""3.2.17"", "">=2.7, ==3.*""),
        (""3.5.4"", ""~=3.5""),
        (""3.7.4"", ""~=3""),
        (""2.7.12"", ""2.7""),
    ],
)
",True
1613,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_python_requires_wheel_tags,"def test_python_requires_wheel_tags(
    mocked_responses, tmpdir, mock_py_version, read_contents, url_to_check
):
    mock_py_version(""3.7.12"")

    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )

    repo = PyPIRepository(INDEX_URL, wheeldir)
    candidate = [
        candidate
        for candidate in repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))
        if candidate.link[1] == url_to_check
    ][0]
    if candidate.py_version:
        assert candidate.py_version.check_compatibility()


@pytest.mark.parametrize(
    ""sys_py_version, py_requires"",
    [
        (""2.7.15"", "">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*""),
        (""3.6.4"", "">=2.7,!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*""),
        (""3.5.0"", ""==3.5""),
        (""3.2.17"", "">=2.7, ==3.*""),
        (""3.5.4"", ""~=3.5""),
        (""3.7.4"", ""~=3""),
        (""2.7.12"", ""2.7""),
    ],
)
",True
1614,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_resolve_new_numpy,"def test_resolve_new_numpy(mocked_responses, tmpdir, read_contents, mocker):
    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )

    repo = PyPIRepository(INDEX_URL, wheeldir)
    candidates = repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))
    for candidate in candidates:
        if ""1.16.3"" in candidate.link[1]:
            mocked_responses.add(
                responses.GET,
                candidate.link[1],
                body=read_contents(""numpy.whl-contents""),
                status=200,
            )

    mock_extract = mocker.MagicMock()
    mock_extract.return_value.name = ""numpy""

    mocker.patch(""req_compile.repos.pypi.extract_metadata"", mock_extract)
    candidate, cached = repo.get_candidate(pkg_resources.Requirement.parse(""numpy""))
    assert candidate is not None
    assert not cached

    listing = tmpdir.listdir()
    assert len(listing) == 1
    assert ""1.16.3"" in str(listing[0])
    assert "".whl"" in str(listing[0])

    # Query the index, and download
    assert len(mocked_responses.calls) == 2


@pytest.mark.parametrize(
    ""url_to_check"",
    [
        ""https://pypi.org/numpy-1.16.3-cp37-cp37m-win_amd64.whl#sha256=HASH"",
        ""https://pypi.org/numpy-1.16.3-cp37-cp37m-manylinux1_x86_64.whl#sha256=HASH"",
        ""https://pypi.org/numpy-1.16.3.zip#sha256=HASH"",
    ],
)
",False
1615,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/repos/test_pypi.py,,test_successful_numpy,"def test_successful_numpy(mocked_responses, tmpdir, read_contents):
    wheeldir = str(tmpdir)
    mocked_responses.add(
        responses.GET,
        INDEX_URL + ""/numpy/"",
        body=read_contents(""numpy.html""),
        status=200,
    )
    repo = PyPIRepository(INDEX_URL, wheeldir)

    candidates = repo.get_candidates(pkg_resources.Requirement.parse(""numpy""))

    # The total is the total number of links - exe links, which we do not support
    assert len(candidates) == 1127 - 34
    assert len(mocked_responses.calls) == 1


",True
1616,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/test_extractor.py,,test_extractor,"def test_extractor(archive_fixture, tmpdir, mock_targz, mock_zip):
    directory = ""comtypes-1.1.7""
    if archive_fixture == ""mock_targz"":
        archive = mock_targz(directory)
    elif archive_fixture == ""mock_zip"":
        archive = mock_zip(directory)
    else:
        archive = os.path.abspath(os.path.join(""source-packages"", directory))

    if archive_fixture == ""mock_targz"":
        extractor = req_compile.metadata.extractor.TarExtractor(""gz"", archive)
        prefix = directory + ""/""
    elif archive_fixture == ""mock_zip"":
        extractor = req_compile.metadata.extractor.ZipExtractor(archive)
        prefix = directory + ""/""
    else:
        extractor = req_compile.metadata.extractor.NonExtractor(archive)
        prefix = """"

    with contextlib.closing(extractor):
        all_names = set(extractor.names())
        assert all_names == {
            prefix + ""README"",
            prefix + ""setup.py"",
            prefix + ""comtypes/__init__.py"",
            prefix + ""test/setup.py"",
        }

        prefix = extractor.fake_root + os.sep + prefix

        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        with extractor.open(prefix + ""README"") as handle:
            assert handle.read(2) == ""RE""
        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        assert extractor.exists(prefix + ""test"")
        assert extractor.exists(prefix + ""test/setup.py"")
        assert not extractor.exists(prefix + ""test/setup2.py"")
",True
1617,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/test_extractor.py,,test_extractor,"def test_extractor(archive_fixture, tmpdir, mock_targz, mock_zip):
    directory = ""comtypes-1.1.7""
    if archive_fixture == ""mock_targz"":
        archive = mock_targz(directory)
    elif archive_fixture == ""mock_zip"":
        archive = mock_zip(directory)
    else:
        archive = os.path.abspath(os.path.join(""source-packages"", directory))

    if archive_fixture == ""mock_targz"":
        extractor = req_compile.metadata.extractor.TarExtractor(""gz"", archive)
        prefix = directory + ""/""
    elif archive_fixture == ""mock_zip"":
        extractor = req_compile.metadata.extractor.ZipExtractor(archive)
        prefix = directory + ""/""
    else:
        extractor = req_compile.metadata.extractor.NonExtractor(archive)
        prefix = """"

    with contextlib.closing(extractor):
        all_names = set(extractor.names())
        assert all_names == {
            prefix + ""README"",
            prefix + ""setup.py"",
            prefix + ""comtypes/__init__.py"",
            prefix + ""test/setup.py"",
        }

        prefix = extractor.fake_root + os.sep + prefix

        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        with extractor.open(prefix + ""README"") as handle:
            assert handle.read(2) == ""RE""
        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        assert extractor.exists(prefix + ""test"")
        assert extractor.exists(prefix + ""test/setup.py"")
        assert not extractor.exists(prefix + ""test/setup2.py"")
",True
1618,https://github.com/sputt/req-compile/blob/c77e6777967ee660447beb9522c867a7233ef78d/tests/test_extractor.py,,test_extractor,"def test_extractor(archive_fixture, tmpdir, mock_targz, mock_zip):
    directory = ""comtypes-1.1.7""
    if archive_fixture == ""mock_targz"":
        archive = mock_targz(directory)
    elif archive_fixture == ""mock_zip"":
        archive = mock_zip(directory)
    else:
        archive = os.path.abspath(os.path.join(""source-packages"", directory))

    if archive_fixture == ""mock_targz"":
        extractor = req_compile.metadata.extractor.TarExtractor(""gz"", archive)
        prefix = directory + ""/""
    elif archive_fixture == ""mock_zip"":
        extractor = req_compile.metadata.extractor.ZipExtractor(archive)
        prefix = directory + ""/""
    else:
        extractor = req_compile.metadata.extractor.NonExtractor(archive)
        prefix = """"

    with contextlib.closing(extractor):
        all_names = set(extractor.names())
        assert all_names == {
            prefix + ""README"",
            prefix + ""setup.py"",
            prefix + ""comtypes/__init__.py"",
            prefix + ""test/setup.py"",
        }

        prefix = extractor.fake_root + os.sep + prefix

        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        with extractor.open(prefix + ""README"") as handle:
            assert handle.read(2) == ""RE""
        assert extractor.contents(prefix + ""README"") == ""README CONTENTS""
        assert extractor.exists(prefix + ""test"")
        assert extractor.exists(prefix + ""test/setup.py"")
        assert not extractor.exists(prefix + ""test/setup2.py"")
",True
1619,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/encoding/test_addresses.py,TestAddresses,test_from_output_script,"def test_from_output_script(self):

        self.assertEqual(
            addr.from_output_script(helpers.OP_IF['output_script']),
            helpers.OP_IF['p2sh'])
        self.assertEqual(
            addr.from_output_script(
                helpers.P2WSH['ser']['ins'][0]['pk_script']),
            helpers.P2WSH['human']['ins'][0]['addr'])
        self.assertEqual(
            addr.from_output_script(helpers.PK['ser'][0]['pkh_output']),
            helpers.ADDR[0]['p2pkh'])
        self.assertEqual(
            addr.from_output_script(helpers.P2WPKH_ADDR['output']),
            helpers.P2WPKH_ADDR['address'])

        with self.assertRaises(ValueError) as context:
            addr.from_output_script(b'\x8e' * 34)
        self.assertIn(
            'Cannot parse address from script.',
            str(context.exception))

    ",False
1620,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/encoding/test_addresses.py,TestAddresses,test_make_p2pkh_address,"def test_make_p2pkh_address(self):
        a = addr.make_p2pkh_address(b'\x00' * 65)
        self.assertEqual(a, helpers.ADDR[0]['p2pkh'])
        b = addr.make_p2pkh_address(b'\x11' * 65)
        self.assertEqual(b, helpers.ADDR[1]['p2pkh'])

    ",True
1621,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/encoding/test_addresses.py,TestAddresses,test_make_p2sh_address,"def test_make_p2sh_address(self):
        a = addr.make_p2sh_address('OP_IF')
        self.assertEqual(a, helpers.OP_IF['p2sh'])

    ",False
1622,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/encoding/test_addresses.py,TestAddresses,test_make_p2sh_address_msig,"def test_make_p2sh_address_msig(self):
        a = addr.make_p2sh_address(helpers.MSIG_2_2['redeem_script'])
        self.assertEqual(a, helpers.MSIG_2_2['p2sh'])

    ",True
1623,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/encoding/test_addresses.py,TestAddresses,test_make_p2wpkh_address,"def test_make_p2wpkh_address(self):
        a = addr.make_p2wpkh_address(helpers.P2WPKH_ADDR['pubkey'])
        self.assertEqual(a, helpers.P2WPKH_ADDR['address'])

    ",False
1624,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/encoding/test_addresses.py,TestAddresses,test_make_p2wsh_address,"def test_make_p2wsh_address(self):
        a = addr.make_p2wsh_address(
            helpers.P2WSH['human']['witnesses'][0]['wit_script'])
        self.assertEqual(a, helpers.P2WSH['human']['ins'][0]['addr'])

    ",True
1625,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/encoding/test_addresses.py,TestAddresses,test_parse,"def test_parse(self):
        self.assertEqual(addr.parse(helpers.OP_IF['p2sh']),
                         b'\x05' + helpers.OP_IF['script_hash'])
        self.assertEqual(addr.parse(helpers.MSIG_2_2['p2sh']),
                         b'\x05' + helpers.MSIG_2_2['script_hash'])
        self.assertEqual(addr.parse(
            helpers.P2WSH['human']['ins'][0]['addr']),
            b'\x00\x20' + helpers.P2WSH['ser']['ins'][0]['pk_script'][2:])
        self.assertEqual(addr.parse(helpers.P2WPKH_ADDR['address']),
                         b'\x00\x14' + helpers.P2WPKH_ADDR['pkh'])
        self.assertEqual(addr.parse(helpers.ADDR[0]['p2pkh']),
                         b'\x00' + helpers.PK['ser'][0]['pkh'])

        with self.assertRaises(ValueError) as context:
            addr.parse('This is not a valid address.')

        self.assertIn('Unsupported address format. Got: ',
                      str(context.exception))

    ",False
1626,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/encoding/test_addresses.py,TestAddresses,test_parse_hash,"def test_parse_hash(self):
        self.assertEqual(addr.parse_hash(helpers.OP_IF['p2sh']),
                         helpers.OP_IF['script_hash'])
        self.assertEqual(addr.parse_hash(helpers.MSIG_2_2['p2sh']),
                         helpers.MSIG_2_2['script_hash'])
        self.assertEqual(
            addr.parse_hash(
                helpers.P2WSH['human']['ins'][0]['addr']),
            helpers.P2WSH['ser']['ins'][0]['pk_script'][2:])
        self.assertEqual(addr.parse_hash(helpers.P2WPKH_ADDR['address']),
                         helpers.P2WPKH_ADDR['pkh'])
        self.assertEqual(addr.parse_hash(helpers.ADDR[0]['p2pkh']),
                         helpers.PK['ser'][0]['pkh'])

        with self.assertRaises(ValueError) as context:
            addr.parse('bc1blahblahblah')

        self.assertIn('Unsupported address format. Got: ',
                      str(context.exception))

        # Test cash addr code
        riemann.select_network('bitcoin_cash_main')
        self.assertEqual(
            addr.parse_hash(helpers.OP_IF['p2sh']),
            helpers.OP_IF['script_hash'])

        self.assertEqual(
            addr.parse_hash(helpers.OP_IF['cashaddr']),
            helpers.OP_IF['script_hash'])

        self.assertEqual(
            addr.parse_hash(helpers.CASHADDR['p2pkh']),
            utils.hash160(helpers.CASHADDR['pubkey']))

    ",False
1627,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/encoding/test_addresses.py,TestAddresses,test_to_output_script,"def test_to_output_script(self):
        self.assertEqual(
            addr.to_output_script(helpers.OP_IF['p2sh']),
            helpers.OP_IF['output_script'])
        self.assertEqual(
            addr.to_output_script(helpers.P2WSH['human']['ins'][0]['addr']),
            helpers.P2WSH['ser']['ins'][0]['pk_script'])
        self.assertEqual(
            addr.to_output_script(helpers.ADDR[0]['p2pkh']),
            helpers.PK['ser'][0]['pkh_output'])
        self.assertEqual(
            addr.to_output_script(helpers.P2WPKH_ADDR['address']),
            helpers.P2WPKH_ADDR['output'])

        with self.assertRaises(ValueError) as context:
            # Junk B58 w valid checksum
            addr.to_output_script('1111111111111111111111111111111111177fdsQ')

        self.assertIn(
            'Cannot parse output script from address.',
            str(context.exception))

    ",False
1628,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/test_simple.py,TestSimple,test_output,"def test_output(self):
        for i in range(len(helpers.P2WSH['human']['outs'])):
            self.assertEqual(
                simple.output(
                    value=helpers.P2WSH['human']['outs'][i]['value'],
                    address=helpers.P2WSH['human']['outs'][i]['addr']),
                helpers.P2WSH['ser']['outs'][i]['output'])

    ",True
1629,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/test_simple.py,TestSimple,test_unsigned_legacy_tx,"def test_unsigned_legacy_tx(self):
        outpoint = simple.outpoint(
            tx_id=helpers.P2PKH['human']['ins'][0]['hash'],
            index=helpers.P2PKH['human']['ins'][0]['index'])
        tx_in = simple.unsigned_input(
            outpoint=outpoint,
            sequence=helpers.P2PKH['human']['ins'][0]['sequence'])
        tx_out = simple.output(
            helpers.P2PKH['human']['outs'][0]['value'],
            helpers.P2PKH['human']['outs'][0]['addr'])
        tx_return_output = txn.make_op_return_output(
            helpers.P2PKH['human']['outs'][1]['memo'])
        tx = simple.unsigned_legacy_tx(
            tx_ins=[tx_in],
            tx_outs=[tx_out, tx_return_output])

        self.assertEqual(tx, helpers.P2PKH['ser']['tx']['unsigned'])

    ",True
1630,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/test_simple.py,TestSimple,test_unsigned_witness_tx,"def test_unsigned_witness_tx(self):
        outpoint = simple.outpoint(
            tx_id=helpers.P2WPKH['human']['ins'][0]['hash'],
            index=helpers.P2WPKH['human']['ins'][0]['index'])
        tx_in = simple.unsigned_input(
            outpoint=outpoint,
            sequence=helpers.P2WPKH['human']['ins'][0]['sequence'])
        tx_out = simple.output(
            helpers.P2WPKH['human']['outs'][0]['value'],
            helpers.P2WPKH['human']['outs'][0]['addr'])
        tx = simple.unsigned_witness_tx(
            tx_ins=[tx_in],
            tx_outs=[tx_out],
            lock_time=helpers.P2WPKH['human']['locktime'])

        self.assertEqual(tx, helpers.P2WPKH['ser']['tx']['unsigned'])
",True
1631,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/tx/test_tx_builder.py,TestTxBuilder,test_make_p2wpkh_output,"def test_make_p2wpkh_output_script(self):
        self.assertEqual(
            tb.make_p2wpkh_output_script(helpers.PK['ser'][0]['pk']),
            helpers.PK['ser'][0]['pkh_p2wpkh_output'])

    ",False
1632,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/tx/test_tx_builder.py,TestTxBuilder,test_make_p2wpkh_output_script,"def test_make_p2wpkh_output_script(self):
        self.assertEqual(
            tb.make_p2wpkh_output_script(helpers.PK['ser'][0]['pk']),
            helpers.PK['ser'][0]['pkh_p2wpkh_output'])

    ",True
1633,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/tx/test_tx_builder.py,TestTxBuilder,test_make_p2wsh_output,"def test_make_p2wsh_output_script(self):
        self.assertEqual(
            tb.make_p2wsh_output_script(
                helpers.P2WSH['human']['witnesses'][0]['wit_script']),
            helpers.P2WSH['ser']['ins'][0]['pk_script'])

    ",False
1634,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/tx/test_tx_builder.py,TestTxBuilder,test_make_p2wsh_output_script,"def test_make_p2wsh_output_script(self):
        self.assertEqual(
            tb.make_p2wsh_output_script(
                helpers.P2WSH['human']['witnesses'][0]['wit_script']),
            helpers.P2WSH['ser']['ins'][0]['pk_script'])

    ",False
1635,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/tx/test_tx_builder.py,TestTxBuilder,test_make_pkh_output_script,"def test_make_pkh_output_script(self):
        self.assertEqual(
            tb.make_pkh_output_script(helpers.PK['ser'][0]['pk']),
            helpers.PK['ser'][0]['pkh_output'])
        self.assertEqual(
            tb.make_pkh_output_script(
                helpers.PK['ser'][0]['pk'],
                witness=True),
            helpers.PK['ser'][0]['pkh_p2wpkh_output'])

        riemann.select_network('bitcoin_cash_main')
        with self.assertRaises(ValueError) as context:
            tb.make_pkh_output_script(helpers.PK['ser'][0]['pk'], witness=True)

        self.assertIn(
            'Network bitcoin_cash_main does not support witness scripts.',
            str(context.exception))

        with self.assertRaises(ValueError) as context:
            tb.make_pkh_output_script('hello world')
        self.assertIn(
            'Unknown pubkey format. Expected bytes. Got: ',
            str(context.exception))

    ",True
1636,https://github.com/summa-tx/riemann/blob/0fda32e783487572c869aaabc6af7adba01cbd00/riemann/tests/tx/test_tx_builder.py,TestTxBuilder,test_make_sh_output_script,"def test_make_sh_output_script(self):
        self.assertEqual(
            tb.make_sh_output_script('OP_IF'),
            helpers.OP_IF['output_script'])
        self.assertEqual(
            tb.make_sh_output_script(
                helpers.P2WSH['human']['witnesses'][0]['wit_script'],
                witness=True),
            helpers.P2WSH['ser']['ins'][0]['pk_script'])

        riemann.select_network('bitcoin_cash_main')
        with self.assertRaises(ValueError) as context:
            tb.make_sh_output_script(
                helpers.P2WSH['human']['witnesses'][0]['wit_script'],
                witness=True)

        self.assertIn(
            'Network bitcoin_cash_main does not support witness scripts.',
            str(context.exception))

    ",False
1637,https://github.com/SergeyShk/ruTS/blob/af02f627d9022f0f4825d9bed4ffc97d3d329f2d/tests/test_utils.py,,test_extract_archive,"def test_extract_archive():
    archive_file_zip = ""/tmp/ruts_download/stopwords.zip""
    archive_file_tar = ""/tmp/ruts_download/razdel.tar.gz""
    extract_dir = ""/tmp/ruts_extract""
    assert extract_archive(archive_file_zip, extract_dir=extract_dir) == ""/tmp/ruts_extract/stopwords""
    assert extract_archive(archive_file_tar) == ""/tmp/ruts_download/razdel""
    assert extract_archive(""/tmp/ruts_extract/stopwords/russian"") == ""/tmp/ruts_extract/stopwords""
    shutil.rmtree(""/tmp/ruts_extract"", ignore_errors=True)
    shutil.rmtree(""/tmp/ruts_download"", ignore_errors=True)

",True
1638,https://github.com/AGTGreg/runium/blob/ba89015859976d3426d25a53af5fa4d8827c7483/tests/test_runium.py,TestLoopDrift,test_processing,"def test_processing(selft, rnp):
        prev_time = time.time()
        rnp.new_task(simple_task).run(every=0.1, times=10).result()
        time_elapsed = time.time() - prev_time
        is_ok = (time_elapsed < 1) and (time_elapsed > 0.88)
        assert is_ok is True


class TestStartIn():
    ",False
1639,https://github.com/AGTGreg/runium/blob/ba89015859976d3426d25a53af5fa4d8827c7483/tests/test_runium.py,TestStartIn,test_processing,"def test_processing(self, rnp):
        prev_time = time.time()
        rnp.new_task(simple_task).run(start_in=0.1).result()
        time_elapsed = time.time() - prev_time
        is_ok = (time_elapsed < 0.11) and (time_elapsed > 0.09)
        assert is_ok is True


class TestTaskSkipping():
    ",True
1640,https://github.com/AGTGreg/runium/blob/ba89015859976d3426d25a53af5fa4d8827c7483/tests/test_runium.py,TestStartIn,test_threading,"def test_threading(self, rnt):
        prev_time = time.time()
        rnt.new_task(simple_task).run(start_in=0.1).result()
        time_elapsed = time.time() - prev_time
        is_ok = (time_elapsed < 0.11) and (time_elapsed > 0.09)
        assert is_ok is True

    ",False
1641,https://github.com/AGTGreg/runium/blob/ba89015859976d3426d25a53af5fa4d8827c7483/tests/test_runium.py,TestTaskSkipping,test_processing,"def test_processing(self, rnp):
        prev_time = time.time()
        rnp.new_task(sleepy_task).run(every=0.1, times=2).result()
        time_elapsed = time.time() - prev_time
        is_ok = (time_elapsed < 0.51) and (time_elapsed > 0.2)
        assert is_ok is True


class TestKwargs():
    ",True
1642,https://github.com/AGTGreg/runium/blob/ba89015859976d3426d25a53af5fa4d8827c7483/tests/test_runium.py,TestTaskSkipping,test_threading,"def test_threading(self, rnt):
        prev_time = time.time()
        rnt.new_task(sleepy_task).run(every=0.1, times=2).result()
        time_elapsed = time.time() - prev_time
        is_ok = (time_elapsed < 0.51) and (time_elapsed > 0.2)
        assert is_ok is True

    ",False
1643,https://github.com/daliclass/rxpy-backpressure/blob/b1a7bddfb370884135d6f2e7d9a3dd332a90d7cc/tests/test_sized_buffer_backpressure_strategy.py,TestDropBackPressureStrategy,test_on_next_drop_new_message_when_buffer_full,"def test_on_next_drop_new_message_when_buffer_full(self):
        mock_observer: MockObserver = MockObserver(include_sleeps=True)
        buffer: SizedBufferBackPressureStrategy = BackPressure.SIZED_BUFFER(
            mock_observer, cache_size=2
        )
        messages = [
            {""id"": 0, ""payload"": ""OK""},
            {""id"": 1, ""payload"": ""OK""},
            {""id"": 2, ""payload"": ""OK""},
            {""id"": 3, ""payload"": ""OK""},
            {""id"": 4, ""payload"": ""OK""},
            {""id"": 5, ""payload"": ""OK""},
            {""id"": 6, ""payload"": ""OK""},
            {""id"": 7, ""payload"": ""OK""},
        ]

        buffer.on_next(messages[0])
        buffer.on_next(messages[1])
        buffer.on_next(messages[2])
        buffer.on_next(messages[3])

        while buffer.is_locked():
            sleep(0.25)

        buffer.on_next(messages[4])
        buffer.on_next(messages[5])
        buffer.on_next(messages[6])
        buffer.on_next(messages[7])

        while buffer.is_locked():
            sleep(0.25)

        mock_observer.on_next_mock.assert_has_calls(
            [
                call(messages[0]),
                call(messages[1]),
                call(messages[1]),
                call(messages[4]),
                call(messages[5]),
                call(messages[5]),
            ]
        )
        self.assertEqual(4, buffer.counter.get_stats().get(""successful_events""))
        self.assertEqual(4, buffer.counter.get_stats().get(""dropped_events""))
",True
1644,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/cli/test_add.py,,test_add_adds_to_index,"def test_add_adds_to_index(saga_folder):
    random_file(""file"")
    run_cmd(""saga add file"")
    print(os.listdir())
    assert os.path.exists(saga_folder.join("".saga"").join(""index"").join(""file""))

",False
1645,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/cli/test_commit_graph.py,,test_lca_merge,"def test_lca_merge(tmpdir):
    # setup saga and get init hash
    os.chdir(tmpdir)
    init_blurb = run_cmd(""saga init"")
    init_hash = blurb_to_hash(str(tmpdir), init_blurb)
    # make a branch a1, a2, and b
    run_cmd(""saga branch a1"")
    run_cmd(""saga branch a2"")
    run_cmd(""saga branch b"")
    # make one commit on a1 and a2
    run_cmd(""saga checkout a1"")
    run_cmd(""saga commit --allow-empty -m \""ack\"""")
    # but we add a random file on a2 so the commit has is different
    run_cmd(""saga checkout a2"")
    random_file(""file"")
    run_cmd(""saga add file"")
    run_cmd(""saga commit -m \""ack\"""")
    # and then merge them 
    merge_blurb = run_cmd(""saga merge a1"")
    merge_hash = blurb_to_hash(str(tmpdir), merge_blurb)
    # make one commit on b
    run_cmd(""saga checkout b"")
    b_blurb = run_cmd(""saga commit --allow-empty -m \""back\"""")
    b_hash = blurb_to_hash(str(tmpdir), b_blurb)
    # check that the lca is the initial commit, from both
    repo = Repository(Path(tmpdir))
    repo.debug()
    commit_graph = CommitGraph(repo)
    need_merge, lcas = commit_graph.least_common_ancestors(merge_hash, b_hash)
    assert len(lcas) == 1
    assert lcas.pop() == init_hash


",False
1646,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/cli/test_commit_graph.py,,test_lca_two,"def test_lca_two(tmpdir):
    # setup saga and get init hash
    os.chdir(tmpdir)
    run_cmd(""saga init"")
    # make a branch a and b
    run_cmd(""saga branch a"")
    run_cmd(""saga branch b"")
    # make one commit on a
    run_cmd(""saga checkout a"")
    random_file(""filea"")
    run_cmd(""saga add filea"")
    a_blurb = run_cmd(""saga commit -m \""ack\"""")
    a_commit = blurb_to_hash(str(tmpdir), a_blurb)
    # make one commit on b
    run_cmd(""saga checkout b"")
    random_file(""fileb"")
    run_cmd(""saga add fileb"")
    b_blurb = run_cmd(""saga commit -m \""ack\"""")
    b_commit = blurb_to_hash(str(tmpdir), b_blurb)
    # merge from b to a
    b_merge_blurb = run_cmd(""saga merge a"")
    b_merge_hash = blurb_to_hash(str(tmpdir), b_merge_blurb)
    # merge from a to b
    run_cmd(""saga checkout a"")
    # TODO: we cannot do this currently, as we have no ability to 
    # merge in remote branches -- or merge in by commit hash
    # (which we should have...)
    return
    a_merge_blurb = run_cmd(""saga merge b"")
    a_merge_hash = blurb_to_hash(str(tmpdir), a_merge_blurb)
    # check that we get two common ancestors
    commit_graph = CommitGraph(os.path.join(tmpdir, "".saga"", ""commits""))
    lcas = commit_graph.least_common_ancestors(b_merge_hash, a_merge_hash)
    assert len(lcas) == 2
    assert a_commit in lcas and b_commit in lcas


",False
1647,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/cli/test_diff.py,,test_diff_empty,"def test_diff_empty(saga_folder):
    out = run_cmd(""saga diff"")
    assert out == ""Saga diff:\n""",False
1648,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/cli/test_log.py,,test_log_empty,"def test_log_empty(saga_folder):
    out = run_cmd(""saga log"")
    expected = """"""commit: 90a474c02eb88a019c2931ec033f3b704f66a86eba6b81ffa51ba627a59cc8bb\n\tCreated repository\n\n""""""
    assert expected in out

",False
1649,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/cli/test_state_hash.py,,test_state_hash_branch,"def test_state_hash_branch(saga_folder):
    empty_file(""file.rtf"")
    run_cmd(""saga add file.rtf"")
    run_cmd(""saga commit -m \""first commit \"""")
    run_cmd(""saga branch branchOne"")
    run_cmd(""saga checkout branchOne"")
    out = run_cmd(""saga state_hash branchOne"")
    expected = ""0f745679e632c1990731a790e486a78fb624a16700fbf0d245d8c520b09edb6f""
    assert expected in out",False
1650,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/cli/test_status.py,,test_status_empty,"def test_status_empty(saga_folder):
    out = run_cmd(""saga status"")
    assert out == """"""On branch master\nChanges staged for commit:\nChange not staged for commit:\nUntracked files:\n""""""
    random_file(""tmp.txt"")
    out = run_cmd(""saga status"")
    assert out == """"""On branch master\nChanges staged for commit:\nChange not staged for commit:\nUntracked files:\n\ttmp.txt\n""""""
    run_cmd(""saga add tmp.txt"")
    out = run_cmd(""saga status"")
    assert out == """"""On branch master\nChanges staged for commit:\n\tinserted: tmp.txt\nChange not staged for commit:\nUntracked files:\n""""""
    run_cmd(""saga commit -m \""add tmp.txt\"""")
    random_file(""tmp.txt"")
    out = run_cmd(""saga status"")
    assert out == """"""On branch master\nChanges staged for commit:\nChange not staged for commit:\n\tmodified: tmp.txt\nUntracked files:\n""""""
    ",False
1651,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_binary.py,,test_get_operations_change,"def test_get_operations_change(setup_binary_files):
    binary_file0 = parse_binary_file(""id"", ""name"", ""temp/binary0"")
    create_binary_file(""temp/binary0"", ""54321"")
    binary_file1 = parse_binary_file(""id"", ""name"", ""temp/binary0"")
    ops = binary_file0.get_operations(binary_file1)
    assert len(ops[""changed""]) == 1
    assert ops[""changed""][0] == [0]",False
1652,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_excel.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""xlsx"")",True
1653,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_excel.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""xlsx"")",True
1654,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_excel.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""xlsx"")",True
1655,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_excel.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""xlsx"")",True
1656,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_excel.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""xlsx"")",True
1657,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_excel.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""xlsx"")",True
1658,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_excel.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""xlsx"")",True
1659,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_text.py,,test_get_operations_insert_end,"def test_get_operations_insert_end(setup_text_files):
    text_file0 = parse_text_file(""id"", ""name"", ""temp/text0"")
    create_text_file(""temp/text0"", ""line1\nline2\nline3"")
    text_file1 = parse_text_file(""id"", ""name"", ""temp/text0"")
    ops = text_file0.get_operations(text_file1)
    assert len(ops[""file""]) == 0
    assert len(ops[""inserted""]) == 1
    assert ops[""inserted""] == [[2]]
    assert len(ops[""changed""]) == 0
    assert len(ops[""removed""]) == 0

",False
1660,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_text.py,,test_get_operations_insert_multiple_middle,"def test_get_operations_insert_multiple_middle(setup_text_files):
    text_file0 = parse_text_file(""id"", ""name"", ""temp/text0"")
    create_text_file(""temp/text0"", ""line1\nline3\nline4\nline2"")
    text_file1 = parse_text_file(""id"", ""name"", ""temp/text0"")
    ops = text_file0.get_operations(text_file1)
    assert len(ops[""file""]) == 0
    assert len(ops[""inserted""]) == 2
    assert ops[""inserted""] == [[1], [2]]
    assert len(ops[""changed""]) == 0
    assert len(ops[""removed""]) == 0

",False
1661,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_text.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""txt"")",True
1662,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_text.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""txt"")",True
1663,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_text.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""txt"")",True
1664,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_text.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""txt"")",True
1665,https://github.com/saga-vcs/saga/blob/7beaae8831696ce813aa85620387e416719198db/tests/test_text.py,,test_merge,"def test_merge(merge_test_name):
    assert do_test_merge(merge_test_name, ""txt"")",True
1666,https://github.com/jamesstidard/sanic-envconfig/blob/c68e09def2ce04c7ab91e443680ff64dc2ef61e1/tests/test_envconfig.py,,test_args_override_env,"def test_args_override_env(config, mock_args, mock_env):
    correct, incorrect = 'correct', 'incorrect'
    mock_env({'ATTRIBUTE_STR': incorrect})
    assert config.ATTRIBUTE_STR == incorrect
    mock_args(f'--attribute-str {correct}')
    assert config.ATTRIBUTE_STR == correct


",False
1667,https://github.com/jamesstidard/sanic-envconfig/blob/c68e09def2ce04c7ab91e443680ff64dc2ef61e1/tests/test_envconfig.py,,test_cant_parse,"def test_cant_parse(config, mock_env):
    mock_env({'ATTRIBUTE_INT': 'string'})
    with pytest.raises(AttributeError):
        print(config.ATTRIBUTE_INT)


",False
1668,https://github.com/jamesstidard/sanic-envconfig/blob/c68e09def2ce04c7ab91e443680ff64dc2ef61e1/tests/test_envconfig.py,,test_env_override,"def test_env_override(config, mock_env, attribute, value_type, new_value_in, new_value_out):
    mock_env({attribute: new_value_in})
    assert getattr(config, attribute) == new_value_out
    assert type(getattr(config, attribute)) == value_type


",False
1669,https://github.com/jamesstidard/sanic-envconfig/blob/c68e09def2ce04c7ab91e443680ff64dc2ef61e1/tests/test_envconfig.py,,test_env_override,"def test_env_override(config, mock_env, attribute, value_type, new_value_in, new_value_out):
    mock_env({attribute: new_value_in})
    assert getattr(config, attribute) == new_value_out
    assert type(getattr(config, attribute)) == value_type


",False
1670,https://github.com/jamesstidard/sanic-envconfig/blob/c68e09def2ce04c7ab91e443680ff64dc2ef61e1/tests/test_envconfig.py,,test_set_existing_attribute_gets_overridden,"def test_set_existing_attribute_gets_overridden(config, mock_env, sentinel):
    mock_env({'ATTRIBUTE_INT': '1'})
    config.ATTRIBUTE_INT = sentinel
    assert config.ATTRIBUTE_INT == 1


",False
1671,https://github.com/jamesstidard/sanic-envconfig/blob/c68e09def2ce04c7ab91e443680ff64dc2ef61e1/tests/test_envconfig.py,,test_set_new_attribute_gets_overridden,"def test_set_new_attribute_gets_overridden(config, mock_env, sentinel):
    mock_env({'ATTRIBUTE_NEW': 'hello attr'})
    config.ATTRIBUTE_NEW = sentinel
    assert config.ATTRIBUTE_NEW == 'hello attr'


",False
1672,https://github.com/qiyangduan/schemaindex/blob/83bfb96c78d194370b068e11f89a9e4d6af48a46/test/test_plugin_mysql_hdfs.py,,test_plugin_hdfs_add,"def test_plugin_hdfs_add():
    dict1 = si_app.get_data_source_dict(ds_name=hdfs_ds_dict['ds_name'])
    assert dict1 is None

    si_app.add_data_soruce(hdfs_ds_dict)
    dict1 = si_app.get_data_source_dict(ds_name=hdfs_ds_dict['ds_name'])
    assert dict1['ds_param']['hdfs_web_url'] ==  'http://localhost:50070'


",True
1673,https://github.com/Alexei-Kornienko/schematics_to_swagger/blob/d9c1c9e43a25c5a4ff60701b3bf22fc039c815c2/tests/test_model.py,,test_compound_type,"def test_compound_type():
    expected = WEATHER_STATS_DEF
    data = schematics_to_swagger.model_to_definition(models.WeatherStats)
    assert expected == data


",True
1674,https://github.com/Alexei-Kornienko/schematics_to_swagger/blob/d9c1c9e43a25c5a4ff60701b3bf22fc039c815c2/tests/test_model.py,,test_read_models_from_module,"def test_read_models_from_module():
    expected = {
        'WeatherReport': WEATHER_REPORT_DEFINITION,
        'WeatherStats': WEATHER_STATS_DEF,
        'WeatherPrivateData': WEATHER_PRIVATE_DATA
    }
    data = schematics_to_swagger.read_models_from_module(models)
    assert expected == data


",True
1675,https://github.com/scikit-hep/scikit-hep//blob/e78234da9e754e380a7d871afb56b20baa73b99b/tests/dataset/test_numpydataset.py,,test_methods,"def test_methods():
    ds1 = NumpyDataset(ar)
    ds1.__repr__()
    assert ds1.__str__() == ""[(1, 1) (2, 2) (3, 3)]""

    assert ds1.nentries == 3
    assert ds1.nevents  == 3

    assert ds1.variables == [""x"", ""y""]
    assert ds1.keys()    == [""x"", ""y""]

    ds1.to_file('npds.npz')
    ds2 = NumpyDataset.from_file('npds.npz')
    assert ds2.provenance[0].__repr__() == '<FileOrigin (1 file)>'
    os.remove('npds.npz')
    with pytest.raises(IOError):
        ds = NumpyDataset.from_file('non_existent_file')
    ds3 = ds1.copy()

    assert ds1['x'].tolist() == [1,2,3]
    assert ds1.x.tolist() == [1,2,3]
    assert ds1.x.name == ""x""
    assert ds1.x.provenance[0].detail == repr(ds1)

    ds1.z = np.ones((3,))
    assert ds1['z'].tolist() == [1,1,1]
    assert ds1.z.tolist() == [1,1,1]
    assert ds1.provenance[-1].__repr__() == ""<Transformation(Array z has been created)>""

    ds1['w'] = np.zeros((3,))
    assert ds1.provenance[-1].__repr__() == ""<Transformation(Array w has been created)>""
    assert ds1['w'].tolist() == [0,0,0]
    assert ds1.w.tolist() == [0,0,0]

    with pytest.raises(ValueError):
        ds1.__setitem__('h',np.ones((4,)))
    with pytest.raises(ValueError):
        ds1.__setitem__('k',""array"")

    ds1.z = ds1.w
    assert ds1.provenance[-1].__repr__() ==""<Transformation(Array z has been replaced by w)>""
    ds1.w = np.array([6,7,8])
    assert ds1.provenance[-1].__repr__() ==""<Transformation(Array w has been replaced by array([6, 7, 8]))>""


",True
1676,https://github.com/scikit-hep/scikit-hep//blob/e78234da9e754e380a7d871afb56b20baa73b99b/tests/dataset/test_numpydataset.py,,test_methods,"def test_methods():
    ds1 = NumpyDataset(ar)
    ds1.__repr__()
    assert ds1.__str__() == ""[(1, 1) (2, 2) (3, 3)]""

    assert ds1.nentries == 3
    assert ds1.nevents  == 3

    assert ds1.variables == [""x"", ""y""]
    assert ds1.keys()    == [""x"", ""y""]

    ds1.to_file('npds.npz')
    ds2 = NumpyDataset.from_file('npds.npz')
    assert ds2.provenance[0].__repr__() == '<FileOrigin (1 file)>'
    os.remove('npds.npz')
    with pytest.raises(IOError):
        ds = NumpyDataset.from_file('non_existent_file')
    ds3 = ds1.copy()

    assert ds1['x'].tolist() == [1,2,3]
    assert ds1.x.tolist() == [1,2,3]
    assert ds1.x.name == ""x""
    assert ds1.x.provenance[0].detail == repr(ds1)

    ds1.z = np.ones((3,))
    assert ds1['z'].tolist() == [1,1,1]
    assert ds1.z.tolist() == [1,1,1]
    assert ds1.provenance[-1].__repr__() == ""<Transformation(Array z has been created)>""

    ds1['w'] = np.zeros((3,))
    assert ds1.provenance[-1].__repr__() == ""<Transformation(Array w has been created)>""
    assert ds1['w'].tolist() == [0,0,0]
    assert ds1.w.tolist() == [0,0,0]

    with pytest.raises(ValueError):
        ds1.__setitem__('h',np.ones((4,)))
    with pytest.raises(ValueError):
        ds1.__setitem__('k',""array"")

    ds1.z = ds1.w
    assert ds1.provenance[-1].__repr__() ==""<Transformation(Array z has been replaced by w)>""
    ds1.w = np.array([6,7,8])
    assert ds1.provenance[-1].__repr__() ==""<Transformation(Array w has been replaced by array([6, 7, 8]))>""


",True
1677,https://github.com/bubylou/scsm/blob/a67059c398b40e31296faea25ae20d3dc78070bd/tests/test_core.py,TestSteamCMD,test_cached_login,"def test_cached_login(self, steamcmd_installed):
        assert steamcmd_installed.cached_login('anonymous') is False

    ",False
1678,https://github.com/ivanprjcts/sdklib/blob/5384b1c7f05abd6350151c08ad6a4a8b5855f8f0/tests/test_http_context.py,TestHttpContext,test_http_context_singleton_clear,"def test_http_context_singleton_clear(self):
        ctxt_singleton = HttpRequestContextSingleton.get_instance()
        ctxt_singleton.method = ""POST""
        self.assertEqual(""POST"", ctxt_singleton.method)
        ctxt_singleton.clear()
        self.assertNotEqual(""POST"", ctxt_singleton.method)

        ctxt_singleton2 = HttpRequestContextSingleton.get_instance()
        self.assertNotEqual(""POST"", ctxt_singleton2.method)

    ",True
1679,https://github.com/securenative/securenative-python/blob/0eae99733b7565341487ad32f044be8dc51032cd/tests/configuration_manager_test.py,ConfigurationManagerTest,test_default_values_for_invalid_enum_config_props,"def test_default_values_for_invalid_enum_config_props(self):
        try:
            os.remove(self.config_file_path)
            del os.environ[""SECURENATIVE_API_KEY""]
            del os.environ[""SECURENATIVE_API_URL""]
            del os.environ[""SECURENATIVE_INTERVAL""]
            del os.environ[""SECURENATIVE_MAX_EVENTS""]
            del os.environ[""SECURENATIVE_TIMEOUT""]
            del os.environ[""SECURENATIVE_AUTO_SEND""]
            del os.environ[""SECURENATIVE_DISABLE""]
            del os.environ[""SECURENATIVE_LOG_LEVEL""]
            del os.environ[""SECURENATIVE_FAILOVER_STRATEGY""]
        except FileNotFoundError:
            pass
        except KeyError:
            pass

        config = {
            ""SECURENATIVE_FAILOVER_STRATEGY"": ""fail-something""
        }

        self.create_ini_file(config)
        options = ConfigurationManager.load_config(None)

        self.assertIsNotNone(options)
        self.assertEqual(options.fail_over_strategy, FailOverStrategy.FAIL_OPEN.value)
",True
1680,https://github.com/securenative/securenative-python/blob/0eae99733b7565341487ad32f044be8dc51032cd/tests/configuration_manager_test.py,ConfigurationManagerTest,test_get_config_from_env_variables,"def test_get_config_from_env_variables(self):
        try:
            os.remove(self.config_file_path)
            del os.environ[""SECURENATIVE_API_KEY""]
            del os.environ[""SECURENATIVE_API_URL""]
            del os.environ[""SECURENATIVE_INTERVAL""]
            del os.environ[""SECURENATIVE_MAX_EVENTS""]
            del os.environ[""SECURENATIVE_TIMEOUT""]
            del os.environ[""SECURENATIVE_AUTO_SEND""]
            del os.environ[""SECURENATIVE_DISABLE""]
            del os.environ[""SECURENATIVE_LOG_LEVEL""]
            del os.environ[""SECURENATIVE_FAILOVER_STRATEGY""]
        except FileNotFoundError:
            pass
        except KeyError:
            pass

        os.environ[""SECURENATIVE_API_KEY""] = ""SOME_ENV_API_KEY""
        os.environ[""SECURENATIVE_API_URL""] = ""SOME_API_URL""
        os.environ[""SECURENATIVE_INTERVAL""] = ""6000""
        os.environ[""SECURENATIVE_MAX_EVENTS""] = ""700""
        os.environ[""SECURENATIVE_TIMEOUT""] = ""1700""
        os.environ[""SECURENATIVE_AUTO_SEND""] = ""False""
        os.environ[""SECURENATIVE_DISABLE""] = ""True""
        os.environ[""SECURENATIVE_LOG_LEVEL""] = ""Debug""
        os.environ[""SECURENATIVE_FAILOVER_STRATEGY""] = ""fail-closed""

        options = ConfigurationManager.load_config(None)

        self.assertEqual(options.api_key, ""SOME_ENV_API_KEY"")
        self.assertEqual(options.api_url, ""SOME_API_URL"")
        self.assertEqual(options.interval, ""6000"")
        self.assertEqual(options.timeout, ""1700"")
        self.assertEqual(options.max_events, ""700"")
        self.assertEqual(options.auto_send, ""False"")
        self.assertEqual(options.disable, ""True"")
        self.assertEqual(options.log_level, ""Debug"")
        self.assertEqual(options.fail_over_strategy, FailOverStrategy.FAIL_CLOSED.value)

    @unittest.skipIf(platform.system() == ""Windows"" or platform.system() == ""windows"", ""test not supported on windows"")
    ",True
1681,https://github.com/securenative/securenative-python/blob/0eae99733b7565341487ad32f044be8dc51032cd/tests/configuration_manager_test.py,ConfigurationManagerTest,test_ignore_unknown_config_in_properties_file,"def test_ignore_unknown_config_in_properties_file(self):
        try:
            os.remove(self.config_file_path)
            del os.environ[""SECURENATIVE_API_KEY""]
            del os.environ[""SECURENATIVE_API_URL""]
            del os.environ[""SECURENATIVE_INTERVAL""]
            del os.environ[""SECURENATIVE_MAX_EVENTS""]
            del os.environ[""SECURENATIVE_TIMEOUT""]
            del os.environ[""SECURENATIVE_AUTO_SEND""]
            del os.environ[""SECURENATIVE_DISABLE""]
            del os.environ[""SECURENATIVE_LOG_LEVEL""]
            del os.environ[""SECURENATIVE_FAILOVER_STRATEGY""]
        except FileNotFoundError:
            pass
        except KeyError:
            pass

        config = {
            ""SECURENATIVE_TIMEOUT"": ""1500"",
            ""SECURENATIVE_UNKNOWN_KEY"": ""SOME_UNKNOWN_KEY""
        }

        self.create_ini_file(config)
        options = ConfigurationManager.load_config(None)

        self.assertIsNotNone(options)
        self.assertEqual(options.timeout, ""1500"")

    @unittest.skipIf(platform.system() == ""Windows"" or platform.system() == ""windows"", ""test not supported on windows"")
    ",True
1682,https://github.com/securenative/securenative-python/blob/0eae99733b7565341487ad32f044be8dc51032cd/tests/configuration_manager_test.py,ConfigurationManagerTest,test_load_default_config,"def test_load_default_config(self):
        try:
            os.remove(self.config_file_path)
            del os.environ[""SECURENATIVE_API_KEY""]
            del os.environ[""SECURENATIVE_API_URL""]
            del os.environ[""SECURENATIVE_INTERVAL""]
            del os.environ[""SECURENATIVE_MAX_EVENTS""]
            del os.environ[""SECURENATIVE_TIMEOUT""]
            del os.environ[""SECURENATIVE_AUTO_SEND""]
            del os.environ[""SECURENATIVE_DISABLE""]
            del os.environ[""SECURENATIVE_LOG_LEVEL""]
            del os.environ[""SECURENATIVE_FAILOVER_STRATEGY""]
        except FileNotFoundError:
            pass
        except KeyError:
            pass

        options = ConfigurationManager.load_config(None)

        self.assertIsNotNone(options)
        self.assertIsNone(options.api_key)
        self.assertEqual(options.api_url, ""https://api.securenative.com/collector/api/v1"")
        self.assertEqual(str(options.interval), ""1000"")
        self.assertEqual(options.timeout, ""1500"")
        self.assertEqual(str(options.max_events), ""1000"")
        self.assertEqual(str(options.auto_send), ""True"")
        self.assertEqual(str(options.disable), ""False"")
        self.assertEqual(options.log_level, ""CRITICAL"")
        self.assertEqual(options.fail_over_strategy, FailOverStrategy.FAIL_OPEN.value)

    @unittest.skipIf(platform.system() == ""Windows"" or platform.system() == ""windows"", ""test not supported on windows"")
    ",True
1683,https://github.com/securenative/securenative-python/blob/0eae99733b7565341487ad32f044be8dc51032cd/tests/configuration_manager_test.py,ConfigurationManagerTest,test_parse_config_file_correctly,"def test_parse_config_file_correctly(self):
        try:
            os.remove(self.config_file_path)
            del os.environ[""SECURENATIVE_API_KEY""]
            del os.environ[""SECURENATIVE_API_URL""]
            del os.environ[""SECURENATIVE_INTERVAL""]
            del os.environ[""SECURENATIVE_MAX_EVENTS""]
            del os.environ[""SECURENATIVE_TIMEOUT""]
            del os.environ[""SECURENATIVE_AUTO_SEND""]
            del os.environ[""SECURENATIVE_DISABLE""]
            del os.environ[""SECURENATIVE_LOG_LEVEL""]
            del os.environ[""SECURENATIVE_FAILOVER_STRATEGY""]
        except FileNotFoundError:
            pass
        except KeyError:
            pass

        config = {
            ""SECURENATIVE_API_KEY"": ""SOME_API_KEY"",
            ""SECURENATIVE_APP_NAME"": ""SOME_APP_NAME"",
            ""SECURENATIVE_API_URL"": ""SOME_API_URL"",
            ""SECURENATIVE_INTERVAL"": ""1000"",
            ""SECURENATIVE_HEARTBEAT_INTERVAL"": ""5000"",
            ""SECURENATIVE_MAX_EVENTS"": ""100"",
            ""SECURENATIVE_TIMEOUT"": ""1500"",
            ""SECURENATIVE_AUTO_SEND"": ""True"",
            ""SECURENATIVE_DISABLE"": ""False"",
            ""SECURENATIVE_LOG_LEVEL"": ""Critical"",
            ""SECURENATIVE_FAILOVER_STRATEGY"": ""fail-closed""
        }

        self.create_ini_file(config)
        options = ConfigurationManager.load_config(None)

        self.assertIsNotNone(options)
        self.assertEqual(options.api_key, ""SOME_API_KEY"")
        self.assertEqual(options.api_url, ""SOME_API_URL"")
        self.assertEqual(options.auto_send, ""True"")
        self.assertEqual(options.disable, ""False"")
        self.assertEqual(options.fail_over_strategy, FailOverStrategy.FAIL_CLOSED.value)
        self.assertEqual(options.interval, ""1000"")
        self.assertEqual(options.log_level, ""Critical"")
        self.assertEqual(options.max_events, ""100"")
        self.assertEqual(options.timeout, ""1500"")

    @unittest.skipIf(platform.system() == ""Windows"" or platform.system() == ""windows"", ""test not supported on windows"")
    ",True
1684,https://github.com/securenative/securenative-python/blob/0eae99733b7565341487ad32f044be8dc51032cd/tests/securenative_test.py,SecureNativeTest,test_get_sdk_instance_without_init_throws,"def test_get_sdk_instance_without_init_throws(self):
        with self.assertRaises(SecureNativeSDKIllegalStateException):
            SecureNative.get_instance()

    ",True
1685,https://github.com/Parsely/serpextract/blob/aec8f2bd79c66953938569a24b05c693ab70b4ce/tests/test_serps.py,TestSERPs,test_custom_parser_explicit,"def test_custom_parser_explicit(self):
        self.assertInvalidSERP(self.custom_serp_url)
        self.assertValidSERP(self.custom_serp_url,
                             self.custom_parser.engine_name,
                             u'test',
                             parser=self.custom_parser)

    ",True
1686,https://github.com/Parsely/serpextract/blob/aec8f2bd79c66953938569a24b05c693ab70b4ce/tests/test_serps.py,TestSERPs,test_custom_parser_implicit,"def test_custom_parser_implicit(self):
        from serpextract.serpextract import _get_search_engines, _engines
        self.assertInvalidSERP(self.custom_serp_url)
        add_custom_parser(u'search.piccshare.com', self.custom_parser)
        self.assertValidSERP(self.custom_serp_url,
                             self.custom_parser.engine_name,
                             u'test')
        del _engines[u'search.piccshare.com']

    ",True
1687,https://github.com/Parsely/serpextract/blob/aec8f2bd79c66953938569a24b05c693ab70b4ce/tests/test_serps.py,TestSERPs,test_naive_detection,"def test_naive_detection(self):
        self.assertInvalidSERP(self.custom_serp_url)
        self.assertValidSERP(self.custom_serp_url, u'piccshare', u'test', use_naive_method=True)
        url = 'http://www.yahoo.com/#/%C2%BF??;%C2%AB99555$&&&4&'
        urlp = urlparse(url)
        self.assertInvalidSERP(urlparse(url), use_naive_method=True)
        self.assertInvalidSERP(url, use_naive_method=True)

    ",True
1688,https://github.com/Parsely/serpextract//blob/aec8f2bd79c66953938569a24b05c693ab70b4ce/tests/test_serps.py,TestSERPs,test_custom_parser_explicit,"def test_custom_parser_explicit(self):
        self.assertInvalidSERP(self.custom_serp_url)
        self.assertValidSERP(self.custom_serp_url,
                             self.custom_parser.engine_name,
                             u'test',
                             parser=self.custom_parser)

    ",True
1689,https://github.com/Parsely/serpextract//blob/aec8f2bd79c66953938569a24b05c693ab70b4ce/tests/test_serps.py,TestSERPs,test_custom_parser_implicit,"def test_custom_parser_implicit(self):
        from serpextract.serpextract import _get_search_engines, _engines
        self.assertInvalidSERP(self.custom_serp_url)
        add_custom_parser(u'search.piccshare.com', self.custom_parser)
        self.assertValidSERP(self.custom_serp_url,
                             self.custom_parser.engine_name,
                             u'test')
        del _engines[u'search.piccshare.com']

    ",True
1690,https://github.com/Parsely/serpextract//blob/aec8f2bd79c66953938569a24b05c693ab70b4ce/tests/test_serps.py,TestSERPs,test_naive_detection,"def test_naive_detection(self):
        self.assertInvalidSERP(self.custom_serp_url)
        self.assertValidSERP(self.custom_serp_url, u'piccshare', u'test', use_naive_method=True)
        url = 'http://www.yahoo.com/#/%C2%BF??;%C2%AB99555$&&&4&'
        urlp = urlparse(url)
        self.assertInvalidSERP(urlparse(url), use_naive_method=True)
        self.assertInvalidSERP(url, use_naive_method=True)

    ",True
1691,https://github.com/benjaminp/six/blob/c0be8815d13df45b6ae471c4c436cce8c192245d/test_six.py,,test_lazy,"def test_lazy():
    if six.PY3:
        html_name = ""html.parser""
    else:
        html_name = ""HTMLParser""
    assert html_name not in sys.modules
    mod = six.moves.html_parser
    assert sys.modules[html_name] is mod
    assert ""htmlparser"" not in six._MovedItems.__dict__


try:
    import _tkinter
except ImportError:
    have_tkinter = False
else:
    have_tkinter = True

have_gdbm = True
try:
    import gdbm
except ImportError:
    try:
        import dbm.gnu
    except ImportError:
        have_gdbm = False

@pytest.mark.parametrize(""item_name"",
                          [item.name for item in six._moved_attributes])
",True
1692,https://github.com/bmweiner/skillful/blob/8646f54faf62cb63f165f7699b8ace5b4a08233c/skillful/tests/test_controller.py,TestSkill,test_process,"def test_process(self):
        """"""Test process method.""""""
        self.skill.logic = {}
        @self.skill.launch
        ",True
1693,https://github.com/bmweiner/skillful/blob/8646f54faf62cb63f165f7699b8ace5b4a08233c/skillful/tests/test_controller.py,TestSkill,test_process_end,"def test_process_end(self):
        """"""Test process method for invalid.""""""
        self.skill.logic = {}
        @self.skill.session_ended
        ",True
1694,https://github.com/flokno/son/blob/a860c049e276151c8fddf82fdbe833d4127ada0d/tests/test_son.py,,test_read,"def test_read(fname=fname):
    """"""test son.load""""""
    metadata, data = son.load(fname)

    assert metadata == m
    assert data == [d1, d2]


",False
1695,https://github.com/flokno/son/blob/a860c049e276151c8fddf82fdbe833d4127ada0d/tests/test_son.py,,test_write_again,"def test_write_again(fname=fname):
    """"""test if writing again throws error""""""

    try:
        test_write(clean_first=False)
        raise RuntimeError(""FIXME"")
    except FileExistsError:
        pass


",False
1696,https://github.com/bwohlberg/sporco/blob/efd9237ec0d254e2ff630ad0ac17eb8dc566c586/tests/test_plot.py,TestSet01,test_09,"def test_09(self):
        fg, ax = plot.imview(self.z, title='Imview Test', fltscl=True,
                             cbar=None)
        ax.format_coord(0, 0)
        plot.close(fg)


    ",True
1697,https://github.com/maxpoint/spylon-kernel/blob/2d0ddf2aca1b91738f938b72a500c20293e3156c/test/test_scala_kernel.py,,test_iscomplete,"def test_iscomplete(spylon_kernel):
    result = spylon_kernel.do_is_complete('val foo = 99')
    assert result['status'] == 'complete'

    result = spylon_kernel.do_is_complete('val foo = {99')
    assert result['status'] == 'incomplete'

    result = spylon_kernel.do_is_complete('val foo {99')
    assert result['status'] == 'invalid'


",False
1698,https://github.com/ohke/sqs-polling/blob/34d1375cf73e05211c73cd43bdd120ce076181c8/sqs_polling/tests/test_sqs_polling.py,TestSqsPolling,test_execute_delete,"def test_execute_delete(self):
        sqs_mock = MagicMock()
        callback_mock = MagicMock(return_value=True)

        with patch(""boto3.client"", return_value=sqs_mock) as _:
            _execute({}, self._get_queue_url(),
                     callback_mock, None, self._get_responses(1)[""Messages""], True)

        callback_mock.assert_called_once_with(self._get_body(0))

        sqs_mock.delete_message.assert_called_once_with(
            QueueUrl=self._get_queue_url(), ReceiptHandle=self._get_receipt_handle(0)
        )

    ",True
1699,https://github.com/stackify/stackify-api-python/blob/c2625f558c41dc6c79474226b1ca7766b192dd66/tests/test_handler.py,TestListener,test_not_identified,"def test_not_identified(self, post, logmsg):
        '''The HTTPClient identifies automatically if needed'''
        listener = StackifyListener(queue_=Mock(), config=self.config)
        listener.handle(Mock())
        listener.send_group()
        self.assertTrue(listener.transport._transport.identified)

    @patch('stackify.transport.default.DefaultTransport.create_message')
    @patch('stackify.transport.default.DefaultTransport.create_group_message')
    @patch('stackify.transport.default.http.HTTPClient.POST')
    ",True
1700,https://github.com/stackify/stackify-api-python/blob/c2625f558c41dc6c79474226b1ca7766b192dd66/tests/test_handler.py,TestListener,test_send_group_crash,"def test_send_group_crash(self, send_log_group, logmsggroup, logmsg):
        '''The listener drops messages after retrying'''
        listener = StackifyListener(queue_=Mock(), max_batch=3, config=self.config)
        listener.transport._transport.identified = True

        send_log_group.side_effect = Exception

        listener.handle(1)
        listener.handle(2)
        listener.handle(3)
        self.assertEqual(len(listener.messages), 0)
        listener.handle(4)
        self.assertEqual(len(listener.messages), 1)
        self.assertEqual(send_log_group.call_count, 1)


",True
1701,https://github.com/stackify/stackify-api-python/blob/c2625f558c41dc6c79474226b1ca7766b192dd66/tests/test_handler.py,TestListener,test_send_group_if_needed,"def test_send_group_if_needed(self, post, logmsggroup, logmsg):
        '''The listener sends groups of messages'''
        listener = StackifyListener(queue_=Mock(), max_batch=3, config=self.config)
        listener.transport._transport.identified = True

        listener.handle(1)
        self.assertFalse(post.called)
        listener.handle(2)
        self.assertFalse(post.called)
        self.assertEqual(len(listener.messages), 2)
        listener.handle(3)
        self.assertTrue(post.called)
        self.assertEqual(len(listener.messages), 0)
        listener.handle(4)
        self.assertEqual(post.call_count, 1)
        self.assertEqual(len(listener.messages), 1)

    @patch('stackify.transport.default.DefaultTransport.create_message')
    @patch('stackify.handler.StackifyListener.send_group')
    ",True
1702,https://github.com/stackify/stackify-api-python/blob/c2625f558c41dc6c79474226b1ca7766b192dd66/tests/transport/test_init.py,TestTransport,test_default_send_url,"def test_default_send_url(self, mock_send):
        config = {
            'application': 'test_appname',
            'environment': 'test_environment',
            'api_key': 'test_apikey',
            'api_url': 'test_apiurl',
        }

        transport = configure_transport(**config)
        message = transport.create_message(logging.makeLogRecord({'mgs': 'message'}))
        group_message = transport.create_group_message([message])
        transport.send(group_message)

        assert mock_send.called
        assert mock_send.call_args_list[0][0][0] == '/Log/Save'

    ",True
1703,https://github.com/michaelpb/stowage/blob/7c619be755b9b73fd202367bcf9014472f318834/test/test_stowage.py,TestFullBehavior,test_backup,"def test_backup(self):
        args = stowage.parse_args([
            '--source', self.dir,
            '--destination', self.out_dir,
            '--backup', join(self.dir, 'path/to/bup'),
            'vim',
        ])
        open(join(self.out_dir, '.vimrc'), 'w+').write('original')
        stowage.main(args)
        assert exists(join(self.out_dir, '.vimrc'))
        assert exists(join(self.out_dir, '.config', 'openbox', 'openbox.xml'))
        assert exists(join(self.dir, 'path', 'to', 'bup', '.vimrc'))
        contents = open(join(self.dir, 'path', 'to', 'bup', '.vimrc')).read()
        assert contents == 'original'
        contents = open(join(self.out_dir, '.vimrc')).read()
        assert contents == '%s contents' % join(self.dir, 'vim', '_vimrc')
",False
1704,https://github.com/michaelpb/stowage/blob/7c619be755b9b73fd202367bcf9014472f318834/test/test_stowage.py,TestFullBehavior,test_main,"def test_main(self):
        args = stowage.parse_args([
            '--source', self.dir,
            '--destination', self.out_dir,
            '--backup', join(self.dir, 'path/to/bup'),
            'vim',
        ])
        stowage.main(args)
        assert exists(join(self.out_dir, '.vimrc'))
        assert exists(join(self.out_dir, '.config', 'openbox', 'openbox.xml'))
        contents = open(join(self.out_dir, '.vimrc')).read()
        assert contents == '%s contents' % join(self.dir, 'vim', '_vimrc')

    ",False
1705,https://github.com/michaelpb/stowage/blob/7c619be755b9b73fd202367bcf9014472f318834/test/test_stowage.py,TestPathGenerators,test_directory_walk,"def test_directory_walk(self):
        results = list(stowage.directory_walk(self.dir, 'test_out'))
        results_set = set(results)
        assert len(results_set) == len(results)  # ensure no dupes
        assert results_set == self.results

    ",True
1706,https://github.com/michaelpb/stowage/blob/7c619be755b9b73fd202367bcf9014472f318834/test/test_stowage.py,TestPathGenerators,test_needed_symlink_walk,"def test_needed_symlink_walk(self):
        results = list(stowage.needed_symlink_walk(self.dir, 'test_out'))
        results_set = set(results)
        assert len(results_set) == len(results)  # ensure no dupes
        assert results_set == self.results

    ",True
1707,https://github.com/michaelpb/stowage/blob/7c619be755b9b73fd202367bcf9014472f318834/test/test_stowage.py,TestPathGenerators,test_partially_needed_symlink_walk,"def test_partially_needed_symlink_walk(self):
        os.symlink(__file__, join(self.dir, '.vimrc'))
        results = list(stowage.needed_symlink_walk(self.dir, self.dir))
        results_set = set(results)
        assert len(results_set) == len(results)  # ensure no dupes
        assert results_set == set([
            (join(self.dir, '_config/openbox/openbox.xml'),
                join(self.dir, '.config/openbox/openbox.xml')),
        ])


class TestFullBehavior:
    FILES = [
        '_vimrc',
        '_config/openbox/openbox.xml',
    ]

    ",False
1708,https://github.com/Stratoscale/skipper/blob/dde3194bf6cf227b30c6e54b18c37317d2e0647e/tests/test_cli.py,TestCLI,test_make_without_build_container_tag,"def test_make_without_build_container_tag_with_context(self, skipper_runner_run_mock):
        global_params = self.global_params[:-2]
        makefile = 'Makefile'
        target = 'all'
        make_params = ['-f', makefile, target]
        self._invoke_cli(
            defaults=config.load_defaults(),
            global_params=global_params,
            subcmd='make',
            subcmd_params=make_params
        )
        expected_commands = [
            mock.call(['build', '--network=host',
                       '-t', 'build-container-image', '-f',
                       'Dockerfile.build-container-image',
                       SKIPPER_CONF_CONTAINER_CONTEXT]),
            mock.call(['make'] + make_params, fqdn_image='build-container-image', environment=[],
                      interactive=False, name=None, net='host', volumes=None, workdir=None,
                      use_cache=False, workspace=None),
        ]
        skipper_runner_run_mock.assert_has_calls(expected_commands)

    @mock.patch('skipper.git.get_hash', mock.MagicMock(autospec=True, return_value='1234567'))
    @mock.patch('os.path.exists', mock.MagicMock(autospec=True, return_value=False))
    @mock.patch('skipper.runner.run', autospec=True)
    ",True
1709,https://github.com/Stratoscale/skipper/blob/dde3194bf6cf227b30c6e54b18c37317d2e0647e/tests/test_cli.py,TestCLI,test_run_without_build_container_tag,"def test_run_without_build_container_tag(self, skipper_runner_run_mock):
        global_params = self.global_params[:-2]
        command = ['ls', '-l']
        run_params = command
        self._invoke_cli(
            global_params=global_params,
            subcmd='run',
            subcmd_params=run_params
        )
        expected_commands = [
            mock.call(['build', '--network=host', '-t', 'build-container-image', '-f',
                       'Dockerfile.build-container-image', '.']),
            mock.call(command, fqdn_image='build-container-image', environment=[],
                      interactive=False, name=None, net='host', volumes=None, workdir=None, workspace=None,
                      use_cache=False),
        ]
        skipper_runner_run_mock.assert_has_calls(expected_commands)

    @mock.patch('subprocess.check_output', mock.MagicMock(autospec=True, return_value=''))
    @mock.patch('skipper.runner.run', autospec=True, return_value=0)
    ",True
1710,https://github.com/Stratoscale/skipper/blob/dde3194bf6cf227b30c6e54b18c37317d2e0647e/tests/test_cli.py,TestCLI,test_run_without_build_container_tag_cached,"def test_run_without_build_container_tag_cached(self, skipper_runner_run_mock):
        global_params = self.global_params[:-2]
        command = ['ls', '-l']
        run_params = ['--cache'] + command
        self._invoke_cli(
            global_params=global_params,
            subcmd='run',
            subcmd_params=run_params
        )
        expected_commands = [
            mock.call(command, fqdn_image='build-container-image', environment=[],
                      interactive=False, name=None, net='host', volumes=None, workdir=None, workspace=None,
                      use_cache=True),
        ]
        skipper_runner_run_mock.assert_has_calls(expected_commands)

    @mock.patch('subprocess.check_output', mock.MagicMock(autospec=True, return_value='1234567'))
    @mock.patch('skipper.runner.run', autospec=True)
    ",True
1711,https://github.com/alexrudy/supertunnel/blob/4c64e2fedda3382b809a2c3d01c711ec4961f933/supertunnel/ssh/continuous_test.py,,test_backoff,"def test_backoff(monkeypatch: Any, proc: ContinuousSSH, caplog: Any) -> None:

    sleep_times = []

    ",True
1712,https://github.com/alexrudy/supertunnel/blob/4c64e2fedda3382b809a2c3d01c711ec4961f933/supertunnel/ssh/continuous_test.py,,test_continuous_repr,"def test_continuous_repr(proc):
    assert repr(proc).startswith(""ContinuousSSH"")


@pytest.mark.parametrize(
    ""logline,expected_action"",
    [
        (""Entering interactive session"", Action.CONNECTED),
        (""debug1: Reading configuration"", Action.CONTINUE),
        (""Host example.com not responding"", Action.DISCONNECTED),
    ],
)
",True
1713,https://github.com/alexrudy/supertunnel/blob/4c64e2fedda3382b809a2c3d01c711ec4961f933/supertunnel/ssh/continuous_test.py,,test_run,"def test_run_continuous(selector: Type[MockSelector], proc: ContinuousSSH, caplog: Any, popen: Type[MockPopen]) -> None:
    selector.events = [selectors.EVENT_READ] * 3
    popen._stdout = b""Entering interactive session\ndebug1: Your server is not responding\ndone""
    proc._run_once()

    assert list(get_transitions(proc)) == [""connecting"", ""connected"", ""disconnected""]


",True
1714,https://github.com/alexrudy/supertunnel/blob/4c64e2fedda3382b809a2c3d01c711ec4961f933/supertunnel/ssh/continuous_test.py,,test_run_continuous,"def test_run_continuous(selector: Type[MockSelector], proc: ContinuousSSH, caplog: Any, popen: Type[MockPopen]) -> None:
    selector.events = [selectors.EVENT_READ] * 3
    popen._stdout = b""Entering interactive session\ndebug1: Your server is not responding\ndone""
    proc._run_once()

    assert list(get_transitions(proc)) == [""connecting"", ""connected"", ""disconnected""]


",True
1715,https://github.com/alexrudy/supertunnel/blob/4c64e2fedda3382b809a2c3d01c711ec4961f933/supertunnel/ssh/continuous_test.py,,test_run_continuous_hang,"def test_run_continuous_hang(
    selector: Type[MockSelector], proc: ContinuousSSH, caplog: Any, popen: Type[MockPopen]
) -> None:
    popen._success = True
    selector.events = [selectors.EVENT_READ] * 3
    popen._stdout = b""Entering interactive session\ndebug1: some other message\ndone""
    proc._run_once()

    assert list(get_transitions(proc)) == [""connecting"", ""connected"", ""disconnected""]


",True
1716,https://github.com/alexrudy/supertunnel/blob/4c64e2fedda3382b809a2c3d01c711ec4961f933/supertunnel/ssh/continuous_test.py,,test_run_continuous_raise,"def test_run_continuous_raise(
    selector: Type[MockSelector], proc: ContinuousSSH, caplog: Any, popen: Type[MockPopen]
) -> None:
    popen._raise = True
    selector.events = [selectors.EVENT_READ] * 3
    popen._stdout = b""Entering interactive session\ndebug1: some other message\ndone""
    with pytest.raises(MockPopenException):
        proc._run_once()

    assert list(get_transitions(proc)) == [""connecting"", ""connected"", ""disconnected""]


",True
1717,https://github.com/alexrudy/supertunnel/blob/4c64e2fedda3382b809a2c3d01c711ec4961f933/supertunnel/ssh/continuous_test.py,,test_ssh_log_line,"def test_ssh_log_line(proc: ContinuousSSH, logline: str, expected_action: Action, caplog: Any) -> None:

    logger = logging.getLogger(__name__).getChild(""ssh"")
    assert proc._handle_ssh_line(logline, logger) == expected_action

    for record in caplog.records:
        assert ""debug1"" not in record.message


",True
1718,https://github.com/alexrudy/supertunnel/blob/4c64e2fedda3382b809a2c3d01c711ec4961f933/supertunnel/ssh/continuous_test.py,,test_ssh_log_line,"def test_ssh_log_line(proc: ContinuousSSH, logline: str, expected_action: Action, caplog: Any) -> None:

    logger = logging.getLogger(__name__).getChild(""ssh"")
    assert proc._handle_ssh_line(logline, logger) == expected_action

    for record in caplog.records:
        assert ""debug1"" not in record.message


",True
1719,https://github.com/alexrudy/supertunnel/blob/4c64e2fedda3382b809a2c3d01c711ec4961f933/supertunnel/ssh/continuous_test.py,,test_ssh_log_line,"def test_ssh_log_line(proc: ContinuousSSH, logline: str, expected_action: Action, caplog: Any) -> None:

    logger = logging.getLogger(__name__).getChild(""ssh"")
    assert proc._handle_ssh_line(logline, logger) == expected_action

    for record in caplog.records:
        assert ""debug1"" not in record.message


",True
1720,https://github.com/peinan/swpy/blob/262515d410bddaa3da72721ae2c11cfda1e2ee37/test_swpy.py,TimerTestCase,test_split,"def test_split(self):
        true_msg = '[test] [exp1] split time:  0.50 sec.'
        f = Mock()

        t = Timer(name='test')
        time.sleep(0.2)
        t.split()
        time.sleep(0.3)
        t.split('exp1', callback=f)
        time.sleep(0.1)
        t.stop()

        self.assertAlmostEqual(t.elapsed, 0.6, 1)
        f.assert_called_once_with(true_msg)

    ",False
1721,https://github.com/peinan/swpy/blob/262515d410bddaa3da72721ae2c11cfda1e2ee37/test_swpy.py,TimerTestCase,test_wo_title,"def test_wo_title(self):
        true_msg = '[test] finish time: 0.50 sec.'
        f = Mock()

        t = Timer(name='test', callback=f)
        time.sleep(0.1)
        t.start()
        time.sleep(0.5)
        t.stop()

        f.assert_called_once_with(true_msg)


",False
1722,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_delete,"def test_delete(self):
        self.create_default_experiment()

        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)
        with self.assertRaises(ValueError):
            # cluster.delete(None)
            # cluster.delete('')
            cluster.delete('Irene')
        self.assertListEqual(cluster.list_experiments(), ['exp'])
        cluster.delete('exp')
        self.assertListEqual(cluster.list_experiments(), [])


    ",False
1723,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_describe_experiment,"def test_describe_experiment(self):
        self.create_default_experiment()
        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)

        with self.assertRaises(ValueError):
            cluster.describe_experiment('Irene')
        exp_dict = cluster.describe_experiment('exp')
        self.assertDictEqual(
                exp_dict,
                {
                    'group': {
                        'hello': {
                            'status': 'live'
                        }
                    },
                    None: {
                        'alone': {
                            'status': 'live'
                        },
                    },
                }
        )

    ",False
1724,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_describe_process,"def test_describe_process_group(self):
        self.create_default_experiment()
        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)

        with self.assertRaises(ValueError):
            cluster.describe_process_group('bad_exp', 'group')
            cluster.describe_process_group('exp', 'bad_group')
        group_dict = cluster.describe_process_group('exp', 'group')
        self.assertDictEqual(group_dict,
                {
                    'hello': {
                        'status': 'live'
                    }
                }
        )
        group_dict = cluster.describe_process_group('exp', None)
        self.assertDictEqual(group_dict,
                    {
                        'alone': {
                            'status': 'live'
                        },
                    }
        )

    ",False
1725,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_describe_process_group,"def test_describe_process_group(self):
        self.create_default_experiment()
        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)

        with self.assertRaises(ValueError):
            cluster.describe_process_group('bad_exp', 'group')
            cluster.describe_process_group('exp', 'bad_group')
        group_dict = cluster.describe_process_group('exp', 'group')
        self.assertDictEqual(group_dict,
                {
                    'hello': {
                        'status': 'live'
                    }
                }
        )
        group_dict = cluster.describe_process_group('exp', None)
        self.assertDictEqual(group_dict,
                    {
                        'alone': {
                            'status': 'live'
                        },
                    }
        )

    ",False
1726,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_dump_dict,"def test_dump_dict(self):
        exp = self.create_default_experiment(launch=False)
        dump = exp.dump_dict()
        self.assertDictEqual(dump, _TEST_DUMP);

    ",False
1727,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_empty_experiment,"def test_empty_experiment(self):
        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)
        exp = cluster.new_experiment('empty_exp')
        cluster.launch(exp)
        # Confirm the launch of experiment on tmux side.
        self.assertListEqual([s.name for s in self.server.sessions],
                             ['empty_exp'])

        # Check windows
        sess = self.server.sessions[0]
        self.assertCountEqual([tmux.cluster._DEFAULT_WINDOW],
                              [w.name for w in sess.windows])

    ",False
1728,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_experiment_preamble,"def test_experiment_preamble(self):
        self.create_default_experiment(exp_preamble=['echo exp preamble'])
        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)

        l = cluster.get_log('exp', 'hello', process_group='group')
        self.assertIn('exp preamble', l)

        l = cluster.get_log('exp', 'alone')
        self.assertIn('exp preamble', l)

    ",False
1729,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_get_log,"def test_get_log(self):
        self.create_default_experiment()
        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)
        l = cluster.get_log('exp', 'hello', process_group='group')
        self.assertIn('Hello World!', l)

    ",False
1730,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_launch_experiment,"def test_launch_experiment(self):
        self.create_default_experiment()
        # Confirm the launch of experiment on tmux side.
        self.assertListEqual([s.name for s in self.server.sessions], ['exp'])

        # One window for each of: default, group:hello, alone
        sess = self.server.sessions[0]
        self.assertCountEqual(
                [tmux.cluster._DEFAULT_WINDOW, 'group:hello', 'alone'],
                [w.name for w in sess.windows])

    ",False
1731,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_list_experiment,"def test_list_experiment(self):
        self.create_default_experiment()
        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)

        experiments = cluster.list_experiments()
        self.assertListEqual(experiments, ['exp'])

    ",False
1732,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_multiple_experiments,"def test_multiple_experiments(self):
        self.create_default_experiment()

        # Launch a second experiment.
        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)
        exp2 = cluster.new_experiment('exp2')
        cluster.launch(exp2)

        # Confirm the launch of experiment on tmux side.
        self.assertListEqual([s.name for s in self.server.sessions],
                             ['exp', 'exp2'])

        # Check windows
        sess = self.server.sessions[0]
        self.assertCountEqual(
                [tmux.cluster._DEFAULT_WINDOW, 'group:hello', 'alone'],
                [w.name for w in sess.windows])
        sess = self.server.sessions[1]
        self.assertCountEqual([tmux.cluster._DEFAULT_WINDOW],
                              [w.name for w in sess.windows])

    ",False
1733,https://github.com/SurrealAI/symphony/blob/747b87eee20d48032b4a554950687d0b1209fd24/test/test_tmux_topdown.py,TestTmuxCluster,test_process_group_preamble,"def test_process_group_preamble(self):
        self.create_default_experiment(exp_preamble=['echo exp preamble'],
                                       group_preamble=['echo group preamble'])
        cluster = Cluster.new('tmux', server_name=_TEST_SERVER)

        l = cluster.get_log('exp', 'hello', process_group='group')
        self.assertIn('exp preamble', l)
        self.assertIn('group preamble', l)
        self.assertLess(l.index('exp preamble'), l.index('group preamble'))

        l = cluster.get_log('exp', 'alone')
        self.assertIn('exp preamble', l)
        self.assertNotIn('group preamble', l)

    #################### Action API tests ####################

    ",False
1734,https://github.com/fifman/tangle/blob/a36cff74d7f09bf8f24a91929b844ea1be7b1bcd/tests/test_bean.py,,test_instance,"def test_instance():
    tb = TestBean()
    _register.uncheck(4)
    tb.field1 = 1
    _register.check(4, 1)
    _register.uncheck(1)
    assert tb.field1 == 1
    _register.check(1)
    with pytest.raises(TypeError):
        tb.field2 = True
    alpha = Alpha()
    tb.field2 = alpha
    _register.uncheck(2)
    assert tb.field2 == alpha
    _register.check(2)
    tb.field3 = ""test""
    _register.uncheck(3)
    assert tb.field3 == ""test""
    _register.check(3)
",True
1735,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_alias_add,"def test_alias_add(cli, alias_config):
    cli('alias', ['add', '-b', 'test', 'bar', '43/1'])

    with open(alias_config.path, 'r') as f:
        config_lines = f.readlines()

    assert 'bar = 43/1\n' in config_lines


",False
1736,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_alias_no_inactive_excludes_inactive_aliases,"def test_alias_no_inactive_excludes_inactive_aliases(cli, alias_config):
    stdout = cli('alias', ['list', '--no-inactive'])

    assert 'not started project' not in stdout
    assert 'active project' in stdout


@freeze_time('2017-06-21')
",False
1737,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_alias_no_results,"def test_alias_no_results(cli, alias_config):
    output = cli('alias', ['list', '12'])
    lines = output.splitlines()

    assert len(lines) == 0


",False
1738,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_alias_search_mapping_exact,"def test_alias_search_mapping_exact(cli, alias_config):
    output = cli('alias', ['list', '--no-inactive', 'active1'])
    assert output == ""[test] active1 -> 43/1 (active project, activity 1)\n""


",False
1739,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_alias_search_mapping_partial,"def test_alias_search_mapping_partial(cli, alias_config):
    output = cli('alias', ['list', '--no-inactive', 'active'])
    lines = output.splitlines()

    assert lines == [
        ""[test] active1 -> 43/1 (active project, activity 1)"",
        ""[test] active2 -> 43/2 (active project, activity 2)"",
        ""[test] p2_active -> 44/1 (2nd active project, activity 1)"",
    ]


",False
1740,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_alias_search_project,"def test_alias_search_project(cli, alias_config):
    output = cli('alias', ['list', '-r', '43'])
    lines = output.splitlines()

    assert lines == [
        ""[test] 43/1 -> active1 (active project, activity 1)"",
        ""[test] 43/2 -> active2 (active project, activity 2)"",
    ]


",False
1741,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_alias_search_project_activity,"def test_alias_search_project_activity(cli, alias_config):
    output = cli('alias', ['list', '-r', '43/1'])
    lines = output.splitlines()
    assert lines == [""[test] 43/1 -> active1 (active project, activity 1)""]


",False
1742,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_alias_without_parameter_forwards_to_list,"def test_alias_without_parameter_forwards_to_list(cli, alias_config):
    output = cli('alias')
    lines = output.splitlines()

    assert lines == [
        ""[test] active1 -> 43/1 (active project, activity 1)"",
        ""[test] active2 -> 43/2 (active project, activity 2)"",
        ""[test] inactive1 -> 42/1 (not started project, activity 1)"",
        ""[test] inactive2 -> 42/2 (not started project, activity 2)"",
        ""[test] p2_active -> 44/1 (2nd active project, activity 1)"",
    ]


",False
1743,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_local_alias,"def test_local_alias(cli, alias_config):
    alias_config.set('local_aliases', '__pingpong', '')
    output = cli('alias', ['list'])
    assert '[local] __pingpong -> not mapped' in output


@freeze_time('2017-06-21')
",False
1744,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_no_inactive_flag_can_be_used_with_used_flag,"def test_no_inactive_flag_can_be_used_with_used_flag(cli, entries_file, alias_config):
    entries_file.write(""""""20.06.2017
    inactive1 1 Play ping-pong
    active2 1 Play ping-pong
    """""")

    stdout = cli('alias', ['list', '--used', '--no-inactive'])

    assert 'inactive1' not in stdout
    assert 'active2' in stdout


@freeze_time('2017-06-21')
",False
1745,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_search_string_can_be_used_with_used_flag,"def test_search_string_can_be_used_with_used_flag(cli, entries_file, alias_config):
    entries_file.write(""""""20.06.2017
    p2_active 1 Play ping-pong
    active2 1 Play ping-pong
    """""")

    stdout = cli('alias', ['list', '--used', 'active2'])

    assert 'active2' in stdout
    assert 'p2_active' not in stdout


@freeze_time('2017-06-21')
",False
1746,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_used_flag_includes_inactive_by_default,"def test_used_flag_includes_inactive_by_default(cli, entries_file, alias_config):
    entries_file.write(""""""20.06.2017
    inactive1 1 Play ping-pong
    """""")

    stdout = cli('alias', ['list', '--used'])

    assert 'inactive1' in stdout
",False
1747,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_alias.py,,test_used_option_only_shows_used_aliases,"def test_used_option_only_shows_used_aliases(cli, entries_file, alias_config):
    entries_file.write(""""""20.06.2017
    active1 1 Play ping-pong
    """""")

    output = cli('alias', ['list', '--used'])

    assert 'active2' not in output
    assert 'active1' in output


",False
1748,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_autofill.py,,test_autofill_top,"def test_autofill_top(cli, config, entries_file):
    config.set_dict({
        'taxi': {
            'auto_fill_days': '1',
            'auto_add': 'top'
        }
    })

    cli('autofill')
    entries_file_contents = entries_file.readlines()

    assert entries_file_contents == [
        ""28/02/2012\n"", ""\n"", ""21/02/2012\n"", ""\n"", ""14/02/2012\n"", ""\n"",
        ""07/02/2012\n""
    ]


@freeze_time('2012-02-20')
",False
1749,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_clean_aliases.py,,test_project_status,"def test_project_status(cli, config, data_dir):
    config.set_dict({
        'test_aliases': {
            'alias_not_started': '0/0',
            'alias_active': '1/0',
            'alias_finished': '2/0',
            'alias_cancelled': '3/0',
        }
    })
    projects_db = ProjectsDb(str(data_dir))

    project_not_started = Project(0, 'not started project',
                                  Project.STATUS_NOT_STARTED)
    project_not_started.backend = 'test'
    project_not_started.activities.append(Activity(0, 'activity'))
    project_active = Project(1, 'active project', Project.STATUS_ACTIVE)
    project_active.backend = 'test'
    project_active.activities.append(Activity(0, 'activity'))
    project_finished = Project(2, 'finished project',
                               Project.STATUS_FINISHED)
    project_finished.backend = 'test'
    project_finished.activities.append(Activity(0, 'activity'))
    project_cancelled = Project(3, 'cancelled project',
                                Project.STATUS_CANCELLED)
    project_cancelled.backend = 'test'
    project_cancelled.activities.append(Activity(0, 'activity'))
    projects_db.update([
        project_not_started, project_active, project_finished,
        project_cancelled
    ])

    cli('clean-aliases', ['--yes'])

    settings = Settings(config.path)
    assert list(settings.get_aliases().keys()) == ['alias_active']
",False
1750,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_commit_confirmation_date_order,"def test_commit_confirmation_date_order(cli, entries_file):
    entries_file.write(""""""20/01/2014
alias_1 2 Play ping-pong

18/01/2014
alias_1 2 Play ping-pong

19/01/2014
alias_1 1 Play ping-pong
"""""")
    stdout = cli('commit', input='y').splitlines()
    dates = [stdout[2], stdout[4], stdout[6]]
    assert dates[0].endswith('18 January')
    assert dates[1].endswith('19 January')
    assert dates[2].endswith('20 January')


@freeze_time('2014-01-21')
",False
1751,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_commit_date,"def test_commit_date(cli, entries_file):
    entries_file.write(""""""21/01/2014
alias_1 2 foobar

20/01/2014
alias_1 1 previous day entry
"""""")
    stdout = cli('commit', args=['--since=21.01.2014', '--until=21.01.2014'])
    assert 'previous day entry' not in stdout

    stdout = cli('commit')
    assert 'previous day entry' in stdout


@freeze_time('2014-01-20')
",False
1752,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_commit_previous_file_previous_month,"def test_commit_previous_file_previous_month(cli, data_dir, config):
    efg = EntriesFileGenerator(data_dir, '%m_%Y.tks')
    efg.expand(datetime.date(2014, 1, 1)).write(
        ""01/01/2014\nalias_1 2 january""
    )
    efg.expand(datetime.date(2014, 2, 1)).write(
        ""01/02/2014\nalias_1 4 february""
    )
    efg.patch_config(config)

    stdout = cli('commit', ['--yes'])

    assert 'january' in stdout
    assert 'february' in stdout


@freeze_time('2014-01-21')
",False
1753,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_commit_previous_file_previous_year,"def test_commit_previous_file_previous_year(cli, data_dir, config):
    efg = EntriesFileGenerator(data_dir, '%m_%Y.tks')
    efg.expand(datetime.date(2013, 11, 1)).write(
        ""01/11/2013\nalias_1 2 november""
    )
    efg.expand(datetime.date(2013, 12, 1)).write(
        ""01/12/2013\nalias_1 2 december""
    )
    efg.expand(datetime.date(2014, 1, 1)).write(
        ""01/01/2014\nalias_1 4 january""
    )
    efg.patch_config(config)

    stdout = cli('commit', args=['--yes'])

    assert 'november' not in stdout
    assert 'december' in stdout
    assert 'january' in stdout


@freeze_time('2014-01-21')
",False
1754,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_commit_previous_file_year_format,"def test_commit_previous_file_year_format(cli, data_dir, config):
    config.set('taxi', 'nb_previous_files', '2')

    efg = EntriesFileGenerator(data_dir, '%Y.tks')
    efg.expand(datetime.date(2013, 1, 1)).write(
        ""01/01/2013\nalias_1 1 january 2013""
    )
    efg.expand(datetime.date(2013, 2, 1)).write(
        ""01/02/2013\nalias_1 1 february 2013"", mode='a'
    )
    efg.expand(datetime.date(2014, 1, 1)).write(
        ""01/01/2014\nalias_1 1 january 2014""
    )
    efg.expand(datetime.date(2014, 2, 1)).write(
        ""01/02/2014\nalias_1 1 february 2014"", mode='a'
    )
    efg.patch_config(config)
    stdout = cli('commit', args=['--yes'])

    assert 'january 2013' in stdout
    assert 'february 2013' in stdout
    assert 'january 2014' in stdout
    assert 'february 2014' in stdout


@freeze_time('2014-01-21')
",False
1755,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_commit_previous_files_previous_months,"def test_commit_previous_files_previous_months(cli, data_dir, config):
    config.set('taxi', 'nb_previous_files', '2')

    efg = EntriesFileGenerator(data_dir, '%m_%Y.tks')
    efg.expand(datetime.date(2013, 11, 1)).write(
        ""01/11/2013\nalias_1 2 november""
    )
    efg.expand(datetime.date(2013, 12, 1)).write(
        ""01/12/2013\nalias_1 2 december""
    )
    efg.expand(datetime.date(2014, 1, 1)).write(
        ""01/01/2014\nalias_1 4 january""
    )
    efg.patch_config(config)

    stdout = cli('commit', args=['--yes'])

    assert 'november' in stdout
    assert 'december' in stdout
    assert 'january' in stdout


@freeze_time('2014-01-21')
",False
1756,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_fix_entries_start_time_without_previous,"def test_fix_entries_start_time_without_previous(cli, entries_file):
    entries_file.write(""""""21/01/2014
fail     -0830  Repair coffee machine
"""""")
    cli('commit')

    lines = entries_file.readlines()

    assert lines[1] == 'fail     -0830  Repair coffee machine\n'


@freeze_time('2014-01-21')
",False
1757,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_ignore_date_error_previous_day,"def test_ignore_date_error_previous_day(cli, entries_file):
    entries_file.write(""""""17/01/2014
alias_1 2 foobar
"""""")
    stdout = cli('commit')
    assert 'Are you sure' in stdout


@freeze_time('2014-02-21')
",False
1758,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_ignore_date_error_week_day,"def test_ignore_date_error_week_day(cli, entries_file):
    entries_file.write(""""""19/01/2014
alias_1 2 foobar
"""""")
    stdout = cli('commit')
    assert 'Are you sure' in stdout


@freeze_time('2014-01-21')
",False
1759,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_not_today_option,"def test_not_today_option(cli, entries_file):
    entries_file.write(""""""20/01/2014
alias_1 2 Play ping-pong

21/01/2014
alias_1     1  Repair coffee machine
alias_1     2  Repair coffee machine
"""""")
    stdout = cli('commit', args=['--not-today'])

    assert 'coffee' not in stdout


@freeze_time('2014-01-21')
",False
1760,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_not_today_option_with_date,"def test_not_today_option_with_date(cli, entries_file):
    entries_file.write(""""""20/01/2014
alias_1 2 Play ping-pong

21/01/2014
alias_1     1  Repair coffee machine
alias_1     2  Repair coffee machine
"""""")
    stdout = cli('commit', args=[
        '--not-today', '--since=19.01.2014', '--until=21.01.2014']
    )

    assert 'coffee' not in stdout


@freeze_time('2014-01-21')
",False
1761,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_post_push_fail,"def test_post_push_fail(cli, entries_file):
    entries_file.write(""""""21/01/2014
post_push_fail     1  Repair coffee machine
alias_1     2  Repair coffee machine
"""""")
    stdout = cli('commit')

    assert 'Failed entries\n\npost_push_fail' in stdout


@freeze_time('2014-01-21')
",False
1762,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_commit.py,,test_regroup_entries_setting,"def test_regroup_entries_setting(cli, config, entries_file):
    config.set('taxi', 'regroup_entries', '0')
    entries_file.write(""""""20/01/2014
alias_1 0800-0900 Play ping-pong
alias_1 1200-1300 Play ping-pong
"""""")

    stdout = cli('commit')
    assert line_in(
        ""alias_1 1.00  Play ping-pong"",
        stdout
    )


@freeze_time('2017-07-03')
",False
1763,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_config.py,,test_config_works_with_invalid_syntax,"def test_config_works_with_invalid_syntax(cli, config):
    with open(config.path, ""w"") as fp:
        fp.write(""[foobar"")

    with patch(""taxi.commands.config.click.edit"") as edit:
        cli(""config"")
        edit.assert_called_once_with(filename=config.path)


",False
1764,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_current.py,,test_current_fails_with_exit_code_1_when_no_current_entry,"def test_current_fails_with_exit_code_1_when_no_current_entry(cli, config, data_dir):
    efg = EntriesFileGenerator(data_dir, '%m_%Y.txt')
    efg.expand(datetime.date(2014, 1, 21)).write(
        ""20/01/2014\nalias_1 5 hello world""
    )
    efg.patch_config(config)

    with freeze_time('2014-01-20 10:45:00'):
        result = cli('current', return_stdout=False)

    assert result.exit_code == 1
    assert result.output.strip() == ""No entry in progress.""


",False
1765,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_current.py,,test_current_shows_current_entry,"def test_current_shows_current_entry(cli, config, data_dir):
    efg = EntriesFileGenerator(data_dir, '%m_%Y.txt')
    efg.expand(datetime.date(2014, 1, 21)).write(
        ""20/01/2014\nalias_1 1000-? hello world""
    )
    efg.patch_config(config)

    with freeze_time('2014-01-20 10:45:00'):
        stdout = cli('current')

    assert stdout.strip() == ""alias_1 00h45m""


",False
1766,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_current.py,,test_current_uses_custom_format,"def test_current_uses_custom_format(cli, config, data_dir):
    efg = EntriesFileGenerator(data_dir, '%m_%Y.txt')
    efg.expand(datetime.date(2014, 1, 21)).write(
        ""20/01/2014\nalias_1 1000-? hello world""
    )
    efg.patch_config(config)

    with freeze_time('2014-01-20 10:45:00'):
        stdout = cli('current', args=['--format={alias} {description} {start_time} {hours} {minutes}'])

    assert stdout.strip() == ""alias_1 hello world 10:00 0 45""


",False
1767,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_current.py,,test_entry_uses_custom_timesheet,"def test_entry_uses_custom_timesheet(cli, data_dir):
    file_path = os.path.join(str(data_dir), 'timesheet.tks')
    with open(file_path, 'w') as f:
        f.write(
            ""20/01/2014\nalias_1 1000-? hello world""
        )

    with freeze_time('2014-01-20 10:45:00'):
        stdout = cli('current', args=['-f%s' % file_path])

    assert stdout.strip() == ""alias_1 00h45m""
",False
1768,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_edit.py,,test_autofill_with_specified_file,"def test_autofill_with_specified_file(cli, config, entries_file):
    """"""
    Edit with specified date should not autofill it.
    """"""
    config.set('taxi', 'auto_fill_days', '0,1,2,3,4,5,6')
    cli('edit', args=['--file=%s' % str(entries_file)])

    assert entries_file.read() == ''


",False
1769,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_edit.py,,test_edit_status,"def test_edit_status(cli, config, data_dir):
    efg = EntriesFileGenerator(data_dir, '%m_%Y.txt')
    efg.expand(datetime.date(2014, 1, 21)).write(
        ""20/01/2014\nalias_1 2 hello world""
    )
    efg.expand(datetime.date(2014, 2, 21)).write(
        ""20/02/2014\nalias_1 2 hello world""
    )
    efg.patch_config(config)

    with freeze_time('2014-01-21'):
        stdout = cli('edit')

    assert 'Monday 20 january' in stdout


",False
1770,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_edit.py,,test_edit_utf8_file,"def test_edit_utf8_file(cli, config, entries_file):
    """"""
    Editing a file that contains accents should not crash.
    """"""
    # I wish I could just `entries_file.write()` without encoding anything but... Python 2
    entries_file.write_binary(
        ""20/01/2014\nalias_1 2 préparation du café pour l'évènement"".encode('utf-8')
    )

    cli('edit')


",False
1771,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_edit.py,,test_edit_with_unsupported_date_format,"def test_edit_with_unsupported_date_format(cli, config, data_dir):
    config.set('taxi', 'file', os.path.join(data_dir, '/tmp/%Y_%f.txt'))
    with pytest.raises(click.ClickException):
        cli('edit')
",False
1772,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_edit.py,,test_prefill_entries_add_to_bottom,"def test_prefill_entries_add_to_bottom(cli, data_dir, config):
    efg = EntriesFileGenerator(data_dir, '%m_%Y.txt')
    efg.expand(datetime.date(2014, 1, 21)).write(
        """"""20/01/2014
alias_1 2 hello world

21/01/2014
alias_1 1 foo bar"""""")
    efg.expand(datetime.date(2014, 2, 21)).write(
        ""20/02/2014\nalias_1 2 hello world""
    )
    efg.patch_config(config)

    with freeze_time('2014-02-21'):
        cli('edit')

    lines = efg.expand(datetime.date(2014, 2, 21)).readlines()

    assert '20/02/2014\n' == lines[0]
    assert '21/02/2014\n' == lines[3]


",False
1773,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_migration.py,,test_migration_to_51_removes_shared_aliases,"def test_migration_to_51_removes_shared_aliases(cli, config):
    config.set('test_shared_aliases', 'foo', '123/456')

    cli('status')

    cp = configparser.RawConfigParser()
    cp.read(config.path)

    assert not cp.has_section('test_shared_aliases')
",False
1774,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_project.py,,test_add_creates_alias,"def test_add_creates_alias(cli, config, projects_db):
    cli('project', ['alias', 'active'], input='1\n0\nfoobar')

    with open(config.path, 'r') as f:
        config_lines = f.readlines()

    assert 'foobar = 43/1\n' in config_lines


",False
1775,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_project.py,,test_add_inactive_project,"def test_add_inactive_project(cli, data_dir):
    project = Project(1, 'test project', Project.STATUS_FINISHED)
    project.activities = [Activity(2, 'test activity')]
    p = ProjectsDb(str(data_dir))
    p.update([project])

    output = cli('project', ['alias', 'test project'], input='test_alias')

    assert ""No active project matches your search string"" in output
",False
1776,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_project.py,,test_add_multiple_choices,"def test_add_multiple_choices(cli, data_dir, config):
    p1 = Project(1, 'test project', Project.STATUS_ACTIVE)
    p1.activities = [Activity(2, 'test activity')]
    p2 = Project(2, 'test project 2', Project.STATUS_ACTIVE)
    p2.activities = [Activity(3, 'test activity 2')]
    p = ProjectsDb(str(data_dir))
    p.update([p1, p2])

    cli('project', ['alias', 'test project'], input='1\ntest_alias')

    with open(config.path, 'r') as f:
        lines = f.readlines()

    assert 'test_alias = 2/3\n' in lines

",False
1777,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_project.py,,test_argument_filters_search,"def test_argument_filters_search(cli, projects_db):
    lines = cli('project', ['list', 'active']).splitlines()

    assert set(lines) == set([
        'A [test]   43 active project',
        'A [test]   44 2nd active project',
    ])


",False
1778,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_project.py,,test_no_arguments_lists_projects,"def test_no_arguments_lists_projects(cli, projects_db):
    lines = cli('project').splitlines()

    assert set(lines) == set([
        'N [test]   42 not started project',
        'A [test]   43 active project',
        'A [test]   44 2nd active project',
    ])


",False
1779,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_project.py,,test_show_inactive_project_shows_project,"def test_show_inactive_project_shows_project(cli, projects_db):
    lines = cli('project', ['show', '42']).splitlines()
    assert lines[0] == 'Id: 42'


",False
1780,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_project.py,,test_show_nonexistent_project_shows_error,"def test_show_nonexistent_project_shows_error(cli):
    output = cli('project', ['show', '777'])
    assert output == 'Error: Could not find project `777`\n'


",False
1781,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_project.py,,test_show_shows_project,"def test_show_shows_project(cli, projects_db):
    lines = cli('project', ['show', '43']).splitlines()
    assert lines[0] == 'Id: 43'


",False
1782,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_show.py,,test_show_alias,"def test_show_alias(cli, projects_db):
    output = cli('show', ['alias_1'])
    assert output == (""Your search string alias_1 is an alias to ""
                      ""my project, my activity (123/456) on the ""
                      ""test backend.\n"")


",False
1783,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_show.py,,test_show_inexistent_object,"def test_show_inexistent_object(cli):
    output = cli('show', ['aoeuidhtns'])
    assert output == ""Your search string aoeuidhtns is nothing.\n""


",False
1784,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_show.py,,test_show_local_alias,"def test_show_local_alias(cli, config):
    config.set('local_aliases', '__pingpong', '')
    output = cli('show', ['__pingpong'])
    assert output == ""Your search string __pingpong is a local alias.\n""
",False
1785,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_show.py,,test_show_project_id,"def test_show_project_id(cli, projects_db):
    output = cli('show', ['42'])
    assert output == (""Your search string 42 is the project not ""
                      ""started project.\n"")


",False
1786,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_start.py,,test_date_not_present_entry_not_present,"def test_date_not_present_entry_not_present(cli, entries_file):
    entries = """"""19/01/2014
alias_1 2 foo
""""""
    expected = """"""20/01/2014

alias_1 00:00-? ?

19/01/2014
alias_1 2 foo
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20'):
        cli('start', ['alias_1'])

    assert entries_file.read() == expected


",False
1787,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_start.py,,test_date_present_entry_not_present,"def test_date_present_entry_not_present(cli, entries_file):
    entries = """"""20/01/2014
""""""
    expected = """"""20/01/2014

alias_1 00:00-? ?
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20'):
        cli('start', ['alias_1'])

    assert entries_file.read() == expected


",False
1788,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_start.py,,test_date_present_entry_present,"def test_date_present_entry_present(cli, entries_file):
    entries = """"""20/01/2014
alias_1 2 foobar
""""""
    expected = """"""20/01/2014
alias_1 2 foobar
alias_1 00:00-? ?
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20'):
        cli('start', ['alias_1'])

    assert entries_file.read() == expected


",False
1789,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_start.py,,test_start_with_description_as_multiple_params,"def test_start_with_description_as_multiple_params(cli, entries_file):
    """"""
    Description can either be entered as a single quoted param or as multiple params, in which case it will be joined
    with space characters.
    """"""
    expected = """"""20/01/2014

alias_1 09:00-? Play ping-pong
""""""

    with freeze_time('2014-01-20 09:00:00'):
        cli('start', ['alias_1', 'Play', 'ping-pong'])
    assert entries_file.read() == expected
",False
1790,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_start.py,,test_start_with_description_uses_description,"def test_start_with_description_uses_description(cli, entries_file):
    expected = """"""20/01/2014

alias_1 09:00-? Play ping-pong
""""""

    with freeze_time('2014-01-20 09:00:00'):
        cli('start', ['alias_1', 'Play ping-pong'])
    assert entries_file.read() == expected


",False
1791,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_start.py,,test_use_previous_end_time_as_start_time,"def test_use_previous_end_time_as_start_time(cli, entries_file):
    entries = """"""20/01/2014
alias_1 09:00-10:00 foobar
""""""
    expected = """"""20/01/2014
alias_1 09:00-10:00 foobar
alias_1 10:00-? ?
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20'):
        cli('start', ['alias_1'])
    assert entries_file.read() == expected


",False
1792,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_local_alias,"def test_local_alias(cli, config, entries_file):
    config.set('local_aliases', '_pingpong', '')

    entries_file.write(""""""20/01/2014
_pingpong 0800-0900 Play ping-pong
"""""")
    stdout = cli('status')

    assert line_in(""_pingpong  ( 1.00)  Play ping-pong"", stdout)


@freeze_time('2014-01-20')
",False
1793,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_not_today_excludes_todays_entries,"def test_not_today_excludes_todays_entries(cli, entries_file):
    entries_file.write(""""""20/01/2014
alias_1 1 Visible entry

21/01/2014
alias_1 1 Invisible entry

22/01/2014
alias_1 1 Visible entry

23/01/2014
alias_1 1 Visible entry
"""""")
    stdout = cli('status', ['--not-today'])

    assert 'Invisible entry' not in stdout
    assert 'Visible entry' in stdout
",False
1794,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_regroup_entries_setting,"def test_regroup_entries_setting(cli, config, entries_file):
    config.set('taxi', 'regroup_entries', '0')
    entries_file.write(""""""20/01/2014
alias_1 0800-0900 Play ping-pong
alias_1 1200-1300 Play ping-pong
"""""")

    stdout = cli('status')
    assert line_in(
        ""alias_1        1.00  Play ping-pong"",
        stdout
    )


@freeze_time('2014-01-20')
",False
1795,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_regrouped_entries,"def test_regrouped_entries(cli, entries_file):
    entries_file.write(""""""20/01/2014
alias_1 0800-0900 Play ping-pong
alias_1 1200-1300 Play ping-pong
"""""")

    stdout = cli('status')
    assert line_in(
        ""alias_1 2.00  Play ping-pong"",
        stdout
    )


@freeze_time('2014-01-20')
",False
1796,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_since_and_until_parameters_limit_dates_to_boundaries,"def test_since_and_until_parameters_limit_dates_to_boundaries(cli, entries_file):
    entries_file.write(""""""20/01/2014
alias_1 1 Invisible entry

21/01/2014
alias_1 1 Visible entry

22/01/2014
alias_1 1 Visible entry

23/01/2014
alias_1 1 Invisible entry
"""""")
    stdout = cli('status', ['--since=21.01.2014', '--until=22.01.2014'])

    assert 'Invisible entry' not in stdout


@freeze_time('2014-01-21')
",False
1797,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_status_doesnt_show_pushed_entries,"def test_status_doesnt_show_pushed_entries(cli, config, entries_file):
    config.set_dict({
        'test_aliases': {'alias_1': '123/456', 'alias_2': '456/789'}
    })
    entries_file.write(""""""20/01/2014
= alias_1 0800-0900 Play ping-pong
alias_2 1200-1300 Play ping-pong
"""""")

    stdout = cli('status')

    assert 'alias_1' not in stdout


@freeze_time('2014-01-20')
",False
1798,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_status_ignored_not_mapped,"def test_status_ignored_not_mapped(cli, entries_file):
    entries_file.write(""""""20/01/2014
? unmapped 0800-0900 Play ping-pong
"""""")

    stdout = cli('status')
    assert line_in(
        ""unmapped (ignored, inexistent alias) 1.00  Play ping-pong"",
        stdout
    )


@freeze_time('2014-01-20')
",False
1799,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_status_previous_file,"def test_status_previous_file(cli, config, data_dir):
    config.set('taxi', 'nb_previous_files', '1')
    efg = EntriesFileGenerator(data_dir, '%m_%Y.tks')
    efg.expand(datetime.date(2014, 1, 1)).write(
        ""01/01/2014\nalias_1 1 january""
    )
    efg.expand(datetime.date(2014, 2, 1)).write(
        ""01/02/2014\nalias_1 1 february""
    )
    efg.patch_config(config)

    stdout = cli('status')

    assert 'january' in stdout
    assert 'february' in stdout


@freeze_time('2014-01-20')
",False
1800,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_status_pushed_option_shows_pushed_entries,"def test_status_pushed_option_shows_pushed_entries(cli, config, entries_file):
    config.set_dict({
        'test_aliases': {'alias_1': '123/456', 'alias_2': '456/789'}
    })
    entries_file.write(""""""20/01/2014
= alias_1 0800-0900 Play ping-pong
alias_2 1200-1300 Play ping-pong
"""""")

    stdout = cli('status', ['--pushed'])
    assert 'alias_1' in stdout


",False
1801,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_status.py,,test_today_only_shows_todays_entries,"def test_today_only_shows_todays_entries(cli, entries_file):
    entries_file.write(""""""20/01/2014
alias_1 1 Invisible entry

21/01/2014
alias_1 1 Visible entry

22/01/2014
alias_1 1 Invisible entry

23/01/2014
alias_1 1 Invisible entry
"""""")
    stdout = cli('status', ['--today'])

    assert 'Invisible entry' not in stdout
    assert 'Visible entry' in stdout


@freeze_time('2014-01-21')
",False
1802,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_stop.py,,test_description_entry_present,"def test_description_entry_present(cli, entries_file):
    entries = """"""20/01/2014
alias_1 10:00-? Play tennis
""""""
    expected = """"""20/01/2014
alias_1 10:00-10:15 Play ping-pong
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20 10:10:00'):
        cli('stop', ['Play ping-pong'])

    assert entries_file.read() == expected


",False
1803,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_stop.py,,test_round_next_quarter,"def test_round_next_quarter(cli, entries_file):
    entries = """"""20/01/2014
alias_1 10:00-? ?
""""""
    expected = """"""20/01/2014
alias_1 10:00-10:15 Play ping-pong
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20 10:01:00'):
        cli('stop', ['Play ping-pong'])

    assert entries_file.read() == expected


",False
1804,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_stop.py,,test_round_with_custom_duration,"def test_round_with_custom_duration(cli, entries_file, config):
    config.set('taxi', 'round_entries', '5')

    entries = """"""20/01/2014
alias_1 10:00-? ?
""""""
    expected = """"""20/01/2014
alias_1 10:00-10:05 Play ping-pong
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20 10:01:00'):
        cli('stop', ['Play ping-pong'])

    assert entries_file.read() == expected


",False
1805,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_stop.py,,test_stop_in_the_past,"def test_stop_in_the_past(cli, entries_file):
    entries = """"""20/01/2014
alias_1 10:00-? ?
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20 09:30:00'):
        output = cli('stop', ['Play ping-pong'])

    assert output == 'Error: You are trying to stop an activity in the future\n'


",False
1806,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_stop.py,,test_stop_with_chained_duration,"def test_stop_with_chained_duration(cli, entries_file):
    entries = """"""20/01/2014
alias_1 09:00-10:00 foobar
alias_1 -? baz
""""""
    expected = """"""20/01/2014
alias_1 09:00-10:00 foobar
alias_1 -11:00 baz
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20 11:00:00'):
        cli('stop')
    assert entries_file.read() == expected
",False
1807,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_stop.py,,test_stop_with_non_parsable_entry,"def test_stop_with_non_parsable_entry(cli, entries_file):
    entries = """"""20/01/2014
alias 10:00-ff:ff Play ping-pong
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20'):
        output = cli('stop', ['Play ping-pong'])

    assert output.startswith('Error: Parse error')


",False
1808,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_stop.py,,test_stop_without_activity_started,"def test_stop_without_activity_started(cli, entries_file):
    entries = """"""20/01/2014
alias_1 10:00-10:30 Play ping-pong
""""""

    entries_file.write(entries)
    with freeze_time('2014-01-20 10:15:00'):
        output = cli('stop', ['Play ping-pong'])

    assert output == ""Error: You don't have any activity in progress for today\n""


",False
1809,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/commands/test_update.py,,test_update_doesnt_clean_local_aliases,"def test_update_doesnt_clean_local_aliases(cli, config):
    config.set('local_aliases', '_local1', '')
    stdout = cli('update')
    assert '_local1' not in stdout
",False
1810,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/test_projects_db.py,,test_legacy_projects_db,"def test_legacy_projects_db(tmpdir):
    projects_db_file = tmpdir.join(projects.ProjectsDb.PROJECTS_FILE)

    local_projects_db = projects.LocalProjectsDb()
    foo = pickle.dumps(local_projects_db)

    with projects_db_file.open(mode='wb') as f:
        f.write(foo)

    p = projects.ProjectsDb(tmpdir.strpath)
    with pytest.raises(projects.OutdatedProjectsDbException):
        p.get_projects()


",False
1811,https://github.com/sephii/taxi/blob/a330f044017c2862ba41fd7fa2e5f35d8807f968/tests/test_projects_db.py,,test_outdated_projects_db,"def test_outdated_projects_db(tmpdir):
    # Simulate a projects db version change
    projects.LocalProjectsDb.VERSION = 1
    try:
        p = projects.ProjectsDb(tmpdir.strpath)
        p.update([])
    finally:
        projects.LocalProjectsDb.VERSION = 2

    with pytest.raises(projects.OutdatedProjectsDbException):
        p.get_projects()
",False
1812,https://github.com/cesar-rodriguez/terrascan/blob/fd4ca9d23e694185fd5cb9ddf357b52b15adc6ca/tests/test_terrascan.py,,test_success,"def test_success():
    """"""
    Test successful terraform templates
    """"""
    with pytest.raises(SystemExit) as pytest_wrapped_e:
        terrascan.main([
            '-l',
            'tests/infrastructure/success',
        ])
    assert pytest_wrapped_e.value.code == 0
    
",True
1813,https://github.com/ioos/thredds_crawler/blob/fb29ea2fb8d079cacc6c09f79245e8f54f77c6a6/thredds_crawler/tests/test_crawler.py,CrawlerTest,test_iso_links,"def test_iso_links(self):
        c = Crawl(""http://thredds.axiomdatascience.com/thredds/global.xml"")
        isos = [s.get(""url"") for d in c.datasets for s in d.services if s.get(""service"").lower() == ""iso""]
        assert ""?dataset="" in isos[0]
        assert ""&catalog="" in isos[0]

    ",False
1814,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1815,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1816,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1817,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1818,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1819,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1820,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1821,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1822,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1823,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1824,https://github.com/tmurph/todo-sync/blob/32915e9a1509aa2c4083613e256cb0d502c441aa/tests/test_org_to_asana.py,,test_o2a_behind_make_fn,"def test_o2a_behind_make_fn(a_node, expected_node, behind_source):
    ""Does the Org Source have a special make_fn method?""
    o_node = behind_source.make_fn(a_node)
    assert_trees_equal_p(o_node, expected_node, ['id'])


@pytest.mark.parametrize(""o_node, a_node, expected"", [
    (mapped_mock_headline_node(), mapped_mock_task_node(), True),
    (mapped_mock_headline_node({'title': 'On the other hand ...'}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_headline_node({'title': 'On the other hand ...',
                                'asana_id': str(MOCK_TASK_ID)}),
     mapped_mock_task_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_project_node({'name': 'My Inbox'}),
     True),
    (mapped_mock_filename_node({'id': 'On the other hand ...'}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     False),
    (mapped_mock_filename_node({'id': 'On the other hand ...',
                                'asana_project_id': str(MOCK_PROJECT_ID)}),
     mapped_mock_project_node({'name': 'On the one hand ...'}),
     True),
    (mapped_mock_headline_node, mapped_mock_project_node(), False),
    (mapped_mock_headline_node({'title': 'A ""project"" headline'}),
     mapped_mock_project_node({'name': 'A ""project"" headline'}),
     False),
    (mapped_mock_filename_node(), mapped_mock_task_node(), False),
    (mapped_mock_filename_node({'id': 'My Inbox'}),
     mapped_mock_task_node({'name': 'My Inbox'}),
     False)])
",True
1825,https://github.com/dowjones/tokendito/blob/f5d8e5171ddcca0c62925263ddb80535f51aded3/tests/functional_test.py,,test_package_exists,"def test_package_exists():
    """"""Check whether the package is installed.""""""
    proc = run_process([sys.executable, '-m', 'pip', 'show', 'tokendito'])
    assert not proc['stderr']
    assert proc['exit_status'] == 0


@pytest.mark.parametrize('runnable', [[sys.executable, '-m', 'tokendito', '--version'],
                                      [sys.executable, sys.path[0] + '/tokendito/tokendito.py',
                                       '--version'],
                                      ['tokendito', '--version']])
",True
1826,https://github.com/dowjones/tokendito/blob/f5d8e5171ddcca0c62925263ddb80535f51aded3/tests/functional_test.py,,test_version,"def test_version(package_version, package_regex, runnable):
    """"""Check if the package version is the same when running in different ways.""""""
    proc = run_process(runnable)
    assert not proc['stderr']
    assert proc['exit_status'] == 0
    match = re.match(package_regex, proc['stdout'])
    local_version = match.group('version')
    assert package_version == local_version


@pytest.mark.run('second-to-last')
",True
1827,https://github.com/dowjones/tokendito/blob/f5d8e5171ddcca0c62925263ddb80535f51aded3/tests/unit_test.py,,test_set_okta_password,"def test_set_okta_password(monkeypatch):
    """"""Test whether data sent is the same as data returned.""""""
    from tokendito import helpers, settings
    import getpass

    monkeypatch.setattr(getpass, 'getpass', lambda: 'pytest_patched')
    val = helpers.set_okta_password()

    assert val == 'pytest_patched'
    assert settings.okta_password == 'pytest_patched'


@pytest.mark.parametrize('url,expected', [
    ('pytest_deadbeef', False),
    ('http://acme.org/', False),
    ('https://acme.okta.org/app/UserHome', False),
    ('http://login.acme.org/home/amazon_aws/0123456789abcdef0123/456', False),
    ('https://login.acme.org/home/amazon_aws/0123456789abcdef0123/456', True),
    ('https://acme.okta.org/home/amazon_aws/0123456789abcdef0123/456?fromHome=true', True)])
",True
1828,https://github.com/dowjones/tokendito/blob/f5d8e5171ddcca0c62925263ddb80535f51aded3/tests/unit_test.py,,test_set_okta_username,"def test_set_okta_username(monkeypatch):
    """"""Test whether data sent is the same as data returned.""""""
    from tokendito import helpers, settings

    monkeypatch.setattr('tokendito.helpers.input', lambda _: 'pytest_patched')
    val = helpers.set_okta_username()

    assert val == 'pytest_patched'
    assert settings.okta_username == 'pytest_patched'


",True
1829,https://github.com/PiotrDabkowski/torchpwl/blob/73b09cfa9f4c173988d8f075485b887c694fc5a8/torchpwl/pwl_test.py,,test_pwl_default_init_response,"def test_pwl_default_init_response(pwl_module, num_channels, num_breakpoints):
    module = pwl_module(
        num_channels=num_channels, num_breakpoints=num_breakpoints)
    x = get_x(num_channels)
    y = module(x)
    # Should initialize to y = x by default.
    expected_y = x
    assert torch.max(torch.abs(y - expected_y)) < TOLERANCE


@pytest.mark.parametrize(""pwl_module"", [MonoSlopedPWL])
@pytest.mark.parametrize(""num_channels"", [1, 3])
@pytest.mark.parametrize(""num_breakpoints"", [1, 7])
@pytest.mark.parametrize(""monotonicity"", [-1, 0, 1])
",True
1830,https://github.com/PiotrDabkowski/torchpwl/blob/73b09cfa9f4c173988d8f075485b887c694fc5a8/torchpwl/pwl_test.py,,test_pwl_is_continous,"def test_pwl_is_continous(pwl_module, num_channels, num_breakpoints):
    module = pwl_module(
        num_channels=num_channels, num_breakpoints=num_breakpoints)
    with torch.no_grad():
        for parameter in module.parameters():
            parameter.normal_()
    x = torch.linspace(
        -4., 4., steps=10000).unsqueeze(1).expand(-1, num_channels)
    y = module(x)
    dy = torch.roll(y, shifts=-1, dims=0) - y
    dx = torch.roll(x, shifts=-1, dims=0) - x
    grad = dy / dx
    if isinstance(module, (PointPWL, MonoPointPWL)):
        allowed_grad = torch.max(4 / module.get_spreads())
    else:
        allowed_grad = 4
    assert torch.max(abs(grad)) < allowed_grad


@pytest.mark.parametrize(""pwl_module"", [SlopedPWL, MonoSlopedPWL])
@pytest.mark.parametrize(""num_channels"", [1, 3])
@pytest.mark.parametrize(""num_breakpoints"", [1, 2, 3, 4])
@pytest.mark.parametrize(
    ""optimizer_fn"",
    [
        #lambda params: torch.optim.SGD(params=params, lr=0.1, momentum=0.5),
        lambda params: torch.optim.Adam(params=params, lr=0.2),
    ])
",False
1831,https://github.com/PiotrDabkowski/torchpwl/blob/73b09cfa9f4c173988d8f075485b887c694fc5a8/torchpwl/pwl_test.py,,test_pwl_is_continous,"def test_pwl_is_continous(pwl_module, num_channels, num_breakpoints):
    module = pwl_module(
        num_channels=num_channels, num_breakpoints=num_breakpoints)
    with torch.no_grad():
        for parameter in module.parameters():
            parameter.normal_()
    x = torch.linspace(
        -4., 4., steps=10000).unsqueeze(1).expand(-1, num_channels)
    y = module(x)
    dy = torch.roll(y, shifts=-1, dims=0) - y
    dx = torch.roll(x, shifts=-1, dims=0) - x
    grad = dy / dx
    if isinstance(module, (PointPWL, MonoPointPWL)):
        allowed_grad = torch.max(4 / module.get_spreads())
    else:
        allowed_grad = 4
    assert torch.max(abs(grad)) < allowed_grad


@pytest.mark.parametrize(""pwl_module"", [SlopedPWL, MonoSlopedPWL])
@pytest.mark.parametrize(""num_channels"", [1, 3])
@pytest.mark.parametrize(""num_breakpoints"", [1, 2, 3, 4])
@pytest.mark.parametrize(
    ""optimizer_fn"",
    [
        #lambda params: torch.optim.SGD(params=params, lr=0.1, momentum=0.5),
        lambda params: torch.optim.Adam(params=params, lr=0.2),
    ])
",True
1832,https://github.com/PiotrDabkowski/torchpwl/blob/73b09cfa9f4c173988d8f075485b887c694fc5a8/torchpwl/pwl_test.py,,test_pwl_is_continous,"def test_pwl_is_continous(pwl_module, num_channels, num_breakpoints):
    module = pwl_module(
        num_channels=num_channels, num_breakpoints=num_breakpoints)
    with torch.no_grad():
        for parameter in module.parameters():
            parameter.normal_()
    x = torch.linspace(
        -4., 4., steps=10000).unsqueeze(1).expand(-1, num_channels)
    y = module(x)
    dy = torch.roll(y, shifts=-1, dims=0) - y
    dx = torch.roll(x, shifts=-1, dims=0) - x
    grad = dy / dx
    if isinstance(module, (PointPWL, MonoPointPWL)):
        allowed_grad = torch.max(4 / module.get_spreads())
    else:
        allowed_grad = 4
    assert torch.max(abs(grad)) < allowed_grad


@pytest.mark.parametrize(""pwl_module"", [SlopedPWL, MonoSlopedPWL])
@pytest.mark.parametrize(""num_channels"", [1, 3])
@pytest.mark.parametrize(""num_breakpoints"", [1, 2, 3, 4])
@pytest.mark.parametrize(
    ""optimizer_fn"",
    [
        #lambda params: torch.optim.SGD(params=params, lr=0.1, momentum=0.5),
        lambda params: torch.optim.Adam(params=params, lr=0.2),
    ])
",False
1833,https://github.com/PiotrDabkowski/torchpwl/blob/73b09cfa9f4c173988d8f075485b887c694fc5a8/torchpwl/pwl_test.py,,test_pwl_is_continous,"def test_pwl_is_continous(pwl_module, num_channels, num_breakpoints):
    module = pwl_module(
        num_channels=num_channels, num_breakpoints=num_breakpoints)
    with torch.no_grad():
        for parameter in module.parameters():
            parameter.normal_()
    x = torch.linspace(
        -4., 4., steps=10000).unsqueeze(1).expand(-1, num_channels)
    y = module(x)
    dy = torch.roll(y, shifts=-1, dims=0) - y
    dx = torch.roll(x, shifts=-1, dims=0) - x
    grad = dy / dx
    if isinstance(module, (PointPWL, MonoPointPWL)):
        allowed_grad = torch.max(4 / module.get_spreads())
    else:
        allowed_grad = 4
    assert torch.max(abs(grad)) < allowed_grad


@pytest.mark.parametrize(""pwl_module"", [SlopedPWL, MonoSlopedPWL])
@pytest.mark.parametrize(""num_channels"", [1, 3])
@pytest.mark.parametrize(""num_breakpoints"", [1, 2, 3, 4])
@pytest.mark.parametrize(
    ""optimizer_fn"",
    [
        #lambda params: torch.optim.SGD(params=params, lr=0.1, momentum=0.5),
        lambda params: torch.optim.Adam(params=params, lr=0.2),
    ])
",True
1834,https://github.com/PiotrDabkowski/torchpwl/blob/73b09cfa9f4c173988d8f075485b887c694fc5a8/torchpwl/pwl_test.py,,test_pwl_is_continous,"def test_pwl_is_continous(pwl_module, num_channels, num_breakpoints):
    module = pwl_module(
        num_channels=num_channels, num_breakpoints=num_breakpoints)
    with torch.no_grad():
        for parameter in module.parameters():
            parameter.normal_()
    x = torch.linspace(
        -4., 4., steps=10000).unsqueeze(1).expand(-1, num_channels)
    y = module(x)
    dy = torch.roll(y, shifts=-1, dims=0) - y
    dx = torch.roll(x, shifts=-1, dims=0) - x
    grad = dy / dx
    if isinstance(module, (PointPWL, MonoPointPWL)):
        allowed_grad = torch.max(4 / module.get_spreads())
    else:
        allowed_grad = 4
    assert torch.max(abs(grad)) < allowed_grad


@pytest.mark.parametrize(""pwl_module"", [SlopedPWL, MonoSlopedPWL])
@pytest.mark.parametrize(""num_channels"", [1, 3])
@pytest.mark.parametrize(""num_breakpoints"", [1, 2, 3, 4])
@pytest.mark.parametrize(
    ""optimizer_fn"",
    [
        #lambda params: torch.optim.SGD(params=params, lr=0.1, momentum=0.5),
        lambda params: torch.optim.Adam(params=params, lr=0.2),
    ])
",False
1835,https://github.com/rduldulao/tornado-swirl/blob/b8df27efc3d7fd0dce0f0290767c94ac2e747311/tests/test_swirl.py,TestSampleEndpoints,test_security_scheme1,"def test_security_scheme1(self):
        self.reset_settings()
        swirl.describe(title='My API', description='My description')
        swirl.add_security_scheme(""test_basic"", security.HTTP(""basic""))
        @swirl.restapi(""/test"")
        class Handler(RequestHandler):

            ",True
1836,https://github.com/rduldulao/tornado-swirl/blob/b8df27efc3d7fd0dce0f0290767c94ac2e747311/tests/test_swirl.py,TestSampleEndpoints,test_security_scheme2,"def test_security_scheme2(self):
        self.reset_settings()
        swirl.describe(title='My API', description='My description')
        swirl.add_security_scheme(""test_basic"", security.HTTP(""bearer"", bearerFormat=""JWT""))
        @swirl.restapi(""/test"")
        class Handler(RequestHandler):

            ",True
1837,https://github.com/transceptor-technology/trender/blob/ef2b7374ea2ecc83dceb139b358ec4ad8ce7033b/test/test_trender.py,TestTRender,test_simple_performance,"def test_simple_performance(self):
        template = '''
        #if @test:
            test is true
        #else:
            test is false
        #end
        #block Person:
        name: @person.name
        #end
        #for @person in @people:
            #Person
        #end'''
        namespace = {
            'test': True,
            'people': [
                {'name': 'Iris'},
                {'name': 'Sasha'}]}
        compiled = TRender(template)
        start = time.time()
        for _ in range(10 ** 4):
            compiled.render(namespace)
        finished = time.time() - start
        # This should be easy below 1.0, even on slower computers
        self.assertLess(finished, 1.0)

    ",False
1870,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_counts,"def test_counts(fake_exp):
    counts = fake_exp._counts
    assert counts['containers'] == 4
    assert counts['cells'] == 24
    assert counts['colonies'] == 4
    assert counts['lineages'] == 12  # number of leaves when no filter is applied
",True
1871,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_experiment_abspath,"def test_experiment_abspath(fake_exp):
    assert fake_exp.abspath == path_fake_exp


",True
1872,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_experiment_attributes,"def test_experiment_attributes(fake_exp):
    attrs = ['label', 'abspath', 'metadata', 'datatype', 'filetype',
             'containers']
    for attr in attrs:
        assert hasattr(fake_exp, attr)


",True
1873,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_experiment_datatype,"def test_experiment_datatype(fake_exp):
    assert len(fake_exp.datatype) == 4
    assert 'cellID' in list(zip(*fake_exp.datatype))[0]


",True
1874,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_experiment_get_container,"def test_experiment_get_container(fake_exp):
    container = fake_exp.get_container('container_01')
    assert isinstance(container, Container)
    

",True
1875,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_experiment_iter,"def test_experiment_iter(fake_exp):
    meths = ['iter_containers']
    for meth in meths:
        method = getattr(fake_exp, meth)
        assert callable(method)


",True
1876,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_experiment_label,"def test_experiment_label(fake_exp):
    assert fake_exp.label == 'fake'


",True
1877,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_experiment_metadata,"def test_experiment_metadata(fake_exp):
    assert fake_exp.metadata['author'] == 'Joachim Rambeau'


",True
1878,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_experiment_number_container,"def test_experiment_number_container(fake_exp):
    assert len(fake_exp.containers) == 4


",True
1879,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_experiment.py,,test_load_experiment,"def test_load_experiment(fake_exp):
    assert isinstance(fake_exp, Experiment)


",True
1880,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_filters.py,,test_cell_any,"def test_cell_any():
    filt = FilterCellAny()
    assert filt._type == 'CELL'
    assert filt.label == 'CELL, Always True'
    assert filt._obs == []
    assert filt('whatever')  # always True


",True
1881,https://github.com/LeBarbouze/tunacell/blob/837d57e1e6caeddf2e6bcdd2db2986fb456dd605/tunacell/tests/test_observable.py,,test_observable_str,"def test_observable_str(all_params):
    """"""This test checks codestring obtained using __str__

    Randomly instantiate a given observable <obs>
    Check that second instance made from str(obs) is identical.
    """"""
    for kwargs in all_params:
        obs = Observable(**kwargs)
        nobs = Observable(from_string=str(obs))
        for attr in obs._attr_names:
            if attr == 'time_window' and not obs.local_fit:
                # check only if local_fit is True,
                # since when it's false, time_window is not printed in str
                continue
            assert hasattr(nobs, attr)
            assert getattr(nobs, attr) == getattr(obs, attr)


",True
1882,https://github.com/eukaryote/uberdict/blob/852b9d8b80ab032ce7eb5c439ea8084336b69d04/tests/test_uberdict.py,,test_pickle_dumpsloads_dotted,"def test_pickle_dumpsloads_dotted():
    orig = udict({'one.two': 'one.two'})
    pickled = pickle.dumps(orig)
    unpickled = pickle.loads(pickled)
    assert items(unpickled) == items(orig)


",True
1883,https://github.com/eukaryote/uberdict/blob/852b9d8b80ab032ce7eb5c439ea8084336b69d04/tests/test_uberdict.py,,test_pickle_dumpsloads_nested,"def test_pickle_dumpsloads_nested():
    orig = udict({'one': {'two': 'one->two'}})
    unpickled = pickle.loads(pickle.dumps(orig))
    assert items(unpickled) == items(orig)


",True
1884,https://github.com/eukaryote/uberdict/blob/852b9d8b80ab032ce7eb5c439ea8084336b69d04/tests/test_uberdict.py,,test_pickle_dumpsloads_nested_dotted,"def test_pickle_dumpsloads_nested_dotted():
    orig = udict.fromdict({
        'one': {
            'two': 'one->two'
        },
        'one.two': 'one.two'
    })
    unpickled = pickle.loads(pickle.dumps(orig))
    # assert unpickled == orig
    assert items(unpickled) == items(orig)
    assert isinstance(unpickled, udict)
    assert isinstance(unpickled['one'], udict)


",True
1885,https://github.com/eukaryote/uberdict/blob/852b9d8b80ab032ce7eb5c439ea8084336b69d04/tests/test_uberdict.py,,test_pickle_dumpsloads_simple,"def test_pickle_dumpsloads_simple():
    orig = udict({'one': 1, 'two': 2})
    unpickled = pickle.loads(pickle.dumps(orig))
    assert items(unpickled) == items(orig)
    assert isinstance(unpickled, udict)


",True
1886,https://github.com/timkostka/ucal/blob/df0ccbc5f8af54fc69df56191bd810481a17b0e3/tests/test_ucal.py,TestSyntax,test_function_ln,"def test_function_ln(self):
        """"""Test ln function.""""""
        self.assertEqual(ucal.evaluate('ln(exp(1))'), '1')
        self.assertEqual(ucal.evaluate('ln(1)'), '0')
        self.assertRaises(ucal.QuantityError, ucal.evaluate, 'ln(1m)')

    ",True
1887,https://github.com/timkostka/ucal/blob/df0ccbc5f8af54fc69df56191bd810481a17b0e3/tests/test_ucal.py,TestSyntax,test_function_log,"def test_function_log(self):
        """"""Test log function.""""""
        self.assertEqual(ucal.evaluate('log(exp(1))'), '1')
        self.assertEqual(ucal.evaluate('log(1)'), '0')
        self.assertRaises(ucal.QuantityError, ucal.evaluate, 'log(1m)')

    ",True
1888,https://github.com/willforde/urlquick/blob/db765372b73800cfa056047a3f3331820abd4ae8/tests/test_urlquick.py,TestCacheHandler,test_cache_check_no_cache,"def test_cache_check_no_cache(self):
        cache = urlquick.CacheAdapter()
        ret = cache.cache_check(""GET"", ""https://httpbin.org/get"", None, {})
        self.assertIsNone(ret)

    ",True
1889,https://github.com/crumpstrr33/Utter-More/blob/418cf5f5ef337700bf0897e746eff8bb275e6da6/test/test_utter_more.py,,test_saving_utterances,"def test_saving_utterances(global_um, tmpdir, fname, saved_as, written_as):
    """"""
    Test the saving methods of UtterMore
    """"""
    written_as = written_as or saved_as
    test_dir = path.join(path.dirname(path.realpath(__file__)), 'test_files')

    if fname == 'alexa_test':
        global_um.save_for_alexa(tmpdir, fname)
    else:
        global_um.save_utterances(tmpdir, fname, saved_as, written_as=written_as)

    file_name = fname + '.' + saved_as
    assert filecmp.cmp(path.join(test_dir, file_name),
                       tmpdir.join(file_name))
",True
1890,https://github.com/crumpstrr33/Utter-More/blob/418cf5f5ef337700bf0897e746eff8bb275e6da6/test/test_utter_more.py,,test_saving_utterances,"def test_saving_utterances(global_um, tmpdir, fname, saved_as, written_as):
    """"""
    Test the saving methods of UtterMore
    """"""
    written_as = written_as or saved_as
    test_dir = path.join(path.dirname(path.realpath(__file__)), 'test_files')

    if fname == 'alexa_test':
        global_um.save_for_alexa(tmpdir, fname)
    else:
        global_um.save_utterances(tmpdir, fname, saved_as, written_as=written_as)

    file_name = fname + '.' + saved_as
    assert filecmp.cmp(path.join(test_dir, file_name),
                       tmpdir.join(file_name))
",True
1891,https://github.com/crumpstrr33/Utter-More/blob/418cf5f5ef337700bf0897e746eff8bb275e6da6/test/test_utter_more.py,,test_saving_utterances,"def test_saving_utterances(global_um, tmpdir, fname, saved_as, written_as):
    """"""
    Test the saving methods of UtterMore
    """"""
    written_as = written_as or saved_as
    test_dir = path.join(path.dirname(path.realpath(__file__)), 'test_files')

    if fname == 'alexa_test':
        global_um.save_for_alexa(tmpdir, fname)
    else:
        global_um.save_utterances(tmpdir, fname, saved_as, written_as=written_as)

    file_name = fname + '.' + saved_as
    assert filecmp.cmp(path.join(test_dir, file_name),
                       tmpdir.join(file_name))
",True
1892,https://github.com/crumpstrr33/Utter-More/blob/418cf5f5ef337700bf0897e746eff8bb275e6da6/test/test_utter_more.py,,test_saving_utterances,"def test_saving_utterances(global_um, tmpdir, fname, saved_as, written_as):
    """"""
    Test the saving methods of UtterMore
    """"""
    written_as = written_as or saved_as
    test_dir = path.join(path.dirname(path.realpath(__file__)), 'test_files')

    if fname == 'alexa_test':
        global_um.save_for_alexa(tmpdir, fname)
    else:
        global_um.save_utterances(tmpdir, fname, saved_as, written_as=written_as)

    file_name = fname + '.' + saved_as
    assert filecmp.cmp(path.join(test_dir, file_name),
                       tmpdir.join(file_name))
",True
1893,https://github.com/Osirium/vcdriver/blob/2f311df9a73c82b5837d01bac16a10eb4db955eb/test/unit/test_config.py,,test_read,"def test_read(config_files):
    assert read() == {
        'Vsphere Session': {
            'vcdriver_host': '',
            'vcdriver_port': '443',
            'vcdriver_username': '',
            'vcdriver_password': ''
        },
        'Virtual Machine Deployment': {
            'vcdriver_resource_pool': '',
            'vcdriver_data_store': '',
            'vcdriver_data_store_threshold': '0',
            'vcdriver_folder': ''
        },
        'Virtual Machine Remote Management': {
            'vcdriver_vm_ssh_username': '',
            'vcdriver_vm_ssh_password': '',
            'vcdriver_vm_winrm_username': '',
            'vcdriver_vm_winrm_password': ''
        }
    }
    load('config_file_3.cfg')
    assert read() == {
        'Vsphere Session': {
            'vcdriver_host': '',
            'vcdriver_port': '443',
            'vcdriver_username': '',
            'vcdriver_password': 'myway'
        },
        'Virtual Machine Deployment': {
            'vcdriver_resource_pool': '',
            'vcdriver_data_store': '',
            'vcdriver_data_store_threshold': '0',
            'vcdriver_folder': ''
        },
        'Virtual Machine Remote Management': {
            'vcdriver_vm_ssh_username': '',
            'vcdriver_vm_ssh_password': '',
            'vcdriver_vm_winrm_username': '',
            'vcdriver_vm_winrm_password': ''
        }
    }


",True
1894,https://github.com/WCraaS/wcraas_common/blob/af209ab412c18473edfaaf2871eef9c0357b91e9/tests/test_wcraas_common.py,,test_default_env_load,"def test_default_env_load():
    conf = AMQPConfig.fromenv()
    assert isinstance(conf, tuple)
    assert conf._fields == (""host"", ""port"", ""user"", ""password"")
    assert conf.host == ""localhost""
    assert conf.port == 5672
    assert conf.user == ""guest""
    assert conf.password == ""guest""

",True
1896,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_auth_with_invalid_pubkey_for_user_robey,"def test_app_auth_with_invalid_pubkey_for_user_robey(self):
        url = self.get_url('/')
        privatekey = 'h' * 1024
        files = [('privatekey', 'user_rsa_key', privatekey)]
        content_type, body = encode_multipart_formdata(self.body_dict.items(),
                                                       files)
        headers = {
            'Content-Type': content_type, 'content-length': str(len(body))
        }

        if swallow_http_errors:
            response = yield self.async_post(url, body, headers=headers)
            self.assertIn(b'Invalid key', response.body)
        else:
            with self.assertRaises(HTTPError) as ctx:
                yield self.async_post(url, body, headers=headers)
            self.assertIn('Bad Request', ctx.exception.message)

    @tornado.testing.gen_test
    ",True
1897,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_auth_with_pubkey_cannot_be_decoded_by_multipart_form,"def test_app_auth_with_pubkey_cannot_be_decoded_by_multipart_form(self):
        url = self.get_url('/')
        privatekey = 'h' * 1024
        files = [('privatekey', 'user_rsa_key', privatekey)]
        content_type, body = encode_multipart_formdata(self.body_dict.items(),
                                                       files)
        body = body.encode('utf-8')
        # added some gbk bytes to the privatekey, make it cannot be decoded
        body = body[:-100] + b'\xb4\xed\xce\xf3' + body[-100:]
        headers = {
            'Content-Type': content_type, 'content-length': str(len(body))
        }
        if swallow_http_errors:
            response = yield self.async_post(url, body, headers=headers)
            self.assertIn(b'Invalid unicode', response.body)
        else:
            with self.assertRaises(HTTPError) as ctx:
                yield self.async_post(url, body, headers=headers)
            self.assertIn('Bad Request', ctx.exception.message)

    ",True
1898,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_auth_with_pubkey_exceeds_key_max_size,"def test_app_auth_with_pubkey_exceeds_key_max_size(self):
        url = self.get_url('/')
        privatekey = 'h' * (handler.PrivateKey.max_length + 1)
        files = [('privatekey', 'user_rsa_key', privatekey)]
        content_type, body = encode_multipart_formdata(self.body_dict.items(),
                                                       files)
        headers = {
            'Content-Type': content_type, 'content-length': str(len(body))
        }
        if swallow_http_errors:
            response = yield self.async_post(url, body, headers=headers)
            self.assertIn(b'Invalid key', response.body)
        else:
            with self.assertRaises(HTTPError) as ctx:
                yield self.async_post(url, body, headers=headers)
            self.assertIn('Bad Request', ctx.exception.message)

    @tornado.testing.gen_test
    ",True
1899,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_auth_with_valid_pubkey_by_multipart_form,"def test_app_auth_with_valid_pubkey_by_multipart_form(self):
        url = self.get_url('/')
        privatekey = read_file(make_tests_data_path('user_rsa_key'))
        files = [('privatekey', 'user_rsa_key', privatekey)]
        content_type, body = encode_multipart_formdata(self.body_dict.items(),
                                                       files)
        headers = {
            'Content-Type': content_type, 'content-length': str(len(body))
        }
        response = yield self.async_post(url, body, headers=headers)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

        url = url.replace('http', 'ws')
        ws_url = url + 'ws?id=' + data['id']
        ws = yield tornado.websocket.websocket_connect(ws_url)
        msg = yield ws.read_message()
        self.assertEqual(to_str(msg, data['encoding']), banner)
        ws.close()

    @tornado.testing.gen_test
    ",True
1900,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_auth_with_valid_pubkey_by_urlencoded_form,"def test_app_auth_with_valid_pubkey_by_urlencoded_form(self):
        url = self.get_url('/')
        privatekey = read_file(make_tests_data_path('user_rsa_key'))
        self.body_dict.update(privatekey=privatekey)
        response = yield self.async_post(url, self.body_dict)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

        url = url.replace('http', 'ws')
        ws_url = url + 'ws?id=' + data['id']
        ws = yield tornado.websocket.websocket_connect(ws_url)
        msg = yield ws.read_message()
        self.assertEqual(to_str(msg, data['encoding']), banner)
        ws.close()

    @tornado.testing.gen_test
    ",True
1901,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_post_form_with_large_body_size_by_multipart_form,"def test_app_post_form_with_large_body_size_by_multipart_form(self):
        privatekey = 'h' * (2 * max_body_size)
        files = [('privatekey', 'user_rsa_key', privatekey)]
        content_type, body = encode_multipart_formdata(self.body_dict.items(),
                                                       files)
        headers = {
            'Content-Type': content_type, 'content-length': str(len(body))
        }
        response = self.sync_post('/', body, headers=headers)
        self.assertIn(response.code, [400, 599])

    ",True
1902,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_post_form_with_large_body_size_by_urlencoded_form,"def test_app_post_form_with_large_body_size_by_urlencoded_form(self):
        privatekey = 'h' * (2 * max_body_size)
        body = self.body + '&privatekey=' + privatekey
        response = self.sync_post('/', body)
        self.assertIn(response.code, [400, 599])

    @tornado.testing.gen_test
    ",True
1903,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_correct_credentials,"def test_app_with_correct_credentials(self):
        response = self.sync_post('/', self.body)
        self.assert_status_none(json.loads(to_str(response.body)))

    ",True
1904,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_correct_credentials_but_empty_id,"def test_app_with_correct_credentials_but_empty_id(self):
        url = self.get_url('/')
        response = yield self.async_post(url, self.body)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

        url = url.replace('http', 'ws')
        ws_url = url + 'ws?id='
        ws = yield tornado.websocket.websocket_connect(ws_url)
        msg = yield ws.read_message()
        self.assertIsNone(msg)
        self.assertIn('Missing value id', ws.close_reason)

    @tornado.testing.gen_test
    ",True
1905,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_correct_credentials_but_ip_not_matched,"def test_app_with_correct_credentials_but_ip_not_matched(self):
        url = self.get_url('/')
        response = yield self.async_post(url, self.body)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

        clients = handler.clients
        handler.clients = {}
        url = url.replace('http', 'ws')
        ws_url = url + 'ws?id=' + data['id']
        ws = yield tornado.websocket.websocket_connect(ws_url)
        msg = yield ws.read_message()
        self.assertIsNone(msg)
        self.assertEqual(ws.close_reason, 'Websocket authentication failed.')
        handler.clients = clients

    @tornado.testing.gen_test
    ",True
1906,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_correct_credentials_but_with_no_port,"def test_app_with_correct_credentials_but_with_no_port(self):
        default_port = handler.DEFAULT_PORT
        handler.DEFAULT_PORT = self.sshserver_port

        # with no port value
        body = self.body.replace(str(self.sshserver_port), '')
        response = self.sync_post('/', body)
        self.assert_status_none(json.loads(to_str(response.body)))

        # with no port argument
        body = body.replace('port=&', '')
        response = self.sync_post('/', body)
        self.assert_status_none(json.loads(to_str(response.body)))

        handler.DEFAULT_PORT = default_port

    @tornado.testing.gen_test
    ",True
1907,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_correct_credentials_but_without_id_argument,"def test_app_with_correct_credentials_but_without_id_argument(self):
        url = self.get_url('/')
        response = yield self.async_post(url, self.body)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

        url = url.replace('http', 'ws')
        ws_url = url + 'ws'
        ws = yield tornado.websocket.websocket_connect(ws_url)
        msg = yield ws.read_message()
        self.assertIsNone(msg)
        self.assertIn('Missing argument id', ws.close_reason)

    @tornado.testing.gen_test
    ",True
1908,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_correct_credentials_but_wrong_id,"def test_app_with_correct_credentials_but_wrong_id(self):
        url = self.get_url('/')
        response = yield self.async_post(url, self.body)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

        url = url.replace('http', 'ws')
        ws_url = url + 'ws?id=1' + data['id']
        ws = yield tornado.websocket.websocket_connect(ws_url)
        msg = yield ws.read_message()
        self.assertIsNone(msg)
        self.assertIn('Websocket authentication failed', ws.close_reason)

    @tornado.testing.gen_test
    ",True
1909,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_correct_credentials_timeout,"def test_app_with_correct_credentials_timeout(self):
        url = self.get_url('/')
        response = yield self.async_post(url, self.body)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

        url = url.replace('http', 'ws')
        ws_url = url + 'ws?id=' + data['id']
        yield tornado.gen.sleep(handler.DELAY + 0.1)
        ws = yield tornado.websocket.websocket_connect(ws_url)
        msg = yield ws.read_message()
        self.assertIsNone(msg)
        self.assertEqual(ws.close_reason, 'Websocket authentication failed.')

    @tornado.testing.gen_test
    ",True
1910,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_correct_credentials_user_bar,"def test_app_with_correct_credentials_user_bar(self):
        body = self.body.replace('robey', 'bar')
        url = self.get_url('/')
        response = yield self.async_post(url, body)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

        url = url.replace('http', 'ws')
        ws_url = url + 'ws?id=' + data['id']
        ws = yield tornado.websocket.websocket_connect(ws_url)
        msg = yield ws.read_message()
        self.assertEqual(to_str(msg, data['encoding']), banner)

        # messages below will be ignored silently
        yield ws.write_message('hello')
        yield ws.write_message('""hello""')
        yield ws.write_message('[hello]')
        yield ws.write_message(json.dumps({'resize': []}))
        yield ws.write_message(json.dumps({'resize': {}}))
        yield ws.write_message(json.dumps({'resize': 'ab'}))
        yield ws.write_message(json.dumps({'resize': ['a', 'b']}))
        yield ws.write_message(json.dumps({'resize': {'a': 1, 'b': 2}}))
        yield ws.write_message(json.dumps({'resize': [100]}))
        yield ws.write_message(json.dumps({'resize': [100]*10}))
        yield ws.write_message(json.dumps({'resize': [-1, -1]}))
        yield ws.write_message(json.dumps({'data': [1]}))
        yield ws.write_message(json.dumps({'data': (1,)}))
        yield ws.write_message(json.dumps({'data': {'a': 2}}))
        yield ws.write_message(json.dumps({'data': 1}))
        yield ws.write_message(json.dumps({'data': 2.1}))
        yield ws.write_message(json.dumps({'key-non-existed': 'hello'}))
        # end - those just for testing webssh websocket stablity

        yield ws.write_message(json.dumps({'resize': [79, 23]}))
        msg = yield ws.read_message()
        self.assertEqual(b'resized', msg)

        yield ws.write_message(json.dumps({'data': 'bye'}))
        msg = yield ws.read_message()
        self.assertEqual(b'bye', msg)
        ws.close()

    @tornado.testing.gen_test
    ",True
1911,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_correct_credentials_user_robey,"def test_app_with_correct_credentials_user_robey(self):
        url = self.get_url('/')
        response = yield self.async_post(url, self.body)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

        url = url.replace('http', 'ws')
        ws_url = url + 'ws?id=' + data['id']
        ws = yield tornado.websocket.websocket_connect(ws_url)
        msg = yield ws.read_message()
        self.assertEqual(to_str(msg, data['encoding']), banner)
        ws.close()

    @tornado.testing.gen_test
    ",True
1912,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_invalid_form_for_invalid_value,"def test_app_with_invalid_form_for_invalid_value(self):
        body = 'hostname=127.0.0&port=22&username=&password&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assert_response(b'Invalid hostname', response)

        body = 'hostname=http://www.googe.com&port=22&username=&password&_xsrf=yummy'  # noqa
        response = self.sync_post('/', body)
        self.assert_response(b'Invalid hostname', response)

        body = 'hostname=127.0.0.1&port=port&username=&password&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assert_response(b'Invalid port', response)

        body = 'hostname=127.0.0.1&port=70000&username=&password&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assert_response(b'Invalid port', response)

    ",True
1913,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_invalid_form_for_missing_argument,"def test_app_with_invalid_form_for_missing_argument(self):
        response = self.fetch('/')
        self.assertEqual(response.code, 200)

        body = 'port=7000&username=admin&password&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assert_response(b'Missing argument hostname', response)

        body = 'hostname=127.0.0.1&port=7000&password&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assert_response(b'Missing argument username', response)

        body = 'hostname=&port=&username=&password&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assert_response(b'Missing value hostname', response)

        body = 'hostname=127.0.0.1&port=7000&username=&password&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assert_response(b'Missing value username', response)

    ",True
1914,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_user_keyonly_for_bad_authentication_type,"def test_app_with_user_keyonly_for_bad_authentication_type(self):
        self.body_dict.update(username='keyonly', password='foo')
        response = yield self.async_post('/', self.body_dict)
        self.assertEqual(response.code, 200)
        self.assert_status_in('Bad authentication type', json.loads(to_str(response.body))) # noqa

    @tornado.testing.gen_test
    ",True
1915,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_user_pass2fa_with_correct_passwords,"def test_app_with_user_pass2fa_with_correct_passwords(self):
        self.body_dict.update(username='pass2fa', password='password',
                              totp='passcode')
        response = yield self.async_post('/', self.body_dict)
        self.assertEqual(response.code, 200)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

    @tornado.testing.gen_test
    ",True
1916,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_user_pass2fa_with_wrong_pkey_correct_passwords,"def test_app_with_user_pass2fa_with_wrong_pkey_correct_passwords(self):
        url = self.get_url('/')
        privatekey = read_file(make_tests_data_path('user_rsa_key'))
        self.body_dict.update(username='pass2fa', password='password',
                              privatekey=privatekey, totp='passcode')
        response = yield self.async_post(url, self.body_dict)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

    @tornado.testing.gen_test
    ",True
1917,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_user_pkey2fa_with_correct_passwords,"def test_app_with_user_pkey2fa_with_correct_passwords(self):
        url = self.get_url('/')
        privatekey = read_file(make_tests_data_path('user_rsa_key'))
        self.body_dict.update(username='pkey2fa', password='password',
                              privatekey=privatekey, totp='passcode')
        response = yield self.async_post(url, self.body_dict)
        data = json.loads(to_str(response.body))
        self.assert_status_none(data)

    @tornado.testing.gen_test
    ",True
1918,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_user_pkey2fa_with_empty_passcode,"def test_app_with_user_pkey2fa_with_empty_passcode(self):
        url = self.get_url('/')
        privatekey = read_file(make_tests_data_path('user_rsa_key'))
        self.body_dict.update(username='pkey2fa', password='password',
                              privatekey=privatekey, totp='')
        response = yield self.async_post(url, self.body_dict)
        data = json.loads(to_str(response.body))
        self.assert_status_in('Need a verification code', data)


class OtherTestBase(TestAppBase):
    sshserver_port = 3300
    headers = {'Cookie': '_xsrf=yummy'}
    debug = False
    policy = None
    xsrf = True
    hostfile = ''
    syshostfile = ''
    tdstream = ''
    maxconn = 20
    origin = 'same'
    encodings = []
    body = {
        'hostname': '127.0.0.1',
        'port': '',
        'username': 'robey',
        'password': 'foo',
        '_xsrf': 'yummy'
    }

    ",True
1919,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_user_pkey2fa_with_wrong_passcode,"def test_app_with_user_pkey2fa_with_wrong_passcode(self):
        url = self.get_url('/')
        privatekey = read_file(make_tests_data_path('user_rsa_key'))
        self.body_dict.update(username='pkey2fa', password='password',
                              privatekey=privatekey, totp='wrongpasscode')
        response = yield self.async_post(url, self.body_dict)
        data = json.loads(to_str(response.body))
        self.assert_status_in('Authentication failed', data)

    @tornado.testing.gen_test
    ",True
1920,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_user_pkey2fa_with_wrong_password,"def test_app_with_user_pkey2fa_with_wrong_password(self):
        url = self.get_url('/')
        privatekey = read_file(make_tests_data_path('user_rsa_key'))
        self.body_dict.update(username='pkey2fa', password='wrongpassword',
                              privatekey=privatekey, totp='passcode')
        response = yield self.async_post(url, self.body_dict)
        data = json.loads(to_str(response.body))
        self.assert_status_in('Authentication failed', data)

    @tornado.testing.gen_test
    ",True
1921,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_wrong_credentials,"def test_app_with_wrong_credentials(self):
        response = self.sync_post('/', self.body + 's')
        self.assert_status_in('Authentication failed.', json.loads(to_str(response.body))) # noqa

    ",True
1922,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_wrong_hostname_domain,"def test_app_with_wrong_hostname_domain(self):
        body = 'hostname=xxxxxxxxxxxx&port=2200&username=admin&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assertEqual(response.code, 200)
        self.assertIn(b'Unable to connect to', response.body)

    ",True
1923,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_wrong_hostname_ip,"def test_app_with_wrong_hostname_ip(self):
        body = 'hostname=127.0.0.2&port=2200&username=admin&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assertEqual(response.code, 200)
        self.assertIn(b'Unable to connect to', response.body)

    ",True
1924,https://github.com/huashengdun/webssh/blob/51d527fe75a62aed239126a6697749a30baecb30/tests/test_app.py,TestAppBasic,test_app_with_wrong_port,"def test_app_with_wrong_port(self):
        body = 'hostname=127.0.0.1&port=7000&username=admin&_xsrf=yummy'
        response = self.sync_post('/', body)
        self.assertEqual(response.code, 200)
        self.assertIn(b'Unable to connect to', response.body)

    ",True
1925,https://github.com/istommao/wechatkit/blob/e46341c29a69805a8e4c425dc620039fb06b1e45/tests/test_api.py,WechatAPITest,test_get_web_user_info_failure,"def test_get_web_user_info_failure(self):
        """"""Test get user info failure""""""

        access_token, openid = 'access_token', 'openid'
        result = WechatAPI.get_web_user_info(access_token, openid)
        self.assertIn('errmsg', result)
        self.assertIn('requrl', result)

    @patch('wechatkit.utils.RequestUtil.get')
    ",False
1926,https://github.com/Xarrow/weibo-scraper/blob/8d1ffc9060ae7ddba217093c23ab8111f9b351c8/test_weibo_scraper.py,TestWeiboScraper,test_get_weibo_tweets_by_name,"def test_get_weibo_tweets_by_name(self):
        result_iterator = weibo_scraper.get_weibo_tweets_by_name(name='嘻红豆', pages=1)
        for i in result_iterator:
            print(i)
        result_iterator2 = weibo_scraper.get_weibo_tweets_by_name(name='nicknameisnotexist', pages=1)
        for i in result_iterator2:
            print(i)

    ",False
1927,https://github.com/Xarrow/weibo-scraper/blob/8d1ffc9060ae7ddba217093c23ab8111f9b351c8/test_weibo_scraper.py,TestWeiboScraper,test_weibo_tweets_with_comments,"def test_weibo_tweets_with_comments(self):
        """"""weibo comments""""""
        for i in weibo_scraper.get_formatted_weibo_tweets_by_name(name='嘻红豆', with_comments=True, pages=1):
            for j in i.cards_node:
                print(str(j.mblog.comment_parser))


",False
1928,https://github.com/Zabamund/wellpathpy/blob/f29b14a9a1c46e77ea98b141e3cdc43674654ea2/wellpathpy/test/test_location.py,,test_wellhead,"def test_wellhead():
    # test well9
    well9_tvd, well9_northing, well9_easting, _ = minimum_curvature(well9_true_md_m, well9_true_inc, well9_true_azi)
    tvd, mN, mE = loc_to_wellhead(
        well9_tvd,
        well9_northing,
        well9_easting,
        well9_true_surface_northing,
        well9_true_surface_easting
        )
    np.testing.assert_equal(tvd, well9_tvd)
    np.testing.assert_allclose(mN, well9_true_northing, atol=1)
    np.testing.assert_allclose(mE, well9_true_easting, atol=1)
    # test well10
    well10_tvd, well10_northing, well10_easting, _ = minimum_curvature(well10_true_md_m, well10_true_inc, well10_true_azi)
    tvd, mN, mE = loc_to_wellhead(
        well10_tvd,
        well10_northing,
        well10_easting,
        well10_true_surface_northing,
        well10_true_surface_easting
        )
    np.testing.assert_equal(tvd, well10_tvd)
    np.testing.assert_allclose(mN, well10_true_northing, atol=1)
    np.testing.assert_allclose(mE, well10_true_easting, atol=1)

",True
1929,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_already_open_file,"def test_already_open_file(binary_file):
    """"""Test that wkr.open passes through files that are already open.""""""
    with open(binary_file, 'rb') as input_file:
        for mode in ['r', 'a', 'w', 'rb', 'ab', 'wb']:
            assert wkr.open(input_file, mode) is input_file


",False
1930,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_cannot_write_zip_file,"def test_cannot_write_zip_file(zip_file):
    """"""Test that wkr.open cannot write to zip files.""""""
    modes = ['w', 'a', 'wb', 'ab']
    for mode in modes:
        with pytest.raises(ValueError):
            _ = wkr.open('{}:file1.txt'.format(zip_file), mode)  # noqa f841


",False
1931,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_count_lines,"def test_count_lines(tmpdir, random_lines):
    """"""Test the wkr.count_lines method.""""""
    for num_lines in range(len(random_lines) + 1):
        filename = tmpdir.join('text.txt')
        assert not filename.exists()
        with open(filename.strpath, 'wb') as output_file:
            output_file.write(
                (u'\n'.join(random_lines[:num_lines]) + u'\n').encode('utf-8'))
        assert filename.exists()
        assert wkr.io.count_lines(filename.strpath) == max(num_lines, 1)
        filename.remove()
        assert not filename.exists()


",False
1932,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_lines_read,"def test_lines_read(text_file, random_lines):
    """"""Test the wkr.lines method on reading text files.""""""
    encoding = re.match(r'.+\.([^.]+)\.txt$', text_file).group(1)
    # read with string decoding
    expected_output = [line + u'\n' for line in random_lines]
    read_lines = list(wkr.lines(text_file, encoding))
    assert all(isinstance(x, text_type) for x in read_lines)
    assert read_lines == expected_output
    # try reading without string decoding
    expected_output = list(
        BytesIO((u'\n'.join(random_lines) + u'\n').encode(encoding)))
    read_lines = list(wkr.lines(text_file, None))
    assert all(isinstance(x, binary_type) for x in read_lines)
    assert read_lines == expected_output


",False
1933,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_lines_read,"def test_lines_read(text_file, random_lines):
    """"""Test the wkr.lines method on reading text files.""""""
    encoding = re.match(r'.+\.([^.]+)\.txt$', text_file).group(1)
    # read with string decoding
    expected_output = [line + u'\n' for line in random_lines]
    read_lines = list(wkr.lines(text_file, encoding))
    assert all(isinstance(x, text_type) for x in read_lines)
    assert read_lines == expected_output
    # try reading without string decoding
    expected_output = list(
        BytesIO((u'\n'.join(random_lines) + u'\n').encode(encoding)))
    read_lines = list(wkr.lines(text_file, None))
    assert all(isinstance(x, binary_type) for x in read_lines)
    assert read_lines == expected_output


",False
1934,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_lines_read,"def test_lines_read(text_file, random_lines):
    """"""Test the wkr.lines method on reading text files.""""""
    encoding = re.match(r'.+\.([^.]+)\.txt$', text_file).group(1)
    # read with string decoding
    expected_output = [line + u'\n' for line in random_lines]
    read_lines = list(wkr.lines(text_file, encoding))
    assert all(isinstance(x, text_type) for x in read_lines)
    assert read_lines == expected_output
    # try reading without string decoding
    expected_output = list(
        BytesIO((u'\n'.join(random_lines) + u'\n').encode(encoding)))
    read_lines = list(wkr.lines(text_file, None))
    assert all(isinstance(x, binary_type) for x in read_lines)
    assert read_lines == expected_output


",False
1935,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_lines_read,"def test_lines_read(text_file, random_lines):
    """"""Test the wkr.lines method on reading text files.""""""
    encoding = re.match(r'.+\.([^.]+)\.txt$', text_file).group(1)
    # read with string decoding
    expected_output = [line + u'\n' for line in random_lines]
    read_lines = list(wkr.lines(text_file, encoding))
    assert all(isinstance(x, text_type) for x in read_lines)
    assert read_lines == expected_output
    # try reading without string decoding
    expected_output = list(
        BytesIO((u'\n'.join(random_lines) + u'\n').encode(encoding)))
    read_lines = list(wkr.lines(text_file, None))
    assert all(isinstance(x, binary_type) for x in read_lines)
    assert read_lines == expected_output


",False
1936,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_lines_read,"def test_lines_read(text_file, random_lines):
    """"""Test the wkr.lines method on reading text files.""""""
    encoding = re.match(r'.+\.([^.]+)\.txt$', text_file).group(1)
    # read with string decoding
    expected_output = [line + u'\n' for line in random_lines]
    read_lines = list(wkr.lines(text_file, encoding))
    assert all(isinstance(x, text_type) for x in read_lines)
    assert read_lines == expected_output
    # try reading without string decoding
    expected_output = list(
        BytesIO((u'\n'.join(random_lines) + u'\n').encode(encoding)))
    read_lines = list(wkr.lines(text_file, None))
    assert all(isinstance(x, binary_type) for x in read_lines)
    assert read_lines == expected_output


",False
1937,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_lines_read,"def test_lines_read(text_file, random_lines):
    """"""Test the wkr.lines method on reading text files.""""""
    encoding = re.match(r'.+\.([^.]+)\.txt$', text_file).group(1)
    # read with string decoding
    expected_output = [line + u'\n' for line in random_lines]
    read_lines = list(wkr.lines(text_file, encoding))
    assert all(isinstance(x, text_type) for x in read_lines)
    assert read_lines == expected_output
    # try reading without string decoding
    expected_output = list(
        BytesIO((u'\n'.join(random_lines) + u'\n').encode(encoding)))
    read_lines = list(wkr.lines(text_file, None))
    assert all(isinstance(x, binary_type) for x in read_lines)
    assert read_lines == expected_output


",False
1938,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_lines_read,"def test_lines_read(text_file, random_lines):
    """"""Test the wkr.lines method on reading text files.""""""
    encoding = re.match(r'.+\.([^.]+)\.txt$', text_file).group(1)
    # read with string decoding
    expected_output = [line + u'\n' for line in random_lines]
    read_lines = list(wkr.lines(text_file, encoding))
    assert all(isinstance(x, text_type) for x in read_lines)
    assert read_lines == expected_output
    # try reading without string decoding
    expected_output = list(
        BytesIO((u'\n'.join(random_lines) + u'\n').encode(encoding)))
    read_lines = list(wkr.lines(text_file, None))
    assert all(isinstance(x, binary_type) for x in read_lines)
    assert read_lines == expected_output


",False
1939,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_lines_read_compressed,"def test_lines_read_compressed(tmpdir, random_lines):
    """"""Test that wkr.lines can read compressed files.""""""
    # make a compressed file
    path = tmpdir.join('text.gz').ensure().strpath
    with wkr.open(path, 'wb') as output_file:
        for line in random_lines:
            output_file.write(line.encode('utf-8') + b'\n')
    # now read it back in with wkr.lines()
    loaded_lines = list(wkr.lines(path))
    assert [[line.strip() for line in loaded_lines] == random_lines]


",False
1940,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_load_counter,"def test_load_counter(tmpdir):
    """"""Test the wkr.io.load_counter method.""""""
    for size in [0, 1, 10, 100, 1000]:
        # produce a Counter dictionary with random counts
        counter = Counter()
        for key in range(size):
            key = 'key{}'.format(key)
            count = random.randint(0, 10000)
            counter[key] = count
        assert len(counter) == size
        # write the counter out to file
        filename = tmpdir.join('counts.tsv').ensure().strpath
        with open(filename, 'wb') as output_file:
            for (key, count) in counter.items():
                output_file.write(
                    u'{}\t{}\n'.format(count, key).encode('utf-8'))
        # read it back in
        assert wkr.io.load_counter(filename) == counter


",False
1941,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_load_counter_2,"def test_load_counter_2(tmpdir):
    """"""Test the wkr.io.load_counter method.""""""
    # write the counter out to file
    filename = tmpdir.join('counts.tsv').ensure().strpath
    with open(filename, 'wb') as output_file:
        output_file.write(b'2\ta\n')
        output_file.write(b'4\tb\n')
        output_file.write(b'1\tc\n')
        output_file.write(b'3\ta\n')
    # read it back in
    assert wkr.io.load_counter(filename) == Counter('aabbbbcaaa')


",False
1942,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_load_counter_3,"def test_load_counter_3(tmpdir):
    """"""Test the wkr.io.load_counter method.""""""
    # write the counter out to file
    filename = tmpdir.join('counts.tsv').ensure().strpath
    with open(filename, 'wb') as output_file:
        output_file.write(b'2\ta\tb\n')
        output_file.write(b'4\tb\tb\n')
        output_file.write(b'1\tc\tb\n')
        output_file.write(b'3\ta\ta\n')
    # read it back in
    assert wkr.io.load_counter(filename) == Counter(dict([
        (('a', 'b'), 2),
        (('b', 'b'), 4),
        (('c', 'b'), 1),
        (('a', 'a'), 3),
    ]))
",False
1943,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_read_compressed_file,"def test_read_compressed_file(compressed_file):
    """"""Test that wkr.open can read compressed file formats.""""""
    with wkr.open(compressed_file, 'rb') as input_file:
        data = input_file.read()
        assert isinstance(data, binary_type)
        assert data == BINARY_DATA


",False
1944,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_read_compressed_file,"def test_read_compressed_file(compressed_file):
    """"""Test that wkr.open can read compressed file formats.""""""
    with wkr.open(compressed_file, 'rb') as input_file:
        data = input_file.read()
        assert isinstance(data, binary_type)
        assert data == BINARY_DATA


",False
1945,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_read_compressed_file,"def test_read_compressed_file(compressed_file):
    """"""Test that wkr.open can read compressed file formats.""""""
    with wkr.open(compressed_file, 'rb') as input_file:
        data = input_file.read()
        assert isinstance(data, binary_type)
        assert data == BINARY_DATA


",False
1946,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_read_zip_file,"def test_read_zip_file(zip_file):
    """"""Test that wkr.open can read zip files.""""""
    for num in range(1, 4):
        with wkr.open('{zip_file}:file{num}.txt'.format(
                zip_file=zip_file, num=num)) as input_file:
            contents = input_file.read()
            assert isinstance(contents, binary_type)
            contents = contents.split(b'\n')
            assert len(contents) == 2
            assert contents[0] == (u'line {}'.format(num)).encode('ascii')
            assert contents[1] == BINARY_DATA


",False
1947,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_write_compressed_file,"def test_write_compressed_file(compressed_file):
    """"""Test that wkr.open can write to compressed file formats.""""""
    contents = b'new file\n' + BINARY_DATA
    with wkr.open(compressed_file, 'wb') as output_file:
        output_file.write(contents)
    ext = os.path.splitext(compressed_file)[1]
    open_fn = {'.bin': open, '.xz': lzma.LZMAFile, '.gz': gzip.open}.get(ext)
    input_file = open_fn(compressed_file, 'rb')
    data = input_file.read()
    assert isinstance(data, binary_type)
    assert data == contents
    input_file.close()


",False
1948,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_write_compressed_file,"def test_write_compressed_file(compressed_file):
    """"""Test that wkr.open can write to compressed file formats.""""""
    contents = b'new file\n' + BINARY_DATA
    with wkr.open(compressed_file, 'wb') as output_file:
        output_file.write(contents)
    ext = os.path.splitext(compressed_file)[1]
    open_fn = {'.bin': open, '.xz': lzma.LZMAFile, '.gz': gzip.open}.get(ext)
    input_file = open_fn(compressed_file, 'rb')
    data = input_file.read()
    assert isinstance(data, binary_type)
    assert data == contents
    input_file.close()


",False
1949,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_io.py,,test_write_compressed_file,"def test_write_compressed_file(compressed_file):
    """"""Test that wkr.open can write to compressed file formats.""""""
    contents = b'new file\n' + BINARY_DATA
    with wkr.open(compressed_file, 'wb') as output_file:
        output_file.write(contents)
    ext = os.path.splitext(compressed_file)[1]
    open_fn = {'.bin': open, '.xz': lzma.LZMAFile, '.gz': gzip.open}.get(ext)
    input_file = open_fn(compressed_file, 'rb')
    data = input_file.read()
    assert isinstance(data, binary_type)
    assert data == contents
    input_file.close()


",False
1950,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_backup_file,"def test_backup_file(tmpdir, binary_file):
    """"""Test wkr.os.backup_file.""""""
    binary_path = tmpdir.__class__(binary_file)
    assert tmpdir.exists()
    assert binary_path.exists()
    assert binary_path.size()
    original_contents = binary_path.read(mode='rb')
    # backup file
    backup_path = binary_path.new(basename=binary_path.basename + '~')
    assert not backup_path.exists()
    # now do the backup
    backup_file(binary_file)
    # assert that the backup_path exists and that it contains the same
    # content as the original file
    assert binary_path.exists()
    assert binary_path.read(mode='rb') == original_contents
    assert backup_path.exists()
    assert backup_path.read(mode='rb') == original_contents


",False
1951,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_backup_file_exists,"def test_backup_file_exists(tmpdir, binary_file):
    """"""Test wkr.os.backup_file where the backup file already exists.""""""
    binary_path = tmpdir.__class__(binary_file)
    # create the backup file and put something in it
    backup_path = binary_path.new(basename=binary_path.basename + '~')
    original_contents = b'abcde'
    backup_path.ensure().write(original_contents)
    # now do the backup
    backup_file(binary_file)
    # assert that the backup_path exists and that it contains the same
    # content as the original file
    assert backup_path.read(mode='rb') != original_contents
    assert backup_path.read(mode='rb') == binary_path.read(mode='rb')


",False
1952,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_mkdir_p_double,"def test_mkdir_p_double(tmpdir):
    """"""Test mkdir_p on creating two directories.""""""
    path1 = tmpdir.join('newdir2')
    assert not path1.exists()
    path2 = path1.join('subdir')
    assert not path2.exists()
    mkdir_p(path2.strpath)
    assert path1.exists()
    assert path2.exists()


",False
1953,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_mkdir_p_exists,"def test_mkdir_p_exists(tmpdir):
    """"""Test mkdir_p on creating a directory that already exists.""""""
    path = tmpdir.join('newdir').ensure(dir=True)
    assert path.exists()
    assert path.isdir()
    mkdir_p(path.strpath)  # should not throw an exception


",False
1954,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_mkdir_p_single,"def test_mkdir_p_single(tmpdir):
    """"""Test mkdir_p on creating a single directory.""""""
    path = tmpdir.join('newdir')
    assert not path.exists()
    mkdir_p(path.strpath)
    assert path.exists()


",False
1955,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_momentary_chdir,"def test_momentary_chdir(tmpdir):
    """"""Test wkr.os.momentary_chdir.""""""
    start_dir = os.getcwd()
    with momentary_chdir(tmpdir.strpath):
        new_dir = os.getcwd()
        assert new_dir != start_dir
        assert new_dir == tmpdir.strpath
    assert os.getcwd() == start_dir


",False
1956,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_momentary_chdir_fail,"def test_momentary_chdir_fail(tmpdir):
    """"""Test wkr.os.momentary_chdir.""""""
    start_dir = os.getcwd()
    path = tmpdir.join('newdir')
    assert not path.exists()
    with pytest.raises(OSError):
        with momentary_chdir(path.strpath):
            # this is never executed
            assert False
    assert os.getcwd() == start_dir
",False
1957,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_open_atomic,"def test_open_atomic(tmpdir, binary_file):
    """"""Test wkr.os.open_atomic.""""""
    binary_path = tmpdir.__class__(binary_file)
    assert tmpdir.exists()
    assert binary_path.exists()
    assert binary_path.size() > 0
    original_contents = binary_path.read(mode='rb')
    # now we do an atomic write on binary_file
    with open_atomic(binary_file, fsync=True) as output_file:
        new_contents = b'abcde'
        assert new_contents != original_contents
        output_file.write(new_contents)
        output_file.flush()
        # at this point the original file still hasn't changed
        assert binary_path.read(mode='rb') == original_contents
    # now we close the file, and it's atomically moved into its final
    # location
    assert binary_path.read(mode='rb') == new_contents


",False
1958,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_temp_file_name,"def test_temp_file_name(tmpdir, tmpdir_suffix):
    """"""Basic test of wkr.os.temp_file_name.""""""
    # directory is empty
    assert not tmpdir.listdir()
    with temp_file_name(suffix=tmpdir_suffix,
                        directory=tmpdir.strpath) as newpath:
        assert newpath.endswith(tmpdir_suffix)
        # either the directory is empty and the file is not there, or
        # it is there and the directory is not empty, but the file is
        # empty
        assert ((not tmpdir.listdir() and not os.path.exists(newpath)) or (
            tmpdir.listdir() and
            os.path.exists(newpath) and
            not os.stat(newpath).st_size))
        # we should be able to write to the file
        output_file = open(newpath, 'wb')
        output_file.write(b'abcde')
        output_file.close()
        # now the file should be there
        assert tmpdir.listdir()
        assert os.path.exists(newpath)
        assert os.stat(newpath).st_size > 0
    # directory is empty
    assert not tmpdir.listdir()


",False
1959,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_temp_file_name_delete,"def test_temp_file_name_delete(tmpdir):
    """"""Test wkr.os.temp_file_name where we manually delete the tmpfile.""""""
    with temp_file_name(directory=tmpdir.strpath) as newpath:
        # write to the file
        with open(newpath, 'wb') as output_file:
            output_file.write(b'abcde')
        # delete the file
        os.remove(newpath)
    # should not raise an exception


",False
1960,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_os.py,,test_write_atomic,"def test_write_atomic(tmpdir, binary_file):
    """"""Test wkr.os.write_atomic.""""""
    binary_path = tmpdir.__class__(binary_file)
    assert tmpdir.exists()
    assert binary_path.exists()
    assert binary_path.size() > 0
    original_contents = binary_path.read(mode='rb')
    # backup file
    backup_path = binary_path.new(basename=binary_path.basename + '~')
    assert not backup_path.exists()
    # now do the atomic write
    new_contents = b'abcde'
    assert new_contents != original_contents
    write_atomic([new_contents], binary_file)
    # assert that the backup_path exists and that it contains the same
    # content as the original file
    assert backup_path.exists()
    assert backup_path.read(mode='rb') == original_contents
    # assert that the original file exists, with different contents
    assert binary_path.exists()
    assert binary_path.read(mode='rb') == new_contents


",False
1961,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_pd.py,,test_memoize_pandas_parse_dates,"def test_memoize_pandas_parse_dates(tmpdir):
    """"""Test `wkr.pd.memoize_pandas` on loading datetimes.""""""
    filename = tmpdir.join('data.csv')

    @pandas_memoize(filename.strpath)
    ",False
1962,https://github.com/wroberts/wkr.py/blob/dbb3c1742c10bfaf697fa276d2cc8885e144ab43/tests/test_pd.py,,test_memoize_pandas_save,"def test_memoize_pandas_save(tmpdir):
    """"""Test that `wkr.pd.memoize_pandas` saves to CSV.""""""
    for idx, df in enumerate(dataframe_gen()):
        filename = tmpdir.join('data{}.csv'.format(idx))

        @pandas_memoize(filename.strpath)
        ",False
1963,https://github.com/aitgon/wopmars/blob/33680f94163d82ce43557cf7f87a5f9ead496fdc/wopmars/tests/test_wopmars.py,TestWopmars,test_dry_run,"def test_dry_run(self):
        cmd_line = [""python"", ""--dry-run"", ""-D"", self.__db_url, ""-w"", self.__example_def_file1, ""-v"", ""-d"",
                    self.test_path]
        with self.assertRaises(SystemExit) as se:
            WopMars().run(cmd_line)
        # The tests is that these files do not exist
        self.assertFalse(os.path.exists(os.path.join(self.test_path, 'outdir/output_file1.txt')))
        self.assertFalse(os.path.exists(os.path.join(self.test_path, 'outdir/output_file2.txt')))
        self.assertFalse(os.path.exists(os.path.join(self.test_path, 'outdir/output_file7.txt')))
        self.assertEqual(se.exception.code, 0)

    ",True
1964,https://github.com/aitgon/wopmars/blob/33680f94163d82ce43557cf7f87a5f9ead496fdc/wopmars/tests/test_wopmars.py,TestWopmars,test_run_rerun_runtime,"def test_run_rerun_runtime(self):

        # Slow run
        cmd_line = [""python"", ""-D"", self.__db_url, ""-w"", self.__example_def_file1, ""-v""]
        time_unix_ms, time_human = get_current_time()
        start = time_unix_ms
        with self.assertRaises(SystemExit):
            WopMars().run(cmd_line)
        time_unix_ms, time_human = get_current_time()
        end = time_unix_ms
        runtime1 = end - start

        # Fast run run2<run1
        time_unix_ms, time_human = get_current_time()
        start = time_unix_ms
        with self.assertRaises(SystemExit):
            WopMars().run(cmd_line)
        time_unix_ms, time_human = get_current_time()
        end = time_unix_ms
        runtime2 = end - start
        self.assertGreater(runtime1 * 1.5, runtime2)

        # Middle run: run3>run2
        PathManager.unlink(""outdir/output_file1.txt"")
        time_unix_ms, time_human = get_current_time()
        start = time_unix_ms
        with self.assertRaises(SystemExit):
            WopMars().run(cmd_line)
        time_unix_ms, time_human = get_current_time()
        end = time_unix_ms
        runtime3 = end - start
        self.assertLess(runtime2, runtime3)

    ",False
1965,https://github.com/aitgon/wopmars/blob/33680f94163d82ce43557cf7f87a5f9ead496fdc/wopmars/tests/test_wopmars.py,TestWopmars,test_run_sourcerule_fail,"def test_run_sourcerule_fail(self):
        cmd_line = [""python"", ""-D"", self.__db_url, ""-w"", self.__example_def_file1, ""-v"", ""--since"", ""failure""]
        with self.assertRaises(SystemExit) as se:
            WopMars().run(cmd_line)
        self.assertFalse(os.path.exists(os.path.join(self.test_path, 'outdir/output_file1.txt')))
        self.assertEqual(se.exception.code, 1)

    ",False
1966,https://github.com/mtik00/yamicache/blob/1109d08b18be94bdee55e113309f7be29f25d840/tests/test_class.py,,test_cached,"def test_cached(cache_obj):
    for _ in range(10):
        cache_obj.test1(8, 0)

    assert len(c) == 1
    assert cache_obj.test1(8, 0) == 1

    for _ in range(10):
        cache_obj.test2()

    assert cache_obj.test2() == 1
    assert len(c) == 2

    c.clear()
    assert len(c) == 0

    # Make sure the cached function is properly wrapped
    assert cache_obj.test2.__doc__ == 'running test2'


",True
1967,https://github.com/mtik00/yamicache/blob/1109d08b18be94bdee55e113309f7be29f25d840/tests/test_class.py,,test_keyed_cached,"def test_keyed_cached(cache_obj):
    for _ in range(10):
        cache_obj.test3(8, 0)

    cache_obj.test4()  # Shouldn't be cached

    assert len(c) == 1

    key = list(c.keys())[0]
    assert key == 'asdf'

    c.clear()
    assert len(c) == 0

    # Make sure the cached function is properly wrapped
    assert cache_obj.test3.__doc__ == 'running test3'


",True
1968,https://github.com/mtik00/yamicache/blob/1109d08b18be94bdee55e113309f7be29f25d840/tests/test_class.py,,test_utility,"def test_utility(cache_obj):
    for _ in range(10):
        cache_obj.test1(8, 0)
        cache_obj.test1(8, 2)
        cache_obj.test1(8, 2)  # Already cached
        cache_obj.test2()
        cache_obj.test3(8, 2)

    assert len(c) == 4

    assert c.dump() != '{}'

    key = list(c.keys())[0]
    c.pop(key)
    assert len(c) == 3
    assert key not in c

    assert len(c.keys()) == 3
    assert len(c.values()) == 3

    assert c.items()

    c.clear()

    assert not c.items()
    assert not c.keys()
    assert not c.values()
    assert not len(c)
    assert c.dump() == '{}'


",True
1969,https://github.com/mtik00/yamicache/blob/1109d08b18be94bdee55e113309f7be29f25d840/tests/test_gc.py,,test_deco_timeout,"def test_deco_timeout(cache_obj):
    '''Test custom decorator timeout'''
    c.clear()

    # Cache the result, which should use a 2s timeout, as opposed to the
    # default of 1s.
    tstart = time.time()
    cache_obj.test2()

    # Wait up to 5s for the GC thread to clear `test2()`.
    while len(c) and ((time.time() - tstart) < 5):
        time.sleep(0.1)  # Give GC a chance to run

    tend = time.time()

    # The defined timeout is 2, and gc_thread_wait is 0.5, so the max we
    # should really be waiting is 2.5 (ish).  The mininum is 2-ish.
    # NOTE: I've had a hell of time with duration variance on Travis-CI, which
    # is why the range is so big.
    time_diff = tend - tstart
    print('actual time: %s' % time_diff)
    assert 1.4 < time_diff < 3.5


",True
1970,https://github.com/mtik00/yamicache/blob/1109d08b18be94bdee55e113309f7be29f25d840/tests/test_noclass.py,,test_main,"def test_main():
    assert len(c) == 0

    for _ in [0, 1, 2, 3, 4, 5]:
        my_func(2, 3)

    assert len(c) == 1


",True
1971,https://github.com/notsag/yaml-resume/blob/25ad6695993a7dab540730e8743d88b28e52df0e/tests/test_cli.py,,test_validate,"def test_validate():
    """"""
    SCENARIO_VALID should validate
    """"""
    runner = CliRunner()
    result = runner.invoke(cli, [""validate"", SCENARIO_VALID[""file""]])
    if result.output != """":
        logging.error(result.output)
    assert result.exit_code == 0


@pytest.mark.xfail(raises=ClickException)
",False
1972,https://github.com/loganasherjones/yapconf/blob/f685ed6a6f532a8f836deb205fc2509e9422329b/tests/spec_test.py,,test_watchers,"def test_watchers(real_world_spec, label):
    original_data = {
        'database': {
            'host': '1.2.3.4',
            'name': 'myapp_prod',
            'port': 3307,
            'verbose': False,
        },
        'emoji': u'💩',
        'file': '/path/to/file.yaml',
        'ssl': {
            'private_key': 'blah',
            'public_key': 'blah',
        },
        'web_port': 443,
    }
    safe_data = copy.deepcopy(original_data)
    flags = {'overall': True, 'individual': True}
    real_world_path = os.path.join(current_dir, 'files', 'real_world')

    ",False
1973,https://github.com/loganasherjones/yapconf/blob/f685ed6a6f532a8f836deb205fc2509e9422329b/tests/spec_test.py,,test_watchers,"def test_watchers(real_world_spec, label):
    original_data = {
        'database': {
            'host': '1.2.3.4',
            'name': 'myapp_prod',
            'port': 3307,
            'verbose': False,
        },
        'emoji': u'💩',
        'file': '/path/to/file.yaml',
        'ssl': {
            'private_key': 'blah',
            'public_key': 'blah',
        },
        'web_port': 443,
    }
    safe_data = copy.deepcopy(original_data)
    flags = {'overall': True, 'individual': True}
    real_world_path = os.path.join(current_dir, 'files', 'real_world')

    ",False
1974,https://github.com/dreid/yunomi/blob/1aa3f166843613331b38e231264ffc3ac40e8094/yunomi/tests/test_metrics_registry.py,MetricsRegistryTests,test_count_calls_decorator,"def test_count_calls_decorator(self):
        @count_calls
        ",True
1975,https://github.com/dreid/yunomi/blob/1aa3f166843613331b38e231264ffc3ac40e8094/yunomi/tests/test_metrics_registry.py,MetricsRegistryTests,test_hist_calls_decorator,"def test_hist_calls_decorator(self):
        @hist_calls
        ",True
1976,https://github.com/dreid/yunomi/blob/1aa3f166843613331b38e231264ffc3ac40e8094/yunomi/tests/test_metrics_registry.py,MetricsRegistryTests,test_meter_calls_decorator,"def test_meter_calls_decorator(self, time_mock):
        time_mock.return_value = 0
        @meter_calls
        ",True
1977,https://github.com/dreid/yunomi/blob/1aa3f166843613331b38e231264ffc3ac40e8094/yunomi/tests/test_metrics_registry.py,MetricsRegistryTests,test_time_calls_decorator,"def test_time_calls_decorator(self, time_mock):
        time_mock.return_value = 0.0
        @time_calls
        ",True
1978,https://github.com/MirkoRossini/zanna/blob/4c28b5ea3940fba69bee3fdf965a039c9b8f45c5/tests/test_decorators.py,TestDecorators,test_class_decorated,"def test_class_decorated(self):
        inj = Injector(use_decorators=True)
        otherthing = inj.get_instance(OtherThing)
        assert otherthing.value == 3
        assert isinstance(otherthing.thing, Thing)
        assert isinstance(otherthing, OtherThing)
",True
1979,https://github.com/MirkoRossini/zanna/blob/4c28b5ea3940fba69bee3fdf965a039c9b8f45c5/tests/test_decorators.py,TestDecorators,test_provider_decorated,"def test_provider_decorated_needs_type_or_name(self):
        with pytest.raises(TypeError):
            @decorators.provider
            ",True
